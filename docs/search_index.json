[
["index.html", "R, Databases, and Docker Chapter 1 Introduction 1.1 Using R to query a DBMS in your organization 1.2 Docker as a tool for UseRs 1.3 Who are we? 1.4 How did this project come about? 1.5 Navigation", " R, Databases, and Docker John David Smith, Sophie Yang, M. Edward (Ed) Borasky, Jim Tyhurst, Scott Came, Mary Anne Thygesen, Ian Frantz, and Dipti Muni 2019-02-17 Chapter 1 Introduction This chapter introduces: The motivation for this book and the strategies we have adopted How Docker can be used to set up a dbms to demonstrate access to a service like PostgreSQL from R Our team and how this project came about 1.1 Using R to query a DBMS in your organization Many R users (or useRs) live a dual life: in the vibrant open-source R community where R is created, improved, discussed, and taught. And then they go to work in a secured, complex, closed organizational environment where they may be on their own. Here is a request on the Rstudio community site for help that has been lightly edited to emphasize the generality that we see: I’m trying to migrate some inherited scripts that […] to connect to a […] database to […] instead. I’ve reviewed the https://db.rstudio.com docs and tried a number of configurations but haven’t been able to connect. I’m in uncharted territory within my org, so haven’t been able to get much help internally. This book will help you create a hybrid environment on your machine that can mimic some of the uncharted territory in your organization. It goes far beyond the basic connection issues and covers issues that you face when you are finding your way around or writing queries to your organization’s databases, not just when maintaining inherited scripts. Technology hurdles. The interfaces (passwords, packages, etc.) and gaps between R and a back end database are hidden from public view as a matter of security, so pinpointing exactly where a problem is can be difficult. A simulated environment such as we offer here can be an important learning resource. Scale issues. We see at least two types of scale issues. Handling large volumes of data so that performance issues must be a consideration requires a basic understanding of what’s happening in “the back end” (which is necessarily hidden from view). Therefore mastering techniques for drawing samples or small batches of data are essential. In addition to their size, your organization’s databases will often have structural characteristics that are complex and obscure. Data documentation is often incomplete and emphasizes operational characteristics, rather than analytic opportunities. A careful useR often needs to confirm the documentation on the fly and de-normalize data carefully. Use cases. R users frequently need to make sense of an organization’s complex data structures and coding schemes to address incompletely formed questions so that informal exploratory data analysis has to be intuitive and fast. The technology details should not get in the way. Sharing and discussing exploratory and diagnostic retrieval techniquesis best in public, but is constrained by organizational requirements. We have found that PostgreSQL in a Docker container solves many of the foregoing problems. 1.2 Docker as a tool for UseRs Noam Ross’s “Docker for the UseR” (Ross 2018a) suggests that there are four distinct Docker use-cases for useRs. Make a fixed working environment for reproducible analysis Access a service outside of R (e.g., PostgreSQL) Create an R based service (e.g., with plumber) Send our compute jobs to the cloud with minimal reconfiguration or revision This book explores #2 because it allows us to work on the database access issues described above and to practice on an industrial-scale DBMS. Docker is a comparatively easy way to simulate the relationship between an R/RStudio session and a database – all on on your machine (provided you have Docker installed and running). Running PostgreSQL on a Docker container avoids OS or system dependencies or conflicts that cause confusion and limit reproducibility. A Docker environment consumes relatively few resources. Our sandbox does much less but only includes PostgreSQL and sample data, so it takes up about 5% of the space taken up by the Vagrant environment that inspired this project. (Makubuya 2018) A simple Docker container such as the one used in our sandbox is easy to use and could be extended for other uses. Docker is a widely used technology for deploying applications in the cloud, so for many useRs it’s worth mastering. 1.3 Who are we? We have been collaborating on this book since the Summer of 2018, each of us chipping into the project as time permits: Dipti Muni - @deemuni Ian Franz - @ianfrantz Jim Tyhurst - @jimtyhurst John David Smith - @smithjd M. Edward (Ed) Borasky - @znmeb Maryanne Thygesen @maryannet Scott Came - @scottcame Sophie Yang - @SophieMYang 1.4 How did this project come about? We trace this book back to the June 2, 2018 Cascadia R Conf where Aaron Makubuya gave a presentation using Vagrant hosting (Makubuya 2018). After that John Smith, Ian Franz, and Sophie Yang had discussions after the monthly Data Discussion Meetups about the difficulties around setting up Vagrant (a virtual environment), connecting to a corporate database, and having realistic public environment to demo or practice the issues that come up behind corporate firewalls. Scott Came’s tutorial on R and Docker (Came 2018) (an alternative to Vagrant) at the 2018 UseR Conference in Melbourne was provocative and it turned out he lived nearby. We re-connected with M. Edward (Ed) Borasky who had done extensive development for a Hack Oregon data science containerization project (Borasky 2018). 1.5 Navigation If this is the first bookdown (Xie 2016) book you’ve read, here’s how to navigate the website. The controls on the upper left: there are four controls on the upper left. A “hamburger” menu: this toggles the table of contents on the left side of the page on or off. A magnifying glass: this toggles a search box on or off. A letter “A”: this lets you pick how you want the site to display. You have your choice of small or large text, a serif or sans-serif font, and a white, sepia or night theme. A pencil: this is the “Edit” button. This will take you to a GitHub edit dialog for the chapter you’re reading. If you’re a committer to the repository, you’ll be able to edit the source directly. If not, GitHub will fork a copy of the repository to your own account and you’ll be able to edit that version. Then you can make a pull request. The share buttons in the upper right hand corner. There’s one for Twitter, one for Facebook, and one that gives a menu of options, including LinkedIn. References "],
["chapter-basic-concepts.html", "Chapter 2 Basic Concepts 2.1 The big picture: R and the Docker / PostgreSQL playground on your machine 2.2 Your computer and its operating system 2.3 R 2.4 Docker 2.5 ‘Normal’ and ‘normalized’ data 2.6 Organizational dbms 2.7 SQL", " Chapter 2 Basic Concepts This chapter introduces: The overall structure of our Docker-based PostgreSQL sandbox Basic concepts around each of the elements that make up our sandbox: tidy data, pipes, Docker, PostgreSQL, and data representation. 2.1 The big picture: R and the Docker / PostgreSQL playground on your machine Here is an overview of how R and Docker fit on your operating system in this book’s sandbox: R and Docker You run R from RStudio to set up Docker, launch PostgreSQL inside it and then send queries directly to PostgreSQL from R. (We provide more details about our sandbox environment in the chapter on mapping your environment. 2.2 Your computer and its operating system The playground that we construct in this book is designed so that some of the mysteries of accessing a corporate database are more visible – it’s all happenning on your computer. The challenge, however, is that we know very little about your computer and its operating system. In the workshops we’ve given about this book, the details of individual computers have turned out to be diverse and difficult to pin down in advance. So there can be many issues, but not many basic concepts that we can highlight in advance. 2.3 R We assume a general familiarity with R and RStudio. RStudio’s Big Data workshop at the 2019 RStudio has an abundance of introductory material (Ruiz 2019). This book is Tidyverse-oriented, so we assume familiarity with the pipe operator, tidy data (Wickham 2014), dplyr, and techniques for tidying data (Wickham 2018). R connects to a database by means of a series of packages that work together. The follwing diagram from a big data workshop at the 2019 RStudio conference shows the big picture. The biggest difference in terms of retrieval strategies is between writing dplyr and native SQL code. Dplyr generates SQL-92 standard code; whereas you can write SQL code that leverages the specific language features of your dbms when you write SQL code yourself. Rstudio’s DBMS architecture - slide # 33 2.4 Docker Docker and the DevOps tools surrounding it have fostered a revolution in the way services are delivered over the internet. In this book, we’re piggybacking on a small piece of that revolution, Docker on the desktop. 2.4.1 Virtual machines and hypervisors A virtual machine is a machine that is running purely as software hosted by another real machine. To the user, a virtual machine looks just like a real one. But it has no processors, memory or I/O devices of its own - all of those are supplied and managed by the host. A virtual machine can run any operating system that will run on the host’s hardware. A Linux host can run a Windows virtual machine and vice versa. A hypervisor is the component of the host system software that manages virtual machines, usually called guests. Linux systems have a native hypervisor called Kernel Virtual Machine (kvm). And laptop, desktop and server processors from Intel and Advanced Micro Devices (AMD) have hardware that makes this hypervisor more efficient. Windows servers and Windows 10 Pro have a hypervisor called Hyper-V. Like kvm, Hyper-V can take advantage of the hardware in Intel and AMD processors. On Macintosh, there is a Hypervisor Framework (https://developer.apple.com/documentation/hypervisor) and other tools build on that. If this book is about Docker, why do we care about virtual machines and hypervisors? Docker is a Linux subsystem - it only runs on Linux laptops, desktops and servers. As we’ll see shortly, if we want to run Docker on Windows or MacOS, we’ll need a hypervisor, a Linux virtual machine and some “glue logic” to provide a Docker user experience equivalent to the one on a Linux system. 2.4.2 Containers A container is a set of processes running in an operating system. The host operating system is usually Linux, but other operating systems also can host containers. Unlike a virtual machine, the container has no operating system kernel of its own. If the host is running the Linux kernel, so is the container. And since the container OS is the same as the host OS, there’s no need for a hypervisor or hardware to support the hypervisor. So a container is more efficient than a virtual machine. A container does have its own filesystem. From inside the container, this filesystem looks like a Linux filesystem, but it can use any Linux distro. For example, you can have an Ubuntu 18.04 LTS host running Ubuntu 14.04 LTS or Fedora 28 or CentOS 7 containers. The kernel will always be the host kernel, but the utilities and applications will be those from the container. 2.4.3 Docker itself While there are both older (lxc) and newer container tools, the one that has caught on in terms of widespread use is Docker (Docker 2019a). Docker is widely used on cloud providers to deploy services of all kinds. Using Docker on the desktop to deliver standardized packages, as we are doing in this book, is a secondary use case, but a common one. If you’re using a Linux laptop / desktop, all you need to do is install Docker CE (Docker 2018a). However, most laptops and desktops don’t run Linux - they run Windows or MacOS. As noted above, to use Docker on Windows or MacOS, you need a hypervisor and a Linux virtual machine. 2.4.4 Docker objects The Docker subsystem manages several kinds of objects - containers, images, volumes and networks. In this book, we are only using the basic command line tools to manage containers, images and volumes. Docker images are files that define a container’s initial filesystem. You can find pre-built images on Docker Hub and the Docker Store - the base PostgreSQL image we use comes from Docker Hub (https://hub.docker.com/_/postgres/). If there isn’t a Docker image that does exactly what you want, you can build your own by creating a Dockerfile and running docker build. We do this in Build the pet-sql Docker Image. Docker volumes – explain mount. 2.4.5 Hosting Docker on Windows machines There are two ways to get Docker on Windows. For Windows 10 Home and older versions of Windows, you need Docker Toolbox (Docker 2019e). Note that for Docker Toolbox, you need a 64-bit AMD or Intel processor with the virtualization hardware installed and enabled in the BIOS. For Windows 10 Pro, you have the Hyper-V virtualizer as standard equipment, and can use Docker for Windows (Docker 2019c). 2.4.6 Hosting Docker on macOS machines As with Windows, there are two ways to get Docker. For older Intel systems, you’ll need Docker Toolbox (Docker 2019d). Newer systems (2010 or later running at least macOS El Capitan 10.11) can run Docker for Mac (Docker 2019b). 2.4.7 Hosting Docker on UNIX machines Unix was the original host for both R and Docker. Unix-like commands show up. 2.5 ‘Normal’ and ‘normalized’ data 2.5.1 Tidy data Tidy data (Wickham 2014) is well behaved from the point of view of analysis and tools in the Tidyverse (RStudio 2019). Tidy data is easier to think about and it is usually worthwhile to make the data tidy (Wickham 2018). Tidy data is roughly equivalent to third normal form as discussed below. 2.5.2 Design of “normal data” Data in a database is most often optimized to minimize storage space and increase performance while preserving integrity when adding, changing, or deleting data. The Wikipedia article on Database Normalization has a good introduction to the characteristics of “normal” data and the process of re-organizing it to meet those desirable criteria (Wikipedia 2019). The bottom line is that “data normalization is practical” although there are mathematical arguments for normalization based on the preservation of data integrity. 2.6 Organizational dbms The organizational context of a database matters just as much as its design characteristics. The design of a database (or data model) may have been purchased from an external vendor or developed in-house. In either case time has a tendency to erode the original design concept so that the data you find in a dbms may not quite match the original design specification. And the original design may or may not be well reflected in the current naming of tables, columns and other objects. It’s a naive misconception to think that the data you are analyzing “comes from the database” even though you are retrieving it from your organization’s dbms. In fact it comes from the people who design, enter, manage, protect, and use your organization’s data. In practice, a database administrator (DBA) is often a key point of contact in terms of access and may have stringent criteria for query performance. Make friends with your DBA. 2.7 SQL Although there are ANSI standards for SQL syntax, different implementations vary in enough details that R’s ability to customize queries for those implementations is very helpful. The tables in a dbms correspond to a data frame in R, so interaction with a dbms is fairly natural for useRs. SQL code is characterized by the fact that it describes what to retrieve, leaving the dbms back end to determine how to do it. Therefore it has a batch feel. The pipe operator (%&gt;%, which is read as and then) is inherently procedural when it’s used with dplyr: it can be used to construct queries step-by-step. Once a test dplyr query has been executed, it is easy to inspect the results and add steps with the pipe operator to refine or expand the query. APPENDIX D - Quick Guide to SQL lists the different elements of the SQL language. 2.7.1 Data mapping between R vs SQL data types The following code shows how different elements of the R bestiary are translated to and from ANSI standard data types. Note that R factors are translated as TEXT so that missing levels are ignored on the SQL side. library(DBI) example(dbDataType, package = &quot;DBI&quot;) ## ## dbDtTy&gt; dbDataType(ANSI(), 1:5) ## [1] &quot;INT&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), 1) ## [1] &quot;DOUBLE&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), TRUE) ## [1] &quot;SMALLINT&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), Sys.Date()) ## [1] &quot;DATE&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), Sys.time()) ## [1] &quot;TIMESTAMP&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), Sys.time() - as.POSIXct(Sys.Date())) ## [1] &quot;TIME&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), c(&quot;x&quot;, &quot;abc&quot;)) ## [1] &quot;TEXT&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), list(raw(10), raw(20))) ## [1] &quot;BLOB&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), I(3)) ## [1] &quot;DOUBLE&quot; ## ## dbDtTy&gt; dbDataType(ANSI(), iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;TEXT&quot; ## ## dbDtTy&gt; con &lt;- dbConnect(RSQLite::SQLite(), &quot;:memory:&quot;) ## ## dbDtTy&gt; dbDataType(con, 1:5) ## [1] &quot;INTEGER&quot; ## ## dbDtTy&gt; dbDataType(con, 1) ## [1] &quot;REAL&quot; ## ## dbDtTy&gt; dbDataType(con, TRUE) ## [1] &quot;INTEGER&quot; ## ## dbDtTy&gt; dbDataType(con, Sys.Date()) ## [1] &quot;REAL&quot; ## ## dbDtTy&gt; dbDataType(con, Sys.time()) ## [1] &quot;REAL&quot; ## ## dbDtTy&gt; dbDataType(con, Sys.time() - as.POSIXct(Sys.Date())) ## [1] &quot;REAL&quot; ## ## dbDtTy&gt; dbDataType(con, c(&quot;x&quot;, &quot;abc&quot;)) ## [1] &quot;TEXT&quot; ## ## dbDtTy&gt; dbDataType(con, list(raw(10), raw(20))) ## [1] &quot;BLOB&quot; ## ## dbDtTy&gt; dbDataType(con, I(3)) ## [1] &quot;REAL&quot; ## ## dbDtTy&gt; dbDataType(con, iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;TEXT&quot; ## ## dbDtTy&gt; dbDisconnect(con) The DBI specification provides extensive documentation that is worth digesting if you intend to work with a dbms from R. As you work through the examples in this book, you will also want to refer to the following resources: RStudio’s Databases using R site describes many of the technical details involved. The RStudio community is an excellent place to ask questions or study what has been discussed previously. 2.7.2 PostgreSQL and connection parameters An important detail: We use a PostgreSQL database server running in a Docker container for the database functions. It is installed inside Docker, so you do not have to download or install it yourself. To connect to it, you have to define some parameters. These parameters are used in two places: When the Docker container is created, they’re used to initialize the database, and Whenever we connect to the database, we need to specify them to authenticate. We define the parameters in an environment file that R reads when starting up. The file is called .Renviron, and is located in your home directory. See the discussion of securing and using dbms credentials. References "],
["chapter-how-to-use-this-book.html", "Chapter 3 How to use this book 3.1 Retrieve the code from GitHub 3.2 Read along, experiment as you go 3.3 Participating", " Chapter 3 How to use this book This chapter explains: Getting the code used in this book How you can contribute to the book project This book is full of examples that you can replicate on your computer. 3.1 Retrieve the code from GitHub The code to generate the book and the exercises it contains can be downloaded from this repo. 3.2 Read along, experiment as you go We have never been sure whether we’re writing an expository book or a massive tutorial. You may use it either way. The best way to learn the material we cover is to experiment. After the introductory chapters and the chapter that creates the persistent database, you can jump around and each chapter stands on its own. 3.3 Participating 3.3.1 Browsing the book If you just want to read the book and copy / paste code into your working environment, simply browse to https://smithjd.github.io/sql-pet. If you get stuck, or find things aren’t working, open an issue at https://github.com/smithjd/sql-pet/issues/new/. 3.3.2 Diving in If you want to experiment with the code in the book, run it in RStudio and interact with it, you’ll need to do two more things: Install the sqlpetr R package (Borasky et al. 2018). See https://smithjd.github.io/sqlpetr for the package documentation. Installation may take some time if it has to install or update packages not available on your computer. Clone the Git repository https://github.com/smithjd/sql-pet.git and open the project file sql-pet.Rproj in RStudio. Enjoy! References "],
["chapter-learning-goals.html", "Chapter 4 Learning Goals and Use Cases 4.1 Ask yourself, what are you aiming for? 4.2 Learning Goals 4.3 Imagining a DVD rental business 4.4 Use cases 4.5 Investigating a question using an organization’s database", " Chapter 4 Learning Goals and Use Cases This chapter sets the context for the book by: Challenging you to think about your goals and expectations Imagining the setting where our sample database would be used Posing some imaginary use cases that a data analyst might face Discussing the different elements involved in answering questions from an organization’s database 4.1 Ask yourself, what are you aiming for? Differences between production and data warehouse environments. Learning to keep your DBAs happy: You are your own DBA in this simulation, so you can wreak havoc and learn from it, but you can learn to be DBA-friendly here. In the end it’s the subject-matter experts that understand your data, but you have to work with your DBAs first. 4.2 Learning Goals After working through the code in this book, you can expect to be able to: Set up a PostgreSQL database in a Docker environment. Gain familiarity with the various ways of interacting with the Docker and PostgreSQL environments Run queries against PostgreSQL in an environment that simulates what you will find in a corporate setting. Understand techniques and some of the trade-offs between: queries aimed at exploration or informal investigation using dplyr (Wickham 2018); and queries that should be written in SQL, because performance is important due to the size of the database or the frequency with which a query is to be run. Understand the equivalence between dplyr and SQL queries, and how R translates one into the other. Gain familiarity with techniques that help you explore a database and verify its documentation. Gain familiarity with the standard metadata that a SQL database contains to describe its own contents. Understand some advanced SQL techniques. Gain some understanding of techniques for assessing query structure and performance. Understand enough about Docker to swap databases, e.g. Sports DB for the DVD rental database used in this tutorial. Or swap the database management system (DBMS), e.g. MySQL for PostgreSQL. 4.3 Imagining a DVD rental business Years ago, people rented videos on DVD disks and video stores were a big business. To understand the data base that we use in this book, try to imagine managing a video rental store like Movie Madness in Portland, Oregon. What data would be needed and what questions would you have to answer about the business? This tutorial uses the PostgreSQL version of “dvd rental” database which represents the transaction database for running a movie (e.g., dvd) rental business. The database can be downloaded here. Here’s a glimpse of it’s structure, which we explore using several different methods: Entity Relationship diagram for the dvdrental database A data analyst uses the database abstraction and the practical business questions to make better decisions and solve problems. 4.4 Use cases Imagine that you have one of following several roles at our fictional company DVDs R Us and you have a following need to be met: As a data scientist, I want to know the distribution of number of rentals per month per customer, so that the Marketing department can create incentives for customers in 3 segments: Frequent Renters, Average Renters, Infrequent Renters. As the Director of Sales, I want to see the total number of rentals per month for the past 6 months and I want to know how fast our customer base is growing/shrinking per month for the past 6 months. As the Director of Marketing, I want to know which categories of DVDs are the least popular, so that I can create a campaign to draw attention to rarely used inventory. As a shipping clerk, I want to add rental information when I fulfill a shipment order. As the Director of Analytics, I want to test as much of the production R code in my shop as possible against a new release of the DBMS that the IT department is implementing next month. etc. 4.5 Investigating a question using an organization’s database Need both familiarity with the data and a focus question An iterative process where the data resource can shape your understanding of the question the question you need to answer will frame how you see the data resource You need to go back and forth between the two, asking do I understand the question? do I understand the data? How well do you understand the data resource (in the DBMS)? Use all available documentation and understand its limits Use your own tools and skills to examine the data resource What is missing from the database: (columns, records, cells) Why is the data missing? How well do you understand the question you seek to answer? How general or specific is your question? How aligned is it with the purpose for which the database was designed and is being operated? How different are your assumptions and concerns from those of the people who enter and use the data on a day to day basis? References "],
["chapter-connect-docker-postgresql-r.html", "Chapter 5 Connecting Docker, PostgreSQL, and R 5.1 Verify that Docker is running 5.2 Remove previous containers if they exist 5.3 Connecting, reading and writing to PostgreSQL from R 5.4 Clean up", " Chapter 5 Connecting Docker, PostgreSQL, and R This chapter demonstrates how to: Run, clean-up and close PostgreSQL in Docker containers. Keep necessary credentials secret while being available to R when it executes. Interact with PostgreSQL when it’s running inside a Docker container. Read and write to PostgreSQL from R. Please install the sqlpetr package if not already installed: library(devtools) if (!require(sqlpetr)) devtools::install_github(&quot;smithjd/sqlpetr&quot;, build_opts = &quot;&quot;) Note that when you install the package the first time, it will ask you to update the packages it uses and that can take some time. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 5.1 Verify that Docker is running Docker commands can be run from a terminal (e.g., the Rstudio Terminal pane) or with a system2() command. (We discuss the diffeent ways of interacting with Docker and other elements in your environment in a separate chapter.) The necessary functions to start, stop Docker containers and do other busy work are provided in the sqlpetr package. As time permits and curiosity dictates, feel free to look at those functions to see how they work. Check that Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 5.2 Remove previous containers if they exist Force remove the cattle and sql-pet containers if they exist (e.g., from prior experiments). sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 We name containers cattle for “throw-aways” and pet for ones we treasure and keep around. :-) sp_make_simple_pg(&quot;cattle&quot;) The first time you run this, Docker downloads the PostgreSQL image, which takes a bit of time. Did it work? The following command shows that a container named cattle is running postgres:10. sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;ae1f5e9af5d7 postgres:10 \\&quot;docker-entrypoint.s…\\&quot; 1 second ago Up Less than a second 0.0.0.0:5432-&gt;5432/tcp cattle&quot; For more details, our package sqlpetr has a function sp_docker_containers_tibble that returns a tibble of the containers in the system: sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ae1f5e9af5d7 post… docker… 2019-02-1… 1 seco… 0.0.… Up Le… 0B (… catt… ## # … with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; 5.3 Connecting, reading and writing to PostgreSQL from R 5.3.1 Connecting to PostgreSQL The sp_make_simple_pg function we called above created a container from the postgres:10 library image from Docker Hub. As part of the process, it set the password for the PostgreSQL database superuser postgres to the value “postgres”. For simplicity, we are using a weak password at this point and it’s shown here and in the code in plain text. That is bad practice because user credentials should not be shared in open code like that. A subsequent chapter demonstrates how to store and use credentials to access the DBMS so that they are kept private. We connect to PostgreSQL using the sp_get_postgres_connection function: con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5432, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;postgres&quot;, seconds_to_test = 30 ) Make sure that you can connect to the PostgreSQL database that you have just started. If you have been executing the code from this tutorial, the database will not contain any tables yet: DBI::dbListTables(con) ## character(0) 5.3.2 Interact with PostgreSQL Write mtcars to PostgreSQL DBI::dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) List the tables in the PostgreSQL database to show that mtcars is now there: DBI::dbListTables(con) ## [1] &quot;mtcars&quot; List the fields in mtcars: DBI::dbListFields(con, &quot;mtcars&quot;) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; Download the table from the DBMS to a local data frame: mtcars_df &lt;- DBI::dbReadTable(con, &quot;mtcars&quot;) Show a few rows: sp_print_df(head(mtcars_df)) 5.4 Clean up Afterwards, always disconnect from the dbms: DBI::dbDisconnect(con) Tell Docker to stop the cattle container: sp_docker_stop(&quot;cattle&quot;) Tell Docker to remove the cattle container from it’s library of active containers: sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 Verify that cattle is gone: sp_docker_containers_tibble() ## # A tibble: 0 x 0 If we just stop the Docker container but don’t remove it (as we did with the sp_docker_remove_container(&quot;cattle&quot;) command), the cattle container will persist and we can start it up again later with sp_docker_start(&quot;cattle&quot;). In that case, mtcars would still be there and we could retrieve it from PostgreSQL again. Since sp_docker_remove_container(&quot;cattle&quot;) has removed it, the updated database has been deleted. (There are enough copies of mtcars in the world, so no great loss.) "],
["chapter-setup-dvdrental-db.html", "Chapter 6 Create the dvdrental database in PostgreSQL in Docker 6.1 Overview 6.2 Verify that Docker is up and running 6.3 Clean up if appropriate 6.4 Build the pet-sql Docker image 6.5 Run the pet-sql Docker Image 6.6 Connect to PostgreSQL with R 6.7 Stop and start to demonstrate persistence 6.8 Cleaning up 6.9 Using the sql-pet container in the rest of the book", " Chapter 6 Create the dvdrental database in PostgreSQL in Docker This chapter demonstrates how to: Setup the dvdrental database in Docker Stop and start Docker container to demonstrate persistence Connect to and disconnect R from the dvdrental database Set up the environment for subsequent chapters 6.1 Overview In the last chapter we connected to PostgreSQL from R. Now we set up a “realistic” database named dvdrental. There are different approaches to doing this: this chapter sets it up in a way that doesn’t show all the Docker details. These packages are called in this Chapter: library(tidyverse) library(DBI) library(RPostgres) library(glue) require(knitr) library(dbplyr) library(sqlpetr) library(bookdown) 6.2 Verify that Docker is up and running sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 6.3 Clean up if appropriate Force-remove the cattle and sql-pet containers if they exist (e.g., from a prior runs): sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 6.4 Build the pet-sql Docker image For the rest of the book we will be using a Docker image called postgres-dvdrental. To save space here in the book, we’ve created a function in sqlpetr to build this image, called sp_make_dvdrental_image. Vignette Building the dvdrental Docker Image describes the build process. sp_make_dvdrental_image(&quot;postgres-dvdrental&quot;) Did it work? We have a function that lists the images into a tibble! sp_docker_images_tibble() ## # A tibble: 7 x 7 ## image_id repository tag digest created created_at size ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 d9449a1f… postgres-dv… latest &lt;none&gt; 2 days… 2019-02-15 … 251MB ## 2 f5e93aa6… &lt;none&gt; &lt;none&gt; &lt;none&gt; 5 mont… 2018-09-10 … 258MB ## 3 ac25c2ba… postgres 10 sha256:b5f07874… 5 mont… 2018-09-04 … 228MB ## 4 93ca3834… r-base latest sha256:3801677d… 7 mont… 2018-07-16 … 678MB ## 5 23e8b4b8… postgres latest sha256:d8011033… 7 mont… 2018-07-16 … 236MB ## 6 74f8760a… ubuntu latest sha256:30e04dda… 7 mont… 2018-07-16 … 82.4… ## 7 11cd0b38… alpine latest sha256:70430763… 7 mont… 2018-07-06 … 4.41… 6.5 Run the pet-sql Docker Image Now we can run the image in a container and connect to the database. To run the image we use an sqlpetr function called sp_pg_docker_run When the image runs in the container, we can mount the current working directory into a path in the container. You’ll see this in action in a future chapter. Docker will create this path if it doesn’t exist. To specify the path, set the parameter mount_here_as to the name you want. Rules for the name: If you don’t want to mount into the container, specify NULL. This is the default! The name must start with a / and be a valid absolute path. The name should contain only slashes, letters, numbers and underscores. Other characters may or may not work. The snakecase package is your friend. sp_pg_docker_run( container_name = &quot;sql-pet&quot;, image_tag = &quot;postgres-dvdrental&quot;, postgres_password = &quot;postgres&quot;, mount_here_as = &quot;/petdir&quot; ) Did it work? sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 60a61f1e10f7 post… docker… 2019-02-1… 1 seco… 0.0.… Up Le… 0B (… sql-… ## # … with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; 6.6 Connect to PostgreSQL with R Use the DBI package to connect to the dvdrental database in PostgreSQL. Remember the settings discussion about [keeping passwords hidden][Pause for some security considerations] con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5432, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) List the tables in the database and the fields in one of those tables. dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; Disconnect from the database: dbDisconnect(con) 6.7 Stop and start to demonstrate persistence Stop the container: sp_docker_stop(&quot;sql-pet&quot;) sp_docker_containers_tibble() ## # A tibble: 0 x 0 When we stopped sql-pet, it no longer appeared in the tibble. But the container is still there. sp_docker_containers_tibble by default only lists the running containers. But we can use the list_all option and see it: sp_docker_containers_tibble(list_all = TRUE) ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 60a61f1e10f7 post… docker… 2019-02-1… 5 seco… &lt;NA&gt; Exite… 0B (… sql-… ## # … with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; Restart the container and verify that the dvdrental tables are still there: sp_docker_start(&quot;sql-pet&quot;) sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 60a61f1e10f7 post… docker… 2019-02-1… 6 seco… 0.0.… Up Le… 63B … sql-… ## # … with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; Connect to the dvdrental database in PostgreSQL: con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5432, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) Check that you can still see the fields in the rental table: dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; 6.8 Cleaning up Always have R disconnect from the database when you’re done. dbDisconnect(con) Stop the sql-pet container: sp_docker_stop(&quot;sql-pet&quot;) Show that the container still exists even though it’s not running sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 7 seconds ago Exited (0) Less than a second ago sql-pet Next time, you can just use this command to start the container: sp_docker_start(&quot;sql-pet&quot;) And once stopped, the container can be removed with: sp_check_that_docker_is_up(&quot;sql-pet&quot;) 6.9 Using the sql-pet container in the rest of the book After this point in the book, we assume that Docker is up and that we can always start up our sql-pet database with: sp_docker_start(&quot;sql-pet&quot;) "],
["chapter-dbms-login-credentials.html", "Chapter 7 Securing and using your dbms log-in credentials 7.1 Set up the sql-pet Docker container 7.2 Storing your dbms credentials 7.3 Clean up", " Chapter 7 Securing and using your dbms log-in credentials This chapter demonstrates how to: Keep necessary credentials secret or at least invisible Interact with PostgreSQL using your stored dbms credentials Connecting to a dbms can be very frustrating at first. In many organizations, simply getting access credentials takes time and may involve jumping through multiple hoops. In addition, a dbms is terse or deliberately inscrutable when your credetials are incorrect. That’s a security strategy, not a limitation of your understanding or of your software. When R can’t log you on to a dbms, you usually will have no information as to what went wrong. There are many different strategies for managing credentials. See Securing Credentials in RStudio’s Databases using R documentation for some alternatives to the method we adopt in this book. We provide more details about PostgreSQL Authentication in our sandbox environment in an appendix. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 7.1 Set up the sql-pet Docker container 7.1.1 Verify that Docker is running Check that Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 7.1.2 Start the Docker container: Start the sql-pet Docker container: sp_docker_start(&quot;sql-pet&quot;) 7.2 Storing your dbms credentials In previous chapters the connection string for connecting to the dbms has used default credentials specified in plain text as follows: user= 'postgres', password = 'postgres' When we call sp_get_postgres_connection below we’ll use environment variables that R obtains from reading the .Renviron file when R starts up. This approach has two benefits: that file is not uploaded to GitHub and R looks for it in your default directory every time it loads. To see whether you have already created that file, use the R Studio Files tab to look at your home directory: That file should contain lines that look like the example below. Although in this example it contains the PostgreSQL default values for the username and password, they are obviously not secret. But this approach demonstrates where you should put secrets that R needs while not risking accidental uploaded to GitHub or some other public location.. Open your .Renviron file with this command: file.edit(&quot;~/.Renviron&quot;) Or you can execute define_postgresql_params.R to create the file or you could copy / paste the following into your .Renviron file: DEFAULT_POSTGRES_PASSWORD=postgres DEFAULT_POSTGRES_USER_NAME=postgres Once that file is created, restart R, and after that R reads it every time it comes up. 7.2.1 Connect with Postgres using the Sys.getenv function Connect to the postgrSQL using the sp_get_postgres_connection function: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30) Once the connection object has been created, you can list all of the tables in the database: dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; 7.3 Clean up Afterwards, always disconnect from the dbms: dbDisconnect(con) Tell Docker to stop the sql-pet container: sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-your-local-environment.html", "Chapter 8 Mapping your local environment 8.1 Set up our standard pet-sql environment 8.2 Sandbox Environment 8.3 Getting there from here: entity connections, equivalence, and commands 8.4 Exercises", " Chapter 8 Mapping your local environment This chapter explores: The different entities involved in running the examples in this book’s sandbox The different roles that each entity plays in the sandbox How those entities are connected and how communication between those entities happens Pointers to the commands that go with each entity These packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(dbplyr) library(sqlpetr) library(DiagrammeR) display_rows &lt;- 5 8.1 Set up our standard pet-sql environment Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. Start up the docker-pet container: sp_docker_start(&quot;sql-pet&quot;) Connect to the dvdrental database with R. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 8.2 Sandbox Environment Here is an overview of our sandbox environment. In this chapter we explore each of the entities in the sandbox, how they are connected and how they communicate with each other. You can skip this chapter and come back later when you are curious about the setup that we’re using in this book. 8.2.1 Sandbox entities and their roles 8.2.2 RStudio You communicate with Rstudio, which can send commands to both R and to Unix. Commands to your OS can be entered directly in the terminal pane or via an R function like exec2(). On a Unix or Mac computer, you typically communicate with bash, while you have several choices on a Windows computer. The following two screenshots show the default options available for the Terminal option in RStudio’s Preferences for Mac and Windows, respectively. Mac choices Windows choices To check on the RStudio version you are using, enter this R command: require(rstudioapi) versionInfo() The RStudio IDE cheat sheet (PDF) is handy for learning your way around the IDE. 8.2.3 OS / local command line interface You can type commands directly into a terminal window on your computer to communicate with your operating system (OS). It will be a bash prompt on a Unix or Mac, but could be one of several flavors on Windows. Our diagram conflates the operating system with the command line interface (CLI) which is a bit of a simplification as discussed below. In addition to operating system commands, you can communicate with the Docker client through the CLI to start and stop the Docker server, load containers with programs such as Unix, PostgreSQL, communicae with those programs, etc. To check on the OS version you are using, enter this on your RStudio terminal or local CLI: uname -a An OS can contain different comand line interfaces. Check on it with this on your RStudio terminal or local CLI: echo $0 A Unix / Linux command line cheet sheet is a handy reference. 8.2.4 R R processes instructions from Rstudio. It can send instructions to your OS via the system2 function. R can also talk directly to PostgreSQL through the DBI package. R functions like file.info(&quot;file.typ&quot;) communicate with your operating system, but do not visibly issue a command to your CLI. That’s an example of an equivalence that can be useful or confusing (as in our environment diagram): you can get the same information from ls -ql README.md on a Unix command line as file.info(&quot;README.md&quot;) on the R console. Although this sandbox seeks to make it easy, connecting to the database often involves technical and organizational hurdles like getting authorization. The main purpose of this book is to provide a sandbox for database queries to experiment with sending commands with one of the DBI functions to the dbms directly from R. However, Docker and PostreSQL commands are useful to know and may be necessary in extending the book’s examples. To check on the version of R that you are using, enter this on your R Console command line: R.version The growing collection of RStudio cheet sheets is indispensable. 8.2.5 Docker client The docker client sets up the Docker server, loads containers, and passes instructions from your OS to the programs running in the Docker server. A Docker container will always contain a subset of the Linux operating system, so that it contains a second CLI in your sandbox. See more about the Docker environment. In addition to interaction with Docker through your computer’s CLI or the RStudio Terminal pane, the docker and stevedore packages can communicate with Docker from R. Both packages rely on the reticulate package and python. For this book, we chose to send instructions to Docker through R’s system2() function calls which do pass commands along to Docker through your computer’s CLI. We chose that route in order to be as transparent as possible and because the book’s sandbox environment is fairly simple. Although Docker has 44 different commands, in this book we only use a subset: ps, build, run, exec, start, stop, and rm. We wrap all of these commands in sqlpetr package functions to encourage you to focus on R and PostgreSQL. To check on the Docker version you are using, enter this on your RStudio Terminal or local CLI: docker version To see what images (if any) are stored locally and available for running in Docker, enter this on your RStudio Terminal or local CLI: docker image ls There are many Docker command-line cheat sheets; this one is recommended. 8.2.6 In Docker: Linux Docker runs a subset of the Linux operating system that in turn runs other programs like psql or PostgreSQL. You may want to poke around the Linux environment inside Docker. To find what version of Linux Docker is running, enter the following command on your local CLI or in the RStudio Terminal pane: docker exec -ti sql-pet uname -a As Linux can itself have different CLIs, enter the following command on your local CLI or in the RStudio Terminal pane to find out which CLI is running inside Docker: docker exec -ti sql-pet echo $0 To enter an interactive session inside Docker’s Linux environment, enter the following command on your local CLI or in the RStudio Terminal pane: docker exec -ti sql-pet bash To exit, enter: exit A Unix / Linux command line cheet sheet is a handy reference. 8.2.7 In Docker: psql If you are comfortable executing SQL from a command line directly against the database, you can run the psql application in our Docker environment. To start up a psql session to investigate PostgreSQL from a command line enter the following command on your computer’s CLI or the RStudio Terminal pane: $ docker exec -ti sql-pet psql -a -p 5432 -d dvdrental -U postgres Exit that environment with: \\q Us this handy psql cheat sheet (PDF) to get around. 8.2.8 In Docker: PostgreSQL The PostgreSQL database is a whole environment unto itself. It can receive instructions through bash from psql, and it will respond to DBI queries from R on port 5282. To check on the version of PostgreSQL client (e.g., psql) you are using, enter this on your RStudio terminal or local command line interface: docker exec -ti sql-pet psql --version To check on the version of PostgreSQL server you are running in Docker, enter this on your RStudio Terminal or local command line interface: docker exec -ti sql-pet psql -U postgres -c 'select version();' Here’s a recommended PostgreSQL cheat sheet (PDF). 8.3 Getting there from here: entity connections, equivalence, and commands pathways, equivalences, command structures. We use two trivial commands to explore the various interfaces. ls -l is the unix command for listing information about a file and \\du is the psql command to list the users that exist in PostgreSQL. Your OS and the OS inside Docker may be looking at the same file but they are in different time zones. 8.3.1 Get info on a local file from R code file.info(&quot;README.md&quot;) ## size isdir mode mtime ctime ## README.md 4493 FALSE 644 2019-02-17 13:04:05 2019-02-17 13:04:05 ## atime uid gid uname grname ## README.md 2019-02-17 13:04:39 502 80 jds admin The equivalent information from executing a command on the CLI or Terminal would be system2(&quot;ls&quot;, &quot;-l README.md&quot;, stdout = TRUE, stderr = FALSE) 8.3.2 Get info on the same OS file inside Docker from R Code system2(&quot;docker&quot;, &quot;exec sql-pet ls -l petdir/README.md&quot;, stdout = TRUE, stderr = FALSE) ## [1] &quot;-rw-r--r-- 1 root root 4493 Feb 17 21:04 petdir/README.md&quot; 8.3.3 Docker and psql together from R or your CLI As you become familiar with using Docker, you’ll see that there are various ways to do any given task. Here’s an illustration of how to get a list of users who have access to the PostegreSQL database. system2(&quot;docker&quot;, &quot;exec sql-pet psql -U postgres -c &#39;\\\\du&#39; &quot;, stdout = TRUE, stderr = FALSE) ## [1] &quot; List of roles&quot; ## [2] &quot; Role name | Attributes | Member of &quot; ## [3] &quot;-----------+------------------------------------------------------------+-----------&quot; ## [4] &quot; postgres | Superuser, Create role, Create DB, Replication, Bypass RLS | {}&quot; ## [5] &quot;&quot; From the RStudio Terminal window, the equivalent would be a matter of dropping off some of the R code: docker exec -it sql-pet psql -U postgres -c '\\du' 8.3.4 Nesting commands illustrates how entities are connected The following table illustrates how the different entities communicate with each other by decomposing a command from the chapter on creating a Docker container one step at a time: system2(&quot;docker&quot;, &quot;exec sql-pet pg_restore -U postgres -d dvdrental petdir/dvdrental.tar&quot;, stdout = TRUE, stderr = TRUE) Code element Comment system2( R command to send instructions to your computer’s CLI. &quot;docker&quot;, The program (docker) on your computer that will interpret the commands passed from the system2 function. &quot; The entire string within the quotes is passed to docker exec sql-pet exec will pass a command to any program running in the sql-pet container. pg_restore pg_restore is the program inside the sql-pet container that processes instructions to restore a previously downloaded backup file. -U postgres -d dvdrental petdir/dvdrental.tar The pg_restore program requires a username, a database and a backup file to be restored. &quot;, End of the docker commands passed to the system2 function in R. stdout = TRUE, stderr = TRUE) The system2 function needs to know what to do with its output, which in this case is to print all of it. 8.4 Exercises Docker containers have a small foot print. In our container, we are running a limited Linux kernel and a PostgreSQL database. To show how tiny the Docker environment is, we will look at all the processes running inside Docker and the top level file structure. In the following exercises, use the -i option and the CONTAINER = sql-pet. Start up R/RStudio and convert the CLI command to an R/RStudio command # Question Docker CLI Command R RStudio command Local Command LINE 1 How many processes are running inside the Docker container? docker exec -i sql-pet ps -eF 1a How many process are running on your local machine? widows: tasklistMac/Linux: ps -ef 2 What is the total number of files and directories in Docker? docker exec -i sql-pet ls -al 2a What is the total number of files and directories on your local machine? 3 Is Docker Running? docker version 3a What are your Client and Server Versions? 4 Does PostgreSQL exist in the container? docker ps -a 4a What is the status of PostgreSQL? docker ps -a 4b What is the size of PostgreSQL? docker images 4c What is the size of your laptop OS https://www.quora.com/What-is-the-actual-size-of-Windows-10-ISO-file 5 If sql-pet status is Up, How do I stop it? docker stop sql-pet 5a If sql-pet status is Exited, How do I start it? docker start sql-pet "],
["chapter-dbms-queries-intro.html", "Chapter 9 Introduction to DBMS queries 9.1 Setup 9.2 Getting data from the database 9.3 Mixing dplyr and SQL 9.4 Examining a single table with R 9.5 Additional reading", " Chapter 9 Introduction to DBMS queries This chapter demonstrates how to: Get a glimpse of what tables are in the database and what fields a table contains Download all or part of a table from the dbms See how dplyr code is translated into SQL commands Get acquainted with some useful tools for investigating a single table Begin thinking about how to divide the work between your local R session and the dbms 9.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. If not go back to Chapter 7 sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 9.2 Getting data from the database As we show later on, the database serves as a store of data and as an engine for sub-setting, joining, and computation on the data. We begin with getting data from the dbms, or “downloading” data. 9.2.1 Finding out what’s there We’ve already seen the simplest way of getting a list of tables in a database with DBI functions that list tables and fields. Generate a vector listing the (public) tables in the database: tables &lt;- DBI::dbListTables(con) tables ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; Print a vector with all the fields (or columns or variables) in one specific table: DBI::dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; 9.2.2 Listing all the fields for all the tables The first example, DBI::dbListTables(con) returned 22 tables and the second example, DBI::dbListFields(con, &quot;rental&quot;) returns 7 fields. Here we combine the two calls to return a list of tables which has a list of all the fields in the table. The code block just shows the first two tables. table_columns &lt;- lapply(tables, dbListFields, conn = con) Or, using purr: table_columns &lt;- purrr::map(tables, ~ dbListFields(.,conn = con) ) Rename each list [[1]] … [[22]] to meaningful table name names(table_columns) &lt;- tables head(table_columns) ## $actor_info ## [1] &quot;actor_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;film_info&quot; ## ## $customer_list ## [1] &quot;id&quot; &quot;name&quot; &quot;address&quot; &quot;zip code&quot; &quot;phone&quot; &quot;city&quot; ## [7] &quot;country&quot; &quot;notes&quot; &quot;sid&quot; ## ## $film_list ## [1] &quot;fid&quot; &quot;title&quot; &quot;description&quot; &quot;category&quot; &quot;price&quot; ## [6] &quot;length&quot; &quot;rating&quot; &quot;actors&quot; ## ## $nicer_but_slower_film_list ## [1] &quot;fid&quot; &quot;title&quot; &quot;description&quot; &quot;category&quot; &quot;price&quot; ## [6] &quot;length&quot; &quot;rating&quot; &quot;actors&quot; ## ## $sales_by_film_category ## [1] &quot;category&quot; &quot;total_sales&quot; ## ## $staff ## [1] &quot;staff_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;address_id&quot; &quot;email&quot; ## [6] &quot;store_id&quot; &quot;active&quot; &quot;username&quot; &quot;password&quot; &quot;last_update&quot; ## [11] &quot;picture&quot; Later on we’ll discuss how to get more extensive data about each table and column from the database’s own store of metadata using a similar technique. As we go further the issue of scale will come up again and again: you need to be careful about how much data a call to the dbms will return, whether it’s a list of tables or a table that could have millions of rows. It’s important to connect with people who own, generate, or are the subjects of the data. A good chat with people who own the data, generate it, or are the subjects can generate insights and set the context for your investigation of the database. The purpose for collecting the data or circumstances where it was collected may be buried far afield in an organization, but usually someone knows. The metadata discussed in a later chapter is essential but will only take you so far. There are different ways of just looking at the data, which we explore below. 9.2.3 Downloading an entire table There are many different methods of getting data from a DBMS, and we’ll explore the different ways of controlling each one of them. DBI::dbReadTable will download an entire table into an R tibble. rental_tibble &lt;- DBI::dbReadTable(con, &quot;rental&quot;) str(rental_tibble) ## &#39;data.frame&#39;: 16044 obs. of 7 variables: ## $ rental_id : int 2 3 4 5 6 7 8 9 10 11 ... ## $ rental_date : POSIXct, format: &quot;2005-05-24 22:54:33&quot; &quot;2005-05-24 23:03:39&quot; ... ## $ inventory_id: int 1525 1711 2452 2079 2792 3995 2346 2580 1824 4443 ... ## $ customer_id : int 459 408 333 222 549 269 239 126 399 142 ... ## $ return_date : POSIXct, format: &quot;2005-05-28 19:40:33&quot; &quot;2005-06-01 22:12:39&quot; ... ## $ staff_id : int 1 1 2 1 1 2 2 1 2 2 ... ## $ last_update : POSIXct, format: &quot;2006-02-16 02:30:53&quot; &quot;2006-02-16 02:30:53&quot; ... That’s very simple, but if the table is large it may not be a good idea, since R is designed to keep the entire table in memory. Note that the first line of the str() output reports the total number of observations. 9.2.4 A table object that can be reused The dplyr::tbl function gives us more control over access to a table by enabling control over which columns and rows to download. It creates an object that might look like a data frame, but it’s actually a list object that dplyr uses for constructing queries and retrieving data from the DBMS. rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) class(rental_table) ## [1] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; ## [4] &quot;tbl_lazy&quot; &quot;tbl&quot; 9.2.5 Controlling the number of rows returned The collect function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R. rental_table %&gt;% dplyr::collect(n = 3) %&gt;% dim ## [1] 3 7 rental_table %&gt;% dplyr::collect(n = 500) %&gt;% dim ## [1] 500 7 9.2.6 Random rows from the dbms When the dbms contains many rows, a sample of the data may be plenty for your purposes. Although dplyr has nice functions to sample a data frame that’s already in R (e.g., the sample_n and sample_frac functions), to get a sample from the dbms we have to use dbGetQuery to send native SQL to the database. To peek ahead, here is one example of a query that retrieves 20 rows from a 1% sample: one_percent_sample &lt;- DBI::dbGetQuery( con, &quot;SELECT rental_id, rental_date, inventory_id, customer_id FROM rental TABLESAMPLE BERNOULLI(1) LIMIT 20; &quot; ) one_percent_sample ## rental_id rental_date inventory_id customer_id ## 1 67 2005-05-25 09:41:01 239 119 ## 2 157 2005-05-26 01:25:21 887 344 ## 3 158 2005-05-26 01:27:11 2395 354 ## 4 217 2005-05-26 09:24:26 4395 121 ## 5 265 2005-05-26 16:07:38 2276 303 ## 6 326 2005-05-27 01:10:11 3979 432 ## 7 379 2005-05-27 09:25:32 3462 584 ## 8 453 2005-05-27 19:31:16 4425 529 ## 9 474 2005-05-27 22:11:56 1474 274 ## 10 517 2005-05-28 03:17:57 234 403 ## 11 636 2005-05-28 17:47:58 4213 239 ## 12 922 2005-05-30 11:55:55 2442 550 ## 13 1006 2005-05-31 00:57:08 3461 222 ## 14 1115 2005-05-31 16:07:09 2140 109 ## 15 1144 2005-05-31 20:04:10 2450 207 ## 16 1218 2005-06-15 03:24:44 239 371 ## 17 1464 2005-06-15 20:38:14 4113 387 ## 18 1508 2005-06-15 22:33:24 1141 511 ## 19 1567 2005-06-16 03:13:30 3098 320 ## 20 1568 2005-06-16 03:14:01 635 178 Exact sample of 100 records This technique depends on knowing the range of a record index, such as the rental_id in the rental table of our dvdrental database. Start by finding the min and max values. DBI::dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; rental_df &lt;- DBI::dbReadTable(con, &quot;rental&quot;) max(rental_df$rental_id) ## [1] 16049 min(rental_df$rental_id) ## [1] 1 Set the random number seed and draw the sample. set.seed(123) sample_rows &lt;- sample(1:16049, 100) rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) Run query with the filter verb listing the randomly sampled rows to be retrieved: rental_sample &lt;- rental_table %&gt;% dplyr::filter(rental_id %in% sample_rows) %&gt;% dplyr::collect() str(rental_sample) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 100 obs. of 7 variables: ## $ rental_id : int 10 395 675 731 734 1494 1517 1643 1651 1775 ... ## $ rental_date : POSIXct, format: &quot;2005-05-25 00:02:21&quot; &quot;2005-05-27 11:45:49&quot; ... ## $ inventory_id: int 1824 752 1273 4124 3084 244 3728 1352 4444 1922 ... ## $ customer_id : int 399 575 338 5 538 575 148 484 524 123 ... ## $ return_date : POSIXct, format: &quot;2005-05-31 22:44:21&quot; &quot;2005-05-31 13:42:49&quot; ... ## $ staff_id : int 2 1 2 1 2 1 1 2 2 2 ... ## $ last_update : POSIXct, format: &quot;2006-02-16 02:30:53&quot; &quot;2006-02-16 02:30:53&quot; ... 9.2.7 Sub-setting variables A table in the dbms may not only have many more rows than you want, but also many more columns. The select command controls which columns are retrieved. rental_table %&gt;% dplyr::select(rental_date, return_date) %&gt;% head() ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_date return_date ## &lt;dttm&gt; &lt;dttm&gt; ## 1 2005-05-24 22:54:33 2005-05-28 19:40:33 ## 2 2005-05-24 23:03:39 2005-06-01 22:12:39 ## 3 2005-05-24 23:04:41 2005-06-03 01:43:41 ## 4 2005-05-24 23:05:21 2005-06-02 04:33:21 ## 5 2005-05-24 23:08:07 2005-05-27 01:32:07 ## 6 2005-05-24 23:11:53 2005-05-29 20:34:53 That’s exactly equivalent to submitting the following SQL commands dirctly: DBI::dbGetQuery( con, &#39;SELECT &quot;rental_date&quot;, &quot;return_date&quot; FROM &quot;rental&quot; LIMIT 6&#39;) ## rental_date return_date ## 1 2005-05-24 22:54:33 2005-05-28 19:40:33 ## 2 2005-05-24 23:03:39 2005-06-01 22:12:39 ## 3 2005-05-24 23:04:41 2005-06-03 01:43:41 ## 4 2005-05-24 23:05:21 2005-06-02 04:33:21 ## 5 2005-05-24 23:08:07 2005-05-27 01:32:07 ## 6 2005-05-24 23:11:53 2005-05-29 20:34:53 We won’t discuss dplyr methods for sub-setting variables, deriving new ones, or sub-setting rows based on the values found in the table, because they are covered well in other places, including: Comprehensive reference: https://dplyr.tidyverse.org/ Good tutorial: https://suzan.rbind.io/tags/dplyr/ In practice we find that, renaming variables is often quite important because the names in an SQL database might not meet your needs as an analyst. In “the wild”, you will find names that are ambiguous or overly specified, with spaces in them, and other problems that will make them difficult to use in R. It is good practice to do whatever renaming you are going to do in a predictable place like at the top of your code. The names in the dvdrental database are simple and clear, but if they were not, you might rename them for subsequent use in this way: tbl(con, &quot;rental&quot;) %&gt;% dplyr::rename(rental_id_number = rental_id, inventory_id_number = inventory_id) %&gt;% dplyr::select(rental_id_number, rental_date, inventory_id_number) %&gt;% head() ## # Source: lazy query [?? x 3] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_id_number rental_date inventory_id_number ## &lt;int&gt; &lt;dttm&gt; &lt;int&gt; ## 1 2 2005-05-24 22:54:33 1525 ## 2 3 2005-05-24 23:03:39 1711 ## 3 4 2005-05-24 23:04:41 2452 ## 4 5 2005-05-24 23:05:21 2079 ## 5 6 2005-05-24 23:08:07 2792 ## 6 7 2005-05-24 23:11:53 3995 That’s equivalent to the following SQL code: DBI::dbGetQuery( con, &#39;SELECT &quot;rental_id_number&quot;, &quot;rental_date&quot;, &quot;inventory_id_number&quot; FROM (SELECT &quot;rental_id&quot; AS &quot;rental_id_number&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot; AS &quot;inventory_id_number&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update&quot; FROM &quot;rental&quot;) &quot;ihebfvnxvb&quot; LIMIT 6&#39; ) ## rental_id_number rental_date inventory_id_number ## 1 2 2005-05-24 22:54:33 1525 ## 2 3 2005-05-24 23:03:39 1711 ## 3 4 2005-05-24 23:04:41 2452 ## 4 5 2005-05-24 23:05:21 2079 ## 5 6 2005-05-24 23:08:07 2792 ## 6 7 2005-05-24 23:11:53 3995 The one difference is that the SQL code returns a regular data frame and the dplyr code returns a tibble. Notice that the seconds are greyed out in the tibble display. 9.2.8 Translating dplyr code to SQL queries Where did the translations we’ve shown above come from? The show_query function shows how dplyr is translating your query to the dialect of the target dbms: rental_table %&gt;% dplyr::count(staff_id) %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;staff_id&quot;, COUNT(*) AS &quot;n&quot; ## FROM &quot;rental&quot; ## GROUP BY &quot;staff_id&quot; Here is an extensive discussion of how dplyr code is translated into SQL: https://dbplyr.tidyverse.org/articles/sql-translation.html If you prefer to use SQL directly, rather than dplyr, you can submit SQL code to the DBMS through the DBI::dbGetQuery function: DBI::dbGetQuery( con, &#39;SELECT &quot;staff_id&quot;, COUNT(*) AS &quot;n&quot; FROM &quot;rental&quot; GROUP BY &quot;staff_id&quot;; &#39; ) ## staff_id n ## 1 2 8004 ## 2 1 8040 When you create a report to run repeatedly, you might want to put that query into R markdown. That way you can also execute that SQL code in a chunk with the following header: {sql, connection=con, output.var = &quot;query_results&quot;} SELECT &quot;staff_id&quot;, COUNT(*) AS &quot;n&quot; FROM &quot;rental&quot; GROUP BY &quot;staff_id&quot;; Rmarkdown stores that query result in a tibble which can be printed by referring to it: query_results ## staff_id n ## 1 2 8004 ## 2 1 8040 9.3 Mixing dplyr and SQL When dplyr finds code that it does not know how to translate into SQL, it will simply pass it along to the dbms. Therefore you can interleave native commands that your dbms will understand in the middle of dplyr code. Consider this example that’s derived from (Ruiz 2019): rental_table %&gt;% dplyr::select_at(vars( -contains(&quot;_id&quot;))) %&gt;% dplyr::mutate(today = now()) %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_date&quot;, &quot;return_date&quot;, &quot;last_update&quot;, NOW() AS &quot;today&quot; ## FROM (SELECT &quot;rental_date&quot;, &quot;return_date&quot;, &quot;last_update&quot; ## FROM &quot;rental&quot;) &quot;yhbysdoypk&quot; That is native to PostgreSQL, not ANSI standard SQL. Verify that it works: rental_table %&gt;% dplyr::select_at(vars( -contains(&quot;_id&quot;))) %&gt;% head() %&gt;% dplyr::mutate(today = now()) %&gt;% dplyr::collect() ## # A tibble: 6 x 4 ## rental_date return_date last_update ## &lt;dttm&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 2005-05-24 22:54:33 2005-05-28 19:40:33 2006-02-16 02:30:53 ## 2 2005-05-24 23:03:39 2005-06-01 22:12:39 2006-02-16 02:30:53 ## 3 2005-05-24 23:04:41 2005-06-03 01:43:41 2006-02-16 02:30:53 ## 4 2005-05-24 23:05:21 2005-06-02 04:33:21 2006-02-16 02:30:53 ## 5 2005-05-24 23:08:07 2005-05-27 01:32:07 2006-02-16 02:30:53 ## 6 2005-05-24 23:11:53 2005-05-29 20:34:53 2006-02-16 02:30:53 ## # … with 1 more variable: today &lt;dttm&gt; 9.4 Examining a single table with R Dealing with a large, complex database highlights the utility of specific tools in R. We include brief examples that we find to be handy: Base R structure: str Printing out some of the data: datatable, kable, and View Summary statistics: summary glimpse in the tibble package, which is included in the tidyverse skim in the skimr package 9.4.1 str - a base package workhorse str is a workhorse function that lists variables, their type and a sample of the first few variable values. str(rental_tibble) ## &#39;data.frame&#39;: 16044 obs. of 7 variables: ## $ rental_id : int 2 3 4 5 6 7 8 9 10 11 ... ## $ rental_date : POSIXct, format: &quot;2005-05-24 22:54:33&quot; &quot;2005-05-24 23:03:39&quot; ... ## $ inventory_id: int 1525 1711 2452 2079 2792 3995 2346 2580 1824 4443 ... ## $ customer_id : int 459 408 333 222 549 269 239 126 399 142 ... ## $ return_date : POSIXct, format: &quot;2005-05-28 19:40:33&quot; &quot;2005-06-01 22:12:39&quot; ... ## $ staff_id : int 1 1 2 1 1 2 2 1 2 2 ... ## $ last_update : POSIXct, format: &quot;2006-02-16 02:30:53&quot; &quot;2006-02-16 02:30:53&quot; ... 9.4.2 Always look at your data with head, View, or kable There is no substitute for looking at your data and R provides several ways to just browse it. The head function controls the number of rows that are displayed. Note that tail does not work against a database object. In every-day practice you would look at more than the default 6 rows, but here we wrap head around the data frame: sqlpetr::sp_print_df(head(rental_tibble)) 9.4.3 The summary function in base The base package’s summary function provides basic statistics that serve a unique diagnostic purpose in this context. For example, the following output shows that: * `rental_id` is a number from 1 to 16,049. In a previous section, we ran the `str` function and saw that there are 16,044 observations in this table. Therefore, the `rental_id` seems to be sequential from 1:16049, but there are 5 values missing from that sequence. _Exercise for the Reader_: Which 5 values from 1:16049 are missing from `rental_id` values in the `rental` table? (_Hint_: In the chapter on SQL Joins, you will learn the functions needed to answer this question.) * The number of NA&#39;s in the `return_date` column is a good first guess as to the number of DVDs rented out or lost as of 2005-09-02 02:35:22. summary(rental_tibble) ## rental_id rental_date inventory_id ## Min. : 1 Min. :2005-05-24 22:53:30 Min. : 1 ## 1st Qu.: 4014 1st Qu.:2005-07-07 00:58:40 1st Qu.:1154 ## Median : 8026 Median :2005-07-28 16:04:32 Median :2291 ## Mean : 8025 Mean :2005-07-23 08:13:34 Mean :2292 ## 3rd Qu.:12037 3rd Qu.:2005-08-17 21:16:23 3rd Qu.:3433 ## Max. :16049 Max. :2006-02-14 15:16:03 Max. :4581 ## ## customer_id return_date staff_id ## Min. : 1.0 Min. :2005-05-25 23:55:21 Min. :1.000 ## 1st Qu.:148.0 1st Qu.:2005-07-10 15:49:36 1st Qu.:1.000 ## Median :296.0 Median :2005-08-01 19:45:29 Median :1.000 ## Mean :297.1 Mean :2005-07-25 23:58:03 Mean :1.499 ## 3rd Qu.:446.0 3rd Qu.:2005-08-20 23:35:55 3rd Qu.:2.000 ## Max. :599.0 Max. :2005-09-02 02:35:22 Max. :2.000 ## NA&#39;s :183 ## last_update ## Min. :2006-02-15 21:30:53 ## 1st Qu.:2006-02-16 02:30:53 ## Median :2006-02-16 02:30:53 ## Mean :2006-02-16 02:31:31 ## 3rd Qu.:2006-02-16 02:30:53 ## Max. :2006-02-23 09:12:08 ## So the summary function is surprisingly useful as we first start to look at the table contents. 9.4.4 The glimpse function in the tibble package The tibble package’s glimpse function is a more compact version of str: tibble::glimpse(rental_tibble) ## Observations: 16,044 ## Variables: 7 ## $ rental_id &lt;int&gt; 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,… ## $ rental_date &lt;dttm&gt; 2005-05-24 22:54:33, 2005-05-24 23:03:39, 2005-05-… ## $ inventory_id &lt;int&gt; 1525, 1711, 2452, 2079, 2792, 3995, 2346, 2580, 182… ## $ customer_id &lt;int&gt; 459, 408, 333, 222, 549, 269, 239, 126, 399, 142, 2… ## $ return_date &lt;dttm&gt; 2005-05-28 19:40:33, 2005-06-01 22:12:39, 2005-06-… ## $ staff_id &lt;int&gt; 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, … ## $ last_update &lt;dttm&gt; 2006-02-16 02:30:53, 2006-02-16 02:30:53, 2006-02-… 9.4.5 The skim function in the skimr package The skimr package has several functions that make it easy to examine an unknown data frame and assess what it contains. It is also extensible. library(skimr) ## ## Attaching package: &#39;skimr&#39; ## The following object is masked from &#39;package:knitr&#39;: ## ## kable skimr::skim(rental_tibble) ## Skim summary statistics ## n obs: 16044 ## n variables: 7 ## ## ── Variable type:integer ──────────────────────────────────────────────────────────────────────── ## variable missing complete n mean sd p0 p25 p50 ## customer_id 0 16044 16044 297.14 172.45 1 148 296 ## inventory_id 0 16044 16044 2291.84 1322.21 1 1154 2291 ## rental_id 0 16044 16044 8025.37 4632.78 1 4013.75 8025.5 ## staff_id 0 16044 16044 1.5 0.5 1 1 1 ## p75 p100 hist ## 446 599 ▇▇▇▇▇▇▇▇ ## 3433 4581 ▇▇▇▇▇▇▇▇ ## 12037.25 16049 ▇▇▇▇▇▇▇▇ ## 2 2 ▇▁▁▁▁▁▁▇ ## ## ── Variable type:POSIXct ──────────────────────────────────────────────────────────────────────── ## variable missing complete n min max median ## last_update 0 16044 16044 2006-02-15 2006-02-23 2006-02-16 ## rental_date 0 16044 16044 2005-05-24 2006-02-14 2005-07-28 ## return_date 183 15861 16044 2005-05-25 2005-09-02 2005-08-01 ## n_unique ## 3 ## 15815 ## 15836 wide_rental_skim &lt;- skimr::skim_to_wide(rental_tibble) 9.4.6 Close the connection and shut down sql-pet Where you place the collect function matters. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) 9.5 Additional reading (Wickham 2018) (Baumer 2018) References "],
["chapter-lazy-evaluation-queries.html", "Chapter 10 Lazy Evaluation and Lazy Queries 10.1 Setup 10.2 R is lazy and comes with guardrails 10.3 Lazy evaluation and lazy queries 10.4 When does a lazy query trigger data retrieval? 10.5 Other resources", " Chapter 10 Lazy Evaluation and Lazy Queries This chapter: Reviews lazy evaluation and discusses its interaction with remote query execution on a dbms Demonstrates how dplyr queries behave in connection with several different functions Offers some further resources on lazy loading, evaluation, execution, etc. 10.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to those instructions to configure your environment. Otherwise, start your sql-pet container: sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 10.2 R is lazy and comes with guardrails By design, R is both a language and an interactive development environment (IDE). As a language, R tries to be as efficient as possible. As an IDE, R creates some guardrails to make it easy and safe to work with your data. For example getOption(&quot;max.print&quot;) prevents R from printing more rows of data than you want to handle in an interactive session, with a default of 99999 lines, which may or may not suit you. On the other hand SQL is a “Structured Query Language (SQL): a standard computer language for relational database management and data manipulation.”.1 SQL has various database-specific Interactive Development Environments (IDEs), such as pgAdmin for PostgreSQL. Roger Peng explains in R Programming for Data Science that: R has maintained the original S philosophy, which is that it provides a language that is both useful for interactive work, but contains a powerful programming language for developing new tools. This is complicated when R interacts with SQL. In a vignette for dbplyr Hadley Wickham explains: The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database on the remote server, not in R on your local machine. When working with databases, dplyr tries to be as lazy as possible: It never pulls data into R unless you explicitly ask for it. It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step. Exactly when, which, and how much data is returned from the dbms is the topic of this chapter. Exactly how the data is represented in the dbms and then translated to a data frame is discussed in the DBI specification. Eventually, if you are interacting with a dbms from R you will need to understand the differences between lazy loading, lazy evaluation, and lazy queries. 10.2.1 Lazy loading “Lazy loading is always used for code in packages but is optional (selected by the package maintainer) for datasets in packages.”2 Lazy loading means that the code for a particular function doesn’t actually get loaded into memory until the last minute – when it’s actually being used. 10.2.2 Lazy evaluation Essentially “Lazy evaluation is a programming strategy that allows a symbol to be evaluated only when needed.”3 That means that lazy evaluation is about symbols such as function arguments4 when they are evaluated. Tidy evaluation complicates lazy evaluation.5 10.2.3 Lazy Queries “When you create a &quot;lazy&quot; query, you’re creating a pointer to a set of conditions on the database, but the query isn’t actually run and the data isn’t actually loaded until you call &quot;next&quot; or some similar method to actually fetch the data and load it into an object.”6 10.3 Lazy evaluation and lazy queries 10.3.1 dplyr connection objects As introduced in the previous chapter, the dplyr::tbl function creates an object that might look like a data frame in that when you enter it on the command line, it prints a bunch of rows from the dbms table. But it is actually a list object that dplyr uses for constructing queries and retrieving data from the DBMS. The following code illustrates these issues. The dplyr::tbl function creates the connection object that we store in an object named rental_table: rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) At first glance, it acts like a data frame when you print it, although it only prints 10 of the table’s 16,044 rows: rental_table ## # Source: table&lt;rental&gt; [?? x 7] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_id rental_date inventory_id customer_id ## &lt;int&gt; &lt;dttm&gt; &lt;int&gt; &lt;int&gt; ## 1 2 2005-05-24 22:54:33 1525 459 ## 2 3 2005-05-24 23:03:39 1711 408 ## 3 4 2005-05-24 23:04:41 2452 333 ## 4 5 2005-05-24 23:05:21 2079 222 ## 5 6 2005-05-24 23:08:07 2792 549 ## 6 7 2005-05-24 23:11:53 3995 269 ## 7 8 2005-05-24 23:31:46 2346 239 ## 8 9 2005-05-25 00:00:40 2580 126 ## 9 10 2005-05-25 00:02:21 1824 399 ## 10 11 2005-05-25 00:09:02 4443 142 ## # … with more rows, and 3 more variables: return_date &lt;dttm&gt;, ## # staff_id &lt;int&gt;, last_update &lt;dttm&gt; However, notice that the first output line shows ??, rather than providing the number of rows in the table. Similarly, the next to last line shows: ... with more rows, and 3 more variables whereas the output for a normal tbl of this rental data would say: ... with 16,034 more rows, and 3 more variables So even though rental_table is a tbl: class(rental_table) ## [1] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; ## [4] &quot;tbl_lazy&quot; &quot;tbl&quot; It is not just a normal tbl of data. We can see that from the structure of rental_table: str(rental_table) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;PqConnection&#39; [package &quot;RPostgres&quot;] with 3 slots ## .. .. ..@ ptr :&lt;externalptr&gt; ## .. .. ..@ bigint : chr &quot;integer64&quot; ## .. .. ..@ typnames:&#39;data.frame&#39;: 437 obs. of 2 variables: ## .. .. .. ..$ oid : int [1:437] 16 17 18 19 20 21 22 23 24 25 ... ## .. .. .. ..$ typname: chr [1:437] &quot;bool&quot; &quot;bytea&quot; &quot;char&quot; &quot;name&quot; ... ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_PqConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 2 ## ..$ x : &#39;ident&#39; chr &quot;rental&quot; ## ..$ vars: chr [1:7] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ... ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_base_remote&quot; &quot;op_base&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... It has only two rows! The first row contains all the information in the con object, which contains information about all the tables and objects in the database: rental_table$src$con@typnames$typname[380:437] ## [1] &quot;customer&quot; &quot;_customer&quot; ## [3] &quot;actor_actor_id_seq&quot; &quot;actor&quot; ## [5] &quot;_actor&quot; &quot;category_category_id_seq&quot; ## [7] &quot;category&quot; &quot;_category&quot; ## [9] &quot;film_film_id_seq&quot; &quot;film&quot; ## [11] &quot;_film&quot; &quot;pg_toast_16434&quot; ## [13] &quot;film_actor&quot; &quot;_film_actor&quot; ## [15] &quot;film_category&quot; &quot;_film_category&quot; ## [17] &quot;actor_info&quot; &quot;_actor_info&quot; ## [19] &quot;address_address_id_seq&quot; &quot;address&quot; ## [21] &quot;_address&quot; &quot;city_city_id_seq&quot; ## [23] &quot;city&quot; &quot;_city&quot; ## [25] &quot;country_country_id_seq&quot; &quot;country&quot; ## [27] &quot;_country&quot; &quot;customer_list&quot; ## [29] &quot;_customer_list&quot; &quot;film_list&quot; ## [31] &quot;_film_list&quot; &quot;inventory_inventory_id_seq&quot; ## [33] &quot;inventory&quot; &quot;_inventory&quot; ## [35] &quot;language_language_id_seq&quot; &quot;language&quot; ## [37] &quot;_language&quot; &quot;nicer_but_slower_film_list&quot; ## [39] &quot;_nicer_but_slower_film_list&quot; &quot;payment_payment_id_seq&quot; ## [41] &quot;payment&quot; &quot;_payment&quot; ## [43] &quot;rental_rental_id_seq&quot; &quot;rental&quot; ## [45] &quot;_rental&quot; &quot;sales_by_film_category&quot; ## [47] &quot;_sales_by_film_category&quot; &quot;staff_staff_id_seq&quot; ## [49] &quot;staff&quot; &quot;_staff&quot; ## [51] &quot;pg_toast_16529&quot; &quot;store_store_id_seq&quot; ## [53] &quot;store&quot; &quot;_store&quot; ## [55] &quot;sales_by_store&quot; &quot;_sales_by_store&quot; ## [57] &quot;staff_list&quot; &quot;_staff_list&quot; The second row contains a list of the columns in the rental table, among other things: rental_table$ops$vars ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; rental_table holds information needed to get the data from the ‘rental’ table, but rental_table does not hold the data itself. In the following sections, we will examine more closely this relationship between the rental_table object and the data in the database’s ‘rental’ table. 10.4 When does a lazy query trigger data retrieval? 10.4.1 Create a black box query for experimentation To illustrate the different issues involved in data retrieval, we create more connection objects to link to two other tables. staff_table &lt;- dplyr::tbl(con, &quot;staff&quot;) The ‘staff’ table has 2 rows. customer_table &lt;- dplyr::tbl(con, &quot;customer&quot;) The ‘customer’ table has 599 rows. Here is a typical string of dplyr verbs strung together with the magrittr %&gt;% pipe command that will be used to tease out the several different behaviors that a lazy query has when passed to different R functions. This query joins three connection objects into a query we’ll call Q: Q &lt;- rental_table %&gt;% dplyr::left_join(staff_table, by = c(&quot;staff_id&quot; = &quot;staff_id&quot;)) %&gt;% dplyr::rename(staff_email = email) %&gt;% dplyr::left_join(customer_table, by = c(&quot;customer_id&quot; = &quot;customer_id&quot;)) %&gt;% dplyr::rename(customer_email = email) %&gt;% dplyr::select(rental_date, staff_email, customer_email) 10.4.2 Experiment overview Think of Q as a black box for the moment. The following examples will show how Q is interpreted differently by different functions. Notation : A single green check indicates that some rows are returned. : Two green checks indicate that all the rows are returned. : The red X indicates that no rows are returned. R code Result Q %&gt;% print() Prints x rows; same as just entering Q Q %&gt;% dplyr::as_tibble() Forces Q to be a tibble Q %&gt;% head() Prints the first 6 rows Q %&gt;% tail() Error: tail() is not supported by sql sources Q %&gt;% length() Counts the rows in Q Q %&gt;% str() Shows the top 3 levels of the object Q Q %&gt;% nrow() Attempts to determine the number of rows Q %&gt;% dplyr::tally() Counts all the rows – on the dbms side Q %&gt;% dplyr::collect(n = 20) Prints 20 rows Q %&gt;% dplyr::collect(n = 20) %&gt;% head() Prints 6 rows Q %&gt;% dplyr::show_query() Translates the lazy query object into SQL Qc &lt;- Q %&gt;% dplyr::count(customer_email, sort = TRUE) Qc Extends the lazy query object The next chapter will discuss how to build queries and how to explore intermediate steps. But first, the following subsections provide a more detailed discussion of each row in the preceding table. 10.4.3 Q %&gt;% print() Remember that Q %&gt;% print() is equivalent to print(Q) and the same as just entering Q on the command line. We use the magrittr pipe operator here, because chaining functions highlights how the same object behaves differently in each use. Q %&gt;% print() ## # Source: lazy query [?? x 3] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_date staff_email customer_email ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 Mike.Hillyer@sakilasta… tommy.collazo@sakilacustome… ## 2 2005-05-24 23:03:39 Mike.Hillyer@sakilasta… manuel.murrell@sakilacustom… ## 3 2005-05-24 23:04:41 Jon.Stephens@sakilasta… andrew.purdy@sakilacustomer… ## 4 2005-05-24 23:05:21 Mike.Hillyer@sakilasta… delores.hansen@sakilacustom… ## 5 2005-05-24 23:08:07 Mike.Hillyer@sakilasta… nelson.christenson@sakilacu… ## 6 2005-05-24 23:11:53 Jon.Stephens@sakilasta… cassandra.walters@sakilacus… ## 7 2005-05-24 23:31:46 Jon.Stephens@sakilasta… minnie.romero@sakilacustome… ## 8 2005-05-25 00:00:40 Mike.Hillyer@sakilasta… ellen.simpson@sakilacustome… ## 9 2005-05-25 00:02:21 Jon.Stephens@sakilasta… danny.isom@sakilacustomer.o… ## 10 2005-05-25 00:09:02 Jon.Stephens@sakilasta… april.burns@sakilacustomer.… ## # … with more rows R retrieves 10 observations and 3 columns. In its role as IDE, R has provided nicely formatted output that is similar to what it prints for a tibble, with descriptive information about the dataset and each column: # Source: lazy query [?? x 3] # Database: postgres [postgres@localhost:5432/dvdrental] rental_date staff_email customer_email &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; R has not determined how many rows are left to retrieve as it shows with [?? x 3] and ... with more rows in the data summary. 10.4.4 Q %&gt;% dplyr::as_tibble() In contrast to print(), the as_tibble() function causes R to download the whole table, using tibble’s default of displaying only the first 10 rows. Q %&gt;% dplyr::as_tibble() ## # A tibble: 16,044 x 3 ## rental_date staff_email customer_email ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 Mike.Hillyer@sakilasta… tommy.collazo@sakilacustome… ## 2 2005-05-24 23:03:39 Mike.Hillyer@sakilasta… manuel.murrell@sakilacustom… ## 3 2005-05-24 23:04:41 Jon.Stephens@sakilasta… andrew.purdy@sakilacustomer… ## 4 2005-05-24 23:05:21 Mike.Hillyer@sakilasta… delores.hansen@sakilacustom… ## 5 2005-05-24 23:08:07 Mike.Hillyer@sakilasta… nelson.christenson@sakilacu… ## 6 2005-05-24 23:11:53 Jon.Stephens@sakilasta… cassandra.walters@sakilacus… ## 7 2005-05-24 23:31:46 Jon.Stephens@sakilasta… minnie.romero@sakilacustome… ## 8 2005-05-25 00:00:40 Mike.Hillyer@sakilasta… ellen.simpson@sakilacustome… ## 9 2005-05-25 00:02:21 Jon.Stephens@sakilasta… danny.isom@sakilacustomer.o… ## 10 2005-05-25 00:09:02 Jon.Stephens@sakilasta… april.burns@sakilacustomer.… ## # … with 16,034 more rows 10.4.5 Q %&gt;% head() The head() function is very similar to print but has a different “max.print” value. Q %&gt;% head() ## # Source: lazy query [?? x 3] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_date staff_email customer_email ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 Mike.Hillyer@sakilasta… tommy.collazo@sakilacustomer… ## 2 2005-05-24 23:03:39 Mike.Hillyer@sakilasta… manuel.murrell@sakilacustome… ## 3 2005-05-24 23:04:41 Jon.Stephens@sakilasta… andrew.purdy@sakilacustomer.… ## 4 2005-05-24 23:05:21 Mike.Hillyer@sakilasta… delores.hansen@sakilacustome… ## 5 2005-05-24 23:08:07 Mike.Hillyer@sakilasta… nelson.christenson@sakilacus… ## 6 2005-05-24 23:11:53 Jon.Stephens@sakilasta… cassandra.walters@sakilacust… 10.4.6 Q %&gt;% tail() Produces an error, because Q does not hold all of the data, so it is not possible to list the last few items from the table: try( Q %&gt;% tail(), silent = FALSE, outFile = stdout() ) ## Error : tail() is not supported by sql sources 10.4.7 Q %&gt;% length() Because the Q object is relatively complex, using str() on it prints many lines. You can glimpse what’s going on with length(): Q %&gt;% length() ## [1] 2 10.4.8 Q %&gt;% str() Looking inside shows some of what’s going on (three levels deep): Q %&gt;% str(max.level = 3) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;PqConnection&#39; [package &quot;RPostgres&quot;] with 3 slots ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_PqConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 4 ## ..$ name: chr &quot;select&quot; ## ..$ x :List of 4 ## .. ..$ name: chr &quot;rename&quot; ## .. ..$ x :List of 4 ## .. .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_join&quot; &quot;op_double&quot; &quot;op&quot; ## .. ..$ dots:List of 1 ## .. ..$ args: list() ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_rename&quot; &quot;op_single&quot; &quot;op&quot; ## ..$ dots:List of 3 ## .. ..$ : language ~rental_date ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x7fb9c5df7e58&gt; ## .. ..$ : language ~staff_email ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x7fb9c5df7e58&gt; ## .. ..$ : language ~customer_email ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x7fb9c5df7e58&gt; ## .. ..- attr(*, &quot;class&quot;)= chr &quot;quosures&quot; ## ..$ args: list() ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_select&quot; &quot;op_single&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... 10.4.9 Q %&gt;% nrow() Notice the difference between nrow() and tally(). The nrow functions returns NA and does not execute a query: Q %&gt;% nrow() ## [1] NA 10.4.10 Q %&gt;% dplyr::tally() The tally function actually counts all the rows. Q %&gt;% dplyr::tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## n ## &lt;S3: integer64&gt; ## 1 16044 The nrow() function knows that Q is a list. On the other hand, the tally() function tells SQL to go count all the rows. Notice that Q results in 16,044 rows – the same number of rows as rental. 10.4.11 Q %&gt;% dplyr::collect() The dplyr::collect function triggers a call to the DBI:dbFetch() function behind the scenes, which forces R to download a specified number of rows: Q %&gt;% dplyr::collect(n = 20) ## # A tibble: 20 x 3 ## rental_date staff_email customer_email ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 Mike.Hillyer@sakilasta… tommy.collazo@sakilacustome… ## 2 2005-05-24 23:03:39 Mike.Hillyer@sakilasta… manuel.murrell@sakilacustom… ## 3 2005-05-24 23:04:41 Jon.Stephens@sakilasta… andrew.purdy@sakilacustomer… ## 4 2005-05-24 23:05:21 Mike.Hillyer@sakilasta… delores.hansen@sakilacustom… ## 5 2005-05-24 23:08:07 Mike.Hillyer@sakilasta… nelson.christenson@sakilacu… ## 6 2005-05-24 23:11:53 Jon.Stephens@sakilasta… cassandra.walters@sakilacus… ## 7 2005-05-24 23:31:46 Jon.Stephens@sakilasta… minnie.romero@sakilacustome… ## 8 2005-05-25 00:00:40 Mike.Hillyer@sakilasta… ellen.simpson@sakilacustome… ## 9 2005-05-25 00:02:21 Jon.Stephens@sakilasta… danny.isom@sakilacustomer.o… ## 10 2005-05-25 00:09:02 Jon.Stephens@sakilasta… april.burns@sakilacustomer.… ## 11 2005-05-25 00:19:27 Jon.Stephens@sakilasta… deanna.byrd@sakilacustomer.… ## 12 2005-05-25 00:22:55 Mike.Hillyer@sakilasta… raymond.mcwhorter@sakilacus… ## 13 2005-05-25 00:31:15 Mike.Hillyer@sakilasta… theodore.culp@sakilacustome… ## 14 2005-05-25 00:39:22 Mike.Hillyer@sakilasta… ronald.weiner@sakilacustome… ## 15 2005-05-25 00:43:11 Jon.Stephens@sakilasta… steven.curley@sakilacustome… ## 16 2005-05-25 01:06:36 Mike.Hillyer@sakilasta… isaac.oglesby@sakilacustome… ## 17 2005-05-25 01:10:47 Jon.Stephens@sakilasta… ruth.martinez@sakilacustome… ## 18 2005-05-25 01:17:24 Mike.Hillyer@sakilasta… ronnie.ricketts@sakilacusto… ## 19 2005-05-25 01:48:41 Jon.Stephens@sakilasta… roberta.harper@sakilacustom… ## 20 2005-05-25 01:59:46 Jon.Stephens@sakilasta… craig.morrell@sakilacustome… Q %&gt;% dplyr::collect(n = 20) %&gt;% head() ## # A tibble: 6 x 3 ## rental_date staff_email customer_email ## &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 Mike.Hillyer@sakilasta… tommy.collazo@sakilacustomer… ## 2 2005-05-24 23:03:39 Mike.Hillyer@sakilasta… manuel.murrell@sakilacustome… ## 3 2005-05-24 23:04:41 Jon.Stephens@sakilasta… andrew.purdy@sakilacustomer.… ## 4 2005-05-24 23:05:21 Mike.Hillyer@sakilasta… delores.hansen@sakilacustome… ## 5 2005-05-24 23:08:07 Mike.Hillyer@sakilasta… nelson.christenson@sakilacus… ## 6 2005-05-24 23:11:53 Jon.Stephens@sakilasta… cassandra.walters@sakilacust… The dplyr::collect function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R. Notice that head only prints 6 of the 20 rows that R has retrieved. If you do not provide a value for the n argument, all of the rows will be retrieved into your R workspace. 10.4.12 Q %&gt;% dplyr::show_query() Q %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_date&quot;, &quot;staff_email&quot;, &quot;customer_email&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name.x&quot;, &quot;last_name.x&quot;, &quot;address_id.x&quot;, &quot;staff_email&quot;, &quot;store_id.x&quot;, &quot;active.x&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot;, &quot;store_id.y&quot;, &quot;first_name.y&quot;, &quot;last_name.y&quot;, &quot;email&quot; AS &quot;customer_email&quot;, &quot;address_id.y&quot;, &quot;activebool&quot;, &quot;create_date&quot;, &quot;last_update&quot;, &quot;active.y&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.x&quot; AS &quot;last_update.x&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;staff_email&quot; AS &quot;staff_email&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active.x&quot;, &quot;TBL_LEFT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_LEFT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.y&quot; AS &quot;last_update.y&quot;, &quot;TBL_LEFT&quot;.&quot;picture&quot; AS &quot;picture&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_RIGHT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active.y&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name&quot;, &quot;last_name&quot;, &quot;address_id&quot;, &quot;email&quot; AS &quot;staff_email&quot;, &quot;store_id&quot;, &quot;active&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.x&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_RIGHT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.y&quot;, &quot;TBL_RIGHT&quot;.&quot;picture&quot; AS &quot;picture&quot; ## FROM &quot;rental&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;staff&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;staff_id&quot; = &quot;TBL_RIGHT&quot;.&quot;staff_id&quot;) ## ) &quot;qzdwvvvtzq&quot;) &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;customer&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;rnitnthkfz&quot;) &quot;ohetoyqsmw&quot; Hand-written SQL code to do the same job will probably look a lot nicer and could be more efficient, but functionally dplyr does the job. 10.4.13 Qc &lt;- Q %&gt;% dplyr::count(customer_email) Until Q is executed, we can add to it. This behavior is the basis for a useful debugging and development process where queries are built up incrementally. Qc &lt;- Q %&gt;% dplyr::count(customer_email, sort = TRUE) When all the accumulated dplyr verbs are executed, they are submitted to the dbms and the number of rows that are returned follow the same rules as discussed above. Qc ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## # Ordered by: desc(n) ## customer_email n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 eleanor.hunt@sakilacustomer.org 46 ## 2 karl.seal@sakilacustomer.org 45 ## 3 clara.shaw@sakilacustomer.org 42 ## 4 marcia.dean@sakilacustomer.org 42 ## 5 tammy.sanders@sakilacustomer.org 41 ## 6 wesley.bull@sakilacustomer.org 40 ## 7 sue.peters@sakilacustomer.org 40 ## 8 marion.snyder@sakilacustomer.org 39 ## 9 rhonda.kennedy@sakilacustomer.org 39 ## 10 tim.cary@sakilacustomer.org 39 ## # … with more rows See more examples of lazy execution here. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) 10.5 Other resources Benjamin S. Baumer. 2017. A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data. https://arxiv.org/abs/1708.07073 dplyr Reference documentation: Remote tables. https://dplyr.tidyverse.org/reference/index.html#section-remote-tables Data Carpentry. SQL Databases and R. https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html https://www.techopedia.com/definition/1245/structured-query-language-sql↩ https://cran.r-project.org/doc/manuals/r-release/R-ints.html#Lazy-loading↩ https://colinfay.me/lazyeval/↩ http://adv-r.had.co.nz/Functions.html#function-arguments↩ https://colinfay.me/tidyeval-1/↩ https://www.quora.com/What-is-a-lazy-query↩ "],
["chapter-dbi-package-sql.html", "Chapter 11 DBI package and SQL 11.1 Setup 11.2 SQL in R Markdown 11.3 DBI Package 11.4 Dividing the work between R on your machine and the DBMS", " Chapter 11 DBI package and SQL This chapter: Introduces more DBI functions and demonstrates techniques for submitting SQL to the dbms Illustrates some of the differences between writing dplyr commands and SQL Suggests some strategies for dividing the work between your local R session and the dbms 11.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to those instructions to configure your environment. Otherwise, start your sql-pet container: sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 11.2 SQL in R Markdown When you create a report to run repeatedly, you might want to put that query into R markdown. See the discussion of multiple language engines in R Markdown. That way you can also execute that SQL code in a chunk with the following header: {sql, connection=con, output.var = &quot;query_results&quot;} SELECT &quot;staff_id&quot;, COUNT(*) AS &quot;n&quot; FROM &quot;rental&quot; GROUP BY &quot;staff_id&quot;; Rmarkdown stored that query result in a tibble: query_results ## staff_id n ## 1 2 8004 ## 2 1 8040 11.3 DBI Package In this chapter we touched on a number of functions from the DBI Package. The table in file 96b shows other functions in the package. The Chapter column references a section in the book if we have used it. film_table &lt;- tbl(con, &quot;film&quot;) 11.3.1 Retrieve the whole table SQL code that is submitted to a database is evaluated all at once7. To think through an SQL query, you can use dplyr to build it up step by step and then convert it to SQL code. Or you can use an IDE such as pgAdmin to develop your SQL code. Once you have the SQL code, the following R code demonstrates how to use dbSendQuery to submit SQL from your R environment. result_set &lt;- DBI::dbSendQuery(con, &#39;SELECT &quot;title&quot;, &quot;rental_duration&quot;, &quot;length&quot; FROM &quot;film&quot; WHERE (&quot;rental_duration&quot; &gt; 5.0 AND &quot;length&quot; &gt; 117.0)&#39;) long_rental_films &lt;- DBI::dbFetch(result_set) str(long_rental_films) ## &#39;data.frame&#39;: 202 obs. of 3 variables: ## $ title : chr &quot;African Egg&quot; &quot;Alamo Videotape&quot; &quot;Alaska Phantom&quot; &quot;Alley Evolution&quot; ... ## $ rental_duration: int 6 6 6 6 6 7 6 7 6 6 ... ## $ length : int 130 126 136 180 181 179 119 127 170 162 ... DBI::dbClearResult(result_set) The dbFetch function returns a data.frame, so you don’t have dplyr’s guardrails that manage the amount of data returned to your workspace. You need to manage the amount of data yourself, using the n = argument of dbFetch to specify the maximum number of records to retrieve per fetch. In the code above, we did not specify n, so dbFetch returned all pending records as the default behavior. When you are finished using the result set object, remember to free all of the associated resources with dbClearResult, as shown in the code above for the result_set variable. 11.3.2 Or a chunk at a time The following code demonstrates using the n argument to dbFetch to specify the maximum number of rows to return. Normally, you would pick some fixed number of records to return each time, but this code shows that you can vary the number of records returned by each call to dbFetch. result_set &lt;- dbSendQuery(con, &#39;SELECT &quot;title&quot;, &quot;rental_duration&quot;, &quot;length&quot; FROM &quot;film&quot; WHERE (&quot;rental_duration&quot; &gt; 5.0 AND &quot;length&quot; &gt; 117.0)&#39;) set.seed(5432) chunk_num &lt;- 0 while (!dbHasCompleted(result_set)) { chunk_num &lt;- chunk_num + 1 chunk &lt;- dbFetch(result_set, n = sample(7:13,1)) # print(nrow(chunk)) chunk$chunk_num &lt;- chunk_num if (!chunk_num %% 9) {print(chunk)} } ## title rental_duration length chunk_num ## 1 Grinch Massage 7 150 9 ## 2 Groundhog Uncut 6 139 9 ## 3 Half Outfield 6 146 9 ## 4 Hamlet Wisdom 7 146 9 ## 5 Harold French 6 168 9 ## 6 Hedwig Alter 7 169 9 ## 7 Holes Brannigan 7 128 9 ## 8 Hollow Jeopardy 7 136 9 ## 9 Holocaust Highball 6 149 9 ## 10 Home Pity 7 185 9 ## 11 Homicide Peach 6 141 9 ## 12 Hotel Happiness 6 181 9 ## title rental_duration length chunk_num ## 1 Towers Hurricane 7 144 18 ## 2 Town Ark 6 136 18 ## 3 Trading Pinocchio 6 170 18 ## 4 Trainspotting Strangers 7 132 18 ## 5 Uncut Suicides 7 172 18 ## 6 Unforgiven Zoolander 7 129 18 ## 7 Uprising Uptown 6 174 18 ## 8 Vanilla Day 7 122 18 ## 9 Vietnam Smoochy 7 174 18 dbClearResult(result_set) 11.4 Dividing the work between R on your machine and the DBMS They work together. 11.4.1 Make the server do as much work as you can show_query as a first draft of SQL. May or may not use SQL code submitted directly. 11.4.2 Criteria for choosing between dplyr and native SQL This probably belongs later in the book. performance considerations: first get the right data, then worry about performance Trade offs between leaving the data in PostgreSQL vs what’s kept in R: browsing the data larger samples and complete tables using what you know to write efficient queries that do most of the work on the server Where you place the collect function matters. Here is a typical string of dplyr verbs strung together with the magrittr %&gt;% pipe command that will be used to tease out the several different behaviors that a lazy query has when passed to different R functions. This query joins three connection objects into a query we’ll call Q: rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) staff_table &lt;- dplyr::tbl(con, &quot;staff&quot;) # the &#39;staff&#39; table has 2 rows customer_table &lt;- dplyr::tbl(con, &quot;customer&quot;) # the &#39;customer&#39; table has 599 rows Q &lt;- rental_table %&gt;% dplyr::left_join(staff_table, by = c(&quot;staff_id&quot; = &quot;staff_id&quot;)) %&gt;% dplyr::rename(staff_email = email) %&gt;% dplyr::left_join(customer_table, by = c(&quot;customer_id&quot; = &quot;customer_id&quot;)) %&gt;% dplyr::rename(customer_email = email) %&gt;% dplyr::select(rental_date, staff_email, customer_email) Q %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_date&quot;, &quot;staff_email&quot;, &quot;customer_email&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name.x&quot;, &quot;last_name.x&quot;, &quot;address_id.x&quot;, &quot;staff_email&quot;, &quot;store_id.x&quot;, &quot;active.x&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot;, &quot;store_id.y&quot;, &quot;first_name.y&quot;, &quot;last_name.y&quot;, &quot;email&quot; AS &quot;customer_email&quot;, &quot;address_id.y&quot;, &quot;activebool&quot;, &quot;create_date&quot;, &quot;last_update&quot;, &quot;active.y&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.x&quot; AS &quot;last_update.x&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;staff_email&quot; AS &quot;staff_email&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active.x&quot;, &quot;TBL_LEFT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_LEFT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.y&quot; AS &quot;last_update.y&quot;, &quot;TBL_LEFT&quot;.&quot;picture&quot; AS &quot;picture&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_RIGHT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active.y&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name&quot;, &quot;last_name&quot;, &quot;address_id&quot;, &quot;email&quot; AS &quot;staff_email&quot;, &quot;store_id&quot;, &quot;active&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.x&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_RIGHT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.y&quot;, &quot;TBL_RIGHT&quot;.&quot;picture&quot; AS &quot;picture&quot; ## FROM &quot;rental&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;staff&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;staff_id&quot; = &quot;TBL_RIGHT&quot;.&quot;staff_id&quot;) ## ) &quot;tvnvuviyiw&quot;) &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;customer&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;dkimtwhtoo&quot;) &quot;dkadgsqpgd&quot; Here is the SQL query formatted for readability: SELECT &quot;rental_date&quot;, &quot;staff_email&quot;, &quot;customer_email&quot; FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name.x&quot;, &quot;last_name.x&quot;, &quot;address_id.x&quot;, &quot;staff_email&quot;, &quot;store_id.x&quot;, &quot;active.x&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot;, &quot;store_id.y&quot;, &quot;first_name.y&quot;, &quot;last_name.y&quot;, &quot;email&quot; AS &quot;customer_email&quot;, &quot;address_id.y&quot;, &quot;activebool&quot;, &quot;create_date&quot;, &quot;last_update&quot;, &quot;active.y&quot; FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.x&quot; AS &quot;last_update.x&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;staff_email&quot; AS &quot;staff_email&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active.x&quot;, &quot;TBL_LEFT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_LEFT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.y&quot; AS &quot;last_update.y&quot;, &quot;TBL_LEFT&quot;.&quot;picture&quot; AS &quot;picture&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_RIGHT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active.y&quot; FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name&quot;, &quot;last_name&quot;, &quot;address_id&quot;, &quot;email&quot; AS &quot;staff_email&quot;, &quot;store_id&quot;, &quot;active&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot; FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.x&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name&quot; , &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_RIGHT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.y&quot;, &quot;TBL_RIGHT&quot;.&quot;picture&quot; AS &quot;picture&quot; FROM &quot;rental&quot; AS &quot;TBL_LEFT&quot; LEFT JOIN &quot;staff&quot; AS &quot;TBL_RIGHT&quot; ON ( &quot;TBL_LEFT&quot;.&quot;staff_id&quot; = &quot;TBL_RIGHT&quot;.&quot;staff_id&quot; )) &quot;ymdofxkiex&quot;) &quot;TBL_LEFT&quot; LEFT JOIN &quot;customer&quot; AS &quot;TBL_RIGHT&quot; ON ( &quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot; )) &quot;exddcnhait&quot;) &quot;aohfdiedlb&quot; Hand-written SQL code to do the same job will probably look a lot nicer and could be more efficient, but functionally dplyr does the job. GQ &lt;- dbGetQuery( con, &quot;select r.rental_date, s.email staff_email,c.email customer_email from rental r left outer join staff s on r.staff_id = s.staff_id left outer join customer c on r.customer_id = c.customer_id &quot; ) But because Q hasn’t been executed, we can add to it. This behavior is the basis for a useful debugging and development process where queries are built up incrementally. Where you place the collect function matters. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) From R’s perspective. Actually there are 4 steps behind the scenes.↩ "],
["chapter-sql-joins.html", "Chapter 12 Introduction to SQL Joins 12.1 Setup 12.2 Making up data for Join Examples 12.3 SQL Multi-Row Insert Data Syntax 12.4 SQL Multi-Row Insert Data Example 12.5 DPLYR Multi-Row Insert Data Example 12.6 Joins 12.7 Natural Join Delayed Time Bomb 12.8 Join Templates 12.9 Inner Joins 12.10 Left Joins 12.11 Why Include one of the Inner Join Key columns? 12.12 Right Joins 12.13 Full Join 12.14 Semi Join 12.15 Anti Joins 12.16 Non-Equa-Join Example", " Chapter 12 Introduction to SQL Joins This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies 12.1 Setup These packages are called in almost every chapter of the book: Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 31 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R. Need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 12.2 Making up data for Join Examples Each chapter in the book stands on its own. If you have worked through the code blocks in this chapter in a previous session, you created some new customer records in order to work through material in the rest of the chapter. The DVD rental database data is too clean to demonstrate some join concepts. To dirty the data, this chapter performs a number of database operations on data tables that a data analyst is typically restricted from doing in the real world. Deleting records from tables. Inserting records from tables. Enabling and disabling table constraints. In our Docker environment, you have no restrictions on the database operations you can perform. In the next couple of code blocks, we delete the new data and then recreate the data for the join examples in this next chapter. 12.2.1 SQL Delete Data Syntax DELETE FROM &lt;source&gt; WHERE &lt;where_clause&gt;; 12.2.2 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental database’s highest customer_id = 599. dbExecute() always returns a scalar numeric that specifies the number of rows affected by the statement. dbExecute( con, &quot;delete from customer where customer_id &gt;= 600; &quot; ) ## [1] 0 The number above tells us how many rows were actually deleted from the customer table. 12.2.3 Delete New Practice Store from the Store Table. In the next code block we delete out the new stores that were added when the book was compliled or added working through the exercises. Out of the box, the DVD rental database’s highest store_id = 2. dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 0 12.2.4 SQL Single Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. The column list is the list of column names on the table and the corresponding list of values must have the correct data type. The following code block returns the CUSTOMER column names and data types. customer_cols &lt;- dbGetQuery( con, &quot;select table_name, column_name, ordinal_position, data_type from information_schema.columns where table_catalog = &#39;dvdrental&#39; and table_name = &#39;customer&#39; ;&quot; ) sp_print_df(customer_cols) In the next code block, we insert Sophie as a new customer into the customer table via a SQL insert statement. The columns list clause has three id columns, customer_id, store_id, and address_id. The customer_id is a primary key column and the other two ‘look like’ foreign key columns. For now, we are interested in getting some new customers into the customer table. We look at the relations between the customer and the store tables later in this chapter. dbExecute( con, &quot; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) &quot; ) ## [1] 1 The number above should be 1 indicating that one record was inserted. new_customers &lt;- dbGetQuery(con ,&quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 12.2.5 Primary Key Constraint Error Message For the new customers, we are concerned with not violating the PK and FK constraints. In the next SQL code block, we try and reinsert the newly created customer record inserted above. Instead of having the code block fail, it throws a duplicate key exception error message. If you knit the document, the exception error message is thrown to the R Markdown tab. dbExecute(con, &quot; do $$ DECLARE v_customer_id INTEGER; begin v_customer_id = 600; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(v_customer_id,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE ,now(),now()::date,1); exception when unique_violation then raise notice &#39;SQLERRM = %, customer_id = %&#39;, SQLERRM, v_customer_id; when others then raise &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 The number above shows how many rows were inserted. To ensure that the thrown error message is part of the book, the error message is shown below. NOTICE: SQLERRM = duplicate key value violates unique constraint &quot;customer_pkey&quot;, customer_id = 600 CONTEXT: PL/pgSQL function inline_code_block line 12 at RAISE 12.2.6 R Exercise: Inserting a Single Row via a Dataframe In the following code block replace Sophie Yang with your name where appropriate. Note: The last data frame parameter sets the stringsAsFactors is FALSE. Databases do not have a native FACTOR type. The dataframe column names must match the table column names. The dbWriteTable function needs append = true to actually insert the new row. The dbWriteTable function has an option ‘overwrite’. It is set to FALSE by default. If it is set to TRUE, the table is first truncated before the row is inserted. No write occurs if both overwrite and append = FALSE. df &lt;- data.frame( customer_id = 601 , store_id = 2 , first_name = &quot;Sophie&quot; , last_name = &quot;Yang&quot; , email = &quot;sophie.yang@sakilacustomer.org&quot; , address_id = 1 , activebool = TRUE , create_date = Sys.Date() , last_update = Sys.time() , active = 1 , stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df, append = TRUE, row.names = FALSE) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 12.3 SQL Multi-Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list1&gt;, ... &lt;values listn&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns (&lt;values list&gt;) : values assoicated with the column list. Postgres and some other flavors of SQL allow multiple rows to be inserted at a time. The syntax is identical to the Single Row syntax, but includes multiple (&lt;values list&gt;) clauses separated by commas. Note that each value list is enclosed it a set of parenthesis. The following code block illustrates the SQL multi-row insert. Note that the customer_id column takes on sequential values to satisfy the PK constraint. 12.4 SQL Multi-Row Insert Data Example # dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(602,4,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE ,now()::date,now()::date,1) ,(603,5,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE ,now()::date,now()::date,1) ,(604,6,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE ,now()::date,now()::date,1) ;&quot; ) ## [1] 3 12.5 DPLYR Multi-Row Insert Data Example The Postgres R multi-row insert is similar to the single row insert. The single column values are converted to a vector of values. 12.5.1 R Exercise: Inserting Multiple Rows via a Dataframe Replace the two first_name, last_name, and email column values with your own made up values in the following code block. The output should be all of our new customers, customer_id = {600 - 606}. customer_id &lt;- c(605, 606) store_id &lt;- c(3, 4) first_name &lt;- c(&quot;John&quot;, &quot;Ian&quot;) last_name &lt;- c(&quot;Smith&quot;, &quot;Frantz&quot;) email &lt;- c(&quot;john.smith@sakilacustomer.org&quot;, &quot;ian.frantz@sakilacustomer.org&quot;) address_id &lt;- c(3, 4) activebool &lt;- c(TRUE, TRUE) create_date &lt;- c(Sys.Date(), Sys.Date()) last_update &lt;- c(Sys.time(), Sys.time()) active &lt;- c(1, 1) df2 &lt;- data.frame(customer_id, store_id, first_name, last_name, email, address_id, activebool, create_date, last_update, active, stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df2, append = TRUE, row.names = FALSE ) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) Confirm that the two new rows, customer_id = { 605, 606} are in the output. The next two code block show all the rows in the store and staff tables. Notice that neither table has a staff_id or a manager_staff_id = 10. We will attempt to insert such a row in the upcoming code blocks. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) staff &lt;- dbGetQuery(con ,&quot;select staff_id, first_name, last_name, address_id, email, store_id from staff;&quot;) sp_print_df(staff) 12.5.2 Creating a Messy Store Row A new store row is needed to illustrate a right outer join in a future code block. However, one cannot insert/update a row into the store table with a manager_staff_id = 10 because of a foreign key constraint on the manager_staff_id column. The manager_staff_id value must satisfy two conditions before the database will allow the new store row to be inserted into the table when the table constraints are enabled.: The manager_staff_id must be unique when inserted into the store table. The manager_staff_id must match a staff table staff_id value. Next we show both error messages: The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 1, but fails with a unique constraint error message. The manager_staff_id = 1 already exists in the store table. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 1; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 Error in result_create(conn@ptr, statement) : Failed to prepare query: server closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request. The number above should be 0 and indicates no row was inserted. The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 10, but fails with a foreign key constraint error message because there does not exist a staff table row with staff_id = 10. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 10; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 NOTICE: SQLERRM = insert or update on table &quot;store&quot; violates foreign key constraint &quot;store_manager_staff_id_fkey&quot;, manager_staff_id = 10 CONTEXT: PL/pgSQL function inline_code_block line 9 at RAISE Again, the number above should be 0 and indicates no row was inserted. The following three code blocks disables all the database constraints on the store table Inserts the store row with store_id = 10 via a dataframe. Re-enabes the database constraints on the store table # dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 df &lt;- data.frame( store_id = 10 , manager_staff_id = 10 , address_id = 10 , last_update = Sys.time() ) dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, row.names = FALSE) dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 The zeros after the dbExecute code blocks indicate that the dbExecute calls did not alter any rows on the table. In the next code block we confirm our new row, store_id = 10, was actually inserted. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) 12.6 Joins In section ‘SQL Quick Start Simple Retrieval’, there is a brief discussion of databases and 3NF. One of the goals of normalization is to eliminate redundant data being kept in multiple tables and having each table contain a very granular level of detail. If a record then needs to be updated, it is updated in one table instead of multiple tables improving overall system performance. This also helps simplify and maintain referential integrity between tables. Normalization breaks data down and JOINs denormalizes the data and builds it back up. The tables are typically related via a primary key - foreign key relationship. The Postgres database enforces the primary and foreign key constraints in the DVD rental database. 12.6.1 Join Types The diagram above shows the hierarchy of the different types of joins. In the boxes above: The joins are based on a single column from the two tables, the left and right tables. Joins can be based on multiple columns from both tables. The L. and R. are aliases for the left and right table names. Often the joining columns have the same name as in the Natural Join, L.col1 = R.col1 However, the joining column names can be different L.col1 = R.col2. All joins are based on equality between the table columns, L.col1 = R.col2, except the inner join which can use non-equality column conditions. Non-equality column conditions are rare. Equa Joins are subset of the Inner Join. For this tutorial, we can think of joins as either an Inner/eqau Join or an Outer Join. Instead of showing standard Venn diagrams showing the different JOINS, we use an analogy. For those interested though, the typical Venn diagrams can be found here. 12.6.2 Valentines Party Imagine you are at a large costume Valentine’s Day dance party. The hostess of the party, a data scientist, would like to learn more about the people attending her party. When the band takes a break, she lets everyone know it is time for the judges to evaluate the winners for best costumes and associated prizes. ValentinesDay She requests the following: All the couples at the party line up in front of her in a single line with the men on her left and the women on her right, (inner join) All the remaining men to form a second line two feet behind the married men, (left outer join, all couples + unattached men) All the remaining women to form a third line two feet in front of the married women, (right outer join, all couples + unattached women) As our data scientist looks out, she can clearly see the three distinct lines, the single men, the man woman couples, and the single women, a full outer join. As the three judges start walking down the lines, she makes one more announcement. There is a special prize for the man and woman who can guess the average age of the members of the opposite sex. To give everyone a chance to come up with an average age, she asks the men to stay in line and the women to move down the men’s line in order circling back around until they get back to their starting point in line, (Cartesian join, every man seen by every woman and vice versa). It is hard enough to tell someone’s age when they don’t have a mask, how do you get the average age when people have masks? The hostess knows that there is usually some data anomalies. As she looks out she sees a small cluster of people who did not line up. Being the hostess with the mostest, she wants to get to know that small cluster better. Since they are far off and in costume, she cannot tell if they are men or women. More importantly, she does not know if they identify as a man or a woman, both – (kind of a stretch for a self join), neither, or something else. Ah, the inquisitive mind wants to know. 12.6.3 Join Syntax The table below shows the two R join function call formats, standalone function call and pipe function call and the corresponding SQL join format. Join dplyr sql inner inner_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% inner_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) left left_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c left outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% left_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) right right_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c right outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% right_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) full full_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c full outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% full_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) semi semi_join(customer_tbl, rental_tbl, by = ‘customer_id’) customer_tbl %&gt;% semi_join(rental_tbl, by = ‘customer_id’) anti anti_join(customer_tbl, rental_tbl, by = ‘customer_id’) 12.6.4 Join Tables The dplyr join documentation describes two different types of joins, mutating and filtering joins. For those coming to R with a SQL background, the mutating documentation is misleading in one respect. Here is the inner_join documentation. inner_join() return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned. The misleading part is ‘and all the columns from x and y.’ If the join column is KEY, SQL will return x.KEY and y.KEY. Dplyr returns just KEY. It appears that the KEY value comes from the driving table. This is important if you are translating SQL to R because SQL developers will reference both columns x.KEY and y.KEY. One needs to mutate the the y.KEY column. This difference should become clear in the outer join examples. In the next couple of examples, we will use a small sample of the customer and store table data from the database to illustrate the diffent joins. In the *_join verbs, the by and suffix parameters are included because it helps document the actual join and the source of join columns. 12.7 Natural Join Delayed Time Bomb The dplyr default join is a natural join, joining tables on common column names. One of many links why one should not use natural joins can be found here. If two tables are joined via a natural join on column C1 the join continues to work as long as no additional common columns are added to either table. If a new new column C2 is added to one of the tables and C2 already exists in the other table, BOOM, the delayed time bomb goes off. The natural join still executes, doesn’t throw any errors, but the returned result set may be smaller, much smaller, than before the new C2 column was added. 12.7.1 SQL Customer store_id Distribution The next code block calculates the store_id distribution in the customer and store tables across all their rows. The results will be used in following sections to validate different join result sets. store_distribution_sql &lt;- dbGetQuery(con ,&quot;select &#39;customer&#39; tbl, store_id,count(*) count from customer group by store_id union select &#39;store&#39; tbl,store_id,count(*) count from store group by store_id order by tbl,store_id;&quot; ) sp_print_df(store_distribution_sql) 12.7.2 Sample Customer and Store Join Data The following code block extracts sample customer and the store data. The customer data is restricted to 10 rows to illustrate the different joins. The 10 rows are used in the detail examples in order to perform a sanity check that the join is actually working. Each detail example is followed by an aggregated summary across all rows of customer and store table. sample_customers &lt;- dbGetQuery(con,&quot;select customer_id,first_name,last_name,store_id from customer where customer_id between 595 and 604&quot;) stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(sample_customers) sp_print_df(stores) 12.7.3 dplyr store_id distribution Exercise Execute and Review the output from the code block below. Union and arrange the output to match the SQL output in the previous code block. customer_table &lt;- DBI::dbReadTable(con, &quot;customer&quot;) store_table &lt;- DBI::dbReadTable(con, &quot;store&quot;) customer_summary &lt;- customer_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;customer&#39;) %&gt;% select(table,store_id,count) store_summary &lt;- store_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;store&#39;) %&gt;% select(table,store_id,count) sp_print_df(customer_summary) sp_print_df(store_summary) ## UNION the two summary tables and ARRANGE the output to match the SQL output from the previouse code block 12.8 Join Templates In this section we perform various joins using dplyr and SQL. Each dplyr code block has three purposes. Show working detail/summary data join examples. The code blocks can be used as templates for beginning more complex dplyr pipes. The code blocks show the number of joins performed. In these examples the ‘customer’ is always the left table and ‘store’ is always the right table. The join condition shown in the by parameter by = c(&#39;store_id&#39;=&#39;store_id&#39;) is on the common foreign - primary key column store_id. This is technically an equi-join condition which makes our joins 1-to-1 and keeps the result set small. In multi-column joins, each language_id would be replaced with a vector of column names used in the join by position. Note the column names do not need to be identical by position. The suffix parameter is a way to distinguish the same column name in the joined tables. The suffixes are usually an single letter to represent the name of the table. 12.9 Inner Joins 12.9.1 SQL Inner Join Details {example_inner-join-details-sql} For an inner join between two tables, it doesn’t matter which table is on the left, the first table, and which is on the right, the second table, because join conditions on both tables must be satisfied. Reviewing the table below shows the inner join on our 10 sample customers and 3 store records returned only 6 rows. The inner join detail shows only rows with matching store_id’s. customer_store_details_sij &lt;- dbGetQuery(con, &quot;select &#39;ij&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot;) sp_print_df(customer_store_details_sij) 12.9.2 Dplyr Inner Join Details {example_inner-join-details-dplyr} customer_ij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% select(customer_id,first_name,last_name,store_id ,store_id,manager_staff_id, address_id) sp_print_df(customer_ij) Compare the output from the SQL and Dplyr version. The SQL output has a c_store_id and a s_store_id column and the Dplyr output only has store_id. In this case, because it is an inner join, it doesn’t matter because they will always the same. 12.9.3 SQL Inner Join Summary {example_inner-join-summary-sql} Note that both the store_id is available from both the customer and store tables, c.store_id,s.store_id, in the select clause. customer_store_summay_sij &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id,s.store_id s_store_id,count(*) n from customer c join store s on c.store_id = s.store_id group by c.store_id,s.store_id;&quot; ) sp_print_df(customer_store_summay_sij) 12.9.4 Dplyr Inner Join Summary {example_inner-join-summary_dplyr} In the previous SQL code block, c. and s. were used in the inner join as table aliases. The dplyr suffix is similar to the SQL table alias. The role of the dplyr suffix and the SQL alias is to disambiguate duplicate table and column names referenced. customer_store_summary_dij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;ij&quot; ,c_store_id = if_else(is.na(customer_id),customer_id, store_id) ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% group_by(join_type,c_store_id,s_store_id) %&gt;% summarize(n = n()) sp_print_df(customer_store_summary_dij) 12.10 Left Joins 12.10.1 SQL Left Join Details {example_left-join-details-sql} The SQL block below shows all 10 sample customer rows, the customer table is on the left and is the driving table, in the detail output which join to 2 of the 3 rows in the store table. All the rows with customer store_id greater than 2 have null/blank store column values. customer_store_details_sloj &lt;- dbGetQuery(con, &quot;select &#39;loj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c left join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot;) sp_print_df(customer_store_details_sloj) 12.10.2 Dplyr Left Join Details {example_left-join-details-dplyr} The next code block shows the left join details. Note that the s_store_id column is derived via the mutate function, but not shown in the output below. Without the s_store_id column, it might accidentally be assumed that the store.store_id = customer.store_id when the store.store_id values are actually NULL/NA based on the output without the s_store_id column. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% select(customer_id,first_name,last_name,store_id ,manager_staff_id, address_id) sp_print_df(customer_store_detail_dloj) The following code block includes the derived s_store_id value. The output makes it explicit that the s_store_id value is missing. The sp_print_df function is replaced with the print function to show the actual NA values. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% rename(c_store_id = store_id) %&gt;% select(customer_id,first_name,last_name,c_store_id ,s_store_id,manager_staff_id, address_id) print(customer_store_detail_dloj) ## customer_id first_name last_name c_store_id s_store_id manager_staff_id ## 1 595 Terrence Gunderson 1 1 1 ## 2 596 Enrique Forsythe 1 1 1 ## 3 597 Freddie Duggan 1 1 1 ## 4 598 Wade Delvalle 1 1 1 ## 5 599 Austin Cintron 2 2 2 ## 6 600 Sophie Yang 3 NA NA ## 7 601 Sophie Yang 2 2 2 ## 8 602 John Smith 4 NA NA ## 9 603 Ian Frantz 5 NA NA ## 10 604 Ed Borasky 6 NA NA In the remaining examples, the dplyr code blocks will show both the customer and store store_id values with the either c_ or s_ store_id prefix . The sp_print_df function returns the SQL NULL and R NA values as blanks. 12.10.3 SQL Left Join Summary {example_left-join-summary-sql} For a left outer join between two tables, it does matter which table is on the left and which is on the right, because every row in the left table is returned when there is no where/filter condition. The second table returns row column values if the join condition exists or null collumn values if the join condition does not exist. The left join is the most frequently used join type. Note that SQL returns the store_id from both the customer and store tables, c.store_id,s.store_id, in the select clause. customer_store_summary_sloj &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id,s.store_id s_store_id,count(*) loj from customer c left join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by c.store_id;&quot; ) sp_print_df(customer_store_summary_sloj) The lojs column returns the number of rows found on the store_id, from the customer table and the store table if on both tables, rows 1 - 2. The right table, the store table returned blank/NA, when the key only exists in the customer table, rows 3 - 6. The left outer join always returns all rows from the left table, the driving/key table, if not reduced via a filter()/where clause. All inner join rows can reference all columns/derived columns specified in the select clause from both the left and right tables. All rows from the left table, the outer table, without a matching row on the right returns all the columns/derived column values specified in the select clause from the left, but the values from right table have all values of NA. 12.10.4 Dplyr Left Join Summary {example_left-join-summary-dplyr} The dplyr outer join verbs do not return the non-driving table join values. Compare the mutate verb s_store_id in the code block below with s.store_id in the equivalent SQL code block above. customer_store_summary_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% group_by(join_type, store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% rename(c_store_id = store_id) %&gt;% select(join_type, c_store_id, s_store_id, n) sp_print_df(customer_store_summary_dloj) print(customer_store_summary_dloj) ## # A tibble: 6 x 4 ## # Groups: join_type, c_store_id [6] ## join_type c_store_id s_store_id n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 loj 1 1 326 ## 2 loj 2 2 274 ## 3 loj 3 NA 2 ## 4 loj 4 NA 2 ## 5 loj 5 NA 1 ## 6 loj 6 NA 1 12.11 Why Include one of the Inner Join Key columns? It is not uncommon to have many many tables joined together as a series of left outer joins. If the inner join key column is included in the output, one knows that the inner join condition was met or not. If the key column is not shown and non-key columns are shown from the inner table, they may actually be null. It is often the case that a long series of left outer joins just join on the key column to get one value out of the table to join to the next table in the series. One can think of the two components of an inner join as a transaction is either in an open state, no matching rows in the inner table or a closed state with one or more matching rows in the inner table. Assume that we have a four DVD rental step process represented via table A, B, C, and D left outer joined together. Summing the null and non-null keys together across all four tables gives a quick snap shot of the business in the four different steps. We will review this concept in some detail in one of the future exercises. 12.12 Right Joins 12.12.1 SQL Right Join Details {example_right-join-details-sql} The SQL block below shows only our sample customer rows, (customer_id between 595 and 604). The driving table is on the right, the store table. Only six of the 10 sample customer rows appear which have store_id = {1, 2}. All three store rows appear, row_id = {1,2,10}. The right join is least frequently used join type. customer_store_detail_sroj &lt;- dbGetQuery(con, &quot;select &#39;roj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c right join store s on c.store_id = s.store_id where coalesce(customer_id,595) between 595 and 604;&quot;) sp_print_df(customer_store_detail_sroj) Compare the SQL left join where clause where customer_id between 595 and 604;&quot;) with the SQL right join where clause where coalesce(customer_id,595) between 595 and 604;&quot;) The customer table is the driving table in the left join and always returns all rows from the customer table on the left that match the join and satisfy the where clause. The store table is the driving table in the right join and always returns all rows from the store table on the right that match the join and satisfy the where clause. The right outer join condition shown always returns the store.store_id=10 row. Since the customer table does not have the corresponding row to join to, the right outer join return a customer row with all null column values. The coalesce is a NULL if-then-else test. If the customer_id is null, it returns 595 to prevent the store_id = 10 row from being dropped from the result set. The right outer join clause can be rewritten as where customer_id between 595 and 604 or customer_id is null; See the next dplyr code block to see the alternative where clause shown above. 12.12.2 Dplyr Right Join Details {example_right-join-details-dplyr} customer_store_detail_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate(join_type = &quot;roj&quot; ,c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename(s_store_id = store_id) %&gt;% select(customer_id,first_name,last_name,s_store_id ,c_store_id,manager_staff_id, address_id) sp_print_df(customer_store_detail_droj) 12.12.3 SQL Right Outer Join Summary {example_right-join-summary-sql} customer_store_summary_sroj &lt;- dbGetQuery( con, &quot;select &#39;roj&#39; join_type,c.store_id c_store_id,s.store_id s_store_id,count(*) rojs from customer c right outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id;&quot; ) sp_print_df(customer_store_summary_sroj) The rojs column returns the number of rows found on the keys from the right table, store, and the left table, the customer table. The right outer join always returns all rows from the right table, the driving/key table, if not reduced via a filter()/where clause. All rows that inner join returns all the columns/derived columns specified in the select clause from both the left and right tables. All rows from the right table, the outer table, without a matching row on the left returns all the columns/derived column values specified in the select clause from the right, but the values from left table have all values of NA. This line 3, store.store_id = 10. 12.12.4 dplyr Right Join Summary {example_right-join-summary-dplyr} customer_store_summary_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;)), all = store_table) %&gt;% mutate( c_store_id = if_else(is.na(customer_id),customer_id, store_id) , join_type = &quot;rojs&quot; ) %&gt;% group_by(join_type, store_id,c_store_id) %&gt;% summarize(n = n()) %&gt;% rename(s_store_id = store_id) %&gt;% select(join_type, s_store_id,c_store_id, n) sp_print_df(customer_store_summary_droj) 12.13 Full Join 12.13.1 SQL Full Join Details {example_full-join-details-sql} The full outer join is a conbination of the left and right outer joins and returns all matched and unmatched rows from the ON clause. The matched rows return their table column values and the unmatched rows return NULL column values. This can result in a very large result set. The next SQL block implements a full outer join and returns 12 rows. Change the Show entries from 10 to 25 to see all the entries. customer_store_details_sfoj &lt;- dbGetQuery(con, &quot;select &#39;foj&#39; join_type, c.customer_id,c.first_name,c.last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id,s.address_id from customer c full outer join store s on c.store_id = s.store_id where coalesce(c.customer_id,595) between 595 and 604;&quot;) sp_print_df(customer_store_details_sfoj) 12.13.2 Dplyr Full Join Details {example_full-join-details-sql} customer_store_detail_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate(join_type = &quot;roj&quot; ,c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename(s_store_id = store_id) %&gt;% select(customer_id,first_name,last_name,s_store_id ,c_store_id,manager_staff_id, address_id) sp_print_df(customer_store_detail_dfoj) 12.13.3 SQL Full Join Summary {example_full-join-summary-sql} The result set below is ordered by the store.store_id. customer_store_summary_sfoj &lt;- dbGetQuery( con, &quot;select &#39;foj&#39; join_type,c.store_id c_store_id,s.store_id s_store_id,count(*) fojs from customer c full outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id,c.store_id;&quot; ) sp_print_df(customer_store_summary_sfoj) 12.13.4 Dplyr Full Join Summary {example_full-join-summary-dplyr} The full outer join summary seven rows. Store_id = {1,2} appear in both table tables. Store_id = {3 - 6} appear only in the customer table which is on the left. Store_id = 10 appears only in the store table which is on the right. customer_store_summary_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &quot;fojs&quot; ,c_store_id = if_else(is.na(customer_id),customer_id, store_id) ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% group_by(join_type,c_store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% arrange(s_store_id) sp_print_df(customer_store_summary_dfoj) 12.14 Semi Join Below is the dplyr semi_join documentation. semi_join() return all rows from x where there are matching values in y, keeping just columns from x. A semi join differs from an inner join because an inner join will return one row of x for each matching row of y, where a semi join will never duplicate rows of x. The semi join always returns one and only one row from the x table that satisfies the inner join condition. If we look at one key value on both x and y where the x table has 1 x.key row and y and n y.key rows, then the inner join returns n x.key rows, (1-to-n), and the semi-join returns just one x.key row, (1-to-1). 12.14.1 SQL Semi Join Customer to Store {example_semi-join-sql-1} SQL does not have an explicity ‘semi join’ key word. The semi join reduces relationships from 1-to-n to 1-to-1. SQL uses an EXISTS - subquery syntax to implement the semi join. 12.14.1.1 SQL EXISTS and Correlated SubQuery Syntax select * FROM table1 l WHERE EXISTS(SELECT 1 FROM table2 r where l.c = r.c) The EXISTS keyword checks if one or more rows satsify the SELECT clause enclosed in parenthesis, the correlated subquery. The r.c column from table2, the inner/right table, is correlated to the l.c column from table1, the outer/left table. For all the table1 rows where the EXISTS clause returns TRUE, the table1 rows are returned. There is no way to reference table2 columns in the outer select, hence the semi join. All the previous joins were mutating joins, the joins resulted in a blending of columns from both tables. A semi join only returns rows from a single table and is a filtering join. The mutating examples included a count column to show the 1-to-n relationships. Filtering joins are 1-to-1 and the count column is dropped in the following examples. customer_store_ssj &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id from customer c where customer_id &gt; 594 and exists( select 1 from store s where c.store_id = s.store_id); ;&quot;) sp_print_df(customer_store_ssj) Note that this returned the six rows from the customer table that satisfied the c.store_id = s.store_id join condition. It is the same as the SQL Inner Join example earlier, but without the store columns. All the relationships are 1-to-1. 12.14.2 Dplyr Semi Join Customer to Store {example_semi-join-dplyr-1} The corresponding Dplyr version is shown in the next code block. customer_store_dsj &lt;- customer_table %&gt;% semi_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type,customer_id,first_name,last_name,store_id ,store_id) sp_print_df(customer_store_dsj) 12.14.3 SQL Semi Join Store to Customer {example_semi-join-sql-2} In the following Semi Join, the driving table is switched to the store table and our 10 sample customers as the right table. store_customer_detail_ssj &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,s.store_id s_store_id,s.manager_staff_id, s.address_id from store s where EXISTS(select 1 from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) ;&quot;) sp_print_df(store_customer_detail_ssj) Here we see that we get the two rows from the store table that satisfy the s.store_id = c.store_id, store_id = {1,2}. In this example the relationship between store and customer is 1-to-n, but we do not know that from the output. 12.14.4 Dplyr Semi Join Store to Customer {example_semi-join-dplyr-2} The corresponding Dplyr version is shown in the next code block. Note that the filter condition on the customer table has been removed because the semi_join does not return any customer columns. store_customer_dsj &lt;- store_table %&gt;% semi_join(customer_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type,store_id,manager_staff_id, address_id) sp_print_df(store_customer_dsj) 12.14.5 SQL Semi Join Store to Customer Take 2 {example_semi-join-sql-3} In the Semi Join Customer to Store examples, we saw four rows with store_id = 1 and two rows with store_id = 2. The EXISTS key word is replaced with a count of the matching rows. store_customer_detail_ssj2 &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,s.store_id s_store_id,s.manager_staff_id, s.address_id from store s where (select count(*) from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) in (2,4) ;&quot;) sp_print_df(store_customer_detail_ssj2) To generalize the test above, replace in {2,4} with &gt; 0. 12.15 Anti Joins A semi join returns rows from one table that has one or more matching rows in the other table. The anti join returns rows from one table that has no matching rows in the other table. 12.15.0.1 dplyr anti Join {example_anti-join-dplyr} The anti join is an outer join without the inner joined rows. It only returns the rows from the driving table that do not have a matching row from the other table. customer_store_aj &lt;- customer_table %&gt;% filter(customer_id &gt; 594) %&gt;% anti_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &quot;anti_join&quot;) sp_print_df(customer_store_aj) All of the rows returned from the customer table have store_id = {3 - 6} which do not exist in the store_id. 12.15.0.2 SQL anti Join 1, NOT EXISTS and Correlated subquery {example_anti-join-sql-1} SQL doesn’t have an anti join key word. Here are three different ways to achieve the same result. This is the negation of the same construct used in the semi join discusion. The anit-join tests for 0 matches instead of 1 or more matches for the semi-join. rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where not exists (select 1 from store s where s.store_id = c.store_id) order by c.customer_id &quot; ) sp_print_df(rs) 12.15.0.3 SQL anti Join 2, Left Outer Join where NULL on Right {example_anti-join-sql-1} rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id ajs from customer c left outer join store s on c.store_id = s.store_id where s.store_id is null order by c.customer_id;&quot; ) sp_print_df(rs) 12.15.0.4 SQL anti Join 3, ID in driving table and NOT IN lookup table {example_anti-join-sql-3} rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where c.store_id NOT IN (select store_id from store) order by c.customer_id;&quot; ) sp_print_df(rs) 12.16 Non-Equa-Join Example All the previous examples are equa-joins and is the most common type of join. The next example is made up and shows a ‘&lt;=’ join. The store table is usd. Assume that the store_id actually represents some distance. The example shows all distances &lt;= to all other distances. store_store_slej &lt;- dbGetQuery( con, &quot;select &#39;lej&#39; join_type,s1.store_id starts,s2.store_id stops, s2.store_id - s1.store_id delta from store s1 join store s2 on s1.store_id &lt;= s2.store_id order by s1.store_id;&quot; ) sp_print_df(store_store_slej) 12.16.1 Dplyr Non-equa Join {example_inner-join-dplyr} Dplyr doesn’t currently support a non-equa join. In the by parameter, one can not change the ‘=’ to ‘&lt;=’ as shown below. {r} store_store_slej &lt;- store_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; &lt;= &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) The above code block throws the following error message. Error: `by` must be a (named) character vector, list, or NULL for natural joins (not recommended in production code), not logical Call `rlang::last_error()` to see a backtrace The explaination below is from here and it was posted Nov 25 ’17. In by = c(“col1” = “col2”), = is not and equality operator, but an assignment operator (the equality operator in R is ==). The expression inside c(…) creates a named character vector (name: col1 value: col2) that dplyr uses for the join. Nowhere do you define the kind of comparison that is made during the join, the comparison is hard-coded in dplyr. I don’t think dplyr supports non-equi joins (yet). Diconnect from the db: dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-joins-complex.html", "Chapter 13 SQL joins and complex queries 13.1 Database Privileges 13.2 Database constraints 13.3 Making up data for Join Examples 13.4 SQL Multi-Row Insert Data Syntax 13.5 SQL Multi-Row Insert Data Example 13.6 Messy Data 13.7 Joins 13.8 Natural Join Delayed Time Bomb 13.9 Join Templates 13.10 SQL anti join Costs 13.11 dplyr Anti joins 13.12 Exercises 13.13 Store analysis 13.14 Different strategies for interacting with the database", " Chapter 13 SQL joins and complex queries This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies These packages are called in almost every chapter of the book: Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 37 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R. Need to wait for Docker &amp; PostgreSQL to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 13.1 Database Privileges In the DVD rental database, you have all database privileges to perform any CRUD operaion, create, read, update, and delete on any database object. As a data analyst, you typically only get select privilege which allows you to read only a subset of the tables in a database. Occasionally, a proof of concept project may have a sandbox spun up where users are granted additional priviledges. 13.2 Database constraints As a data analyst, you really do not need to worry about database constraints since you are primarily writing dplyr/SQL queries to pull data out of the database. Constraints can be enforced at multiple levels: column, table, multiple tables, or at the schema itself. The common database constraints are a column is NOT NULL, a column is UNIQUE, a column is a PRIMARY KEY, both NOT NULL and UNIQUE, or a column is a FOREIGN KEY, the PRIMARY KEY on another table. Constraints restrict column values to a set of defined values and help enforce referential integrity between tables. 13.2.1 DVD Rental Primary Foreign Key Constraints For this tutorial, we are primarily concerned with primary and foreign key relationships between tables in order to correctly join the data between tables. If one looks at all the tables in the DVD Rental ERD, add link here, the first column is the name of the table followed by &quot;_id“. This is the primary key on the table. In some of the tables, there are other columns that begin with the name of a different table, the foreign table, and end in”_id&quot;. These are foreign keys and the foreign key value is the primary key value on the foreign table. The DBA will index the primary and foreign key columns to speed up query performanace. In the table below, all the primary foreign key relationships are shown because the DVD rental system is small. Real world databases typically have hundreds or thousands of primary foreign key relationships. In the search box, enter ‘PRIMARY’ or ‘FOREIGN’ to see the table primary key or the table’s foreign key relationships. Searching for ‘FOREIGN’ in the table above, one sees that the column_name matches the ref_table_col. This is pretty typical, but not always the case. This can occur because of an inconsistent naming convention in the application design or a table contains multiple references to the same table foreign table and each reference indicates a different role. A non-DVD rental example of the latter is a patient transaction record that has a referring doctor and and performing doctor. The two columns will have different names, but may refer to the same or different doctors in the doctor table. In this case you may hear one say that the doctor table is performing two different roles. 13.3 Making up data for Join Examples Each chapter in the book stands on its own. If you have worked through the code blocks in this chapter in a previous session, you created some new customer records in order to work through material in the rest of the chapter. In the next couple of code blocks, we delete the new data and then recreate the data for the join examples in the next chapter. 13.3.1 SQL Delete Data Syntax DELETE FROM &lt;source&gt; WHERE &lt;where_clause&gt;; 13.3.2 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added working through the exercises. Out of the box, the DVD rental database’s highest customer_id = 599. dbExecute() always returns a scalar numeric that specifies the number of rows affected by the statement. dbExecute( con, &quot;delete from customer where customer_id &gt;= 600; &quot; ) ## [1] 7 The number above tells us how many rows were actually deleted from the customer table. 13.3.3 Delete New Practice Films from the Film table. In the next code block we delete out the new films that were added when the book was compliled or added working through the exercises. Out of the box, the DVD film database’s highest film_id = 1000. dbExecute( con, &quot;delete from film where film_id &gt; 1000; &quot; ) ## [1] 0 13.3.4 SQL Single Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. The column list is the list of column names on the table and the corresponding list of values have to have the correct data type. The following code block returns the CUSTOMER column names and data types. customer_cols &lt;- dbGetQuery( con, &quot;select table_name, column_name, ordinal_position, data_type from information_schema.columns where table_catalog = &#39;dvdrental&#39; and table_name = &#39;customer&#39; ;&quot; ) sp_print_df(customer_cols) In the next code block, we insert Sophie as a new customer into the customer table via a SQL insert statement. The columns list clause has three id columns, customer_id, store_id, and address_id. The customer_id is a primary key column and the other two ‘look like’ foreign key columns. For now, we are interested in getting some new customers into the customer table. We look at the relations between the customer table and the store and address tables later in this chapter. dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) &quot; ) ## [1] 1 new_customers &lt;- dbGetQuery(con, &quot;select * from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 13.3.5 Primary and Foreign Key Constraint Error Messages For the new customers, we are concerned with not violating the PK and FK constraints. If the customer_id = 600 value is changed to 599, the database throws the following error message. Error in result_create(conn@ptr, statement) : Failed to fetch row: ERROR: duplicate key value violates unique constraint &quot;customer_pkey&quot; DETAIL: Key (customer_id)=(599) already exists. If the address_id value = 1 is changed to 611, the database throws the following error message: Error in result_create(conn@ptr, statement) : Failed to fetch row: ERROR: insert or update on table &quot;customer&quot; violates foreign key constraint &quot;customer_address_id_fkey&quot; DETAIL: Key (address_id)=(611) is not present in table &quot;address&quot;. 13.3.6 R Exercise: Inserting a Single Row via a Dataframe In the following code block replace Sophie Yang with your name where appropriate. Note: The last data frame parameter sets the stringsAsFactors is FALSE. Databases do not have a native FACTOR type. The dataframe column names must match the table column names. The dbWriteTable function needs append = true to actually insert the new row. The dbWriteTable function has an option ‘overwrite’. It is set to FALSE by default. If it is set to TRUE, the table is first truncated. No write occurs if both overwrite and append = FALSE. df &lt;- data.frame( customer_id = 601 , store_id = 2 , first_name = &quot;Sophie&quot; , last_name = &quot;Yang&quot; , email = &quot;sophie.yang@sakilacustomer.org&quot; , address_id = 1 , activebool = TRUE , create_date = Sys.Date() , last_update = Sys.time() , active = 1 , stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df, append = TRUE, row.names = FALSE) new_customers &lt;- dbGetQuery(con, &quot;select * from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 13.4 SQL Multi-Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list1&gt;, ... &lt;values listn&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. PostgreSQL and some other flavors of SQL allow multiple rows to be inserted at a time. The syntax is identical to the Single Row syntax, but includes multiple &lt;values list&gt; clauses separated by commas. The following code block illustrates the SQL multi-row insert. Note that the customer_id column takes on sequential values to satisfy the PK constraint. 13.5 SQL Multi-Row Insert Data Example # dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(602,1,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE ,now()::date,now()::date,1) ,(603,1,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE ,now()::date,now()::date,1) ,(604,1,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE ,now()::date,now()::date,1) ;&quot; ) ## [1] 3 The PostgreSQL R multi-row insert is similar to the single row insert. The single column values are converted to a vector of values. 13.5.1 R Exercise: Inserting Multiple Rows via a Dataframe Replace the two first_name, last_name, and email column values with your own made up values. customer_id &lt;- c(605, 606) store_id &lt;- c(3, 4) first_name &lt;- c(&quot;John&quot;, &quot;Ian&quot;) last_name &lt;- c(&quot;Smith&quot;, &quot;Frantz&quot;) email &lt;- c( &quot;john.smith@sakilacustomer.org&quot;, &quot;ian.frantz@sakilacustomer.org&quot; ) address_id &lt;- c(3, 4) activebool &lt;- c(TRUE, TRUE) create_date &lt;- c(Sys.Date(), Sys.Date()) last_update &lt;- c(Sys.time(), Sys.time()) active &lt;- c(1, 1) df2 &lt;- data.frame(customer_id, store_id, first_name, last_name, email, address_id, activebool, create_date, last_update, active, stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df2, append = TRUE, row.names = FALSE ) new_customers &lt;- dbGetQuery(con, &quot;select * from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) The film table has a primary key, film_id, and a foreign key column, language_id. In the next code bloock we see five sample rows from the film table. films &lt;- dbGetQuery( con, &quot;select film_id,title, language_id from film order by film_id limit 5 ;&quot; ) sp_print_df(films) The next code block shows all the rows in the language table. languages &lt;- dbGetQuery( con, &quot;select language_id, name, last_update from language ;&quot; ) sp_print_df(languages) One cannot insert/update a row into the film table with a language_id = 10 because of a constraint on the language_id column. The language_id value must already exist in the language table, values 1 - 6, before the database will allow the new row to be inserted into the table. 13.6 Messy Data The data in the DVD rental system is too clean to show some of the issues one comes across in the real world. In the following xxxx code blocks, we look at one row in the film table where the film_id = 1. We first reinitialize language_id to 1 and display the row. dbExecute(con, &quot;update film set language_id = 1 where film_id = 1;&quot;) ## [1] 1 dbGetQuery(con, &quot;select &#39;1. Update language_id = 1 successful&#39; step ,film_id, language_id from film where film_id = 1;&quot;) ## step film_id language_id ## 1 1. Update language_id = 1 successful 1 1 The following code block is an example of a SQL anonymous code block that gracefully handles the exception error when we try and update the row with language_id = 10. Note that the language_id is still 1. dbExecute(con, &quot; do $$ DECLARE v_id INTEGER; begin v_id = 10; update film set language_id = v_id where film_id = 1; exception when foreign_key_violation then raise notice &#39;SQLERRM = %, language_id = %&#39;, SQLERRM, v_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 dbGetQuery(con, &quot;select &#39;2. Update language_id = 10 failed&#39; step ,film_id, language_id from film where film_id = 1;&quot;) ## step film_id language_id ## 1 2. Update language_id = 10 failed 1 1 13.6.1 Messing up the row The following code block disables all the database constraints on the film table Updates the row with language_id = 10. Re-enabes the database constraints on the film table # dbExecute(con, &quot;ALTER TABLE film DISABLE TRIGGER ALL;&quot;) ## [1] 0 count &lt;- dbExecute(con, &quot;update film set language_id = 10 where film_id = 1;&quot;) While the film table constraints are disabled, we will insert a new film with a language_id = 10. dbExecute( con, &quot;insert into film (film_id,title,description,release_year,language_id ,rental_duration,rental_rate,length,replacement_cost,rating ,last_update,special_features,fulltext) values(1001,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;orphaned language_id=10&#39;,2018,10 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ; &quot; ) ## [1] 1 In the following code block we re-enable the film table constraints and confirm that the new record exists. dbExecute(con, &quot;ALTER TABLE film ENABLE TRIGGER ALL;&quot;) ## [1] 0 dbGetQuery( con, &quot;select film_id,title,description,language_id from film where film_id = 1001;&quot; ) ## film_id title description language_id ## 1 1001 Sophie&#39;s Choice orphaned language_id=10 10 13.7 Joins In section ‘SQL Quick Start Simple Retrieval’, there is a brief discussion of databases and 3NF. One of the goals of normalization is to eliminate redundant data being kept in multiple tables and having each table contain a very granular level of detail. If a record then needs to be updated, it is updated in one table instead of multiple tables improving overall system performance. This also helps simplify and maintain referential integerity between tables. Bill Kent famously summarized 3NF as every non-key column “must provide a fact about the key,the whole key, and nothing but the key, so help me Codd.” Normalization breaks data down and JOINs denormalizes the data and builds it back up. The tables are typically related via a primary key - foreign key relationship. The PostgreSQL database enforces the primary and foreign key constraints in the DVD rental database. 13.7.1 Join Types SQL_JOIN_TYPES The above diagram can be found here There are additional graphics at the link, but the explanations are poorly worded and hard to follow. The diagram above shows nicely the hierarchy of different types of joins. For this tutorial, we can think of joins as either an Inner Join or an Outer Join. Instead of showing standard Venn diagrams showing the different JOINS, we use an analogy. For those interested though, the typical Venn diagrams can be found here. 13.7.2 Valentines Party Imagine you are at a large costume Valentine’s Day dance party. The hostess of the party, a data scientist, would like to learn more about the people attending her party. When the band takes a break, she lets everyone know it is time for the judges to evaluate the winners for best costumes and associated prizes. ValentinesDay She requests the following: All the couples at the party line up in front of her in a single line with the men on her left and the women on her right, (inner join) All the remaining men to form a second line two feet behind the married men, (left outer join, all couples + unattached men) All the remaining women to form a third line two feet in front of the married women, (right outer join, all couples + unattached women) As our data scientist looks out, she can clearly see the three distinct lines, the single men, the man woman couples, and the single women, a full outer join. As the three judges start walking down the lines, she makes one more announcement. There is a special prize for the man and woman who can guess the average age of the members of the opposite sex. To give everyone a chance to come up with an average age, she asks the men to stay in line and the women to move down the mens line in order circling back around until they get back to their starting point in line, (cartesian join, every man seen by every woman and vice versa). It is hard enough to tell someone’s age when they don’t have a mask, how do you get the average age when people have masks? The hostess knows that there is usually some data anomolies. As she looks out she sees a small cluster of people who did not line up. Being the hostess with the mostest, she wants to get to know that small cluster better. Since they are far off and in costume, she cannot tell if they are men or women. More importantly, she does not know if they identify as a man or a woman, both – (kind of a stretch for a self join), neither, or something else. Ahh, the inquisitive mind wants to know. 13.7.3 Join Syntax The table below shows the two R join function call formats, standalone function call and pipe function call and the corresponding SQL join format. Join dplyr sql inner inner_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% inner_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) left left_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c left outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% left_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) right right_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c right outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% right_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) full full_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c full outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% full_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) 13.7.4 Join Tables The dplyr join documentation describes two different types of joins, mutating and filtering joins. For those coming to R with a SQL background, the mutating documentation is misleading in one respect. Here is the inner_join documentation. inner_join() return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned. The misleading part is that all the columns from x and y. If the join column is KEY, SQL will return x.KEY and y.KEY. Dplyr retuns KEY. It appears that the KEY value comes from the driving table. This difference should become clear in the outer join examples. In the next couple of examples, we will pull all the language and film table data from the database into memory because the tables are small. In the *_join verbs, the by and suffix parameters are included because it helps document the actual join and the source of join columns. 13.8 Natural Join Delayed Time Bomb The dplyr default join is a natural join, joining tables on common column names. One of many links why one should not use natural joins can be found here. If two tables are joined via a natural join on column C1 the join continues to work as long as no additional common columns are added to either table. If a new new column C2 is added to one of the tables and C2 already exists in the other table, BOOM, the delayed time bomb goes off. The natural join still executes, doesn’t throw any errors, but the returned result set may be smaller, much smaller, than before the new C2 column was added. ### SQL Language_id Distribution The next code block calculates the language_id distribution in the film and language tables. The results will be used in following sections to validate different join result sets. lang_distribution_sql &lt;- dbGetQuery(con ,&quot;select &#39;film&#39; tbl,language_id,count(*) count from film group by language_id union select &#39;language&#39; tbl,language_id,count(*) count from language group by language_id order by tbl,language_id;&quot; ) sp_print_df(lang_distribution_sql) 13.8.1 dplyr language distribution Exercise Execute and Review the output from the code block below. Union and arrange the output to match the SQL output in the previous code block. language_table &lt;- DBI::dbReadTable(con, &quot;language&quot;) film_table &lt;- DBI::dbReadTable(con, &quot;film&quot;) language_summary &lt;- language_table %&gt;% group_by(language_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;language&#39;) %&gt;% select(table,language_id,count) film_summary &lt;- film_table %&gt;% group_by(language_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;film&#39;) %&gt;% select(table,language_id,count) sp_print_df(language_summary) sp_print_df(film_summary) ## UNION the two summary tables and ARRANGE the output to match the SQL output from the previouse code block 13.9 Join Templates In this section we perform various joins using dplyr and SQL. Each dplyr code block has three purposes. Show a working join example. The code blocks can be used as templates for beginning more complex dplyr pipes. The code blocks show the number of joins performed. In these examples, the join condition, the by parameter, by = c(&#39;language_id&#39;,&#39;language_id&#39;) the two columns are the same. In multi-column joins, each language_id would be replaced with a vector of column names used in the join by position. Note the column names do not need to be identical by position. The suffix parameter is a way to distinguish the same column name in the joined tables. The suffixes are usually an single letter to represent the name of the table. 13.9.1 dplyr Inner Join Template For an inner join between two tables, it doesn’t matter which table is on the left, the first table, and which is on the right, the second table, because join conditions on both tables must be satisfied. languages_ij &lt;- language_table %&gt;% inner_join(film_table, by = c(&quot;language_id&quot; = &quot;language_id&quot;), suffix(c(&quot;.l&quot;, &quot;.f&quot;))) %&gt;% group_by(language_id, name) %&gt;% summarize(inner_joins = n()) sp_print_df(languages_ij) 13.9.1.1 SQL Inner Join The dplyr suffix is similar to the SQL table. In the previous code block, .l and .f were used in the inner_join suffix parameter. l. and f. are used as aliases in the SQL version below. The role of the dplyr suffix and the SQL alias is to disambiguate duplicate table and column names referenced. rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,count(*) n from language l join film f on l.language_id = f.language_id group by l.language_id,l.name;&quot; ) sp_print_df(rs) The output tells us that there are 0 inner joins occurred between the language_table and the film_table. 13.9.2 dplyr Left Outer Join Template For a left outer join between two tables, it does matter which table is on the left, the first table, and which is on the right, the second table, because every row in the left table that satsifies the filter/where conditions are returned. The second table returns rows if the join condition is met or returns a row of all null column values. languages_loj &lt;- language_table %&gt;% left_join(film_table, by = c(&quot;language_id&quot;, &quot;language_id&quot;), suffix(c(&quot;.l&quot;, &quot;.f&quot;))) %&gt;% mutate( join_type = &quot;loj&quot;, film_lang_id = if_else(is.na(film_id), film_id, language_id) ) %&gt;% group_by(join_type, language_id, name, film_lang_id) %&gt;% summarize(lojs = n()) %&gt;% select(join_type, language_id, film_lang_id, name, lojs) print(languages_loj) ## # A tibble: 6 x 5 ## # Groups: join_type, language_id, name [6] ## join_type language_id film_lang_id name lojs ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 loj 1 1 &quot;English &quot; 999 ## 2 loj 2 NA &quot;Italian &quot; 1 ## 3 loj 3 NA &quot;Japanese &quot; 1 ## 4 loj 4 NA &quot;Mandarin &quot; 1 ## 5 loj 5 NA &quot;French &quot; 1 ## 6 loj 6 NA &quot;German &quot; 1 sp_print_df(languages_loj) Compare the mutate verb in the above code block with film_lang_id in the equivalent SQL code block below. 13.9.2.1 SQL Left Outer Join rs &lt;- dbGetQuery( con, &quot;select l.language_id ,f.language_id film_lang_id ,trim(l.name) as name ,count(*) lojs from language l left outer join film f on l.language_id = f.language_id group by l.language_id,l.name,f.language_id order by l.language_id;&quot; ) sp_print_df(rs) The lojs column returns the number of rows found on the keys from the left table, language, and the right table, the film table. For the “English” row, the language_id and film_lang_id match and 0 inner joins were performed. For all the other languages, there was only 1 join and they all came from the left outer table, the language table, language_id’s 2 - 6. The right table, the film table returned NA, because no match was found. The left outer join always returns all rows from the left table, the driving/key table, if not reduced via a filter()/where clause. All rows that inner join returns all the columns/derived columns specified in the select clause from both the left and right tables. All rows from the left table, the outer table, without a matching row on the right returns all the columns/derived column values specified in the select clause from the left, but the values from right table have all values of NA. 13.9.2.2 dplyr Right Outer Join languages_roj &lt;- language_table %&gt;% right_join(film_table, by = c(&quot;language_id&quot;, &quot;language_id&quot;), suffix(c(&quot;.l&quot;, &quot;.f&quot;)), all = film_table) %&gt;% mutate( lang_id = if_else(is.na(name), 0L, language_id), join_type = &quot;rojs&quot; ) %&gt;% group_by(join_type, language_id, name, lang_id) %&gt;% summarize(rojs = n()) %&gt;% select(join_type, lang_id, language_id, name, rojs) sp_print_df(languages_roj) languages_roj ## # A tibble: 2 x 5 ## # Groups: join_type, language_id, name [2] ## join_type lang_id language_id name rojs ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 rojs 1 1 &quot;English &quot; 999 ## 2 rojs 0 10 &lt;NA&gt; 2 Review the mutate above with l.language_id below. 13.9.2.3 SQL Right Outer Join rs &lt;- dbGetQuery( con, &quot;select &#39;roj&#39; join_type,l.language_id,f.language_id language_id_f,l.name,count(*) rojs from language l right outer join film f on l.language_id = f.language_id group by l.language_id,l.name,f.language_id order by l.language_id;&quot; ) sp_print_df(rs) rs ## join_type language_id language_id_f name rojs ## 1 roj 1 1 English 999 ## 2 roj NA 10 &lt;NA&gt; 2 The rojs column returns the number of rows found on the keys from the right table, film, and the left table, the language table. For the “English” row, the language_id and film_lang_id match and a 1000 inner joins were performed. For language_id = 30 from the right table, there was only 1 join to a non-existant row in the language table on the left. The right outer join always returns all rows from the right table, the driving/key table, if not reduced via a filter()/where clause. All rows that inner join returns all the columns/derived columns specified in the select clause from both the left and right tables. All rows from the right table, the outer table, without a matching row on the left returns all the columns/derived column values specified in the select clause from the right, but the values from left table have all values of NA. 13.9.2.4 dplyr Full Outer Join languages_foj &lt;- language_table %&gt;% full_join(film_table, by = c(&quot;language_id&quot;, &quot;language_id&quot;), suffix(c(&quot;.l&quot;, &quot;.f&quot;))) %&gt;% mutate(film_lang = if_else(is.na(film_id), paste0(&quot;No &quot;, name, &quot; films.&quot;), if_else(is.na(name), &quot;Alien&quot;, name))) %&gt;% group_by(language_id, name, film_lang) %&gt;% summarize(n = n()) sp_print_df(languages_foj) languages_foj ## # A tibble: 7 x 4 ## # Groups: language_id, name [7] ## language_id name film_lang n ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 &quot;English &quot; &quot;English &quot; 999 ## 2 2 &quot;Italian &quot; No Italian films. 1 ## 3 3 &quot;Japanese &quot; No Japanese films. 1 ## 4 4 &quot;Mandarin &quot; No Mandarin films. 1 ## 5 5 &quot;French &quot; No French films. 1 ## 6 6 &quot;German &quot; No German films. 1 ## 7 10 &lt;NA&gt; Alien 2 13.9.2.5 SQL full Outer Join rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,f.language_id language_id_f,count(*) fojs from language l full outer join film f on l.language_id = f.language_id group by l.language_id,l.name,f.language_id order by l.language_id;&quot; ) sp_print_df(rs) rs ## language_id name language_id_f fojs ## 1 1 English 1 999 ## 2 2 Italian NA 1 ## 3 3 Japanese NA 1 ## 4 4 Mandarin NA 1 ## 5 5 French NA 1 ## 6 6 German NA 1 ## 7 NA &lt;NA&gt; 10 2 Looking at the SQL output, the full outer join is the combination of the left and right outer joins. Language_id = 1 is the inner join. Language_id = 2 - 6 is the left outer join Language_id = 30 is the right outer join. One can also just look at the language_id on the left and language_id_f on the right for a non NA value to see which side is outer side/driving side of the join. 13.9.2.6 dplyr anti Join The anti join is a left outer join without the inner joined rows. It only returns the rows from the left table that do not have a match from the right table. languages_aj &lt;- language_table %&gt;% anti_join(film_table, by = c(&quot;language_id&quot;, &quot;language_id&quot;), suffix(c(&quot;.l&quot;, &quot;.f&quot;))) %&gt;% mutate(type = &quot;anti_join&quot;) %&gt;% group_by(type, language_id, name) %&gt;% summarize(anti_joins = n()) %&gt;% select(type, language_id, name, anti_joins) sp_print_df(languages_aj) languages_aj ## # A tibble: 5 x 4 ## # Groups: type, language_id [5] ## type language_id name anti_joins ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 anti_join 2 &quot;Italian &quot; 1 ## 2 anti_join 3 &quot;Japanese &quot; 1 ## 3 anti_join 4 &quot;Mandarin &quot; 1 ## 4 anti_join 5 &quot;French &quot; 1 ## 5 anti_join 6 &quot;German &quot; 1 13.9.2.7 SQL anti Join 1, Left Outer Join where NULL on Right SQL doesn’t have an anti join key word. Here are three different ways to achieve the same result. rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,count(*) fojs from language l left outer join film f on l.language_id = f.language_id where f.language_id is null group by l.language_id,l.name order by l.language_id;&quot; ) sp_print_df(rs) rs ## language_id name fojs ## 1 2 Italian 1 ## 2 3 Japanese 1 ## 3 4 Mandarin 1 ## 4 5 French 1 ## 5 6 German 1 13.9.2.8 SQL anti Join 2, ID in driving table and NOT IN lookup table rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,count(*) fojs from language l where l.language_id NOT IN (select language_id from film) group by l.language_id,l.name order by l.language_id;&quot; ) sp_print_df(rs) rs ## language_id name fojs ## 1 2 Italian 1 ## 2 3 Japanese 1 ## 3 4 Mandarin 1 ## 4 5 French 1 ## 5 6 German 1 13.9.2.9 SQL anti Join 3, NOT EXISTS and Correlated subquery rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,count(*) fojs from language l where not exists (select language_id from film f where f.language_id = l.language_id) group by l.language_id,l.name &quot; ) sp_print_df(rs) rs ## language_id name fojs ## 1 2 Italian 1 ## 2 3 Japanese 1 ## 3 4 Mandarin 1 ## 4 5 French 1 ## 5 6 German 1 13.10 SQL anti join Costs sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select l.language_id,l.name,count(*) fojs from language l left outer join film f on l.language_id = f.language_id where f.language_id is null group by l.language_id,l.name &quot; ) sql_aj2 &lt;- dbGetQuery( con, &quot;explain analyze select l.language_id,l.name,count(*) fojs from language l where l.language_id NOT IN (select language_id from film) group by l.language_id,l.name &quot; ) sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select l.language_id,l.name,count(*) fojs from language l where not exists (select language_id from film f where f.language_id = l.language_id) group by l.language_id,l.name &quot; ) 13.10.0.0.1 SQL Costs print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=24.24..24.30 rows=3 width=96) (actual time=0.456..0.568 rows=5 loops=1) print(glue(&quot;sql_aj2 not in costs=&quot;, sql_aj2[1, 1])) ## sql_aj2 not in costs=GroupAggregate (cost=67.60..67.65 rows=3 width=96) (actual time=16.523..16.633 rows=5 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=GroupAggregate (cost=24.24..24.30 rows=3 width=96) (actual time=0.371..0.477 rows=5 loops=1) 13.11 dplyr Anti joins In this next section we look at two methods to implemnt an anti join in dplyr. customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) Method 1. dplyr anti_join daj1 &lt;- anti_join(customer_table, rental_table, by = &quot;customer_id&quot;, suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT * FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## ## WHERE NOT EXISTS ( ## SELECT 1 FROM &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## WHERE (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## )) &quot;cqpqwqagrn&quot; ## ## &lt;PLAN&gt; ## Hash Anti Join (cost=510.99..552.63 rows=300 width=334) ## Hash Cond: (&quot;TBL_LEFT&quot;.customer_id = &quot;TBL_RIGHT&quot;.customer_id) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) ## -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=2) customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) Method 2. dplyr loj with NA daj2 &lt;- left_join(customer_table, rental_table, by = c(&quot;customer_id&quot;, &quot;customer_id&quot;), suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% filter(is.na(rental_id)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_LEFT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_LEFT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_LEFT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.c&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_RIGHT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_RIGHT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_RIGHT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.r&quot; ## FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;ihebfvnxvb&quot; ## WHERE (((&quot;rental_id&quot;) IS NULL)) ## ## &lt;PLAN&gt; ## Hash Right Join (cost=22.48..375.33 rows=80 width=334) ## Hash Cond: (&quot;TBL_RIGHT&quot;.customer_id = &quot;TBL_LEFT&quot;.customer_id) ## Filter: (&quot;TBL_RIGHT&quot;.rental_id IS NULL) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=6) ## -&gt; Hash (cost=14.99..14.99 rows=599 width=338) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) 13.11.1 dplyr Costs &lt;PLAN&gt; Hash Anti Join (cost=510.99..529.72 rows=1 width=45) Hash Cond: (&quot;TBL_LEFT&quot;.customer_id = &quot;TBL_RIGHT&quot;.customer_id) -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=49) -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=2) &lt;PLAN&gt; Hash Right Join (cost=22.48..375.33 rows=1 width=45) Hash Cond: (&quot;TBL_RIGHT&quot;.customer_id = &quot;TBL_LEFT&quot;.customer_id) Filter: (&quot;TBL_RIGHT&quot;.rental_id IS NULL) -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=6) -&gt; Hash (cost=14.99..14.99 rows=599 width=49) -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=49) In this example, the dplyr anti_join verb is 1.4113447 to 22.7308719 times more expensive than the left outer join with a null condition. sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c left outer join rental r on c.customer_id = r.customer_id where r.customer_id is null group by c.customer_id order by c.customer_id;&quot; ) sp_print_df(sql_aj1) sql_aj1 ## QUERY PLAN ## 1 GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=261.153..261.293 rows=7 loops=1) ## 2 Group Key: c.customer_id ## 3 -&gt; Sort (cost=564.97..565.72 rows=300 width=4) (actual time=261.119..261.173 rows=7 loops=1) ## 4 Sort Key: c.customer_id ## 5 Sort Method: quicksort Memory: 25kB ## 6 -&gt; Hash Anti Join (cost=510.99..552.63 rows=300 width=4) (actual time=260.910..261.060 rows=7 loops=1) ## 7 Hash Cond: (c.customer_id = r.customer_id) ## 8 -&gt; Seq Scan on customer c (cost=0.00..14.99 rows=599 width=4) (actual time=0.015..4.324 rows=606 loops=1) ## 9 -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) (actual time=252.166..252.173 rows=16044 loops=1) ## 10 Buckets: 16384 Batches: 1 Memory Usage: 661kB ## 11 -&gt; Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=2) (actual time=0.014..125.464 rows=16044 loops=1) ## 12 Planning time: 0.162 ms ## 13 Execution time: 261.488 ms sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c where not exists (select customer_id from rental r where c.customer_id = r.customer_id) group by c.customer_id &quot; ) print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=261.153..261.293 rows=7 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=HashAggregate (cost=554.13..557.13 rows=300 width=12) (actual time=241.205..241.262 rows=7 loops=1) 13.12 Exercises 13.12.1 Anti joins – Find customers who have never rented a movie, take 2. This is a left outer join from customer to the rental table with an NA rental_id. 13.12.1.1 SQL Anti-Join rs &lt;- dbGetQuery( con, &quot;select c.first_name ,c.last_name ,c.email from customer c left outer join rental r on c.customer_id = r.customer_id where r.rental_id is null; &quot; ) sp_print_df(head(rs)) &lt;– Add dplyr semi-join example –&gt; 13.12.2 SQL Rows Per Table In the examples above, we looked at how many rows were involved in each of the join examples and which side of the join they came from. It is often helpful to know how many rows are in each table as a sanity check on the joins. Below is the SQL version to return all the row counts from each table in the DVD Rental System. rs &lt;- dbGetQuery( con, &quot;select * from ( select &#39;actor&#39; tbl_name,count(*) from actor union select &#39;category&#39; tbl_name,count(*) from category union select &#39;film&#39; tbl_name,count(*) from film union select &#39;film_actor&#39; tbl_name,count(*) from film_actor union select &#39;film_category&#39; tbl_name,count(*) from film_category union select &#39;language&#39; tbl_name,count(*) from language union select &#39;inventory&#39; tbl_name,count(*) from inventory union select &#39;rental&#39; tbl_name,count(*) from rental union select &#39;payment&#39; tbl_name,count(*) from payment union select &#39;staff&#39; tbl_name,count(*) from staff union select &#39;customer&#39; tbl_name,count(*) from customer union select &#39;address&#39; tbl_name,count(*) from address union select &#39;city&#39; tbl_name,count(*) from city union select &#39;country&#39; tbl_name,count(*) from country union select &#39;store&#39; tbl_name,count(*) from store ) counts order by tbl_name ; &quot; ) sp_print_df(head(rs)) rs ## tbl_name count ## 1 actor 200 ## 2 address 603 ## 3 category 16 ## 4 city 600 ## 5 country 109 ## 6 customer 606 ## 7 film 1001 ## 8 film_actor 5462 ## 9 film_category 1000 ## 10 inventory 4581 ## 11 language 6 ## 12 payment 14596 ## 13 rental 16044 ## 14 staff 2 ## 15 store 3 13.12.2.1 Exercise dplyr Rows Per Table In the code block below Get the row counts for a couple more tables What is the structure of film_table object? film_table &lt;- tbl(con, &quot;film&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) language_table &lt;- tbl(con, &quot;language&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) film_rows &lt;- film_table %&gt;% mutate(name = &quot;film&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()) language_rows &lt;- language_table %&gt;% mutate(name = &quot;language&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()) rows_per_table &lt;- rbind(as.data.frame(film_rows), as.data.frame(language_rows)) rows_per_table ## name rows ## 1 film 1001 ## 2 language 6 13.12.2.2 SQL film distribution based on language The SQL below is very similar to the SQL full Outer Join above. Instead of counting the joins, it counts the number films associated with each language. rs &lt;- dbGetQuery( con, &quot;select l.language_id id ,l.name ,sum(case when f.language_id is not null then 1 else 0 end) total from language l full outer join film f on l.language_id = f.language_id group by l.language_id,l.name order by l.name; ; &quot; ) sp_print_df(head(rs)) rs ## id name total ## 1 1 English 999 ## 2 5 French 0 ## 3 6 German 0 ## 4 2 Italian 0 ## 5 3 Japanese 0 ## 6 4 Mandarin 0 ## 7 NA &lt;NA&gt; 2 13.12.2.3 Exercise dplyr film distribution based on language Below is the code block from the dplyr Full Outer Join section above. Modify the code block to match the output from the SQL version. rs &lt;- dbGetQuery( con, &quot;select l.language_id,l.name,f.language_id language_id_f,count(*) fojs from language l full outer join film f on l.language_id = f.language_id group by l.language_id,l.name,f.language_id order by l.language_id;&quot; ) sp_print_df(rs) rs ## language_id name language_id_f fojs ## 1 1 English 1 999 ## 2 2 Italian NA 1 ## 3 3 Japanese NA 1 ## 4 4 Mandarin NA 1 ## 5 5 French NA 1 ## 6 6 German NA 1 ## 7 NA &lt;NA&gt; 10 2 13.13 Store analysis How are the stores performing. 13.13.1 SQL store revenue stream How are the stores performing? The SQL code shows the payments made to each store in the business. rs &lt;- dbGetQuery( con, &quot;select store_id,sum(p.amount) amt,count(*) cnt from payment p join staff s on p.staff_id = s.staff_id group by store_id order by 2 desc ; &quot; ) sp_print_df(head(rs)) 13.13.1.1 Exercise dplyr store revenue stream Complete the following code block to return the payments made to each store. payment_table &lt;- tbl(con, &quot;payment&quot;) # DBI::dbReadTable(con, &quot;payment&quot;) staff_table &lt;- tbl(con, &quot;staff&quot;) # DBI::dbReadTable(con, &quot;staff&quot;) store_revenue &lt;- payment_table %&gt;% inner_join(staff_table, by = &quot;staff_id&quot;, suffix = c(&quot;.p&quot;, &quot;.s&quot;)) %&gt;% head() store_revenue ## # Source: lazy query [?? x 16] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## payment_id customer_id staff_id rental_id amount payment_date ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 17503 341 2 1520 7.99 2007-02-15 22:25:46 ## 2 17504 341 1 1778 1.99 2007-02-16 17:23:14 ## 3 17505 341 1 1849 7.99 2007-02-16 22:41:45 ## 4 17506 341 2 2829 2.99 2007-02-19 19:39:56 ## 5 17507 341 2 3130 7.99 2007-02-20 17:31:48 ## 6 17508 341 1 3382 5.99 2007-02-21 12:33:49 ## # … with 10 more variables: first_name &lt;chr&gt;, last_name &lt;chr&gt;, ## # address_id &lt;int&gt;, email &lt;chr&gt;, store_id &lt;int&gt;, active &lt;lgl&gt;, ## # username &lt;chr&gt;, password &lt;chr&gt;, last_update &lt;dttm&gt;, picture &lt;blob&gt; 13.13.2 SQL:Estimate Outstanding Balance The following SQL code calculates for each store the number of payments still open and closed from the DVD Rental Stores customer base. the total amount that their customers have paid the average price per/movie based off of the movies that have been paid. the estimated outstanding balance based off the open unpaid rentals * the average price per paid movie. rs &lt;- dbGetQuery( con, &quot;SELECT s.store_id store,sum(CASE WHEN payment_id IS NULL THEN 1 ELSE 0 END) open ,sum(CASE WHEN payment_id IS NOT NULL THEN 1 ELSE 0 END) paid ,sum(p.amount) paid_amt ,count(*) rentals ,round(sum(p.amount) / sum(CASE WHEN payment_id IS NOT NULL THEN 1 ELSE 0 END), 2) avg_price ,round(round(sum(p.amount) / sum(CASE WHEN payment_id IS NOT NULL THEN 1 ELSE 0 END), 2) * sum(CASE WHEN payment_id IS NULL THEN 1 ELSE 0 END), 2) est_balance FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id JOIN staff s ON r.staff_id = s.staff_id group by s.store_id; &quot; ) sp_print_df(head(rs)) rs ## store open paid paid_amt rentals avg_price est_balance ## 1 1 713 7331 30498.71 8044 4.16 2966.08 ## 2 2 739 7265 30813.33 8004 4.24 3133.36 13.13.2.1 Exercise Dplyr Modify the following dplyr code to match the SQL output from above. payment_table &lt;- tbl(con, &quot;payment&quot;) # DBI::dbReadTable(con, &quot;payment&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) est_bal &lt;- rental_table %&gt;% left_join(payment_table, by = c(&quot;rental_id&quot;, &quot;rental_id&quot;), suffix = c(&quot;.r&quot;, &quot;.p&quot;)) %&gt;% mutate( missing = ifelse(is.na(payment_id), 1, 0), found = ifelse(!is.na(payment_id), 1, 0) ) %&gt;% summarize( open = sum(missing, na.rm = TRUE), paid = sum(found, na.rm = TRUE), paid_amt = sum(amount, na.rm = TRUE), rentals = n() ) %&gt;% summarize( open = open, paid = paid, paid_amt = paid_amt, rentals = rentals, avg_price = paid_amt / paid, est_balance = paid_amt / paid * open ) est_bal ## # Source: lazy query [?? x 6] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## open paid paid_amt rentals avg_price est_balance ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;S3: integer64&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1452 14596 61312. 16048 4.20 6099. 13.13.3 SQL actual outstanding balance In the previous exercise, we estimated the outstanding amount. After reviewing the rental table, the actual movie rental rate is in the table. We use that to calculate the outstanding balance below. rs &lt;- dbGetQuery( con, &quot;SELECT sum(f.rental_rate) open_amt ,count(*) count FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id WHERE p.rental_id IS NULL ;&quot; ) sp_print_df(head(rs)) rs ## open_amt count ## 1 4297.48 1452 payment_table &lt;- tbl(con, &quot;payment&quot;) # DBI::dbReadTable(con, &quot;payment&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) inventory_table &lt;- tbl(con, &quot;inventory&quot;) # DBI::dbReadTable(con, &quot;inventory&quot;) film_table &lt;- tbl(con, &quot;film&quot;) # DBI::dbReadTable(con, &quot;film&quot;) act_bal &lt;- rental_table %&gt;% left_join(payment_table, by = c(&quot;rental_id&quot;, &quot;rental_id&quot;), suffix = c(&quot;.r&quot;, &quot;.p&quot;)) %&gt;% inner_join(inventory_table, by = c(&quot;inventory_id&quot;, &quot;inventory_id&quot;), suffix = c(&quot;.r&quot;, &quot;.i&quot;)) %&gt;% inner_join(film_table, by = c(&quot;film_id&quot;, &quot;film_id&quot;), suffix = c(&quot;.i&quot;, &quot;.f&quot;)) %&gt;% head() act_bal ## # Source: lazy query [?? x 27] ## # Database: postgres [postgres@localhost:5432/dvdrental] ## rental_id rental_date inventory_id customer_id.r ## &lt;int&gt; &lt;dttm&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2005-05-24 22:53:30 367 130 ## 2 2 2005-05-24 22:54:33 1525 459 ## 3 3 2005-05-24 23:03:39 1711 408 ## 4 4 2005-05-24 23:04:41 2452 333 ## 5 5 2005-05-24 23:05:21 2079 222 ## 6 6 2005-05-24 23:08:07 2792 549 ## # … with 23 more variables: return_date &lt;dttm&gt;, staff_id.r &lt;int&gt;, ## # last_update.r &lt;dttm&gt;, payment_id &lt;int&gt;, customer_id.p &lt;int&gt;, ## # staff_id.p &lt;int&gt;, amount &lt;dbl&gt;, payment_date &lt;dttm&gt;, film_id &lt;int&gt;, ## # store_id &lt;int&gt;, last_update.i &lt;dttm&gt;, title &lt;chr&gt;, description &lt;chr&gt;, ## # release_year &lt;int&gt;, language_id &lt;int&gt;, rental_duration &lt;int&gt;, ## # rental_rate &lt;dbl&gt;, length &lt;int&gt;, replacement_cost &lt;dbl&gt;, rating &lt;S3: ## # pq_mpaa_rating&gt;, last_update &lt;dttm&gt;, special_features &lt;S3: pq__text&gt;, ## # fulltext &lt;S3: pq_tsvector&gt; 13.13.4 Rank customers with highest open amounts rs &lt;- dbGetQuery( con, &quot;select c.customer_id,c.first_name,c.last_name,sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join customer c on r.customer_id = c.customer_id where p.rental_id is null group by c.customer_id,c.first_name,c.last_name order by open_amt desc limit 25 ;&quot; ) sp_print_df(head(rs)) rs ## customer_id first_name last_name open_amt count ## 1 293 Mae Fletcher 35.90 10 ## 2 307 Joseph Joy 31.90 10 ## 3 316 Steven Curley 31.90 10 ## 4 299 James Gannon 30.91 9 ## 5 274 Naomi Jennings 29.92 8 ## 6 326 Jose Andrew 28.93 7 ## 7 338 Dennis Gilman 27.92 8 ## 8 277 Olga Jimenez 27.92 8 ## 9 327 Larry Thrasher 26.93 7 ## 10 330 Scott Shelley 26.93 7 ## 11 322 Jason Morrissey 26.91 9 ## 12 340 Patrick Newsom 25.92 8 ## 13 336 Joshua Mark 25.92 8 ## 14 304 David Royal 24.93 7 ## 15 339 Walter Perryman 23.94 6 ## 16 239 Minnie Romero 23.94 6 ## 17 310 Daniel Cabral 22.93 7 ## 18 296 Ramona Hale 22.93 7 ## 19 313 Donald Mahon 22.93 7 ## 20 287 Becky Miles 22.93 7 ## 21 272 Kay Caldwell 22.93 7 ## 22 303 William Satterfield 22.93 7 ## 23 329 Frank Waggoner 22.91 9 ## 24 311 Paul Trout 21.92 8 ## 25 109 Edna West 20.93 7 13.13.5 what film has been rented the most rs &lt;- dbGetQuery( con, &quot;SELECT i.film_id ,f.title ,rental_rate ,sum(rental_rate) revenue ,count(*) count --16044 FROM rental r INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id GROUP BY i.film_id ,f.title ,rental_rate ORDER BY count DESC LIMIT 25 ;&quot; ) sp_print_df(head(rs)) rs ## film_id title rental_rate revenue count ## 1 103 Bucket Brotherhood 4.99 169.66 34 ## 2 738 Rocketeer Mother 0.99 32.67 33 ## 3 489 Juggler Hardly 0.99 31.68 32 ## 4 730 Ridgemont Submarine 0.99 31.68 32 ## 5 767 Scalawag Duck 4.99 159.68 32 ## 6 331 Forward Temple 2.99 95.68 32 ## 7 382 Grit Clockwork 0.99 31.68 32 ## 8 735 Robbers Joon 2.99 92.69 31 ## 9 973 Wife Turn 4.99 154.69 31 ## 10 621 Network Peak 2.99 92.69 31 ## 11 1000 Zorro Ark 4.99 154.69 31 ## 12 31 Apache Divine 4.99 154.69 31 ## 13 369 Goodfellas Salute 4.99 154.69 31 ## 14 753 Rush Goodfellas 0.99 30.69 31 ## 15 891 Timberland Sky 0.99 30.69 31 ## 16 418 Hobbit Alien 0.99 30.69 31 ## 17 127 Cat Coneheads 4.99 149.70 30 ## 18 559 Married Go 2.99 89.70 30 ## 19 374 Graffiti Love 0.99 29.70 30 ## 20 748 Rugrats Shakespeare 0.99 29.70 30 ## 21 239 Dogma Family 4.99 149.70 30 ## 22 285 English Bulworth 0.99 29.70 30 ## 23 109 Butterfly Chocolat 0.99 29.70 30 ## 24 450 Idols Snatchers 2.99 89.70 30 ## 25 609 Muscle Bright 2.99 89.70 30 13.13.6 what film has been generated the most revenue assuming all amounts are collected rs &lt;- dbGetQuery( con, &quot;select i.film_id,f.title,rental_rate ,sum(rental_rate) revenue,count(*) count --16044 from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by i.film_id,f.title,rental_rate order by revenue desc ;&quot; ) sp_print_df(head(rs)) 13.13.7 which films are in one store but not the other. rs &lt;- dbGetQuery( con, &quot;select coalesce(i1.film_id,i2.film_id) film_id ,f.title,f.rental_rate,i1.store_id,i1.count,i2.store_id,i2.count from (select film_id,store_id,count(*) count from inventory where store_id = 1 group by film_id,store_id) as i1 full outer join (select film_id,store_id,count(*) count from inventory where store_id = 2 group by film_id,store_id ) as i2 on i1.film_id = i2.film_id join film f on coalesce(i1.film_id,i2.film_id) = f.film_id where i1.film_id is null or i2.film_id is null order by f.title ; &quot; ) sp_print_df(head(rs)) 13.13.8 Compute the outstanding balance. rs &lt;- dbGetQuery( con, &quot;select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot; ) sp_print_df(head(rs)) ### Which Stores Have Movies That Have Never Rented? not_rented &lt;- dbGetQuery(con, &quot;select i.store_id,f.film_id,f.title,f.description,i.last_update from inventory i left outer join rental r on i.inventory_id = r.inventory_id join film f on i.film_id = f.film_id where r.inventory_id is null &quot;) sp_print_df(not_rented) sp_print_df(dbGetQuery(con,&quot;select min(last_update) mn, max(last_update) mx from inventory;&quot;)) sp_print_df(dbGetQuery(con,&quot;select rental_date,count(*) from rental group by rental_date order by rental_date;&quot;)) 13.14 Different strategies for interacting with the database select examples dbGetQuery returns the entire result set as a data frame. For large returned datasets, complex or inefficient SQL statements, this may take a long time. dbSendQuery: parses, compiles, creates the optimized execution plan. dbFetch: Execute optimzed execution plan and return the dataset. dbClearResult: remove pending query results from the database to your R environment 13.14.1 Use dbGetQuery How many customers are there in the DVD Rental System rs1 &lt;- dbGetQuery(con, &quot;select * from customer;&quot;) sp_print_df(head(rs1)) pco &lt;- dbSendQuery(con, &quot;select * from customer;&quot;) rs2 &lt;- dbFetch(pco) dbClearResult(pco) sp_print_df(head(rs2)) 13.14.2 Use dbExecute 13.14.3 Anti join – Find Sophie who has never rented a movie. customer_table &lt;- DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- DBI::dbReadTable(con, &quot;rental&quot;) customer_tbl &lt;- dplyr::tbl(con, &quot;customer&quot;) rental_tbl &lt;- dplyr::tbl(con, &quot;rental&quot;) dplyr_tbl_loj &lt;- left_join(customer_tbl, rental_tbl, by = &quot;customer_id&quot;, suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% filter(is.na(rental_id)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% collect() rs &lt;- dbGetQuery( con, &quot;select c.first_name ,c.last_name ,c.email from customer c left outer join rental r on c.customer_id = r.customer_id where r.rental_id is null; &quot; ) sp_print_df(head(rs)) sp_print_df(dplyr_tbl_loj) Create an edge data frame, edf Disconnect from the db: dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-dplyr-data.html", "Chapter 14 SQL &amp; dplyr joins additional data 14.1 Making up data for Join Examples 14.2 SQL Multi-Row Insert Data Syntax 14.3 SQL Multi-Row Insert Data Example 14.4 DPLYR Multi-Row Insert Data Example 14.5 Create a film record", " Chapter 14 SQL &amp; dplyr joins additional data This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies These packages are called in almost every chapter of the book: Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 46 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R. Need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 14.1 Making up data for Join Examples Each chapter in the book stands on its own. If you have worked through the code blocks in this chapter in a previous session, you created some new customer records in order to work through material in the rest of the chapter. The DVD rental database data is too clean to demonstrate some join concepts. To dirty the data, this chapter performs a number of database operations on data tables that a data analyst is typically restricted from doing in the real world. Deleting records from tables. Inserting records from tables. Enabling and disabling table constraints. In our Docker environment, you have no restrictions on the database operations you can perform. In the next couple of code blocks, we delete the new data and then recreate the data for the join examples in this next chapter. 14.1.1 SQL Delete Data Syntax DELETE FROM &lt;source&gt; WHERE &lt;where_clause&gt;; 14.1.2 Delete New Practice Store from the Store Table. In the next code block we delete out the new stores that were added when the book was compliled or added working through the exercises. Out of the box, the DVD rental database’s highest store_id = 2. dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 14.1.3 Delete film 1001, Sophie’s Choice, records in film_category, rental, inventory, and film The records need to be deleted in a specific order to not violate constraints. dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 0 dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 0 dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 0 dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 1 14.1.4 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental database’s highest customer_id = 599. 14.1.5 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental database’s highest customer_id = 599. dbExecute() always returns a scalar numeric that specifies the number of rows affected by the statement. dbExecute( con, &quot;delete from customer where customer_id &gt;= 600; &quot; ) ## [1] 7 The number above tells us how many rows were actually deleted from the customer table. 14.1.6 SQL Single Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. The column list is the list of column names on the table and the corresponding list of values must have the correct data type. The following code block returns the CUSTOMER column names and data types. customer_cols &lt;- dbGetQuery( con, &quot;select table_name, column_name, ordinal_position, data_type from information_schema.columns where table_catalog = &#39;dvdrental&#39; and table_name = &#39;customer&#39; ;&quot; ) sp_print_df(customer_cols) In the next code block, we insert Sophie as a new customer into the customer table via a SQL insert statement. The columns list clause has three id columns, customer_id, store_id, and address_id. The customer_id is a primary key column and the other two ‘look like’ foreign key columns. For now, we are interested in getting some new customers into the customer table. We look at the relations between the customer and the store tables later in this chapter. dbExecute( con, &quot; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) &quot; ) ## [1] 1 The number above should be 1 indicating that one record was inserted. new_customers &lt;- dbGetQuery(con ,&quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 14.1.7 Primary Key Constraint Error Message For the new customers, we are concerned with not violating the PK and FK constraints. In the next SQL code block, we try and reinsert the newly created customer record inserted above. Instead of having the code block fail, it throws a duplicate key exception error message. If you knit the document, the exception error message is thrown to the R Markdown tab. dbExecute(con, &quot; do $$ DECLARE v_customer_id INTEGER; begin v_customer_id = 600; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(v_customer_id,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE ,now(),now()::date,1); exception when unique_violation then raise notice &#39;SQLERRM = %, customer_id = %&#39;, SQLERRM, v_customer_id; when others then raise &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 The number above shows how many rows were inserted. To ensure that the thrown error message is part of the book, the error message is shown below. NOTICE: SQLERRM = duplicate key value violates unique constraint &quot;customer_pkey&quot;, customer_id = 600 CONTEXT: PL/pgSQL function inline_code_block line 12 at RAISE 14.1.8 R Exercise: Inserting a Single Row via a Dataframe In the following code block replace Sophie Yang with your name where appropriate. Note: The last data frame parameter sets the stringsAsFactors is FALSE. Databases do not have a native FACTOR type. The dataframe column names must match the table column names. The dbWriteTable function needs append = true to actually insert the new row. The dbWriteTable function has an option ‘overwrite’. It is set to FALSE by default. If it is set to TRUE, the table is first truncated before the row is inserted. No write occurs if both overwrite and append = FALSE. df &lt;- data.frame( customer_id = 601 , store_id = 2 , first_name = &quot;Sophie&quot; , last_name = &quot;Yang&quot; , email = &quot;sophie.yang@sakilacustomer.org&quot; , address_id = 1 , activebool = TRUE , create_date = Sys.Date() , last_update = Sys.time() , active = 1 , stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df, append = TRUE, row.names = FALSE) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 14.2 SQL Multi-Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list1&gt;, ... &lt;values listn&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns (&lt;values list&gt;) : values assoicated with the column list. Postgres and some other flavors of SQL allow multiple rows to be inserted at a time. The syntax is identical to the Single Row syntax, but includes multiple (&lt;values list&gt;) clauses separated by commas. Note that each value list is enclosed it a set of parenthesis. The following code block illustrates the SQL multi-row insert. Note that the customer_id column takes on sequential values to satisfy the PK constraint. 14.3 SQL Multi-Row Insert Data Example # dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(602,4,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE ,now()::date,now()::date,1) ,(603,5,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE ,now()::date,now()::date,1) ,(604,6,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE ,now()::date,now()::date,1) ;&quot; ) ## [1] 3 14.4 DPLYR Multi-Row Insert Data Example The Postgres R multi-row insert is similar to the single row insert. The single column values are converted to a vector of values. 14.4.1 R Exercise: Inserting Multiple Rows via a Dataframe Replace the two first_name, last_name, and email column values with your own made up values in the following code block. The output should be all of our new customers, customer_id = {600 - 606}. customer_id &lt;- c(605, 606) store_id &lt;- c(3, 4) first_name &lt;- c(&quot;John&quot;, &quot;Ian&quot;) last_name &lt;- c(&quot;Smith&quot;, &quot;Frantz&quot;) email &lt;- c(&quot;john.smith@sakilacustomer.org&quot;, &quot;ian.frantz@sakilacustomer.org&quot;) address_id &lt;- c(3, 4) activebool &lt;- c(TRUE, TRUE) create_date &lt;- c(Sys.Date(), Sys.Date()) last_update &lt;- c(Sys.time(), Sys.time()) active &lt;- c(1, 1) df2 &lt;- data.frame(customer_id, store_id, first_name, last_name, email, address_id, activebool, create_date, last_update, active, stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df2, append = TRUE, row.names = FALSE ) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) Confirm that the two new rows, customer_id = { 605, 606} are in the output. The next two code block show all the rows in the store and staff tables. Notice that neither table has a staff_id or a manager_staff_id = 10. We will attempt to insert such a row in the upcoming code blocks. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) staff &lt;- dbGetQuery(con ,&quot;select staff_id, first_name, last_name, address_id, email, store_id from staff;&quot;) sp_print_df(staff) 14.4.2 Creating a Messy Store Row A new store row is needed to illustrate a right outer join in a future code block. However, one cannot insert/update a row into the store table with a manager_staff_id = 10 because of a foreign key constraint on the manager_staff_id column. The manager_staff_id value must satisfy two conditions before the database will allow the new store row to be inserted into the table when the table constraints are enabled.: The manager_staff_id must be unique when inserted into the store table. The manager_staff_id must match a staff table staff_id value. Next we show both error messages: The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 1, but fails with a unique constraint error message. The manager_staff_id = 1 already exists in the store table. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 1; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 Error in result_create(conn@ptr, statement) : Failed to prepare query: server closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request. The number above should be 0 and indicates no row was inserted. The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 10, but fails with a foreign key constraint error message because there does not exist a staff table row with staff_id = 10. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 10; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 NOTICE: SQLERRM = insert or update on table &quot;store&quot; violates foreign key constraint &quot;store_manager_staff_id_fkey&quot;, manager_staff_id = 10 CONTEXT: PL/pgSQL function inline_code_block line 9 at RAISE Again, the number above should be 0 and indicates no row was inserted. The following three code blocks disables all the database constraints on the store table Inserts the store row with store_id = 10 via a dataframe. Re-enabes the database constraints on the store table # dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 df &lt;- data.frame( store_id = 10 , manager_staff_id = 10 , address_id = 10 , last_update = Sys.time() ) dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, row.names = FALSE) dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 The zeros after the dbExecute code blocks indicate that the dbExecute calls did not alter any rows on the table. In the next code block we confirm our new row, store_id = 10, was actually inserted. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) 14.5 Create a film record dbExecute( con, &quot;insert into film (film_id,title,description,release_year,language_id ,rental_duration,rental_rate,length,replacement_cost,rating ,last_update,special_features,fulltext) values(1001,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;orphaned language_id=10&#39;,2018,1 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ,(1002,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;orphaned language_id=10&#39;,2018,1 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ; &quot;) ## [1] 2 dbExecute( con, &quot;insert into film_category (film_id,category_id,last_update) values(1001,6,now()::date) ,(1001,7,now()::date) ,(1002,6,now()::date) ,(1002,7,now()::date) ;&quot;) ## [1] 4 dbExecute( con, &quot;insert into inventory (inventory_id,film_id,store_id,last_update) values(4582,1001,1,now()::date) ,(4583,1001,2,now()::date) ;&quot;) ## [1] 2 dbExecute( con, &quot;insert into rental (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update) values(16050,now()::date - interval &#39;1 week&#39;,4582,600,now()::date,1,now()::date) ;&quot;) ## [1] 1 Diconnect from the db: dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-dplyr-joins.html", "Chapter 15 SQL &amp; dplyr joins 15.1 Joins 15.2 Natural Join Delayed Time Bomb 15.3 Join Templates 15.4 Inner Joins 15.5 Left Joins 15.6 Why Include one of the Inner Join Key columns? 15.7 Right Joins 15.8 Full Join 15.9 Semi Join 15.10 Anti Joins 15.11 Non-Equa-Join Example", " Chapter 15 SQL &amp; dplyr joins This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 51 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) source(file=here(&#39;book-src/sql_pet_data.R&#39;),echo=TRUE) ## ## &gt; dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 4 ## ## &gt; dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from customer where customer_id &gt;= 600;&quot;) ## [1] 7 ## ## &gt; dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into customer\\n (customer_id,store_id,first_name,last_name,email,address_id,activebool\\n ,create_date,last_update,active)\\n ...&quot; ... [TRUNCATED] ## [1] 5 ## ## &gt; dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; df &lt;- data.frame(store_id = 10, manager_staff_id = 10, ## + address_id = 10, last_update = Sys.time()) ## ## &gt; dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, ## + row.names = FALSE) ## ## &gt; dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; dbExecute(con, &quot;insert into film\\n (film_id,title,description,release_year,language_id\\n ,rental_duration,rental_rate,length,replacement_cost,rati ...&quot; ... [TRUNCATED] ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into film_category\\n (film_id,category_id,last_update)\\n values(1001,6,now()::date)\\n ,(1001,7,now()::date)\\n ;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into inventory\\n (inventory_id,film_id,store_id,last_update)\\n values(4582,1001,1,now()::date)\\n ,(4583,1001,2,now()::date ...&quot; ... [TRUNCATED] ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into rental\\n (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update)\\n values(16050,now()::date ...&quot; ... [TRUNCATED] ## [1] 1 15.1 Joins In section ‘SQL Quick Start Simple Retrieval’, there is a brief discussion of databases and 3NF. One of the goals of normalization is to eliminate redundant data being kept in multiple tables and having each table contain a very granular level of detail. If a record then needs to be updated, it is updated in one table instead of multiple tables improving overall system performance. This also helps simplify and maintain referential integrity between tables. Normalization breaks data down and JOINs denormalizes the data and builds it back up. The tables are typically related via a primary key - foreign key relationship. The Postgres database enforces the primary and foreign key constraints in the DVD rental database. 15.1.1 Join Types The diagram above shows the hierarchy of the different types of joins. In the boxes above: The joins are based on a single column from the two tables, the left and right tables. Joins can be based on multiple columns from both tables. The L. and R. are aliases for the left and right table names. Often the joining columns have the same name as in the Natural Join, L.col1 = R.col1 However, the joining column names can be different L.col1 = R.col2. All joins are based on equality between the table columns, L.col1 = R.col2, except the inner join which can use non-equality column conditions. Non-equality column conditions are rare. Equa Joins are subset of the Inner Join. For this tutorial, we can think of joins as either an Inner/eqau Join or an Outer Join. Instead of showing standard Venn diagrams showing the different JOINS, we use an analogy. For those interested though, the typical Venn diagrams can be found here. 15.1.2 Valentines Party Imagine you are at a large costume Valentine’s Day dance party. The hostess of the party, a data scientist, would like to learn more about the people attending her party. When the band takes a break, she lets everyone know it is time for the judges to evaluate the winners for best costumes and associated prizes. ValentinesDay She requests the following: All the couples at the party line up in front of her in a single line with the men on her left and the women on her right, (inner join) All the remaining men to form a second line two feet behind the married men, (left outer join, all couples + unattached men) All the remaining women to form a third line two feet in front of the married women, (right outer join, all couples + unattached women) As our data scientist looks out, she can clearly see the three distinct lines, the single men, the man woman couples, and the single women, a full outer join. As the three judges start walking down the lines, she makes one more announcement. There is a special prize for the man and woman who can guess the average age of the members of the opposite sex. To give everyone a chance to come up with an average age, she asks the men to stay in line and the women to move down the men’s line in order circling back around until they get back to their starting point in line, (Cartesian join, every man seen by every woman and vice versa). It is hard enough to tell someone’s age when they don’t have a mask, how do you get the average age when people have masks? The hostess knows that there is usually some data anomalies. As she looks out she sees a small cluster of people who did not line up. Being the hostess with the mostest, she wants to get to know that small cluster better. Since they are far off and in costume, she cannot tell if they are men or women. More importantly, she does not know if they identify as a man or a woman, both – (kind of a stretch for a self join), neither, or something else. Ah, the inquisitive mind wants to know. 15.1.3 Join Syntax The table below shows the two R join function call formats, standalone function call and pipe function call and the corresponding SQL join format. Join dplyr sql inner inner_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% inner_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) left left_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c left outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% left_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) right right_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c right outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% right_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) full full_join(customer_tbl, rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) from customer c full outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% full_join(rental_tbl, by = ‘customer_id’, suffix = c(“.c”, “.r”)) semi semi_join(customer_tbl, rental_tbl, by = ‘customer_id’) customer_tbl %&gt;% semi_join(rental_tbl, by = ‘customer_id’) anti anti_join(customer_tbl, rental_tbl, by = ‘customer_id’) 15.1.4 Join Tables The dplyr join documentation describes two different types of joins, mutating and filtering joins. For those coming to R with a SQL background, the mutating documentation is misleading in one respect. Here is the inner_join documentation. inner_join() return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned. The misleading part is ‘and all the columns from x and y.’ If the join column is KEY, SQL will return x.KEY and y.KEY. Dplyr returns just KEY, the KEY from the driving table. This is important if you are translating SQL to R because SQL developers will reference both columns x.KEY and y.KEY. One needs to mutate the the y.KEY column. This difference should become clear in the outer join examples. In the next couple of examples, we will use a small sample of the customer and store table data from the database to illustrate the diffent joins. In the *_join verbs, the by and suffix parameters are included because it helps document the actual join and the source of join columns. If the suffix parameter is excluded, it defaults to .x to refer to the first table and .y for the second table. If the dplyr pipe has many joins, the suffix parameter makes it clearer which table the column came from. In the next code block, we perform a Cartesian join to illustrate the default suffix behavior. Note that every column that has a suffix of x or y except the key column and that the column values may or may not be the same based on the column name without the suffix. If one has a lot of joins in the piple with tables that have many duplicate column names, it is hard to keep track of the source of the column. store_table &lt;- DBI::dbReadTable(con, &quot;store&quot;) store_table$key &lt;- 1 cartesian_join &lt;- inner_join(store_table,store_table, by=(&#39;key&#39;=&#39;key&#39;)) %&gt;% select(-key,-last_update.x,-last_update.y) sp_print_df(cartesian_join) The suffix parameter helps distinguish the duplicate column names as shown in next example. cartesian_join2 &lt;- inner_join(store_table,store_table, by=(&#39;key&#39;=&#39;key&#39;) , suffix=c(&#39;.store1&#39;,&#39;.store2&#39;)) %&gt;% select(-key,-last_update.store1,-last_update.store2) sp_print_df(cartesian_join2) 15.2 Natural Join Delayed Time Bomb The dplyr default join is a natural join, joining tables on common column names. One of many links why one should not use natural joins can be found here. If two tables are joined via a natural join on column C1 the join continues to work as long as no additional common columns are added to either table. If a new new column C2 is added to one of the tables and C2 already exists in the other table, BOOM, the delayed time bomb goes off. The natural join still executes, doesn’t throw any errors, but the returned result set may be smaller, much smaller, than before the new C2 column was added. 15.2.1 SQL Customer store_id Distribution The next code block calculates the store_id distribution in the customer and store tables across all their rows. The results will be used in following sections to validate different join result sets. store_distribution_sql &lt;- dbGetQuery(con ,&quot;select &#39;customer&#39; tbl, store_id,count(*) count from customer group by store_id union select &#39;store&#39; tbl,store_id,count(*) count from store group by store_id order by tbl,store_id;&quot; ) sp_print_df(store_distribution_sql) 15.2.2 Sample Customer and Store Join Data The following code block extracts sample customer and the store data. The customer data is restricted to 10 rows to illustrate the different joins. The 10 rows are used in the detail examples in order to perform a sanity check that the join is actually working. Each detail example is followed by an aggregated summary across all rows of customer and store table. sample_customers &lt;- dbGetQuery(con,&quot;select customer_id,first_name,last_name,store_id from customer where customer_id between 595 and 604&quot;) stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(sample_customers) sp_print_df(stores) 15.2.3 dplyr store_id distribution Exercise Execute and Review the output from the code block below. Union and arrange the output to match the SQL output in the previous code block. customer_table &lt;- DBI::dbReadTable(con, &quot;customer&quot;) store_table &lt;- DBI::dbReadTable(con, &quot;store&quot;) customer_summary &lt;- customer_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;customer&#39;) %&gt;% select(table,store_id,count) store_summary &lt;- store_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;store&#39;) %&gt;% select(table,store_id,count) sp_print_df(customer_summary) sp_print_df(store_summary) ## UNION the two summary tables and ARRANGE the output to match the SQL output from the previouse code block 15.3 Join Templates In this section we perform various joins using dplyr and SQL. Each dplyr code block has three purposes. Show working detail/summary data join examples. The code blocks can be used as templates for beginning more complex dplyr pipes. The code blocks show the number of joins performed. In these examples the ‘customer’ is always the left table and ‘store’ is always the right table. The join condition shown in the by parameter by = c(&#39;store_id&#39;=&#39;store_id&#39;) is on the common foreign - primary key column store_id. This is technically an equi-join condition which makes our joins 1-to-1 and keeps the result set small. In multi-column joins, each language_id would be replaced with a vector of column names used in the join by position. Note the column names do not need to be identical by position. The suffix parameter is a way to distinguish the same column name in the joined tables. The suffixes are usually an single letter to represent the name of the table. 15.4 Inner Joins 15.4.1 SQL Inner Join Details {example_inner-join-details-sql} For an inner join between two tables, it doesn’t matter which table is on the left, the first table, and which is on the right, the second table, because join conditions on both tables must be satisfied. Reviewing the table below shows the inner join on our 10 sample customers and 3 store records returned only 6 rows. The inner join detail shows only rows with matching store_id’s. customer_store_details_sij &lt;- dbGetQuery(con, &quot;select &#39;ij&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot;) sp_print_df(customer_store_details_sij) 15.4.2 Dplyr Inner Join Details {example_inner-join-details-dplyr} customer_ij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &#39;ij&#39; ) %&gt;% rename(s_address_id = address_id.y) %&gt;% select(join_type,customer_id,first_name,last_name,store_id ,store_id,manager_staff_id, s_address_id) sp_print_df(customer_ij) Compare the output from the SQL and Dplyr version. The SQL output has a c_store_id and a s_store_id column and the Dplyr output only has store_id. In this case, because it is an inner join, it doesn’t matter because they will always the same. 15.4.3 SQL Inner Join Summary {example_inner-join-summary-sql} Note that both the store_id is available from both the customer and store tables, c.store_id,s.store_id, in the select clause. customer_store_summay_sij &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id,s.store_id s_store_id,count(*) n from customer c join store s on c.store_id = s.store_id group by c.store_id,s.store_id;&quot; ) sp_print_df(customer_store_summay_sij) 15.4.4 Dplyr Inner Join Summary {example_inner-join-summary_dplyr} In the previous SQL code block, c. and s. were used in the inner join as table aliases. The dplyr suffix is similar to the SQL table alias. The role of the dplyr suffix and the SQL alias is to disambiguate duplicate table and column names referenced. customer_store_summary_dij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;ij&quot; ,c_store_id = if_else(is.na(customer_id),customer_id, store_id) ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% group_by(join_type,c_store_id,s_store_id) %&gt;% summarize(n = n()) sp_print_df(customer_store_summary_dij) 15.5 Left Joins 15.5.1 SQL Left Join Details {example_left-join-details-sql} The SQL block below shows all 10 sample customer rows, the customer table is on the left and is the driving table, in the detail output which join to 2 of the 3 rows in the store table. All the rows with customer store_id greater than 2 have null/blank store column values. customer_store_details_sloj &lt;- dbGetQuery(con, &quot;select &#39;loj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c left join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot;) sp_print_df(customer_store_details_sloj) 15.5.2 Dplyr Left Join Details {example_left-join-details-dplyr} The next code block shows the left join details. Note that the s_store_id column is derived via the mutate function, but not shown in the output below. Without the s_store_id column, it might accidentally be assumed that the store.store_id = customer.store_id when the store.store_id values are actually NULL/NA based on the output without the s_store_id column. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% rename(s_address_id = address_id.y) %&gt;% select(join_type,customer_id,first_name,last_name,store_id ,manager_staff_id, s_address_id) sp_print_df(customer_store_detail_dloj) The following code block includes the derived s_store_id value. The output makes it explicit that the s_store_id value is missing. The sp_print_df function is replaced with the print function to show the actual NA values. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% rename(c_store_id = store_id ,s_address_id = address_id.y) %&gt;% select(customer_id,first_name,last_name,c_store_id ,s_store_id,manager_staff_id, s_address_id) print(customer_store_detail_dloj) ## customer_id first_name last_name c_store_id s_store_id manager_staff_id ## 1 595 Terrence Gunderson 1 1 1 ## 2 596 Enrique Forsythe 1 1 1 ## 3 597 Freddie Duggan 1 1 1 ## 4 598 Wade Delvalle 1 1 1 ## 5 599 Austin Cintron 2 2 2 ## 6 600 Sophie Yang 3 NA NA ## 7 601 Sophie Yang 2 2 2 ## 8 602 John Smith 4 NA NA ## 9 603 Ian Frantz 5 NA NA ## 10 604 Ed Borasky 6 NA NA ## s_address_id ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 2 ## 6 NA ## 7 2 ## 8 NA ## 9 NA ## 10 NA In the remaining examples, the dplyr code blocks will show both the customer and store store_id values with the either c_ or s_ store_id prefix . The sp_print_df function returns the SQL NULL and R NA values as blanks. 15.5.3 SQL Left Join Summary {example_left-join-summary-sql} For a left outer join between two tables, it does matter which table is on the left and which is on the right, because every row in the left table is returned when there is no where/filter condition. The second table returns row column values if the join condition exists or null collumn values if the join condition does not exist. The left join is the most frequently used join type. Note that SQL returns the store_id from both the customer and store tables, c.store_id,s.store_id, in the select clause. customer_store_summary_sloj &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id,s.store_id s_store_id,count(*) loj from customer c left join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by c.store_id;&quot; ) sp_print_df(customer_store_summary_sloj) The lojs column returns the number of rows found on the store_id, from the customer table and the store table if on both tables, rows 1 - 2. The right table, the store table returned blank/NA, when the key only exists in the customer table, rows 3 - 6. The left outer join always returns all rows from the left table, the driving/key table, if not reduced via a filter()/where clause. All inner join rows can reference all columns/derived columns specified in the select clause from both the left and right tables. All rows from the left table, the outer table, without a matching row on the right returns all the columns/derived column values specified in the select clause from the left, but the values from right table have all values of NA. 15.5.4 Dplyr Left Join Summary {example_left-join-summary-dplyr} The dplyr outer join verbs do not return the non-driving table join values. Compare the mutate verb s_store_id in the code block below with s.store_id in the equivalent SQL code block above. customer_store_summary_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;loj&quot; ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% group_by(join_type, store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% rename(c_store_id = store_id) %&gt;% select(join_type, c_store_id, s_store_id, n) sp_print_df(customer_store_summary_dloj) print(customer_store_summary_dloj) ## # A tibble: 6 x 4 ## # Groups: join_type, c_store_id [6] ## join_type c_store_id s_store_id n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 loj 1 1 326 ## 2 loj 2 2 274 ## 3 loj 3 NA 1 ## 4 loj 4 NA 1 ## 5 loj 5 NA 1 ## 6 loj 6 NA 1 15.6 Why Include one of the Inner Join Key columns? It is not uncommon to have many many tables joined together as a series of left outer joins. If the inner join key column is included in the output, one knows that the inner join condition was met or not. If the key column is not shown and non-key columns are shown from the inner table, they may actually be null. It is often the case that a long series of left outer joins just join on the key column to get one value out of the table to join to the next table in the series. One can think of the two components of an inner join as a transaction is either in an open state, no matching rows in the inner table or a closed state with one or more matching rows in the inner table. Assume that we have a four DVD rental step process represented via table A, B, C, and D left outer joined together. Summing the null and non-null keys together across all four tables gives a quick snap shot of the business in the four different steps. We will review this concept in some detail in one of the future exercises. 15.7 Right Joins 15.7.1 SQL Right Join Details {example_right-join-details-sql} The SQL block below shows only our sample customer rows, (customer_id between 595 and 604). The driving table is on the right, the store table. Only six of the 10 sample customer rows appear which have store_id = {1, 2}. All three store rows appear, row_id = {1,2,10}. The right join is least frequently used join type. customer_store_detail_sroj &lt;- dbGetQuery(con, &quot;select &#39;roj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id, s.address_id from customer c right join store s on c.store_id = s.store_id where coalesce(customer_id,595) between 595 and 604;&quot;) sp_print_df(customer_store_detail_sroj) Compare the SQL left join where clause where customer_id between 595 and 604;&quot;) with the SQL right join where clause where coalesce(customer_id,595) between 595 and 604;&quot;) The customer table is the driving table in the left join and always returns all rows from the customer table on the left that match the join and satisfy the where clause. The store table is the driving table in the right join and always returns all rows from the store table on the right that match the join and satisfy the where clause. The right outer join condition shown always returns the store.store_id=10 row. Since the customer table does not have the corresponding row to join to, the right outer join return a customer row with all null column values. The coalesce is a NULL if-then-else test. If the customer_id is null, it returns 595 to prevent the store_id = 10 row from being dropped from the result set. The right outer join clause can be rewritten as where customer_id between 595 and 604 or customer_id is null; See the next dplyr code block to see the alternative where clause shown above. 15.7.2 Dplyr Right Join Details {example_right-join-details-dplyr} customer_store_detail_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate(join_type = &quot;roj&quot; ,c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename(s_store_id = store_id ,s_address_id = address_id.y) %&gt;% select(customer_id,first_name,last_name,s_store_id ,c_store_id,manager_staff_id, s_address_id) sp_print_df(customer_store_detail_droj) 15.7.3 SQL Right Outer Join Summary {example_right-join-summary-sql} customer_store_summary_sroj &lt;- dbGetQuery( con, &quot;select &#39;roj&#39; join_type,c.store_id c_store_id,s.store_id s_store_id,count(*) rojs from customer c right outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id;&quot; ) sp_print_df(customer_store_summary_sroj) The rojs column returns the number of rows found on the keys from the right table, store, and the left table, the customer table. The right outer join always returns all rows from the right table, the driving/key table, if not reduced via a filter()/where clause. All rows that inner join returns all the columns/derived columns specified in the select clause from both the left and right tables. All rows from the right table, the outer table, without a matching row on the left returns all the columns/derived column values specified in the select clause from the right, but the values from left table have all values of NA. This line 3, store.store_id = 10. 15.7.4 dplyr Right Join Summary {example_right-join-summary-dplyr} customer_store_summary_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;)), all = store_table) %&gt;% mutate( c_store_id = if_else(is.na(customer_id),customer_id, store_id) , join_type = &quot;rojs&quot; ) %&gt;% group_by(join_type, store_id,c_store_id) %&gt;% summarize(n = n()) %&gt;% rename(s_store_id = store_id) %&gt;% select(join_type, s_store_id,c_store_id, n) sp_print_df(customer_store_summary_droj) 15.8 Full Join 15.8.1 SQL Full Join Details {example_full-join-details-sql} The full outer join is a conbination of the left and right outer joins and returns all matched and unmatched rows from the ON clause. The matched rows return their table column values and the unmatched rows return NULL column values. This can result in a very large result set. The next SQL block implements a full outer join and returns 12 rows. Change the Show entries from 10 to 25 to see all the entries. customer_store_details_sfoj &lt;- dbGetQuery(con, &quot;select &#39;foj&#39; join_type, c.customer_id,c.first_name,c.last_name,c.store_id c_store_id ,s.store_id s_store_id,s.manager_staff_id,s.address_id from customer c full outer join store s on c.store_id = s.store_id where coalesce(c.customer_id,595) between 595 and 604;&quot;) sp_print_df(customer_store_details_sfoj) 15.8.2 Dplyr Full Join Details {example_full-join-details-sql} customer_store_detail_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate(join_type = &quot;roj&quot; ,c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename(s_store_id = store_id ,s_address_id = address_id.y) %&gt;% select(customer_id,first_name,last_name,s_store_id ,c_store_id,manager_staff_id, s_address_id) sp_print_df(customer_store_detail_dfoj) 15.8.3 SQL Full Join Summary {example_full-join-summary-sql} The result set below is ordered by the store.store_id. customer_store_summary_sfoj &lt;- dbGetQuery( con, &quot;select &#39;foj&#39; join_type,c.store_id c_store_id,s.store_id s_store_id,count(*) fojs from customer c full outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id,c.store_id;&quot; ) sp_print_df(customer_store_summary_sfoj) 15.8.4 Dplyr Full Join Summary {example_full-join-summary-dplyr} The full outer join summary seven rows. Store_id = {1,2} appear in both table tables. Store_id = {3 - 6} appear only in the customer table which is on the left. Store_id = 10 appears only in the store table which is on the right. customer_store_summary_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &quot;fojs&quot; ,c_store_id = if_else(is.na(customer_id),customer_id, store_id) ,s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% group_by(join_type,c_store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% arrange(s_store_id) sp_print_df(customer_store_summary_dfoj) 15.9 Semi Join Below is the dplyr semi_join documentation. semi_join() return all rows from x where there are matching values in y, keeping just columns from x. A semi join differs from an inner join because an inner join will return one row of x for each matching row of y, where a semi join will never duplicate rows of x. The semi join always returns one and only one row from the x table that satisfies the inner join condition. If we look at one key value on both x and y where the x table has 1 x.key row and y and n y.key rows, then the inner join returns n x.key rows, (1-to-n), and the semi-join returns just one x.key row, (1-to-1). 15.9.1 SQL Semi Join Customer to Store {example_semi-join-sql-1} SQL does not have an explicity ‘semi join’ key word. The semi join reduces relationships from 1-to-n to 1-to-1. SQL uses an EXISTS - subquery syntax to implement the semi join. 15.9.1.1 SQL EXISTS and Correlated SubQuery Syntax select * FROM table1 l WHERE EXISTS(SELECT 1 FROM table2 r where l.c = r.c) The EXISTS keyword checks if one or more rows satsify the SELECT clause enclosed in parenthesis, the correlated subquery. The r.c column from table2, the inner/right table, is correlated to the l.c column from table1, the outer/left table. For all the table1 rows where the EXISTS clause returns TRUE, the table1 rows are returned. There is no way to reference table2 columns in the outer select, hence the semi join. All the previous joins were mutating joins, the joins resulted in a blending of columns from both tables. A semi join only returns rows from a single table and is a filtering join. The mutating examples included a count column to show the 1-to-n relationships. Filtering joins are 1-to-1 and the count column is dropped in the following examples. customer_store_ssj &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,customer_id,first_name,last_name,c.store_id c_store_id from customer c where customer_id &gt; 594 and exists( select 1 from store s where c.store_id = s.store_id); ;&quot;) sp_print_df(customer_store_ssj) Note that this returned the six rows from the customer table that satisfied the c.store_id = s.store_id join condition. It is the same as the SQL Inner Join example earlier, but without the store columns. All the relationships are 1-to-1. 15.9.2 Dplyr Semi Join Customer to Store {example_semi-join-dplyr-1} The corresponding Dplyr version is shown in the next code block. customer_store_dsj &lt;- customer_table %&gt;% semi_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type,customer_id,first_name,last_name,store_id ,store_id) sp_print_df(customer_store_dsj) 15.9.3 SQL Semi Join Store to Customer {example_semi-join-sql-2} In the following Semi Join, the driving table is switched to the store table and our 10 sample customers as the right table. store_customer_detail_ssj &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,s.store_id s_store_id,s.manager_staff_id, s.address_id from store s where EXISTS(select 1 from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) ;&quot;) sp_print_df(store_customer_detail_ssj) Here we see that we get the two rows from the store table that satisfy the s.store_id = c.store_id, store_id = {1,2}. In this example the relationship between store and customer is 1-to-n, but we do not know that from the output. 15.9.4 Dplyr Semi Join Store to Customer {example_semi-join-dplyr-2} The corresponding Dplyr version is shown in the next code block. Note that the filter condition on the customer table has been removed because the semi_join does not return any customer columns. store_customer_dsj &lt;- store_table %&gt;% semi_join(customer_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type,store_id,manager_staff_id, address_id) sp_print_df(store_customer_dsj) 15.9.5 SQL Semi Join Store to Customer Take 2 {example_semi-join-sql-3} In the Semi Join Customer to Store examples, we saw four rows with store_id = 1 and two rows with store_id = 2. The EXISTS key word is replaced with a count of the matching rows. store_customer_detail_ssj2 &lt;- dbGetQuery(con, &quot;select &#39;sj&#39; join_type,s.store_id s_store_id,s.manager_staff_id, s.address_id from store s where (select count(*) from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) in (2,4) ;&quot;) sp_print_df(store_customer_detail_ssj2) To generalize the test above, replace in {2,4} with &gt; 0. 15.10 Anti Joins A semi join returns rows from one table that has one or more matching rows in the other table. The anti join returns rows from one table that has no matching rows in the other table. 15.10.0.1 dplyr anti Join {example_anti-join-dplyr} The anti join is an outer join without the inner joined rows. It only returns the rows from the driving table that do not have a matching row from the other table. customer_store_aj &lt;- customer_table %&gt;% filter(customer_id &gt; 594) %&gt;% anti_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &quot;anti_join&quot;) sp_print_df(customer_store_aj) All of the rows returned from the customer table have store_id = {3 - 6} which do not exist in the store_id. 15.10.0.2 SQL anti Join 1, NOT EXISTS and Correlated subquery {example_anti-join-sql-1} SQL doesn’t have an anti join key word. Here are three different ways to achieve the same result. This is the negation of the same construct used in the semi join discusion. The anit-join tests for 0 matches instead of 1 or more matches for the semi-join. rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where not exists (select 1 from store s where s.store_id = c.store_id) order by c.customer_id &quot; ) sp_print_df(rs) 15.10.0.3 SQL anti Join 2, Left Outer Join where NULL on Right {example_anti-join-sql-1} rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id ajs from customer c left outer join store s on c.store_id = s.store_id where s.store_id is null order by c.customer_id;&quot; ) sp_print_df(rs) 15.10.0.4 SQL anti Join 3, ID in driving table and NOT IN lookup table {example_anti-join-sql-3} rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where c.store_id NOT IN (select store_id from store) order by c.customer_id;&quot; ) sp_print_df(rs) 15.11 Non-Equa-Join Example All the previous examples are equa-joins and is the most common type of join. The next example is made up and shows a ‘&lt;=’ join. The store table is usd. Assume that the store_id actually represents some distance. The example shows all distances &lt;= to all other distances. store_store_slej &lt;- dbGetQuery( con, &quot;select &#39;lej&#39; join_type,s1.store_id starts,s2.store_id stops, s2.store_id - s1.store_id delta from store s1 join store s2 on s1.store_id &lt;= s2.store_id order by s1.store_id;&quot; ) sp_print_df(store_store_slej) 15.11.1 Dplyr Non-equa Join {example_inner-join-dplyr} Dplyr doesn’t currently support a non-equa join. In the by parameter, one can not change the ‘=’ to ‘&lt;=’ as shown below. {r} store_store_slej &lt;- store_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; &lt;= &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) The above code block throws the following error message. Error: `by` must be a (named) character vector, list, or NULL for natural joins (not recommended in production code), not logical Call `rlang::last_error()` to see a backtrace The explaination below is from here and it was posted Nov 25 ’17. In by = c(“col1” = “col2”), = is not and equality operator, but an assignment operator (the equality operator in R is ==). The expression inside c(…) creates a named character vector (name: col1 value: col2) that dplyr uses for the join. Nowhere do you define the kind of comparison that is made during the join, the comparison is hard-coded in dplyr. I don’t think dplyr supports non-equi joins (yet). # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["sql-metadata-exercises.html", "Chapter 16 SQL Metadata exercises 16.1 Table Structures 16.2 Table Column Metadata 16.3 Primary and Foreign Key Constraints 16.4 We need documentation and/or a DBA.", " Chapter 16 SQL Metadata exercises This chapter demonstrates: Finding table column metadata for any specific table Finding the primary and foreign keys for any specific table Reusing SQL via parameterization Why understanding the contents of a database requires a team approach. Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; 57 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 16.1 Table Structures 16.1.1 Customer Columns In an earlier chapter we used functions dbListTable and dbListFields from the DBI package to get a list of tables and the fields in a table. Below we list out the columns from the customer table. dbListFields(con, &quot;customer&quot;) ## [1] &quot;customer_id&quot; &quot;store_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;email&quot; ## [6] &quot;address_id&quot; &quot;activebool&quot; &quot;create_date&quot; &quot;last_update&quot; &quot;active&quot; A couple of things immediately jump out based on the column names: There are three *_id columns, customer_id, store_id, and address_id. ID columns are typically an integer type. It is common convention to have the table primary key column(s) at the beginning of the table or a set of columns at the beginning of the table that make the row unique. Just looking at the column names, one cannot tell if the customer is uniquely identified by just the customer_id or the customer_id + store_id. Are there customers who visit both stores? Based on the column names, it looks like there are three string/character columns, first_name, last_name, and email. What are the sizes of these colums? There are two dates, create_date and last_update. There are two active columns, activebool and active. The activebool looks like it is a boolean column. What type of column is active, integer or text? Databases maintains a data dictionary of metadata on all the database objects. SQL databases have two useful tables for getting table and table column information, information_schema.tables and information_schema.columns. AS an example, the following code block returns a summary of the number of tables and views in the differnt schemas. The tables and views associated with DVD Rentals are in the public table_schema. The metadata of the tables and views in the public table_schema are contained in the information_schema. The information_schema provides information about all of the tables, views, columns, and procedures in the entire database, not just DVD Rentals. We are interested in the tables and columns views. info_schema &lt;- dbGetQuery(con ,&quot;Select t.table_catalog ,t.table_schema ,t.table_name ,t.table_type from information_schema.tables t where t.table_schema = &#39;information_schema&#39; and table_name in (&#39;tables&#39;,&#39;columns&#39;) &quot;) sp_print_df(info_schema) 16.2 Table Column Metadata The next code block uses the information_schema.columns to return column information from any table in the Dvdrental database. This code block is an example of a parameterized R function, sp_tbl_descr, sql pet table description. Sp_tbl_descr uses the dvdrental.information_schema.columns table to return some of the metadata on a dvdrental table. The function is restricted to the dvdrenatal database, see the where clause and c.table_catalog = 'dvdrental'. The function has one parameter passed it, table_name. Parameter substitution occurs in the where clause, and c.table_name = $1. The paramter substituion variable syntax depends on the vendor. The dbGetQuery documentation shows con &lt;- dbConnect(RSQLite::SQLite(), &quot;:memory:&quot;) dbGetQuery(con, &quot;SELECT COUNT(*) FROM mtcars WHERE cyl = ?&quot;, param = list(1:8)) 16.2.1 sp_tbl_descr – Parameterized Table Description Function sp_tbl_descr &lt;- function (table_name) { dbGetQuery( con, &quot;select btrim(c.table_name) table_name, c.ordinal_position seq , c.column_name COL_NAME , case when c.udt_name = &#39;varchar&#39; then c.udt_name || case when c.character_maximum_length is not null then &#39;(&#39;||cast(c.character_maximum_length as varchar)||&#39;)&#39; else &#39;&#39; end when c.udt_name like (&#39;int%&#39;) then c.udt_name ||&#39;-&#39;||cast(c.numeric_precision as varchar) else c.udt_name end COL_TYPE , c.is_nullable is_null -- , c.column_default -- , t.table_catalog ,t.table_schema from dvdrental.information_schema.columns c join information_schema.tables t on c.table_name = t.table_name where 1 = 1 and c.table_catalog = &#39;dvdrental&#39; and c.table_name = $1&quot; ,table_name ) } The next code block returns the customer metadata via a call to the previous function. sp_tbl_descr(&#39;customer&#39;) ## table_name seq col_name col_type is_null table_schema ## 1 customer 1 customer_id int4-32 NO public ## 2 customer 2 store_id int2-16 NO public ## 3 customer 3 first_name varchar(45) NO public ## 4 customer 4 last_name varchar(45) NO public ## 5 customer 5 email varchar(50) YES public ## 6 customer 6 address_id int2-16 NO public ## 7 customer 7 activebool bool NO public ## 8 customer 8 create_date date NO public ## 9 customer 9 last_update timestamp YES public ## 10 customer 10 active int4-32 YES public The metadata tells us the length of the three varchar, variable length, columns. We can see that our two date columns are of different types, date and timestamp. is_null=NO tells us the column is required to have a value non-null value. is_null=YESotherwise it can be null. The activebool is either true or false. Without a definitive description of the column, we will assume that the customer is active, activebool=true or inactive, activebool=false. The active column, an int4 data type, can take on a large set of values. Why would an application need two active indicators? 16.3 Primary and Foreign Key Constraints The database or application designers implement constraints to help maintain referential integrity and improve database performance. One is the implementation of a primary key which must be unique for each row in the table. The primary key is usually defined as the first column. On occasion the primary key consists of multiple columns and none of these columns can be null. Looking back to the customer columns, what is the customer table primary key, customer_id or customer_id + store_id? The other constraint is a foreign key constraint which is one or more columns in one table that make up a primary key in another table. From the DVD Rental ERD, here, one can see that out of the 15 tables in the ERD, all but two tables have a single column primary key, film_category and the film_actor tables have two columns that define the primary key. The primary key columns have an asterisk to the left of the column name. For the single column keys, the primary key column is the name of the table suffixed with _id. The customer primary key is just customer_id column. Is the customer.store_id a foreign key to the store table? Based on ERD, the customer.store_id is not a foreign key to the store table. The next code block uses many information_schema objects to return a table’s primary and foreign keys for any table in the Dvdrental database. This code block is another example of a parameterized R function, sp_tbl_pk_fk, sql pet table primary key and foreign keys. Not all tables are required to have a primary key. If a table has one The function returns one or more columns that make up the table primary key. The function also returns any other table that has a foreign key reference to the table. The function is restricted to the Dvdrenatal database, see the where clause and c.table_catalog = 'dvdrental'. The function is restricted to the public schema where the Dvd rental table/views are kept, see the where clause c.table_schema = ‘public’. The function has one parameter passed it, table_name. Parameter substitution occurs in the where clause, AND (c.table_name = $1 or coalesce(c2.table_name, '') = $1). The paramter substituion occurs to see if the table_name passed has a primary key or refereced as a foreign table. 16.3.1 sp_tbl_pk_fk – Parameterized Table Primary Foreign Key(s) Function sp_tbl_pk_fk_sql &lt;- function(table_name) { dbGetQuery(con ,&quot;SELECT c.table_name ,kcu.column_name ,c.constraint_name ,c.constraint_type ,coalesce(c2.table_name, &#39;&#39;) ref_table ,coalesce(kcu2.column_name, &#39;&#39;) ref_table_col FROM information_schema.tables t LEFT JOIN information_schema.table_constraints c ON t.table_catalog = c.table_catalog AND t.table_schema = c.table_schema AND t.table_name = c.table_name LEFT JOIN information_schema.key_column_usage kcu ON c.constraint_schema = kcu.constraint_schema AND c.constraint_name = kcu.constraint_name LEFT JOIN information_schema.referential_constraints rc ON c.constraint_schema = rc.constraint_schema AND c.constraint_name = rc.constraint_name LEFT JOIN information_schema.table_constraints c2 ON rc.unique_constraint_schema = c2.constraint_schema AND rc.unique_constraint_name = c2.constraint_name LEFT JOIN information_schema.key_column_usage kcu2 ON c2.constraint_schema = kcu2.constraint_schema AND c2.constraint_name = kcu2.constraint_name AND kcu.ordinal_position = kcu2.ordinal_position WHERE c.constraint_type IN (&#39;PRIMARY KEY&#39;, &#39;FOREIGN KEY&#39;) AND c.table_catalog = &#39;dvdrental&#39; AND c.table_schema = &#39;public&#39; AND (c.table_name = $1 or coalesce(c2.table_name, &#39;&#39;) = $1) ORDER BY c.table_name,c.constraint_type desc&quot; ,param = list(table_name) ) } 16.3.2 Customer primary and foreign key constraints The next code block returns the customer primary and foreign key metadata via a call to the previous function. sp_tbl_pk_fk_sql(&#39;customer&#39;) ## table_name column_name constraint_name constraint_type ## 1 customer customer_id customer_pkey PRIMARY KEY ## 2 customer address_id customer_address_id_fkey FOREIGN KEY ## 3 payment customer_id payment_customer_id_fkey FOREIGN KEY ## 4 rental customer_id rental_customer_id_fkey FOREIGN KEY ## ref_table ref_table_col ## 1 ## 2 address address_id ## 3 customer customer_id ## 4 customer customer_id The table above tells us: The customer has customer_id as the primary key which matches the ERD. The customer address_id is a foreign key to the address table, the ref_table column and joins on the ref_table_col, address_id. The payment and rental tables have customer_id as a foreign key back to the customer table. The ERD matches the Primary and Foreign Key information in the table above. 16.4 We need documentation and/or a DBA. The output above shows that the store_id column is not part of the customer primary key and it isn’t foreign key to the store table. Some possible explanations are: The ERD is incomplete or it excluded some foreign keys to highlight other relationships. The SQL above is wrong. The customer-store foreign key constraint was just missed. On large systems this is not out of the realm of possibilities. The customer-store foreign key constraint was diabled. The customer-store foreign key constraint was designed out of the system. The DBA team or project documentation may help explain The true relation between the customer and store tables. Why there are two customer active columns, activebool and active. Some possible explanation for the two active columns are: The application vendor adds new functionality resulting in new columns being added to a table dropping a table and migrating the old data into one or more new tables splitting a table into one or more tables Sometimes applications are migrated from one vendor’s RDBMS to a different vedor’s RDBMS which usually introduces some kind of incompatability. A company has its own DBA’s add columns to a table to reflect new business requirements. All the existing records are updated to reconstruct the new data for the new columns or All the existing columns are defaulted to a single value. There is a break in the meaning of the new columns between the existing records and new records. The business DBA’s add new columns are added to tables to reflect some new business requirements. New columns are typically added to the end of the table. If a table is wide and the new column is at the end, it is very easy to miss the new column when having to scroll across the screen to find it. See figure 1 here for another ERD. What does this ERD tell us about the relationship between the customer and store tables? See the customer table column description here. What can we learn about the active column from this link? 16.4.1 Other Table Column Metadata In the next code block, change the function parameter to different table names to get the associated column metadata. If necessary, uncomment the dbListTable line to get a list of table names. #dbListTables(con) sp_tbl_descr(&#39;customer&#39;) ## table_name seq col_name col_type is_null table_schema ## 1 customer 1 customer_id int4-32 NO public ## 2 customer 2 store_id int2-16 NO public ## 3 customer 3 first_name varchar(45) NO public ## 4 customer 4 last_name varchar(45) NO public ## 5 customer 5 email varchar(50) YES public ## 6 customer 6 address_id int2-16 NO public ## 7 customer 7 activebool bool NO public ## 8 customer 8 create_date date NO public ## 9 customer 9 last_update timestamp YES public ## 10 customer 10 active int4-32 YES public 16.4.2 Other Table PK FK In the next code block, change the function parameter to different table names to get the associated PK and FK associated wih the table. #dbListTables(con) sp_tbl_pk_fk_sql(&#39;customer&#39;) ## table_name column_name constraint_name constraint_type ## 1 customer customer_id customer_pkey PRIMARY KEY ## 2 customer address_id customer_address_id_fkey FOREIGN KEY ## 3 payment customer_id payment_customer_id_fkey FOREIGN KEY ## 4 rental customer_id rental_customer_id_fkey FOREIGN KEY ## ref_table ref_table_col ## 1 ## 2 address address_id ## 3 customer customer_id ## 4 customer customer_id "],
["chapter-sql-joins-exercises.html", "Chapter 17 SQL Joins exercises", " Chapter 17 SQL Joins exercises This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies Parameterized table description function Parameterized table primary foreign keys function The DVD rental database data is too clean to demonstrate some join concepts. To dirty the data, this chapter performs a number of database operations on tables that a data analyst is typically restricted from doing. Deleting records from tables. Inserting records from tables. Enabling and disabling table constraints. In your Docker environment, you have all database privledges. . blue &lt;- function(x) { # x string # color outputFormat = knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) if(outputFormat == &#39;html&#39;) paste(&#39;&lt;style&gt;div.blue &#39; ,&#39;{ background-color:#e6f0ff; border-radius: 5px; padding:20px;}&#39; ,&#39;&lt;/style&gt;&#39; ,&#39;&lt;div class = &quot;blue&quot;&gt;&#39; ,x ,&#39;&lt;/div&gt;&#39; ,sep=&#39;&#39; ) else x } Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;60a61f1e10f7 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; About a minute ago Up 3 seconds 0.0.0.0:5432-&gt;5432/tcp sql-pet&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; About a minute ago Up 3 seconds 0.0.0.0:5432-&gt;5432/tcp sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) The following code block deletes and inserts records into the different tables used in the exercises in this chpater. The techniques used in this code block are discussed in detail in the appendix, ??add link here.?? # source(file=here(&#39;book-src/sql_pet_data.R&#39;),echo=TRUE) dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 2 dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 1 dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 2 dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 1 dbExecute(con, &quot;delete from customer where customer_id &gt;= 600;&quot;) ## [1] 5 dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 # Insert new customers dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) ,(601,2,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) ,(602,4,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE,now()::date,now()::date,1) ,(603,5,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE,now()::date,now()::date,1) ,(604,6,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE,now()::date,now()::date,1) ;&quot; ) ## [1] 5 # Insert new store record dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 df &lt;- data.frame( store_id = 10 , manager_staff_id = 10 , address_id = 10 , last_update = Sys.time() ) dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, row.names = FALSE) dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 # Insert new film row. dbExecute( con, &quot;insert into film (film_id,title,description,release_year,language_id ,rental_duration,rental_rate,length,replacement_cost,rating ,last_update,special_features,fulltext) values(1001,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;Bad Choices&#39;,2018,1 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ; &quot;) ## [1] 1 # Insert Film Category dbExecute( con, &quot;insert into film_category (film_id,category_id,last_update) values(1001,6,now()::date) ,(1001,7,now()::date) ;&quot;) ## [1] 2 # Insert new film into inventory. dbExecute( con, &quot;insert into inventory (inventory_id,film_id,store_id,last_update) values(4582,1001,1,now()::date) ,(4583,1001,2,now()::date) ;&quot;) ## [1] 2 # Insert new film rental record. dbExecute( con, &quot;insert into rental (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update) values(16050,now()::date - interval &#39;1 week&#39;,4582,600,now()::date,1,now()::date) ;&quot;) ## [1] 1 "],
["sql-union-exercise.html", "Chapter 18 SQL Union Exercise 18.1 1. How many rows are in each table? 18.2 Exercises 18.3 30. What is the business cash flow? 18.4 Different strategies for interacting with the database", " Chapter 18 SQL Union Exercise When joining many tables, it is helpful to have the number of rows from each table as an initial sanity check that the joins are returning a reasonable number of rows. 18.1 1. How many rows are in each table? table_rows_sql &lt;- dbGetQuery( con, &quot;select * from ( select &#39;actor&#39; tbl_name,count(*) from actor union select &#39;category&#39; tbl_name,count(*) from category union select &#39;film&#39; tbl_name,count(*) from film union select &#39;film_actor&#39; tbl_name,count(*) from film_actor union select &#39;film_category&#39; tbl_name,count(*) from film_category union select &#39;language&#39; tbl_name,count(*) from language union select &#39;inventory&#39; tbl_name,count(*) from inventory union select &#39;rental&#39; tbl_name,count(*) from rental union select &#39;payment&#39; tbl_name,count(*) from payment union select &#39;staff&#39; tbl_name,count(*) from staff union select &#39;customer&#39; tbl_name,count(*) from customer union select &#39;address&#39; tbl_name,count(*) from address union select &#39;city&#39; tbl_name,count(*) from city union select &#39;country&#39; tbl_name,count(*) from country union select &#39;store&#39; tbl_name,count(*) from store ) counts order by tbl_name ; &quot; ) sp_print_df(table_rows_sql) 18.1.0.1 Replicate the output above using dplyr syntax. 18.2 Exercises 18.2.1 1. Where is the DVD Rental Business located? To answer this question we look at the store, address, city, and country tables to answer this question. store_locations_sql &lt;- dbGetQuery(con, &quot;select s.store_id ,a.address ,c.city ,a.district ,a.postal_code ,c2.country ,s.last_update from store s join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_locations_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. 18.2.1.1 Replicate the output above using dplyr syntax. 18.2.2 2. List Each Store and the Staff Contact Information? To answer this question we look at the store, staff, address, city, and country tables. store_employees_sql &lt;- dbGetQuery(con, &quot;select st.store_id ,s.first_name ,s.last_name ,s.email ,a.phone ,a.address ,c.city ,a.district ,a.postal_code ,c2.country from store st left join staff s on st.manager_staff_id = s.staff_id left join address a on s.address_id = a.address_id left join city c on a.city_id = c.city_id left join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_employees_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each, Mike Hillyer and Jon Stephens respectively. The store in the United States has no employees yet. 18.2.2.1 Replicate the output above using dplyr syntax. 18.2.3 3. How Many Active, Inactive, and Total Customers Does the DVD Rental Business Have? To answer this question we look at the customer table. In a previous chapter we observed that there are two columns, activebool and active. We consider active = 1 as active. customer_cnt_sql &lt;- dbGetQuery(con, &quot;SELECT sum(case when active = 1 then 1 else 0 end) active ,sum(case when active = 0 then 1 else 0 end) inactive ,count(*) total from customer &quot;) sp_print_df(customer_cnt_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each. The store in the United States has no employees yet. The business has 604 international customers, 589 are active and 15 inactive. 18.2.3.1 Replicate the output above using dplyr syntax. 18.2.4 4. How Many and What Percent of Customers Are From Each Country? To answer this question we look at the customer, address, city, and country tables. customers_sql &lt;- dbGetQuery(con, &quot;select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country order by count(*) desc &quot;) sp_print_df(customers_sql) Based on the table above, the DVD Rental business has customers in 118 countries. The DVD Rental business cannot have many walk in customers. It may possibly use a mail order distribution model. For an international company, how are the different currencies converted to a standard currency? Looking at the ERD, there is no currency conversion rate. 18.2.4.1 Replicate the output above using dplyr syntax. 18.2.5 5 What Countries Constitute the Top 25% of the Customer Base? Using the previous code, add two new columns. One column shows a running total and the second column shows a running percentage. To answer this question we look at the customer, address, city, and country tables again. customers_sql &lt;- dbGetQuery(con, &quot;select active,country,count ,sum(count) over (order by count desc rows between unbounded preceding and current row) running_total , pct ,sum(pct) over (order by pct desc rows between unbounded preceding and current row) running_pct from (-- Start of inner SQL Block select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country ) ctry -- End of inner SQL Block order by count desc &quot;) sp_print_df(customers_sql) The top 25% of the customer base are from India, China, the United States, and Japan. The next six countries, the top 10, Mexico, Brazil, Russian Federation, Philipines, Indonesia, and Turkey round out the top 50% of the businesses customer base. 18.2.5.1 Replicate the output above using dplyr syntax. 18.2.6 6. How many customers are in Australia and Canada? customers_sql %&gt;% filter(country == &#39;Australia&#39; | country == &#39;Canada&#39;) ## active country count running_total pct running_pct ## 1 1 Canada 8 369 1.3245 61.0928 ## 2 1 Australia 2 524 0.3311 86.7551 The two countries with a store with an employee have less the 2% of the business’ customer base world wide. 18.2.7 7. How Many Languages? With an international customer base, how many languages does the DVD Rental business distribute DVD’s in. To answer this question we look at the language table. languages_sql &lt;- dbGetQuery(con, &quot; select * from language &quot;) sp_print_df(languages_sql) DVD’s are distributed in six languages. 18.2.7.1 Replicate the output above using dplyr syntax. 18.2.8 8. What is the distribution of DVD’s by Language To answer this question we look at the language and film tables. language_distribution_sql &lt;- dbGetQuery(con, &#39; select l.language_id,name &quot;language&quot;,count(f.film_id) from language l left join film f on l.language_id = f.language_id group by l.language_id,name order by l.language_id &#39;) sp_print_df(language_distribution_sql) This is a surprise. For an international customer base, the entire stock of 1001 DVD’s are in English only. 18.2.8.1 Replicate the output above using dplyr syntax. 18.2.9 9. What are the number of rentals and rented amount by store, by month? To answer this question we look at the rental, inventory, and film tables to answer this question. film_rank_sql &lt;- dbGetQuery(con, &quot;select * ,sum(rental_amt) over (order by yyyy_mm,store_id rows between unbounded preceding and current row) running_rental_amt from (select yyyy_mm,store_id,rentals,rental_amt ,sum(rentals) over(partition by yyyy_mm order by store_id) mo_rentals ,sum(rental_amt) over (partition by yyyy_mm order by store_id) mo_rental_amt from (select to_char(rental_date,&#39;yyyy-mm&#39;) yyyy_mm ,i.store_id,count(*) rentals, sum(f.rental_rate) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by to_char(rental_date,&#39;yyyy-mm&#39;),i.store_id ) as details ) as mo_running order by yyyy_mm,store_id &quot;) sp_print_df(film_rank_sql) We have data for five periods. The first four months from 2005-05 to 2005-08 the business is booming. It started off with 1156 rentals with recievables of 3388.44. The next month, 2005-06, the rentals doubled, 2311 rentals with recievables of 6775.89. The third month, 2005-07, the rentals nearly tripled from the previous month, 6709 rentals with recievables of of 19775.91. The fourth month, 2005-08, the rentals dropped 16% to 5686 with recievables of 16757.14. The fifth period, is 6 months later and the business has dropped below the opening month. In 2006-02 the business only had 182 rentals with recievables of 514.18. It is unclear what currency the rental receivables are in. The current entry is our new rental row we added to show the different joins in a previous chapter. 18.2.10 10. Rank Films Based on the Number of Times Rented and Associated Revenue To answer this question we look at the rental, inventory, and film tables. film_rank_sql &lt;- dbGetQuery(con, &quot;select f.film_id,f.title,f.rental_rate,count(*) count,f.rental_rate * count(*) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.film_id,f.title,f.rental_rate order by count(*) desc&quot;) sp_print_df(film_rank_sql) The most frequently rented movie, 34 times, is ‘Bucket Brotherhood’ followed by Rocketeer Mother, 33 times. 18.2.10.1 Replicate the output above using dplyr syntax. 18.2.11 11 What is the rental distribution/DVD for the top two rented films? From the previous exercise we know that the top two films are Bucket Brotherhood and Rocketeer Mother. To answer this question we look at the rental, inventory, and film tables again. Instead of looking at the film level, we need to drill down to the individual dvd’s for each film to answer this question. film_rank_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id,count(*) from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where i.film_id in (103,738) group by i.store_id,i.film_id,f.title,i.inventory_id&quot;) sp_print_df(film_rank_sql) The ‘Bucket Brotherhood’ and ‘Rocketeer Mother’ DVD’s are equally distributed between the two stores, 4 dvd’s each per film. The ‘Bucket Brotherhood’ was rented 17 times from both stores. The ‘Rocketeer Mother’ was rented 15 times from store 1 and 18 times from store 2. 18.2.11.1 Replicate the output above using dplyr syntax. 18.2.12 12. List staffing information for store 1 associated with the Bucket Brother rentals? To answer this question we look at the rental, inventory, film, staff, address, city, and country tables. film_103_details_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id inv_id ,r.rental_date::date rented,r.return_date::date returned ,s.staff_id,s.store_id staff_store_id,concat(s.first_name,&#39; &#39;,s.last_name) staff,ctry.country from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join staff s on r.staff_id = s.staff_id join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where i.film_id in (103) and r.rental_date::date between &#39;2005-05-01&#39;::date and &#39;2005-06-01&#39;::date order by r.rental_date &quot;) sp_print_df(film_103_details_sql) In a previous exercise we saw that store 1 based in Canada and store 2 based in Austrailia each had one employee, staff_id 1 and 2 respectively. We see that Mike from store 1, Canada, had transactions in store 1 and store 2 on 5/25/2005. Similarly Jon from store 2, Australia, had transaction in store 2 and store 1 on 5/31/2005. ### 12. Which film(s) have never been rented To answer this question we look at the film, inventory and rental tables. never_rented_dvds_sql &lt;- dbGetQuery(con, &#39;select i.store_id,f.film_id, f.title,f.description, i.inventory_id from film f join inventory i on f.film_id = i.film_id left join rental r on i.inventory_id = r.inventory_id where r.inventory_id is null &#39; ) sp_print_df(never_rented_dvds_sql) 18.2.12.1 Replicate the output above using dplyr syntax. 18.2.13 13. How many films are in each film rating? To answer this question we look at the film table to answer this question. film_ratings_sql &lt;- dbGetQuery(con, &#39;select f.rating,count(*) from film f group by f.rating order by count(*) desc &#39; ) sp_print_df(film_ratings_sql) 18.2.14 14. What are the different film categories? film_categories_sql &lt;- dbGetQuery(con, &#39;select * from category&#39; ) sp_print_df(film_categories_sql) 18.2.15 15. Rank the film categeories in descending order film_categories_sql &lt;- dbGetQuery(con, &#39;select c.name,count(*) count from category c join film_category fc on c.category_id = fc.category_id group by c.name order by count(*) desc &#39; ) sp_print_df(film_categories_sql) There are 16 film categories. The highest category, Sports, has 77 films followed by the International category which has 76 film. What is an example of an international category film where all films are currently in English? 18.2.16 16. Which films are listed in multiple categories? To answer this question we look at the film, film_category and category tables. multiple_categories_sql &lt;- dbGetQuery(con, &#39;select f.film_id, f.title,c.name from film_category fc join film f on fc.film_id = f.film_id join category c on fc.category_id = c.category_id where fc.film_id in (select fc.film_id from film f join film_category fc on f.film_id = fc.film_id group by fc.film_id having count(*) &gt; 1 ) &#39; ) sp_print_df(multiple_categories_sql) There is only one film which has two categories, Sophie’s Choice. 18.2.17 17. Which films are in one store’s inventory but not the other In the table below we show the first 10 rows. To answer this question we look at the inventory and film tables. rs &lt;- dbGetQuery( con, &quot; -- select store1,count(count1) not_in2,sum(count1) store1_dvds -- ,store2,count(count2) not_in1,sum(count2) store2_dvds -- from ( select coalesce(i1.film_id,i2.film_id) film_id,f.title,f.rental_rate ,i1.store_id store1,i1.count count1 ,i2.store_id store2,i2.count count2 from (select film_id,store_id,count(*) count from inventory where store_id = 1 group by film_id,store_id) as i1 full outer join (select film_id,store_id,count(*) count from inventory where store_id = 2 group by film_id,store_id ) as i2 on i1.film_id = i2.film_id join film f on coalesce(i1.film_id,i2.film_id) = f.film_id where i1.film_id is null or i2.film_id is null order by f.title ; -- ) as src -- group by store1,store2 &quot; ) if(HEAD_N &gt; 0) { sp_print_df(head(rs,n=HEAD_N)) } else { sp_print_df(rs) } Store 1 has 196 films, 576 dvd’s that are not in store 2 and store 2 has 199 films that are not in store1. 18.2.18 18 Which films are not tracked in inventory? To answer this question we look at the film and rental tables. film_rank_sql &lt;- dbGetQuery(con, &quot; select f.film_id,title,rating,rental_rate,replacement_cost from film f left outer join inventory i on f.film_id = i.film_id where i.film_id is null; &quot;) if(HEAD_N &gt; 0) { sp_print_df(head(film_rank_sql,n=HEAD_N)) } else { sp_print_df(film_rank_sql) } There are 42 films that do not exist in inventory or in either store. These may be DVD’s that have been ordered but the business has not received them. Looking at the price and the replacement cost, it doesn’t look like there is any rhyme or reason to the setting of the price. 18.2.19 19 List film categories in descending accounts receivable. To answer this question we look at the rental, inventory, film, film_category and category tables. Column Mapping Definition category category.name ar film.rental_rate film_category_AR_rank_sql &lt;- dbGetQuery(con, &quot; select category,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select c.name category, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join film_category fc on f.film_id = fc.film_id join category c on fc.category_id = c.category_id group by c.name ) src &quot;) sp_print_df(film_category_AR_rank_sql) There are 16 film categories. The top three categories based on highest AR amounts are Sports, Drama, and Sci-Fi. The total number of rentals are 16046 with an AR amount of 47221.54. 18.2.20 20. List film ratings in descending accounts receivable order. To answer this question we look at the rental, inventory, and film tables. film_rating_rank_sql &lt;- dbGetQuery(con, &quot;select rating,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select f.rating, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.rating ) as src &quot;) sp_print_df(film_rating_rank_sql) There are 5 film ratings. The total number of rentals are 16045 with an AR amount of 47216.55. Why do the film categories revenue and film rating revenue amounts and counts differ? 18.2.20.1 Replicate the output above using dplyr syntax. column mapping definition rating film.rating ar f.rental_rate running_ar accumulated ar amounts based on ratings rentals number of rentals associated with the rating running_rentals running rating rentals 18.2.21 21. How many rentals were returned on time, returned late, never returned? To answer this question we look at the rental, inventory, and film tables. rs &lt;- dbGetQuery(con, &quot;with details as (select case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_stat ,case when r.return_date is null and r.rental_id is null then null when r.return_date is not null or r.return_date is null and r.rental_id is null then 0 else 1 end not_rtn from rental r join inventory i on r.inventory_id = i.inventory_id left join film f on i.film_id = f.film_id ) select sum(case when rtn_stat &lt;= 0 then 1 else 0 end) on_time ,sum(case when rtn_stat &gt; 0 then 1 else 0 end) late ,sum(not_rtn) not_rtn ,count(*) rented ,round(100. * sum(case when rtn_stat &lt;= 0 then 1 else 0 end)/count(*),2) on_time_pct ,round(100. * sum(case when rtn_stat &gt; 0 then 1 else 0 end)/count(*),2) late_pct ,round(100. * sum(not_rtn)/count(*),2) not_rtn_pct from details &quot;) sp_print_df(rs) To date 53.56% of the rented DVD’s were returned on time, 45.30% were returned late, and 1.14% were never returned. 18.2.21.1 Replicate the output above using dplyr syntax. column mapping definition 18.2.22 22. Are there duplicate customers? We assume that if the customer first and last name match in two different rows, then it is a duplicate customer. customer_dupes_sql &lt;- dbGetQuery( con, &quot;select cust.customer_id id ,cust.store_id store ,concat(cust.first_name,&#39; &#39;,cust.last_name) customer ,cust.email -- ,a.phone ,a.address ,c.city ,a.postal_code zip ,a.district ,ctry.country from customer cust join address a on cust.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where concat(cust.first_name,cust.last_name) in (select concat(first_name,last_name) from customer group by concat(first_name,last_name) having count(*) &gt;1 ) &quot;) sp_print_df(customer_dupes_sql) Sophie is the only duplicate customer. The only difference between the two records is the store. Record 600 is associated with store 3, which has no employees, and 601 is associated with store 2 18.2.22.1 Replicate the output above using dplyr syntax. column mapping definition 18.2.23 23. Which customers have never rented a movie? To answer this question we look at the customer and rental tables. customer_rental_anti_join_sql &lt;- dbGetQuery( con, &quot;select c.customer_id id ,c.first_name ,c.last_name ,c.email ,a.phone ,city.city ,ctry.country ,c.active ,c.create_date -- ,c.last_update from customer c left join rental r on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on a.city_id = city.city_id left join country ctry on city.country_id = ctry.country_id where r.rental_id is null; &quot; ) sp_print_df(customer_rental_anti_join_sql) We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. 18.2.23.1 Replicate the output above using dplyr syntax. 18.2.24 24 Who are the top 5 customers with the most rentals and associated payments? This exercise uses the customer, rental, and payment tables. customer_rental_ij_sql &lt;- dbGetQuery( con, &quot;select c.customer_id id,c.store_id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,min(rental_date)::date mn_rental_dt ,max(rental_date)::date mx_rental_dt ,count(r.rental_id) ,sum(COALESCE(p.amount,0.)) from customer c left join rental r on c.customer_id = r.customer_id left join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ,c.store_id order by count(r.rental_id) desc limit 5 &quot; ) sp_print_df(customer_rental_ij_sql) The top 5 customers all rented between 41 to 46 DVD’s. Three of the top 5 rented about 14 DVD’s per month over a three month period. The other two customers 41 and 42 DVD’s per 12 months. 18.2.24.1 Replicate the output above using dplyr syntax. Use the dplyr inner_join verb to find the top 5 customers who have rented the most movies. 18.2.25 25 Combine the top 5 rental customers, (40 or more rentals), and zero rental customers The managers love the two reports, but they would like them combined into a single report. customer_rental_high_low_sql &lt;- dbGetQuery( con, &quot;select c.customer_id cust_id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name having count(r.rental_id) = 0 or count(r.rental_id) &gt; 40 order by count(r.rental_id) desc &quot; ) sp_print_df(customer_rental_high_low_sql) 18.2.25.1 Replicate the output above using dplyr syntax. 18.2.26 26. Who are the top-n1 and bottom-n2 customers? The issue with the two previous reports is that the top end is hardcoded, rentals &gt; 40. Over time, the current customers will always be in the top section and new customers will get added. Another way of looking at the previous report is to show just the top and bottom 5 customers. Parmeterize the previous exercise to show the top 5 and bottom 5 customers. customer_rentals_hi_low_sql &lt;- function(high_n,low_n) { customer_rental_high_low_sql &lt;- dbGetQuery(con, &quot;select * from ( select * ,ROW_NUMBER() OVER(ORDER BY rentals desc) rent_hi_low ,ROW_NUMBER() OVER(ORDER BY rentals ) rent_low_hi FROM ( select c.customer_id id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ) as summary ) row_nums where rent_hi_low &lt;= $1 or rent_low_hi &lt;= $2 order by rent_hi_low &quot; ,c(high_n,low_n) ) return (customer_rental_high_low_sql) } The next code block executes a sql version of such a function. With top_n = 5 and bot_n = 5, it replicates the hard coded version of the previous exercise. With top_n = 5 and bot_n = 0, it gives a top 5 report. With top_n = 0 and bot_n = 5, the report returns the bottom 5. Change the two parameters to see the output from the different combinations. top_n = 5 bot_n = 5 sp_print_df(customer_rentals_hi_low_sql(top_n,bot_n)) 18.2.26.1 Replicate the function above use dplyr syntax. top_n = 0 bot_n = 0 sp_print_df(customer_rentals_hi_low_dplr(top_n,bot_n)) 18.2.27 27. How much has each store collected? How are the stores performing? The SQL code shows the payments made to each store in the business. rs &lt;- dbGetQuery( con, &quot;select store_id,sum(p.amount) amt,count(*) cnt from payment p join staff s on p.staff_id = s.staff_id group by store_id order by 2 desc ; &quot; ) sp_print_df(head(rs)) 18.2.27.1 Exercise dplyr store revenue stream Complete the following code block to return the payments made to each store. 18.2.28 28. What is the business’ distribution of payments? To answer this question we look at the rental, payment, inventory, and film tables to answer this question. As a sanity check, we first check the number of rental records. sp_print_df(dbGetQuery(con,&quot;select count(*) Rentals from rental&quot;)) This table describes the columns in the code block answer that follows. Column Mapping Definition no_pay_rec film.rental_rate aggregated DVD rental rates without an associated payment record. no_pay_rec_cnt number of DVD rentals without an associated payment record. paid_off payment.amount aggregated DVD payments that match the film rental rate. paid_off_cnt number of DVD payments that match the film rental rate. over_paid payment.amount aggregated DVD payments greater than the film rental rate. over_paid_cnt number of DVD payments greater than the film rental rate. under_paid payment.amount aggregated DVD payments less than the film rental rate. under_paid_cnt number of DVD payments greater than the film rental rate. count number of records analyzed business_payment_dist_sql &lt;- dbGetQuery( con, &quot;SELECT sum(case when p.rental_id is null then rental_rate else 0 end ) no_pay_rec ,sum(case when p.rental_id is null then 1 else 0 end) no_pay_rec_cnt ,round(100.*sum(case when p.rental_id is null then 1 else 0 end) /count(*),2) no_pay_rec_pct ,sum(case when f.rental_rate = p.amount then p.amount else 0 end) paid_off ,round(100.*sum(case when f.rental_rate = p.amount then 1 else 0 end ) /count(*),2) paid_off_pct ,sum(case when f.rental_rate &lt; p.amount then p.amount - rental_rate else 0 end ) over_paid ,sum(case when f.rental_rate &lt; p.amount then 1 else 0 end ) over_paid_cnt ,round(100.*sum(case when f.rental_rate &lt; p.amount then 1 else 0 end ) /count(*),2) over_paid_pct ,sum(case when f.rental_rate &gt; p.amount then rental_rate - p.amount else 0 end ) under_paid ,sum(case when f.rental_rate &gt; p.amount then 1 else 0 end ) under_paid_cnt ,round(100.*sum(case when f.rental_rate &gt; p.amount then 1 else 0 end ) /count(*),2) under_paid_pct ,count(*) count FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id ;&quot; ) sp_print_df(business_payment_dist_sql) These are interesting results. 09.06% of the total records have no associated payment record in the amount of 4302.47 49.39% of the rentals have been fully paid in full, 23397.75. 41.40% of the rentals have collected more than the rental amount by 18456.75 00.15% of the rentals have collected less than the rental amount by 67.76. The no_pay_rec_cnt + under_paid_cnt, \\(1453 + 24 = 1477\\) is the number of rentals which have not been paid in full. The total outstanding balance is \\(4302.47 + 67.76 = 4370.23\\) With over 40 percent over collection, someone needs to find out what is wrong with the collection process. Many customers are owed credits or free rentals. 18.2.28.1 Replicate the output above using dplyr syntax. If you are not getting the incorrect count, use the following SQL and results to correct your joins. rs &lt;- dbGetQuery( con, &quot;SELECT &#39;correct join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id where r.rental_id = 4591 UNION SELECT &#39;incorrect join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id where r.rental_id = 4591; ;&quot;) sp_print_df(head(rs)) 18.2.29 29. Which customers have the highest open amounts? From the previous exercise, we know that there are 1478 missing payment records or not fully paid payment records. List the top 5 from each category base on balance due amounts. rs &lt;- dbGetQuery( con, &quot; select customer_id ,concat(first_name,&#39; &#39;,last_name) customer ,pay_record ,rental_amt ,paid_amt ,due_amt ,cnt ,rn from (select c.customer_id ,c.first_name ,c.last_name ,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end Pay_record ,sum(f.rental_rate) rental_amt ,sum(coalesce(p.amount,0)) paid_amt ,sum(f.rental_rate - coalesce(p.amount,0)) due_amt ,count(*) cnt ,row_number() over (partition by case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end order by sum(f.rental_rate - coalesce(p.amount,0)) desc,c.customer_id) rn FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id INNER JOIN customer c ON r.customer_id = c.customer_id WHERE coalesce(p.amount,0) = 0 or f.rental_rate &gt; coalesce(p.amount, 0) group by c.customer_id,c.first_name,c.last_name,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end ) as src where rn &lt;= 5 -- and Pay_record = &#39;No&#39; or Pay_record = &#39;Yes&#39; order by Pay_record,rn &quot;) sp_print_df(rs) From the previous exercise we see that the number of rentals that have not been paid in full is 1477. There are 24 records that have a payment record, pay_record = ‘Yes’, all have a 0 paid amount. There are 1453 DVD’s rented out that have no payment record. The top 3 customers have 10 DVD’s that have not been paid. 18.2.29.1 Replicate the output above using dplyr syntax. 18.3 30. What is the business cash flow? In the previous exercise we saw that about 50% of the rentals collected the correct amount and 40% of the rentals over collected. The last 10% were never collected. Calculate the number of days it took before the payment was collected and the amount collected? To answer this question we look at the rental, customer, payment, inventory, payment and film tables to answer this question. rs &lt;- dbGetQuery( con, &quot;with details as ( select c.customer_id id,concat(first_name,&#39; &#39;,c.last_name) customer ,c.email,a.phone,city.city,ctry.country ,f.title ,f.film_id ,r.rental_date::date rented ,r.return_date::date returned ,(r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date exp_rtn_dt ,case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_stat ,case when r.return_date is null and r.rental_id is null then null when r.return_date is not null or r.return_date is null and r.rental_id is null then 0 else 1 end not_rtn ,payment_date::date pay_dt ,f.rental_rate charges ,p.amount paid ,p.amount-f.rental_rate delta ,p.staff_id ,payment_date::date - rental_date::date pay_days ,c.customer_id,f.film_id,r.rental_id,i.inventory_id,payment_id from rental r left join customer c on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on city.city_id = a.city_id left join country ctry on ctry.country_id = city.country_id left join inventory i on r.inventory_id = i.inventory_id left join payment p on c.customer_id = p.customer_id and p.rental_id = r.rental_id left join film f on i.film_id = f.film_id ) select pay_dt - exp_rtn_dt payment_days ,sum(coalesce(paid,charges)) paid_or_due -- ,min(pay_dt - exp_rtn_dt) mn_late_pay -- ,round(avg(pay_dt - exp_rtn_dt),1) avg_late_pay -- ,max(pay_dt - exp_rtn_dt) mx_late_pay ,count(*) late_returns from details --where returned &gt; exp_rtn_dt group by pay_dt - exp_rtn_dt order by pay_dt - exp_rtn_dt desc &quot;) sp_print_df(rs) Wow those are really generous terms. Customers are paying 1.2 to 1.7 years after they returned the DVD. This business is in serious financial trouble! 18.4 Different strategies for interacting with the database select examples dbGetQuery returns the entire result set as a data frame. For large returned datasets, complex or inefficient SQL statements, this may take a long time. dbSendQuery: parses, compiles, creates the optimized execution plan. dbFetch: Execute optimzed execution plan and return the dataset. dbClearResult: remove pending query results from the database to your R environment 18.4.1 Use dbGetQuery How many customers are there in the DVD Rental System rs1 &lt;- dbGetQuery(con, &quot;select * from customer;&quot;) sp_print_df(head(rs1)) pco &lt;- dbSendQuery(con, &quot;select * from customer;&quot;) rs2 &lt;- dbFetch(pco) dbClearResult(pco) sp_print_df(head(rs2)) # diconnect from the db # dbDisconnect(con) # sp_docker_stop(&quot;sql-pet&quot;) # knitr::knit_exit() "],
["chapter-anti-join-cost-comparisons.html", "Chapter 19 Anti-join cost comparisons 19.1 SQL anti join Costs 19.2 dplyr Anti joins", " Chapter 19 Anti-join cost comparisons Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;60a61f1e10f7 postgres-dvdrental \\&quot;docker-entrypoint.s…\\&quot; About a minute ago Up 12 seconds 0.0.0.0:5432-&gt;5432/tcp sql-pet&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 60a61f1e10f7 postgres-dvdrental &quot;docker-entrypoint.s…&quot; About a minute ago Up 12 seconds 0.0.0.0:5432-&gt;5432/tcp sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) source(file=here(&#39;book-src/sql_pet_data.R&#39;),echo=TRUE) ## ## &gt; dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from customer where customer_id &gt;= 600;&quot;) ## [1] 5 ## ## &gt; dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into customer\\n (customer_id,store_id,first_name,last_name,email,address_id,activebool\\n ,create_date,last_update,active)\\n ...&quot; ... [TRUNCATED] ## [1] 5 ## ## &gt; dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; df &lt;- data.frame(store_id = 10, manager_staff_id = 10, ## + address_id = 10, last_update = Sys.time()) ## ## &gt; dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, ## + row.names = FALSE) ## ## &gt; dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; dbExecute(con, &quot;insert into film\\n (film_id,title,description,release_year,language_id\\n ,rental_duration,rental_rate,length,replacement_cost,rati ...&quot; ... [TRUNCATED] ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into film_category\\n (film_id,category_id,last_update)\\n values(1001,6,now()::date)\\n ,(1001,7,now()::date)\\n ;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into inventory\\n (inventory_id,film_id,store_id,last_update)\\n values(4582,1001,1,now()::date)\\n ,(4583,1001,2,now()::date ...&quot; ... [TRUNCATED] ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into rental\\n (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update)\\n values(16050,now()::date ...&quot; ... [TRUNCATED] ## [1] 1 Explain plans here 19.1 SQL anti join Costs sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c left outer join store s on c.store_id = s.store_id where s.store_id is null group by customer_id, first_name, last_name, c.store_id order by c.customer_id;&quot; ) sql_aj2 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c where c.store_id NOT IN (select store_id from store) group by customer_id, first_name, last_name, c.store_id order by c.customer_id;&quot; ) sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c where not exists (select s.store_id from store s where s.store_id = c.store_id) group by customer_id, first_name, last_name, c.store_id order by c.customer_id &quot; ) 19.1.0.0.1 SQL Costs print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=33.28..38.53 rows=300 width=266) (actual time=10.089..10.175 rows=4 loops=1) print(glue(&quot;sql_aj2 not in costs=&quot;, sql_aj2[1, 1])) ## sql_aj2 not in costs=GroupAggregate (cost=29.86..35.11 rows=300 width=262) (actual time=0.306..0.393 rows=4 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=GroupAggregate (cost=33.28..38.53 rows=300 width=262) (actual time=9.919..10.006 rows=4 loops=1) 19.2 dplyr Anti joins In this next section we look at two methods to implemnt an anti join in dplyr. customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) # Method 1. dplyr anti_join daj1 &lt;- anti_join(customer_table, rental_table, by = &quot;customer_id&quot;, suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT * FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## ## WHERE NOT EXISTS ( ## SELECT 1 FROM &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## WHERE (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## )) &quot;cqpqwqagrn&quot; ## ## &lt;PLAN&gt; ## Hash Anti Join (cost=510.99..552.63 rows=300 width=334) ## Hash Cond: (&quot;TBL_LEFT&quot;.customer_id = &quot;TBL_RIGHT&quot;.customer_id) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) ## -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=2) customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) # Method 2. dplyr loj with NA daj2 &lt;- left_join(customer_table, rental_table, by = c(&quot;customer_id&quot;, &quot;customer_id&quot;), suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% filter(is.na(rental_id)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_LEFT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_LEFT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_LEFT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.c&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_RIGHT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_RIGHT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_RIGHT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.r&quot; ## FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;ihebfvnxvb&quot; ## WHERE (((&quot;rental_id&quot;) IS NULL)) ## ## &lt;PLAN&gt; ## Hash Right Join (cost=22.48..375.33 rows=80 width=334) ## Hash Cond: (&quot;TBL_RIGHT&quot;.customer_id = &quot;TBL_LEFT&quot;.customer_id) ## Filter: (&quot;TBL_RIGHT&quot;.rental_id IS NULL) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=6) ## -&gt; Hash (cost=14.99..14.99 rows=599 width=338) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) In this example, the dplyr anti_join verb is 1.4113447 to 22.7308719 times more expensive than the left outer join with a null condition. sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c left outer join rental r on c.customer_id = r.customer_id where r.customer_id is null group by c.customer_id order by c.customer_id;&quot; ) sp_print_df(sql_aj1) sql_aj1 ## QUERY PLAN ## 1 GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=255.165..255.241 rows=4 loops=1) ## 2 Group Key: c.customer_id ## 3 -&gt; Sort (cost=564.97..565.72 rows=300 width=4) (actual time=255.132..255.166 rows=4 loops=1) ## 4 Sort Key: c.customer_id ## 5 Sort Method: quicksort Memory: 25kB ## 6 -&gt; Hash Anti Join (cost=510.99..552.63 rows=300 width=4) (actual time=254.998..255.087 rows=4 loops=1) ## 7 Hash Cond: (c.customer_id = r.customer_id) ## 8 -&gt; Seq Scan on customer c (cost=0.00..14.99 rows=599 width=4) (actual time=0.015..4.188 rows=604 loops=1) ## 9 -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) (actual time=246.424..246.431 rows=16045 loops=1) ## 10 Buckets: 16384 Batches: 1 Memory Usage: 661kB ## 11 -&gt; Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=2) (actual time=0.012..122.113 rows=16045 loops=1) ## 12 Planning time: 0.135 ms ## 13 Execution time: 255.398 ms sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c where not exists (select customer_id from rental r where c.customer_id = r.customer_id) group by c.customer_id &quot; ) print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=255.165..255.241 rows=4 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=HashAggregate (cost=554.13..557.13 rows=300 width=12) (actual time=246.213..246.249 rows=4 loops=1) "],
["chapter-sql-quick-start.html", "Chapter 20 SQL Quick start - simple retrieval 20.1 Intro 20.2 Databases and Third Normal Form - 3NF 20.3 SQL Commands 20.4 SQL SELECT Quick Start 20.5 Paradigm Shift from R-Dplyr to SQL", " Chapter 20 SQL Quick start - simple retrieval This chapter demonstrates: Several elementary SQL statements SQL databases and 3rd normal form 20.1 Intro Coverage in this book. There are many SQL tutorials that are available. For example, we are drawing some materials from a tutorial we recommend. In particular, we will not replicate the lessons there, which you might want to complete. Instead, we are showing strategies that are recommended for R users. That will include some translations of queries that are discussed there. https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html Very good intro. How is ours different? Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 colFmt &lt;- function(x,color) { # x string # color outputFormat = knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) if(outputFormat == &#39;latex&#39;) paste(&quot;\\\\textcolor{&quot;,color,&quot;}{&quot;,x,&quot;}&quot;,sep=&quot;&quot;) else if(outputFormat == &#39;html&#39;) paste(&quot;&lt;font color=&#39;&quot;,color,&quot;&#39;&gt;&quot;,x,&quot;&lt;/font&gt;&quot;,sep=&quot;&quot;) else x } # sample call # * `r colFmt(&#39;Cover inline tables in future section&#39;,&#39;red&#39;)` Moved this from 11-elementary-queries dplyr_summary_df &lt;- read.delim( &#39;11-dplyr_sql_summary_table.tsv&#39;, header = TRUE, sep = &#39;\\t&#39;, as.is = TRUE ) head(dplyr_summary_df) ## In Dplyr_Function ## 1 Y arrange() ## 2 Y? distinct() ## 3 Y select() rename() ## 4 N pull() ## 5 Y mutate() transmute() ## 6 Y summarise() summarize() ## description ## 1 Arrange rows by variables ## 2 Return rows with matching conditions ## 3 Select/rename variables by name ## 4 Pull out a single variable ## 5 Add new variables ## 6 Reduces multiple values down to a single value ## SQL_Clause Notes Category ## 1 ORDER BY NA Basic single-table verbs ## 2 SELECT distinct * NA Basic single-table verbs ## 3 SELECT column_name alias_name NA Basic single-table verbs ## 4 SELECT column_name; NA Basic single-table verbs ## 5 SELECT computed_value computed_name NA Basic single-table verbs ## 6 SELECT aggregate_functions GROUP BY NA Basic single-table verbs 20.2 Databases and Third Normal Form - 3NF Most relational database applications are designed to be third normal form “like”, 3NF. The key benefits of 3NF are speedy on-line transactional processing, OLTP. improved referential integrity, reduce modification anomalies that can occur during an insert, update, or delete operation. reduced storage, elimination of redundant data. 3NF is great for database application input performance, but not so great for getting the data back out for the data analyst or report writer. As a data analyst, you might get the ubiquitous Excel spreadsheet with all the information needed to start an Exploratory Data Analysis, EDA. The spreadsheet may have provider, patient, diagnosis, procedure, and insurance information all “neatly” arranged on a single row. At least “neatly” when compared to the same information stored in the database, in at least 5 tables. For this tutorial, the most important thing to know about 3NF is that the data you are looking for gets spread across many many tables. Working in a relational database requires you to find the many many different tables that contains your data. Understand the relationships that tie the tables together correctly to ensure that data is not dropped or duplicated. Data that is dropped or duplicated can either over or understate your aggregated numeric values. hospital-billing-erd https://www.smartdraw.com/entity-relationship-diagram/examples/hospital-billing-entity-relationship-diagram/ Real life applications have 100’s or even 1000’s of tables supporting the application. The goal is to transform the application data model into a useful data analysis model using the DDL and DML SQL statements. 20.3 SQL Commands SQL commands fall into four categories. SQL Category Definition DDL:Data Definition Language DBA’s execute these commands to define objects in the database. DML:Data Manipulation Language Users and developers execute these commands to investigate data. DCL:Data Control Language DBA’s execute these commands to grant/revoke access to TCL:Transaction Control Language Developers execute these commands when developing applications. Data analysts use the SELECT DML command to learn interesting things about the data stored in the database. Applications are used to control the insert, update, and deletion of data in the database. Data users can update the database objects via the application which enforces referential integrity in the database. Data users should never directly update data application database objects. Leave this task to the developers and DBA’s. DBA’s can setup a sandbox within the database for a data analyst. The application(s) do not maintain the data in the sandbox. The sql-pet database is tiny, but for the purposes of these exercises, we assume that data so large that it will not easily fit into the memory of your laptop. This tutorial focuses on the most frequently used SQL statement, the SQL SELECT statement. A SQL SELECT statement consists of 1 to 6 clauses. SQL Clause DPLYR Verb SQL Description SELECT SELECT() Contains a list of column names from an object or a derived value. mutate() FROM Contains a list of related tables from which the SELECT list of columns is derived. WHERE filter() Provides the filter conditions the objects in the FROM clause must meet. GROUP BY group_by() Contains a list rollup aggregation columns. HAVING Provides the filter condition on the the GROUP BY clause. ORDER BY arrange() Contains a list of column names indicating the order of the column value. Each column can be either ASCending or DEScending. The foundation of the SQL language is based set theory and the result of a SQL SELECT statement is referred to as a result set. A SQL SELECT statement is “guaranteed” to return the same set of data, but not necessarily in the same order. However, in practice, the result set is usually in the same order. SQL SELECT statements can be broken up into two categories, SELECT detail statements and SELECT aggregate statements. SELECT DETAIL SELECT AGGREGATE select det_col1…det_coln select det_agg1…, agg1,…,aggn from same from same where same where same group by det_agg1 having order by same order by same The difference between the two statements is the AGGREGATE has select clause has one or more detail columns, det_agg1…, on which values get aggregated against/rolled up to. select clause zero or more aggregated values, agg1, …, aggn group by clause is required and matches the one or more detail columns, det_agg1. having clause is optional and adds a filter condition on one or more agg1 … aggn values. 20.4 SQL SELECT Quick Start This section focuses on getting new SQL users familiar with the six SQL query clauses and a single table. SQL queries from multiple tables are discussed in the JOIN section of this tutorial. The JOIN section resolves the issue introduced with 3NF, the splitting of data into many many tables, back into a denormalaized format similar to the Excel spreadsheet. The DBI::dbGetQuery function is used to submit SQL SELECT statements to the PostgreSQL database. At a minimum it requires two parameters, a connection object and a SQL SELECT statement. In the following section we only look at SELECT DETAIL statements. 20.4.1 SELECT Clause: Column Selection – Vertical Partioning of Data 20.4.1.1 1. Simplest SQL query: All rows and all columns from a single table. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store; &quot;) kable(rs,caption = &#39;select all columns&#39;) Table 20.1: select all columns store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-02-17 18:44:13 20.4.1.2 2. Same Query as 1, but only show first two columns; rs &lt;- DBI::dbGetQuery( con, &quot; select STORE_ID, manager_staff_id from store; &quot;) kable(rs,caption = &#39;select first two columns only&#39;) Table 20.2: select first two columns only store_id manager_staff_id 1 1 2 2 10 10 20.4.1.3 3. Same Query as 2, but reverse the column order dvdrental=# select manager_staff_id,store_id from store; rs &lt;- DBI::dbGetQuery( con, &quot; select manager_staff_id,store_id from store; &quot;) kable(rs,caption = &#39;reverse the column order&#39;) Table 20.3: reverse the column order manager_staff_id store_id 1 1 2 2 10 10 20.4.1.4 4. Rename Columns – SQL column alias in the result set rs &lt;- DBI::dbGetQuery( con, &quot; select manager_staff_id mgr_sid,store_id st_id from store; &quot;) kable(rs,caption = &#39;Rename Columns&#39;) Table 20.4: Rename Columns mgr_sid st_id 1 1 2 2 10 10 The manager_staff_id has changed to mgr_sid. store_id has changed to st_id. Note that the column names have changed in the result set only, not in the actual database table. The DBA&#39;s will not allow a space or other special characters in a database table column name. Some motivations for aliasing the result set column names are 1. Some database table column names are not user friendly. 2. When multiple tables are joined, the column names may be the same in one or more tables and one needs to distinguish between the column names from the different tables. 20.4.1.5 5. Adding Meta Data Columns to the Result Set rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;derived column&#39; showing ,* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; &quot;) kable(rs,caption = &#39;Adding Meta Data Columns&#39;) Table 20.5: Adding Meta Data Columns showing store_id manager_staff_id address_id last_update db user dtts derived column 1 1 1 2006-02-15 09:57:12 dvdrental postgres 2019/02/18 02:44:16 derived column 2 2 2 2006-02-15 09:57:12 dvdrental postgres 2019/02/18 02:44:16 derived column 10 10 10 2019-02-17 18:44:13 dvdrental postgres 2019/02/18 02:44:16 All the previous examples easily fit on a single line. This one is longer. Each column is entered on its own line, indented past the select keyword, and preceeded by a comma. 1. The showing column is a hard coded string surrounded by single quotes. Note that single quotes are for hard coded values and double quotes are for column aliases. 2. The db and dtts, date timestamp, are new columns generated from PostgreSQL System Information Functions. 3. Note that `user` is not a function call, no parenthesis. 20.4.2 SQL Comments SQL supports both a single line comment, preceed the line with two dashes, --, and a C like block comment, \\* … */. 20.4.2.1 6. Single line comment – rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;single line comment, dtts&#39; showing ,* ,current_database() db ,user -- ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; &quot;) kable(rs,caption = &#39;Sincle line comment&#39;) Table 20.6: Sincle line comment showing store_id manager_staff_id address_id last_update db user single line comment, dtts 1 1 1 2006-02-15 09:57:12 dvdrental postgres single line comment, dtts 2 2 2 2006-02-15 09:57:12 dvdrental postgres single line comment, dtts 10 10 10 2019-02-17 18:44:13 dvdrental postgres The dtts line is commented out with the two dashes and is dropped from the end of the result set columns. 20.4.2.2 7. Multi-line comment /*…*/ rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;block comment drop db, user, and dtts&#39; showing ,* /* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts */ from store; &quot;) kable(rs,caption = &#39;Multi-line comment&#39;) Table 20.7: Multi-line comment showing store_id manager_staff_id address_id last_update block comment drop db, user, and dtts 1 1 1 2006-02-15 09:57:12 block comment drop db, user, and dtts 2 2 2 2006-02-15 09:57:12 block comment drop db, user, and dtts 10 10 10 2019-02-17 18:44:13 The three columns db, user, and dtts, between the /\\* and \\*/ have been commented and no longer appear as the end columns of the result set. 20.4.3 FROM Clause The FROM clause contains one or more datasets, usually database tables/views, from which the SELECT columns are derived. For now, in the examples, we are only using a single table. If the database reflects a relational model, your data is likely spread out over several tables. The key take away when beginning your analysis is to pick the table that has most of the data that you need for your analysis. This table becomes your main or driving table to build your SQL query statement around. After identifying your driving table, potentially save yourself a lot of time and heart ache, review any view that is built on your driving table. If one or more exist, especially, if vendor built, may already have the additional information needed for your analysis. Insert SQL here or link to Views dependent on what In this tutorial, there is only a single user hitting the database and row/table locking is not necessary and considered out of scope. 20.4.3.1 Table Uses A table can be used more than once in a FROM clause. These are self-referencing tables. An example is an EMPLOYEE table which contains a foriegn key to her manager. Her manager also has a foriegn key to her manager, etc up the corporate ladder. In the example above, the EMPLOYEE table plays two roles, employee and manager. The next line shows the FROM clause showing the same table used twice. FROM EMPLOYEE EE, EMPLOYEE MGR The EE and MGR are aliases for the EMPLOYEE table and represent the different roles the EMPLOYEE table plays. Since all the column names are exactly the same for the EE and MGR role, the column names need to be prefixed with their role alias, e.g., SELECT MGR.EE_NAME, EE.EE_NAME … shows the manager name and her employee name(s) who work for her. It is a good habit to always alias your tables and prefix your column names with the table alias to eliminate any ambiguity as to where the column came from. This is critical where there is inconsistent table column naming convention. It also helps when debugging larger SQL queries. Cover inline tables in future section Side Note: Do not create an unintended Cartesian join. If one has more than one table in the FROM clause, make sure that every table in the FROM clause joins to at least one other table in the WHERE clause. If your result set has an unexpectantly high rowcount and long runtime, check for a missing join in the FROM clause. 20.4.4 WHERE Clause: Row Selection – Horizontal Partitioning of Data In the previous SELECT clause section, the SELECT statement either partitioned data vertically across the table columns or derived vertical column values. This section provides examples that partitions the table data across rows in the table. The WHERE clause defines all the conditions the data must meet to be included or excluded in the final result set. If all the conditions are met data is returned or it is rejected. This is commonly referred to as the data set filter condition. Side Note: For performance optimization reasons, the WHERE clause should reduce the dataset down to the smallest dataset as quickly as possible. This is typically done using indexed columns, range conditions, and any other condition that rejects a lot of rows from being retrieved. The WHERE condition(s) can be simple or complex, but in the end are the appliction of the logic rules shown in the table below. p q p and q p or q T T T T T F F T T N N T F F F F F N F T N N N N When the filter logic is complex, it is sometimes easier to represent the where clause symbollically and apply a version of DeMorgan’s law which is shown below. (A and B)’ = A’ or B’ (A or B)’ = A’ and B’ 20.4.4.1 Examples Continued We begin with 1, our simplest SQL query. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store; &quot;) kable(rs,caption = &#39;select all columns&#39;) Table 20.8: select all columns store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-02-17 18:44:13 20.4.4.2 8 WHERE condition logically never TRUE. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where 1 = 0; &quot;) kable(rs,caption = &#39;WHERE always FALSE&#39;) Table: (#tab:unnamed-chunk-13)WHERE always FALSE store_id manager_staff_id address_id last_update ——— —————– ———– ———— Since 1 = 0 is always false, no rows are ever returned. Initially this construct seems useless, but actually is quite handy when debugging large scripts where a portion of the script needs to be turned off or when creating an empty table with the exact same column names and types as the FROM table(s). 20.4.4.3 9 WHERE condition logically always TRUE. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where 1 = 1; &quot;) kable(rs,caption = &#39;WHERE always TRUE&#39;) Table 20.10: WHERE always TRUE store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-02-17 18:44:13 Since 1 = 1 is always true, all rows are always returned. Initially this construct seems useless, but actually is also quite handy when debugging large scripts and creating a backup of table. 20.4.4.4 10 WHERE equality condition rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where store_id = 2; &quot;) kable(rs,caption = &#39;WHERE EQUAL&#39;) Table 20.11: WHERE EQUAL store_id manager_staff_id address_id last_update 2 2 2 2006-02-15 09:57:12 The only row where the store_id = 2 is row 2 and it is the only row returned. 20.4.4.5 11 WHERE NOT equal conditions rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where store_id &lt;&gt; 2; &quot;) kable(rs,caption = &#39;WHERE NOT EQUAL&#39;) Table 20.12: WHERE NOT EQUAL store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 10 10 10 2019-02-17 18:44:13 &lt;&gt; is syntactically the same as != The only row where the store_id &lt;&gt; 2 is row 1 and only row 1 is returned. 20.4.4.6 12 WHERE OR condition rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where manager_staff_id = 1 or store_id &lt; 3; &quot;) kable(rs,caption = &#39;WHERE OR condition&#39;) Table 20.13: WHERE OR condition store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 The first condition manager_staff_id = 1 returns a single row and the second condition store_id &lt; 3 returns two rows. Following table is modified from http://www.tutorialspoint.com/sql/sql-operators SQL Comparison Operators Operator Description example = Checks if the values of two operands are equal or not, if yes then condition becomes true. (a = b) is not true. != Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a != b) is true. &lt;&gt; Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a &lt;&gt; b) is true. &gt; Checks if the value of left operand is greater than the value of right operand, if yes then condition becomes true. (a &gt; b) is not true. &lt; Checks if the value of left operand is less than the value of right operand, if yes then condition becomes true. (a &lt; b) is true. &gt;= Checks if the value of left operand is greater than or equal to the value of right operand, if yes then condition becomes true. (a &gt;= b) is not true. &lt;= Checks if the value of left operand is less than or equal to the value of right operand, if yes then condition becomes true. (a &lt;= b) is true. !&lt; Checks if the value of left operand is not less than the value of right operand, if yes then condition becomes true. (a !&lt; b) is false. !&gt; Checks if the value of left operand is not greater than the value of right operand, if yes then condition becomes true. (a !&gt; b) is true. Operator Description ALL The ALL operator is used to compare a value to all values in another value set. AND The AND operator allows the existence of multiple conditions in an SQL statement’s WHERE clause. ANY The ANY operator is used to compare a value to any applicable value in the list as per the condition. BETWEEN The BETWEEN operator is used to search for values that are within a set of values, given the minimum value and the maximum value. EXISTS The EXISTS operator is used to search for the presence of a row in a specified table that meets a certain criterion. IN The IN operator is used to compare a value to a list of literal values that have been specified. LIKE The LIKE operator is used to compare a value to similar values using wildcard operators. NOT The NOT operator reverses the meaning of the logical operator with which it is used. Eg: NOT EXISTS, NOT BETWEEN, NOT IN, etc. This is a negate operator. OR The OR operator is used to combine multiple conditions in an SQL statement’s WHERE clause. IS NULL The NULL operator is used to compare a value with a NULL value. UNIQUE The UNIQUE operator searches every row of a specified table for uniqueness (no duplicates). https://pgexercises.com/questions/basic ## TO-DO’s inline tables correlated subqueries 20.5 Paradigm Shift from R-Dplyr to SQL Paraphrasing what some have said with an R dplyr background and no SQL experience, “It is like working from the inside out.” This sentiment occurs because The SQL SELECT statement begins at the end, the SELECT clause, and drills backwards, loosely speaking, to derive the desired result set. SQL SELECT statements are an all or nothing proposition. One gets nothing if there is any kind of syntax error. SQL SELECT result sets can be quite opaque. The WHERE clause can be very dense and difficult to trace through. It is rarely ever linear in nature. Validating all the permutations in the where clause can be tough and tedious. 20.5.1 Big bang versus piped incremental steps. Dplyr starts with one or more sources joined together in a conceptually similar way that SQL joins sources. The pipe and filter() function breaks down the filter conditions into small managable logical steps. This makes it much easier to understand what is happening in the derivation of the final tibble. Adding tees through out the pipe line gives one full trace back of all the data transformations at every pipe. Helpful tidyverse functions that output tibbles: tbl_module function in https://github.com/nhemerson/tibbleColumns package; Mental picture: SQL approach: Imagine a data lake named Niagera Falls and drinking from it without drowning. R-Dplyr approach: Imagine a resturant at the bottom of the Niagera Falls data lake and having a refreshing dring out of the water faucet. 20.5.2 SQL Execution Order The table below is derived from this site. https://www.periscopedata.com/blog/sql-query-order-of-operations It shows what goes on under the hood SQL SELECT hood. SEQ SQL Function Dplyr 1 WITH Common Table expression, CTE, one or more datasets/tables used FROM clause. .data parameter in dplyr functions 2 FROM Choose and join tables to get base data .data parameter in dplyr functions 3 ON Choose and join tables to get base data dplyr join family of functions 4 JOIN Choose and join tables to get base data dplyr join family of functions 5 WHERE filters the base data dplyr filter() 6 GROUP BY aggregates the base data dplyr group_by family of functions 7 WITH CUBE/ROLLUP aggregates the base data is this part of the dplyr grammar 8 HAVING filters aggregated data dplyr filter() 9 SELECT Returns final data set dplyr select() 10 DISTINCT Dedupe the final data set dplyr distinct() 11 ORDER BY Sorts the final data set arrange() 12 TOP/LIMIT Limits the number of rows in data set 13 OFFSET/FETCH Limits the number of rows in data set The SEQ column shows the standard order of SQL execution. One take away for this tutorial is that the SELECT clause actually executes late in the process, even though it is the first clause in the entire SELECT statement. A second take away is that SQL execution order, or tweaked order, plays a critical role in SQL query tuning. SQL for View table dependencies. Add cartesian join exercise. "],
["chapter-postgresql-metadata.html", "Chapter 21 Getting metadata about and from PostgreSQL 21.1 Database contents and structure 21.2 What columns do those tables contain? 21.3 Characterizing how things are named 21.4 Database keys 21.5 Creating your own data dictionary", " Chapter 21 Getting metadata about and from PostgreSQL This chapter demonstrates: What kind of data about the database is contained in a dbms Several methods for obtaining metadata from the dbms The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(glue) library(here) require(knitr) library(dbplyr) library(sqlpetr) Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) 21.1 Database contents and structure After just looking at the data you seek, it might be worthwhile stepping back and looking at the big picture. 21.1.1 Database structure For large or complex databases you need to use both the available documentation for your database (e.g., the dvdrental database) and the other empirical tools that are available. For example it’s worth learning to interpret the symbols in an Entity Relationship Diagram: The information_schema is a trove of information about the database. Its format is more or less consistent across the different SQL implementations that are available. Here we explore some of what’s available using several different methods. PostgreSQL stores a lot of metadata. 21.1.2 Contents of the information_schema For this chapter R needs the dbplyr package to access alternate schemas. A schema is an object that contains one or more tables. Most often there will be a default schema, but to access the metadata, you need to explicitly specify which schema contains the data you want. 21.1.3 What tables are in the database? The simplest way to get a list of tables is with table_list &lt;- DBI::dbListTables(con) kable(table_list) x actor_info customer_list film_list nicer_but_slower_film_list sales_by_film_category staff sales_by_store staff_list category film_category country actor language inventory payment rental city store film address film_actor customer smy_customer 21.1.4 Digging into the information_schema We usually need more detail than just a list of tables. Most SQL databases have an information_schema that has a standard structure to describe and control the database. The information_schema is in a different schema from the default, so to connect to the tables table in the information_schema we connect to the database in a different way: table_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) The information_schema is large and complex and contains 211 tables. So it’s easy to get lost in it. This query retrieves a list of the tables in the database that includes additional detail, not just the name of the table. table_info &lt;- table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select(table_catalog, table_schema, table_name, table_type) %&gt;% arrange(table_type, table_name) %&gt;% collect() kable(table_info) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public smy_customer BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW In this context table_catalog is synonymous with `database `. Notice that VIEWS are composites made up of one or more BASE TABLES. The SQL world has its own terminology. For example rs is shorthand for result set. That’s equivalent to using df for a data frame. The following SQL query returns the same information as the previous one. rs &lt;- dbGetQuery( con, &quot;select table_catalog, table_schema, table_name, table_type from information_schema.tables where table_schema not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) order by table_type, table_name ;&quot; ) kable(rs) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public smy_customer BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW 21.2 What columns do those tables contain? Of course, the DBI package has a dbListFields function that provides the simplest way to get the minimum, a list of column names: DBI::dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; But the information_schema has a lot more useful information that we can use. columns_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;columns&quot;)) Since the information_schema contains 1865 columns, we are narrowing our focus to just one table. This query retrieves more information about the rental table: columns_info_schema_info &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select( table_catalog, table_schema, table_name, column_name, data_type, ordinal_position, character_maximum_length, column_default, numeric_precision, numeric_precision_radix ) %&gt;% collect(n = Inf) %&gt;% mutate(data_type = case_when( data_type == &quot;character varying&quot; ~ paste0(data_type, &quot; (&quot;, character_maximum_length, &quot;)&quot;), data_type == &quot;real&quot; ~ paste0(data_type, &quot; (&quot;, numeric_precision, &quot;,&quot;, numeric_precision_radix, &quot;)&quot;), TRUE ~ data_type )) %&gt;% filter(table_name == &quot;rental&quot;) %&gt;% select(-table_schema, -numeric_precision, -numeric_precision_radix) glimpse(columns_info_schema_info) ## Observations: 7 ## Variables: 7 ## $ table_catalog &lt;chr&gt; &quot;dvdrental&quot;, &quot;dvdrental&quot;, &quot;dvdrental&quot;, … ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;,… ## $ column_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_… ## $ data_type &lt;chr&gt; &quot;integer&quot;, &quot;timestamp without time zone… ## $ ordinal_position &lt;int&gt; 1, 2, 3, 4, 5, 6, 7 ## $ character_maximum_length &lt;int&gt; NA, NA, NA, NA, NA, NA, NA ## $ column_default &lt;chr&gt; &quot;nextval(&#39;rental_rental_id_seq&#39;::regcla… kable(columns_info_schema_info) table_catalog table_name column_name data_type ordinal_position character_maximum_length column_default dvdrental rental rental_id integer 1 NA nextval(‘rental_rental_id_seq’::regclass) dvdrental rental rental_date timestamp without time zone 2 NA NA dvdrental rental inventory_id integer 3 NA NA dvdrental rental customer_id smallint 4 NA NA dvdrental rental return_date timestamp without time zone 5 NA NA dvdrental rental staff_id smallint 6 NA NA dvdrental rental last_update timestamp without time zone 7 NA now() 21.2.1 What is the difference between a VIEW and a BASE TABLE? The BASE TABLE has the underlying data in the database table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;BASE TABLE&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default BASE TABLE customer store_id smallint 2 NA BASE TABLE customer first_name character varying 3 NA BASE TABLE customer last_name character varying 4 NA BASE TABLE customer email character varying 5 NA BASE TABLE customer address_id smallint 6 NA BASE TABLE customer active integer 10 NA BASE TABLE customer customer_id integer 1 nextval(‘customer_customer_id_seq’::regclass) BASE TABLE customer activebool boolean 7 true BASE TABLE customer create_date date 8 (‘now’::text)::date BASE TABLE customer last_update timestamp without time zone 9 now() BASE TABLE smy_customer customer_id integer 1 NA BASE TABLE smy_customer store_id smallint 2 NA BASE TABLE smy_customer first_name character varying 3 NA BASE TABLE smy_customer last_name character varying 4 NA BASE TABLE smy_customer email character varying 5 NA BASE TABLE smy_customer address_id smallint 6 NA BASE TABLE smy_customer activebool boolean 7 NA BASE TABLE smy_customer create_date date 8 NA BASE TABLE smy_customer last_update timestamp without time zone 9 NA BASE TABLE smy_customer active integer 10 NA Probably should explore how the VIEW is made up of data from BASE TABLEs. table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;VIEW&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default VIEW customer_list id integer 1 NA VIEW customer_list name text 2 NA VIEW customer_list address character varying 3 NA VIEW customer_list zip code character varying 4 NA VIEW customer_list phone character varying 5 NA VIEW customer_list city character varying 6 NA VIEW customer_list country character varying 7 NA VIEW customer_list notes text 8 NA VIEW customer_list sid smallint 9 NA 21.2.2 What data types are found in the database? columns_info_schema_info %&gt;% count(data_type) ## # A tibble: 3 x 2 ## data_type n ## &lt;chr&gt; &lt;int&gt; ## 1 integer 2 ## 2 smallint 2 ## 3 timestamp without time zone 3 21.3 Characterizing how things are named Names are the handle for accessing the data. Tables and columns may or may not be named consistently or in a way that makes sense to you. You should look at these names as data. 21.3.1 Counting columns and name reuse Pull out some rough-and-ready but useful statistics about your database. Since we are in SQL-land we talk about variables as columns. public_tables &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% collect() public_tables %&gt;% count(table_name, sort = TRUE) %&gt;% head(n = 15) %&gt;% kable() table_name n film 13 staff 11 customer 10 smy_customer 10 customer_list 9 address 8 film_list 8 nicer_but_slower_film_list 8 staff_list 8 rental 7 payment 6 actor 4 actor_info 4 city 4 inventory 4 How many column names are shared across tables (or duplicated)? public_tables %&gt;% count(column_name, sort = TRUE) %&gt;% filter(n &gt; 1) ## # A tibble: 36 x 2 ## column_name n ## &lt;chr&gt; &lt;int&gt; ## 1 last_update 15 ## 2 address_id 5 ## 3 first_name 5 ## 4 last_name 5 ## 5 store_id 5 ## 6 customer_id 4 ## 7 film_id 4 ## 8 name 4 ## 9 active 3 ## 10 actor_id 3 ## # … with 26 more rows How many column names are unique? public_tables %&gt;% count(column_name) %&gt;% filter(n == 1) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 22 21.4 Database keys 21.4.1 Direct SQL How do we use this output? Could it be generated by dplyr? rs &lt;- dbGetQuery( con, &quot; --SELECT conrelid::regclass as table_from select table_catalog||&#39;.&#39;||table_schema||&#39;.&#39;||table_name table_name , conname, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM information_schema.columns c,pg_catalog.pg_constraint r WHERE 1 = 1 --r.conrelid = &#39;16485&#39; AND r.contype in (&#39;f&#39;,&#39;p&#39;) ORDER BY 1 ;&quot; ) glimpse(rs) ## Observations: 61,545 ## Variables: 3 ## $ table_name &lt;chr&gt; &quot;dvdrental.information_schema.administrable_role_auth… ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;country_pk… ## $ condef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (actor_id)&quot;, &quot;… kable(head(rs)) table_name conname condef dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) The following is more compact and looks more useful. What is the difference bet ween the two? rs &lt;- dbGetQuery( con, &quot;select conrelid::regclass as table_from ,c.conname ,pg_get_constraintdef(c.oid) from pg_constraint c join pg_namespace n on n.oid = c.connamespace where c.contype in (&#39;f&#39;,&#39;p&#39;) and n.nspname = &#39;public&#39; order by conrelid::regclass::text, contype DESC; &quot; ) glimpse(rs) ## Observations: 33 ## Variables: 3 ## $ table_from &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;, … ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address_c… ## $ pg_get_constraintdef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (add… kable(head(rs)) table_from conname pg_get_constraintdef actor actor_pkey PRIMARY KEY (actor_id) address address_pkey PRIMARY KEY (address_id) address fk_address_city FOREIGN KEY (city_id) REFERENCES city(city_id) category category_pkey PRIMARY KEY (category_id) city city_pkey PRIMARY KEY (city_id) city fk_city FOREIGN KEY (country_id) REFERENCES country(country_id) dim(rs)[1] ## [1] 33 21.4.2 Database keys with dplyr This query shows the primary and foreign keys in the database. tables &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) table_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;table_constraints&quot;)) key_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;key_column_usage&quot;)) referential_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;referential_constraints&quot;)) constraint_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;constraint_column_usage&quot;)) keys &lt;- tables %&gt;% left_join(table_constraints, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot; )) %&gt;% # table_constraints %&gt;% filter(constraint_type %in% c(&quot;FOREIGN KEY&quot;, &quot;PRIMARY KEY&quot;)) %&gt;% left_join(key_column_usage, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;constraint_catalog&quot; = &quot;constraint_catalog&quot;, &quot;constraint_schema&quot; = &quot;constraint_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;constraint_name&quot; = &quot;constraint_name&quot; ) ) %&gt;% # left_join(constraint_column_usage) %&gt;% # does this table add anything useful? select(table_name, table_type, constraint_name, constraint_type, column_name, ordinal_position) %&gt;% arrange(table_name) %&gt;% collect() glimpse(keys) ## Observations: 35 ## Variables: 6 ## $ table_name &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;, &quot;cit… ## $ table_type &lt;chr&gt; &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BASE… ## $ constraint_name &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address_city&quot;… ## $ constraint_type &lt;chr&gt; &quot;PRIMARY KEY&quot;, &quot;PRIMARY KEY&quot;, &quot;FOREIGN KEY&quot;, &quot;P… ## $ column_name &lt;chr&gt; &quot;actor_id&quot;, &quot;address_id&quot;, &quot;city_id&quot;, &quot;category_… ## $ ordinal_position &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,… kable(keys) table_name table_type constraint_name constraint_type column_name ordinal_position actor BASE TABLE actor_pkey PRIMARY KEY actor_id 1 address BASE TABLE address_pkey PRIMARY KEY address_id 1 address BASE TABLE fk_address_city FOREIGN KEY city_id 1 category BASE TABLE category_pkey PRIMARY KEY category_id 1 city BASE TABLE city_pkey PRIMARY KEY city_id 1 city BASE TABLE fk_city FOREIGN KEY country_id 1 country BASE TABLE country_pkey PRIMARY KEY country_id 1 customer BASE TABLE customer_address_id_fkey FOREIGN KEY address_id 1 customer BASE TABLE customer_pkey PRIMARY KEY customer_id 1 film BASE TABLE film_language_id_fkey FOREIGN KEY language_id 1 film BASE TABLE film_pkey PRIMARY KEY film_id 1 film_actor BASE TABLE film_actor_actor_id_fkey FOREIGN KEY actor_id 1 film_actor BASE TABLE film_actor_film_id_fkey FOREIGN KEY film_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY actor_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY film_id 2 film_category BASE TABLE film_category_category_id_fkey FOREIGN KEY category_id 1 film_category BASE TABLE film_category_film_id_fkey FOREIGN KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY category_id 2 inventory BASE TABLE inventory_film_id_fkey FOREIGN KEY film_id 1 inventory BASE TABLE inventory_pkey PRIMARY KEY inventory_id 1 language BASE TABLE language_pkey PRIMARY KEY language_id 1 payment BASE TABLE payment_customer_id_fkey FOREIGN KEY customer_id 1 payment BASE TABLE payment_pkey PRIMARY KEY payment_id 1 payment BASE TABLE payment_rental_id_fkey FOREIGN KEY rental_id 1 payment BASE TABLE payment_staff_id_fkey FOREIGN KEY staff_id 1 rental BASE TABLE rental_customer_id_fkey FOREIGN KEY customer_id 1 rental BASE TABLE rental_inventory_id_fkey FOREIGN KEY inventory_id 1 rental BASE TABLE rental_pkey PRIMARY KEY rental_id 1 rental BASE TABLE rental_staff_id_key FOREIGN KEY staff_id 1 staff BASE TABLE staff_address_id_fkey FOREIGN KEY address_id 1 staff BASE TABLE staff_pkey PRIMARY KEY staff_id 1 store BASE TABLE store_address_id_fkey FOREIGN KEY address_id 1 store BASE TABLE store_manager_staff_id_fkey FOREIGN KEY manager_staff_id 1 store BASE TABLE store_pkey PRIMARY KEY store_id 1 What do we learn from the following query? How is it useful? rs &lt;- dbGetQuery( con, &quot;SELECT r.*, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM pg_catalog.pg_constraint r WHERE 1=1 --r.conrelid = &#39;16485&#39; AND r.contype = &#39;f&#39; ORDER BY 1; &quot; ) head(rs) ## conname connamespace contype condeferrable ## 1 cardinal_number_domain_check 12703 c FALSE ## 2 yes_or_no_check 12703 c FALSE ## 3 year_check 2200 c FALSE ## 4 actor_pkey 2200 p FALSE ## 5 address_pkey 2200 p FALSE ## 6 category_pkey 2200 p FALSE ## condeferred convalidated conrelid contypid conindid confrelid ## 1 FALSE TRUE 0 12716 0 0 ## 2 FALSE TRUE 0 12724 0 0 ## 3 FALSE TRUE 0 16397 0 0 ## 4 FALSE TRUE 16420 0 16555 0 ## 5 FALSE TRUE 16461 0 16557 0 ## 6 FALSE TRUE 16427 0 16559 0 ## confupdtype confdeltype confmatchtype conislocal coninhcount ## 1 TRUE 0 ## 2 TRUE 0 ## 3 TRUE 0 ## 4 TRUE 0 ## 5 TRUE 0 ## 6 TRUE 0 ## connoinherit conkey confkey conpfeqop conppeqop conffeqop conexclop ## 1 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## conbin ## 1 {OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 195} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 204 :constvalue 4 [ 0 0 0 0 0 0 0 0 ]}) :location 201} ## 2 {SCALARARRAYOPEXPR :opno 98 :opfuncid 67 :useOr true :inputcollid 100 :args ({RELABELTYPE :arg {COERCETODOMAINVALUE :typeId 1043 :typeMod 7 :collation 100 :location 121} :resulttype 25 :resulttypmod -1 :resultcollid 100 :relabelformat 2 :location -1} {ARRAYCOERCEEXPR :arg {ARRAY :array_typeid 1015 :array_collid 100 :element_typeid 1043 :elements ({CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 131 :constvalue 7 [ 28 0 0 0 89 69 83 ]} {CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 138 :constvalue 6 [ 24 0 0 0 78 79 ]}) :multidims false :location -1} :elemfuncid 0 :resulttype 1009 :resulttypmod -1 :resultcollid 100 :isExplicit false :coerceformat 2 :location -1}) :location 127} ## 3 {BOOLEXPR :boolop and :args ({OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 62} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 71 :constvalue 4 [ 109 7 0 0 0 0 0 0 ]}) :location 68} {OPEXPR :opno 523 :opfuncid 149 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 82} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 91 :constvalue 4 [ 107 8 0 0 0 0 0 0 ]}) :location 88}) :location 77} ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## consrc ## 1 (VALUE &gt;= 0) ## 2 ((VALUE)::text = ANY ((ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying])::text[])) ## 3 ((VALUE &gt;= 1901) AND (VALUE &lt;= 2155)) ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## condef ## 1 CHECK (VALUE &gt;= 0) ## 2 CHECK (VALUE::text = ANY (ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying]::text[])) ## 3 CHECK (VALUE &gt;= 1901 AND VALUE &lt;= 2155) ## 4 PRIMARY KEY (actor_id) ## 5 PRIMARY KEY (address_id) ## 6 PRIMARY KEY (category_id) 21.5 Creating your own data dictionary If you are going to work with a database for an extended period it can be useful to create your own data dictionary. This can take the form of keeping detaild notes as well as extracting metadata from the dbms. Here is an illustration of the idea. some_tables &lt;- c(&quot;rental&quot;, &quot;city&quot;, &quot;store&quot;) all_meta &lt;- map_df(some_tables, sp_get_dbms_data_dictionary, con = con) all_meta ## # A tibble: 15 x 11 ## table_name var_name var_type num_rows num_blank num_unique min q_25 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rental rental_… integer 16045 0 16045 1 4013 ## 2 rental rental_… double 16045 0 15816 2005… 2005… ## 3 rental invento… integer 16045 0 4581 1 1154 ## 4 rental custome… integer 16045 0 600 1 148 ## 5 rental return_… double 16045 183 15837 2005… 2005… ## 6 rental staff_id integer 16045 0 2 1 1 ## 7 rental last_up… double 16045 0 4 2006… 2006… ## 8 city city_id integer 600 0 600 1 150 ## 9 city city charact… 600 0 599 A Co… Dzer… ## 10 city country… integer 600 0 109 1 28 ## 11 city last_up… double 600 0 1 2006… 2006… ## 12 store store_id integer 3 0 3 1 1 ## 13 store manager… integer 3 0 3 1 1 ## 14 store address… integer 3 0 3 1 1 ## 15 store last_up… double 3 0 2 2006… 2006… ## # … with 3 more variables: q_50 &lt;chr&gt;, q_75 &lt;chr&gt;, max &lt;chr&gt; glimpse(all_meta) ## Observations: 15 ## Variables: 11 ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;re… ## $ var_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer… ## $ var_type &lt;chr&gt; &quot;integer&quot;, &quot;double&quot;, &quot;integer&quot;, &quot;integer&quot;, &quot;double&quot;, … ## $ num_rows &lt;int&gt; 16045, 16045, 16045, 16045, 16045, 16045, 16045, 600,… ## $ num_blank &lt;int&gt; 0, 0, 0, 0, 183, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ## $ num_unique &lt;int&gt; 16045, 15816, 4581, 600, 15837, 2, 4, 600, 599, 109, … ## $ min &lt;chr&gt; &quot;1&quot;, &quot;2005-05-24 22:53:30&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2005-05-25 23:… ## $ q_25 &lt;chr&gt; &quot;4013&quot;, &quot;2005-07-07 00:58:00&quot;, &quot;1154&quot;, &quot;148&quot;, &quot;2005-0… ## $ q_50 &lt;chr&gt; &quot;8025&quot;, &quot;2005-07-28 16:03:27&quot;, &quot;2291&quot;, &quot;296&quot;, &quot;2005-0… ## $ q_75 &lt;chr&gt; &quot;12037&quot;, &quot;2005-08-17 21:13:35&quot;, &quot;3433&quot;, &quot;446&quot;, &quot;2005-… ## $ max &lt;chr&gt; &quot;16050&quot;, &quot;2019-02-11&quot;, &quot;4582&quot;, &quot;600&quot;, &quot;2019-02-18&quot;, &quot;… kable(head(all_meta)) table_name var_name var_type num_rows num_blank num_unique min q_25 q_50 q_75 max rental rental_id integer 16045 0 16045 1 4013 8025 12037 16050 rental rental_date double 16045 0 15816 2005-05-24 22:53:30 2005-07-07 00:58:00 2005-07-28 16:03:27 2005-08-17 21:13:35 2019-02-11 rental inventory_id integer 16045 0 4581 1 1154 2291 3433 4582 rental customer_id integer 16045 0 600 1 148 296 446 600 rental return_date double 16045 183 15837 2005-05-25 23:55:21 2005-07-10 15:48:58 2005-08-01 19:45:29 2005-08-20 23:49:25 2019-02-18 rental staff_id integer 16045 0 2 1 1 1 2 2 ## Save your work! The work you do to understand the structure and contents of a database can be useful for others (including future-you). So at the end of a session, you might look at all the data frames you want to save. Consider saving them in a form where you can add notes at the appropriate level (as in a Google Doc representing table or columns that you annotate over time). ls() ## [1] &quot;all_meta&quot; &quot;columns_info_schema_info&quot; ## [3] &quot;columns_info_schema_table&quot; &quot;con&quot; ## [5] &quot;constraint_column_usage&quot; &quot;cranex&quot; ## [7] &quot;key_column_usage&quot; &quot;keys&quot; ## [9] &quot;public_tables&quot; &quot;referential_constraints&quot; ## [11] &quot;rs&quot; &quot;some_tables&quot; ## [13] &quot;table_constraints&quot; &quot;table_info&quot; ## [15] &quot;table_info_schema_table&quot; &quot;table_list&quot; ## [17] &quot;tables&quot; "],
["chapter-dbms-environment.html", "Chapter 22 Drilling into your DBMS environment 22.1 Which database? 22.2 How many databases reside in the Docker Container? 22.3 Which Schema? 22.4 Exercises", " Chapter 22 Drilling into your DBMS environment This chapter investigates: Elements of the database environment Differences between a database, a schema, and other objects Exercises The following packages are used in this chapter: # These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(dbplyr) library(sqlpetr) display_rows &lt;- 15 # as a default, show 15 rows Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 22.1 Which database? Your DBA will create your user accounts and priviledges for the database(s) that you can access. One of the challenges when working with a database(s) is finding where your data actually resides. Your best resources will be one or more subject matter experts, SME, and your DBA. Your data may actually reside in multiple databases, e.g., a detail and summary databases. In our tutorial, we focus on the one database, dvdrental. Database names usually reflect something about the data that they contain. Your laptop is a server for the Docker PostgreSQL databases. A database is a collection of files that PostgreSQL manages in the background. 22.2 How many databases reside in the Docker Container? rs &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Names in Docker&#39; showing ,datname DB FROM pg_database WHERE datistemplate = false; &quot; ) kable(rs) showing db DB Names in Docker postgres DB Names in Docker dvdrental Which databases are available? Modify the connection call to connect to the `postgres` database. # this code chunk is not evaluated because the `dbname` is not valid! con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;your code goes here&quot;, seconds_to_test = 30 ) con if (con != &quot;There is no connection&quot;) { dbDisconnect(con) } # Answer: con &lt;PqConnection&gt; postgres@localhost:5432 # Reconnect to dvdrental con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) con ## &lt;PqConnection&gt; dvdrental@localhost:5432 Note that the two Sys.getenv function calls work in this tutorial because both the user and password are available in both databases. This is a common practice in organinzations that have implemented single sign on across their organization. Gotcha: If one has data in multiple databases or multiple environments, Development, Integration, and Prodution, it is very easy to connect to the wrong database in the wrong environment. Always double check your connection information when logging in and before performing any inserts, updates, or deletes against the database. The following code block should be used to reduce propagating the above gotcha. Current_database(), CURRENT_DATE or CURRENT_TIMESTAMP, and ‘result set’ are the most useful and last three not so much. Instead of the host IP address having the actual hostname would be a nice addition. rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT current_database() DB ,CURRENT_DATE ,CURRENT_TIMESTAMP ,&#39;result set description&#39; showing ,session_user ,inet_server_addr() host ,inet_server_port() port &quot; ) kable(rs1) db current_date current_timestamp showing session_user host port dvdrental 2019-02-18 2019-02-17 18:44:22 result set description postgres 172.17.0.2 5432 Since we will only be working in the dvdrental database in this tutorial and reduce the number of output columns shown, only the ‘result set description’ will be used. 22.3 Which Schema? In the code block below, we look at the information_schema.table which contains information about all the schemas and table/views within our dvdrental database. Databases can have one or more schemas, containers that hold tables or views. Schemas partition the database into big logical blocks of related data. Schema names usually reflect an application or logically related datasets. Occasionally a DBA will set up a new schema and use a users name. What schemas are in the dvdrental database? How many entries are in each schema? ## Database Schemas # rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Schemas&#39; showing,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot; ) kable(rs1) showing db table_schema tbl_vws DB Schemas dvdrental pg_catalog 121 DB Schemas dvdrental public 23 DB Schemas dvdrental information_schema 67 We see that there are three schemas. The pg_catalog is the standard PostgreSQL meta data and core schema. PostgreSQL uses this schema to manage the internal workings of the database. DBA’s are the primary users of pg_catalog. We used the pg_catalog schema to answer the question ‘How many databases reside in the Docker Container?’, but normally the data analyst is not interested in analyzing database data. The information_schema contains ANSI standardized views used across the different SQL vendors, (Oracle, Sysbase, MS SQL Server, IBM DB2, etc). The information_schema contains a plethora of metadata that will help you locate your data tables, understand the relationships between the tables, and write efficient SQL queries. 22.4 Exercises # # Add an order by clause to order the output by the table catalog. rs1 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;1. ORDER BY table_catalog&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot;) kable(rs1) showing db table_schema tbl_vws 1. ORDER BY table_catalog dvdrental pg_catalog 121 1. ORDER BY table_catalog dvdrental public 23 1. ORDER BY table_catalog dvdrental information_schema 67 # Add an order by clause to order the output by tbl_vws in descending order. rs2 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;2. ORDER BY tbl_vws desc&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot;) kable(rs2) showing db table_schema tbl_vws 2. ORDER BY tbl_vws desc dvdrental pg_catalog 121 2. ORDER BY tbl_vws desc dvdrental public 23 2. ORDER BY tbl_vws desc dvdrental information_schema 67 # Complete the SQL statement to show everything about all the tables. rs3 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;3. all information_schema tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t &quot;) kable(head(rs3, display_rows)) showing ?column? 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here # Use the results from above to pull interesting columns from just the information_schema rs4 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;4. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) head(rs4, display_rows) ## showing ?column? ## 1 4. information_schema.tables your code goes here ## 2 4. information_schema.tables your code goes here ## 3 4. information_schema.tables your code goes here ## 4 4. information_schema.tables your code goes here ## 5 4. information_schema.tables your code goes here ## 6 4. information_schema.tables your code goes here ## 7 4. information_schema.tables your code goes here ## 8 4. information_schema.tables your code goes here ## 9 4. information_schema.tables your code goes here ## 10 4. information_schema.tables your code goes here ## 11 4. information_schema.tables your code goes here ## 12 4. information_schema.tables your code goes here ## 13 4. information_schema.tables your code goes here ## 14 4. information_schema.tables your code goes here ## 15 4. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;tab&#39; rs5 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;5. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) kable(head(rs5, display_rows)) showing ?column? 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;col&#39; rs6 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;6. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) kable(head(rs6, display_rows)) showing ?column? 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here In the next exercise we combine both the table and column output from the previous exercises. Review the following code block. The last two lines of the WHERE clause are swithced. Will the result set be the same or different? Execute the code block and review the two datasets. rs7 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;7. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; and table_type = &#39;VIEW&#39; &quot;) kable(head(rs7, display_rows)) showing db_info table_name table_type 7. information_schema.tables dvdrental.information_schema collations VIEW 7. information_schema.tables dvdrental.information_schema collation_character_set_applicability VIEW 7. information_schema.tables dvdrental.information_schema column_domain_usage VIEW 7. information_schema.tables dvdrental.information_schema column_privileges VIEW 7. information_schema.tables dvdrental.information_schema column_udt_usage VIEW 7. information_schema.tables dvdrental.information_schema columns VIEW 7. information_schema.tables dvdrental.information_schema constraint_column_usage VIEW 7. information_schema.tables dvdrental.information_schema key_column_usage VIEW 7. information_schema.tables dvdrental.information_schema role_column_grants VIEW 7. information_schema.tables dvdrental.information_schema table_constraints VIEW 7. information_schema.tables dvdrental.information_schema table_privileges VIEW 7. information_schema.tables dvdrental.information_schema tables VIEW 7. information_schema.tables dvdrental.information_schema triggered_update_columns VIEW 7. information_schema.tables dvdrental.information_schema view_column_usage VIEW 7. information_schema.tables dvdrental.information_schema _pg_foreign_table_columns VIEW rs8 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;8. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_type = &#39;VIEW&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; &quot;) kable(head(rs8, display_rows)) showing db_info table_name table_type 8. information_schema.tables dvdrental.information_schema column_options VIEW 8. information_schema.tables dvdrental.information_schema _pg_foreign_table_columns VIEW 8. information_schema.tables dvdrental.information_schema view_column_usage VIEW 8. information_schema.tables dvdrental.information_schema triggered_update_columns VIEW 8. information_schema.tables dvdrental.information_schema tables VIEW 8. information_schema.tables dvdrental.information_schema table_privileges VIEW 8. information_schema.tables dvdrental.information_schema table_constraints VIEW 8. information_schema.tables dvdrental.information_schema role_column_grants VIEW 8. information_schema.tables dvdrental.information_schema key_column_usage VIEW 8. information_schema.tables dvdrental.information_schema constraint_column_usage VIEW 8. information_schema.tables dvdrental.information_schema columns VIEW 8. information_schema.tables dvdrental.information_schema column_udt_usage VIEW 8. information_schema.tables dvdrental.information_schema column_privileges VIEW 8. information_schema.tables dvdrental.information_schema column_domain_usage VIEW 8. information_schema.tables dvdrental.information_schema collation_character_set_applicability VIEW Operator/Element Associativity Description . left table/column name separator :: left PostgreSQL-style typecast [ ] left array element selection - right unary minus ^ left exponentiation * / % left multiplication, division, modulo + - left addition, subtraction IS IS TRUE, IS FALSE, IS UNKNOWN, IS NULL ISNULL test for null NOTNULL test for not null (any other) left all other native and user-defined operators IN set membership BETWEEN range containment OVERLAPS time interval overlap LIKE ILIKE SIMILAR string pattern matching &lt; &gt; less than, greater than = right equality, assignment NOT right logical negation AND left logical conjunction OR left logical disjunction rs1 &lt;- DBI::dbGetQuery(con, &quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_name,t.table_type FROM information_schema.tables t&quot;) rs2 &lt;- DBI::dbGetQuery(con, &quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_type,COUNT(*) tbls FROM information_schema.tables t group by t.table_catalog ,t.table_schema ,t.table_type &quot;) rs3 &lt;- DBI::dbGetQuery(con, &quot;SELECT distinct t.table_catalog DB ,t.table_schema ,t.table_type tbls FROM information_schema.tables t &quot;) # kable(head(rs1 %&gt;% arrange (table_name))) # View(rs1) # View(rs2) # View(rs3) kable(head(rs1)) db table_schema table_name table_type dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public staff BASE TABLE kable(head(rs2)) db table_schema table_type tbls dvdrental information_schema BASE TABLE 7 dvdrental information_schema VIEW 60 dvdrental pg_catalog BASE TABLE 62 dvdrental public BASE TABLE 16 dvdrental public VIEW 7 dvdrental pg_catalog VIEW 59 kable(head(rs3)) db table_schema tbls dvdrental information_schema BASE TABLE dvdrental information_schema VIEW dvdrental pg_catalog BASE TABLE dvdrental public BASE TABLE dvdrental public VIEW dvdrental pg_catalog VIEW www.dataquest.io/blog/postgres-internals Comment on the practice of putting a comma at the beginning of a line in SQL code. ## Explain a `dplyr::join tbl_pk_fk_df &lt;- DBI::dbGetQuery( con, &quot; SELECT --t.table_catalog,t.table_schema, c.table_name ,kcu.column_name ,c.constraint_name ,c.constraint_type ,coalesce(c2.table_name, &#39;&#39;) ref_table ,coalesce(kcu2.column_name, &#39;&#39;) ref_table_col FROM information_schema.tables t LEFT JOIN information_schema.table_constraints c ON t.table_catalog = c.table_catalog AND t.table_schema = c.table_schema AND t.table_name = c.table_name LEFT JOIN information_schema.key_column_usage kcu ON c.constraint_schema = kcu.constraint_schema AND c.constraint_name = kcu.constraint_name LEFT JOIN information_schema.referential_constraints rc ON c.constraint_schema = rc.constraint_schema AND c.constraint_name = rc.constraint_name LEFT JOIN information_schema.table_constraints c2 ON rc.unique_constraint_schema = c2.constraint_schema AND rc.unique_constraint_name = c2.constraint_name LEFT JOIN information_schema.key_column_usage kcu2 ON c2.constraint_schema = kcu2.constraint_schema AND c2.constraint_name = kcu2.constraint_name AND kcu.ordinal_position = kcu2.ordinal_position WHERE c.constraint_type IN (&#39;PRIMARY KEY&#39;, &#39;FOREIGN KEY&#39;) AND c.table_catalog = &#39;dvdrental&#39; AND c.table_schema = &#39;public&#39; ORDER BY c.table_name; &quot; ) # View(tbl_pk_fk_df) tables_df &lt;- tbl_pk_fk_df %&gt;% distinct(table_name) # View(tables_df) library(DiagrammeR) table_nodes_ndf &lt;- create_node_df( n &lt;- nrow(tables_df) , type &lt;- &quot;table&quot; , label &lt;- tables_df$table_name , shape = &quot;rectangle&quot; , width = 1 , height = .5 , fontsize = 18 ) tbl_pk_fk_ids_df &lt;- inner_join(tbl_pk_fk_df, table_nodes_ndf , by = c(&quot;table_name&quot; = &quot;label&quot;) , suffix(c(&quot;st&quot;, &quot;s&quot;)) ) %&gt;% rename(&quot;src_tbl_id&quot; = id) %&gt;% left_join(table_nodes_ndf , by = c(&quot;ref_table&quot; = &quot;label&quot;) , suffix(c(&quot;st&quot;, &quot;t&quot;)) ) %&gt;% rename(&quot;fk_tbl_id&quot; = id) tbl_fk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &quot;FOREIGN KEY&quot;) tbl_pk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &quot;PRIMARY KEY&quot;) # View(tbl_pk_fk_ids_df) # View(tbl_fk_df) # View(tbl_pk_df) kable(head(tbl_fk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y address city_id fk_address_city FOREIGN KEY city city_id 2 table rectangle 1 0.5 18 4 table rectangle 1 0.5 18 city country_id fk_city FOREIGN KEY country country_id 4 table rectangle 1 0.5 18 5 table rectangle 1 0.5 18 customer address_id customer_address_id_fkey FOREIGN KEY address address_id 6 table rectangle 1 0.5 18 2 table rectangle 1 0.5 18 film language_id film_language_id_fkey FOREIGN KEY language language_id 7 table rectangle 1 0.5 18 11 table rectangle 1 0.5 18 film_actor actor_id film_actor_actor_id_fkey FOREIGN KEY actor actor_id 8 table rectangle 1 0.5 18 1 table rectangle 1 0.5 18 film_actor film_id film_actor_film_id_fkey FOREIGN KEY film film_id 8 table rectangle 1 0.5 18 7 table rectangle 1 0.5 18 kable(head(tbl_pk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y actor actor_id actor_pkey PRIMARY KEY 1 table rectangle 1 0.5 18 NA NA NA NA NA NA address address_id address_pkey PRIMARY KEY 2 table rectangle 1 0.5 18 NA NA NA NA NA NA category category_id category_pkey PRIMARY KEY 3 table rectangle 1 0.5 18 NA NA NA NA NA NA city city_id city_pkey PRIMARY KEY 4 table rectangle 1 0.5 18 NA NA NA NA NA NA country country_id country_pkey PRIMARY KEY 5 table rectangle 1 0.5 18 NA NA NA NA NA NA customer customer_id customer_pkey PRIMARY KEY 6 table rectangle 1 0.5 18 NA NA NA NA NA NA # Create an edge data frame, edf fk_edf &lt;- create_edge_df( from = tbl_fk_df$src_tbl_id, to = tbl_fk_df$fk_tbl_id, rel = &quot;fk&quot;, label = tbl_fk_df$constraint_name, fontsize = 15 ) # View(fk_edf) create_graph( nodes_df = table_nodes_ndf, edges_df = fk_edf, graph_name = &quot;Simple FK Graph&quot; ) %&gt;% render_graph() dbDisconnect(con) # system2(&#39;docker&#39;,&#39;stop sql-pet&#39;) "],
["chapter-explain-queries.html", "Chapter 23 Explain queries 23.1 Performance considerations 23.2 Clean up", " Chapter 23 Explain queries This chapter demonstrates: How to investigate SQL query performance # These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) library(glue) library(here) require(knitr) library(dbplyr) library(sqlpetr) examining dplyr queries (dplyr::show_query on the R side v EXPLAIN on the PostgreSQL side) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30) 23.1 Performance considerations ## Explain a `dplyr::join` ## Explain the quivalent SQL join rs1 &lt;- DBI::dbGetQuery(con ,&quot;SELECT c.* FROM pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = &#39;public&#39; AND c.relname = &#39;cust_movies&#39; AND c.relkind = &#39;r&#39; ; &quot; ) head(rs1) ## [1] relname relnamespace reltype ## [4] reloftype relowner relam ## [7] relfilenode reltablespace relpages ## [10] reltuples relallvisible reltoastrelid ## [13] relhasindex relisshared relpersistence ## [16] relkind relnatts relchecks ## [19] relhasoids relhaspkey relhasrules ## [22] relhastriggers relhassubclass relrowsecurity ## [25] relforcerowsecurity relispopulated relreplident ## [28] relispartition relfrozenxid relminmxid ## [31] relacl reloptions relpartbound ## &lt;0 rows&gt; (or 0-length row.names) This came from 14-sql_pet-examples-part-b.Rmd rs1 &lt;- DBI::dbGetQuery(con, &quot;explain select r.* from rental r ;&quot; ) head(rs1) ## QUERY PLAN ## 1 Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=36) rs2 &lt;- DBI::dbGetQuery(con, &quot;explain select count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id where p.rental_id is null ;&quot;) head(rs2) ## QUERY PLAN ## 1 Aggregate (cost=2086.78..2086.80 rows=1 width=8) ## 2 -&gt; Merge Anti Join (cost=0.57..2066.73 rows=8022 width=0) ## 3 Merge Cond: (r.rental_id = p.rental_id) ## 4 -&gt; Index Only Scan using rental_pkey on rental r (cost=0.29..1024.95 rows=16044 width=4) ## 5 -&gt; Index Only Scan using idx_fk_rental_id on payment p (cost=0.29..819.23 rows=14596 width=4) rs3 &lt;- DBI::dbGetQuery(con, &quot;explain select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot;) head(rs3) ## QUERY PLAN ## 1 Aggregate (cost=2353.64..2353.65 rows=1 width=40) ## 2 -&gt; Hash Join (cost=205.14..2313.53 rows=8022 width=12) ## 3 Hash Cond: (i.film_id = f.film_id) ## 4 -&gt; Hash Join (cost=128.64..2215.88 rows=8022 width=2) ## 5 Hash Cond: (r.inventory_id = i.inventory_id) ## 6 -&gt; Merge Anti Join (cost=0.57..2066.73 rows=8022 width=4) rs4 &lt;- DBI::dbGetQuery(con, &quot;explain select c.customer_id,c.first_name,c.last_name,sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join customer c on r.customer_id = c.customer_id where p.rental_id is null group by c.customer_id,c.first_name,c.last_name order by open_amt desc ;&quot; ) head(rs4) ## QUERY PLAN ## 1 Sort (cost=2452.49..2453.99 rows=599 width=260) ## 2 Sort Key: (sum(f.rental_rate)) DESC ## 3 -&gt; HashAggregate (cost=2417.37..2424.86 rows=599 width=260) ## 4 Group Key: c.customer_id ## 5 -&gt; Hash Join (cost=227.62..2357.21 rows=8022 width=232) ## 6 Hash Cond: (r.customer_id = c.customer_id) 23.2 Clean up # dbRemoveTable(con, &quot;cars&quot;) # dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-sql-queries-breakdown.html", "Chapter 24 SQL queries broken down 24.1 SQL Execution Steps 24.2 Passing values to SQL statements 24.3 Pass multiple sets of values with dbBind(): 24.4 Clean up", " Chapter 24 SQL queries broken down This chapter has two separate topics: SQL execution steps and passing values to SQL statements. Do they belong together? Does the chapter have the right title? This chapter explains: Some details about how SQL queries work behind the scenes SQL queries are executed behind the scenes You can pass values to SQL queries These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) library(glue) require(knitr) library(dbplyr) library(sqlpetr) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Connect to the database with R: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30) 24.1 SQL Execution Steps Parse the incoming SQL query Compile the SQL query Plan/optimize the data acquisition path Execute the optimized query / acquire and return data how do those steps map to the following code? dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 24.2 Passing values to SQL statements #Pass one set of values with the param argument: rs &lt;- dbSendQuery(con,&quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 24.3 Pass multiple sets of values with dbBind(): rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = $1&quot;) dbBind(rs, list(6L)) # cyl = 6 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## 3 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## 4 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## 5 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## 6 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## 7 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 dbBind(rs, list(8L)) # cyl = 8 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## 2 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## 3 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## 4 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## 5 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## 6 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## 7 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## 8 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## 9 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## 10 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## 11 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## 12 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## 13 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## 14 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 dbClearResult(rs) 24.4 Clean up # dbRemoveTable(con, &quot;cars&quot;) dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-writing-to-the-dbms.html", "Chapter 25 Writing to the DBMS 25.1 Set up a cattle container 25.2 Interact with PostgreSQL 25.3 Clean up", " Chapter 25 Writing to the DBMS This chapter demonstrates how to: Set up and connect to a cattle database Create, modify, and remove a database table In a corporate setting, you may be creating your own tables or modifying existing tables less frequently than retrieving data. Nevertheless, in our sandbox you can easily do so. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 25.1 Set up a cattle container Check that Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 25.1.1 Remove previous containers if they exist Remove the cattle and sql-pet containers if they exist (e.g., from prior experiments). sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 Create a new cattle container: sp_make_simple_pg(&quot;cattle&quot;) Show that we’re ready to connect: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;34d865912d97 postgres:10 \\&quot;docker-entrypoint.s…\\&quot; 1 second ago Up Less than a second 0.0.0.0:5432-&gt;5432/tcp cattle&quot; 25.1.2 Connect to PostgreSQL Connect to PostgreSQL using the sp_get_postgres_connection function: con &lt;- sp_get_postgres_connection(user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;postgres&quot;, seconds_to_test = 30) 25.2 Interact with PostgreSQL Check on the contents of the database. DBI::dbListTables(con) ## character(0) It does not contain any tables yet. 25.2.1 Create a new table in the database This is an example from the DBI help file using the “cars” built-in dataset, not to be confused with mtcars: dbWriteTable(con, &quot;cars&quot;, head(cars, 3)) # The cars table has 3 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 25.2.2 Modify an existing table To add additional rows or instances to the “cars” table, we will use INSERT command with their values. There are two different ways of adding values: list them or pass values using the param argument. dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES (1, 1), (2, 2), (3, 3)&quot; ) ## [1] 3 Now it has 6 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 Pass values using the param argument: dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES ($1, $2)&quot;, param = list(4:7, 5:8) ) ## [1] 4 Now there are 10 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 ## 7 4 5 ## 8 5 6 ## 9 6 7 ## 10 7 8 25.2.3 Remove the table Remove the “cars” table. dbRemoveTable(con, &quot;cars&quot;) 25.3 Clean up Disconnect from the database: dbDisconnect(con) Stop the cattle container, but leave it around for future use. sp_docker_stop(&quot;cattle&quot;) "],
["chapter-appendix-setup-instructions.html", "A Appendix A - Setup instructions A.1 Sandbox prerequisites A.2 R, RStudio and Git A.3 Install Docker", " A Appendix A - Setup instructions This appendix explains: Hardware and software prerequisites for setting up the sandbox used in this book Documentation for all of the elements used in this sandbox A.1 Sandbox prerequisites The sandbox environment requires: A computer running Windows (Windows 7 64-bit or later - Windows 10-Pro is recommended), MacOS, or Linux (any Linux distro that will run Docker Community Edition, R and RStudio will work) Current versions of R and RStudio [Vargas (2018)) required. Docker (instructions below) Our companion package sqlpetr (Borasky et al. 2018) The database we use is PostgreSQL 10, but you do not need to install it - it’s installed via a Docker image. In addition to the current version of R and RStudio, you will need current versions of the following packages: DBI (R Special Interest Group on Databases (R-SIG-DB), Wickham, and Müller 2018) DiagrammeR (Iannone 2018) RPostgres (Wickham, Ooms, and Müller 2018) dbplyr (Wickham and Ruiz 2019) devtools (Wickham, Hester, and Chang 2018) downloader (Chang 2015) glue (Hester 2018) here (Müller 2017) knitr (Xie 2018b) skimr (McNamara et al. 2019) tidyverse (Wickham 2017) bookdown (Xie 2018a) (for compiling the book, if you want to) A.2 R, RStudio and Git Most readers will probably have these already, but if not: If you do not have R: Go to https://cran.rstudio.com/ (R Core Team 2018). Select the download link for your system. For Linux, choose your distro. We recommend Ubuntu 18.04 LTS “Bionic Beaver”. It’s much easier to find support answers on the web for Ubuntu than other distros. Follow the instructions. Note: if you already have R, make sure it’s upgraded to R 3.5.1. We don’t test on older versions! If you do not have RStudio: go to https://www.rstudio.com/products/rstudio/download/#download. Make sure you have version 1.1.463 or later. If you do not have Git: On Windows, go to https://git-scm.com/download/win and follow instructions. There are a lot of options. Just pick the defaults!!! On MacOS, go to https://sourceforge.net/projects/git-osx-installer/files/ and follow instructions. On Linux, install Git from your distribution. A.3 Install Docker Installation depends on your operating system and we have found that it can be somewhat intricate. You will need Docker Community Edition (Docker CE): For Windows, consider these issues and follow these instructions: Go to https://store.docker.com/editions/community/docker-ce-desktop-windows. If you don’t have a Docker Store log in, you’ll need to create one. Then: If you have Windows 10 Pro, download and install Docker for Windows. If you have an older version of Windows, download and install Docker Toolbox (https://docs.docker.com/toolbox/overview/). Note that both versions require 64-bit hardware and the virtualization needs to be enabled in the firmware. On a Mac (Docker 2018c): Go to https://store.docker.com/editions/community/docker-ce-desktop-mac. If you don’t have a Docker Store login, you’ll need to create one. Then download and install Docker for Mac. Your MacOS must be at least release Yosemite (10.10.3). On UNIX flavors (Docker 2018a): note that, as with Windows and MacOS, you’ll need a Docker Store loin. Although most Linux distros ship with some version of Docker, chances are it’s not the same as the official Docker CE version. Ubuntu: https://store.docker.com/editions/community/docker-ce-server-ubuntu, Fedora: https://store.docker.com/editions/community/docker-ce-server-fedora, Cent OS: https://store.docker.com/editions/community/docker-ce-server-centos, Debian: https://store.docker.com/editions/community/docker-ce-server-debian. Note that on Linux, you will need to be a member of the docker group to use Docker. To do that, execute sudo usermod -aG docker ${USER}. Then, log out and back in again. References "],
["chapter-windows-tech-details.html", "B Appendix B - Additional technical details for Windows users B.1 Hardware requirements B.2 Software requirements B.3 Docker for Windows settings B.4 Git, GitHub and line endings", " B Appendix B - Additional technical details for Windows users This chapter explains: How to setup your environment for Windows How to use Git and GitHub effectively on Windows Skip these instructions if your computer has either OSX or a Unix variant. B.1 Hardware requirements You will need an Intel or AMD processor with 64-bit hardware and the hardware virtualization feature. Most machines you buy today will have that, but older ones may not. You will need to go into the BIOS / firmware and enable the virtualization feature. You will need at least 4 gigabytes of RAM! B.2 Software requirements You will need Windows 7 64-bit or later. If you can afford it, I highly recommend upgrading to Windows 10 Pro. B.2.1 Windows 7, 8, 8.1 and Windows 10 Home (64 bit) Install Docker Toolbox. The instructions are here: https://docs.docker.com/toolbox/toolbox_install_windows/. Make sure you try the test cases and they work! B.2.2 Windows 10 Pro Install Docker for Windows stable. The instructions are here: https://docs.docker.com/docker-for-windows/install/#start-docker-for-windows. Again, make sure you try the test cases and they work. B.3 Docker for Windows settings B.3.1 Shared drives If you’re going to mount host files into container file systems (as we do in the following chapters), you need to set up shared drives. Open the Docker settings dialog and select Shared Drives. Check the drives you want to share. In this screenshot, the D: drive is my 1 terabyte hard drive. B.3.2 Kubernetes Kubernetes is a container orchestration / cloud management package that’s a major DevOps tool. It’s heavily supported by Red Hat and Google, and as a result is becoming a required skill for DevOps. However, it’s overkill for this project at the moment. So you should make sure it’s not enabled. Go to the Kubernetes dialog and make sure the Enable Kubernetes checkbox is cleared. B.4 Git, GitHub and line endings Git was originally developed for Linux - in fact, it was created by Linus Torvalds to manage hundreds of different versions of the Linux kernel on different machines all around the world. As usage has grown, Git has achieved a huge following and is the version control system used by most large open source projects, including this one. If you’re on Windows, there are some things about Git and GitHub you need to watch. First of all, there are quite a few tools for running Git on Windows, but the RStudio default and recommended one is Git for Windows (https://git-scm.com/download/win). By default, text files on Linux end with a single linefeed (\\n) character. But on Windows, text files end with a carriage return and a line feed (\\r\\n). See https://en.wikipedia.org/wiki/Newline for the gory details. Git defaults to checking files out in the native mode. So if you’re on Linux, a text file will show up with the Linux convention, and if you’re on Windows, it will show up with the Windows convention. Most of the time this doesn’t cause any problems. But Docker containers usually run Linux, and if you have files from a repository on Windows that you’ve sent to the container, the container may malfunction or give weird results. This kind of situation has caused a lot of grief for contributors to this project, so beware. In particular, executable sh or bash scripts will fail in a Docker container if they have Windows line endings. You may see an error message with \\r in it, which means the shell saw the carriage return (\\r) and gave up. But often you’ll see no hint at all what the problem was. So you need a way to tell Git that some files need to be checked out with Linux line endings. See https://help.github.com/articles/dealing-with-line-endings/ for the details. Summary: You’ll need a .gitattributes file in the root of the repository. In that file, all text files (scripts, program source, data, etc.) that are destined for a Docker container will need to have the designator &lt;spec&gt; text eol=lf, where &lt;spec&gt; is the file name specifier, for example, *.sh. This repo includes a sample: .gitattributes "],
["chapter-appendix-postresql-authentication.html", "C Appendix C - PostgreSQL Authentication C.1 Introduction C.2 Password authentication on the PostgreSQL Docker image C.3 Adding roles", " C Appendix C - PostgreSQL Authentication C.1 Introduction PostgreSQL has a very robust and flexible set of authentication methods (PostgreSQL Global Development Group 2018a). In most production environments, these will be managed by the database administrator (DBA) on a need-to-access basis. People and programs will be granted access only to a minimum set of capabilities required to function, and nothing more. In this book, we are using a PostgreSQL Docker image (Docker 2018d). When we create a container from that image, we use its native mechanism to create the postgres database superuser with a password specified in an R environment file ~/.Renviron. See Securing and using your dbms log-in credentials for how we do this. What that means is that you are the DBA - the database superuser - for the PostgreSQL database cluster running in the container! You can create and destroy databases, schemas, tables, views, etc. You can also create and destroy users - called roles in PostgreSQL, and GRANT or REVOKE their privileges with great precision. You don’t have to do that to use this book. But if you want to experiment with it, feel free! C.2 Password authentication on the PostgreSQL Docker image Of the many PostgreSQL authentication mechanisms, the simplest that’s universallly available is password authentication (PostgreSQL Global Development Group 2018c). That’s what we use for the postgres database superuser, and what we recommend for any roles you may create. Once a role has been created, you need five items to open a connection to the PostgreSQL database cluster: The host. This is a name or IP address that your network can access. In this book, with the database running in a Docker container, that’s usually localhost. The port. This is the port the server is listening on. It’s usually the default, 5432, and that’s what we use. But in a secure environment, it will often be some random number to lower the chances that an attacker can find the database server. And if you have more than one server on the network, you’ll need to use different ports for each of them. The dbname to connect to. This database must exist or the connection attempt will fail. The user. This user must exist in the database cluster and be allowed to access the database. We are using the database superuser postgres in this book. The password. This is set by the DBA for the user. In this book we use the password defined in Securing and using your dbms log-in credentials. C.3 Adding roles As noted above, PostgreSQL has a very flexible fine-grained access permissions system. We can’t cover all of it; see PostgreSQL Global Development Group (2018b) for the full details. But we can give an example. C.3.1 Setting up Docker First, we need to make sure we don’t have any other databases listening on the default port 5432. sqlpetr::sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; sqlpetr::sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sqlpetr::sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 # sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) C.3.2 Creating a new container We’ll create a “cattle” container with a default PostgreSQL 10 database cluster. sqlpetr::sp_make_simple_pg(&quot;cattle&quot;) cattle_conn &lt;- sqlpetr::sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5432, dbname = &quot;postgres&quot;, user = &quot;postgres&quot;, password = &quot;postgres&quot;, seconds_to_test = 30 ) C.3.3 Adding a role Now, let’s add a role. We’ll add a role that can log in and create databases, but isn’t a superuser. Since this is a demo and not a real production database cluster, we’ll specify a password in plaintext. And we’ll create a database for our new user. Create the role: CREATE ROLE charlie LOGIN CREATEDB PASSWORD &#39;chaplin&#39;; Create the database: CREATE DATABASE charlie OWNER = charlie; C.3.4 Did it work? DBI::dbDisconnect(cattle_conn) cattle_conn &lt;- sqlpetr::sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5432, dbname = &quot;charlie&quot;, user = &quot;charlie&quot;, password = &quot;chaplin&quot;, seconds_to_test = 30 ) print(cattle_conn) ## &lt;PqConnection&gt; charlie@localhost:5432 OK, we can connect. Let’s do some stuff! data(&quot;iris&quot;) dbCreateTable creates the table with columns matching the data frame. But it does not send data to the table. DBI::dbCreateTable(cattle_conn, &quot;iris&quot;, iris) To send data, we use dbAppendTable. DBI::dbAppendTable(cattle_conn, &quot;iris&quot;, iris) ## Warning: Factors converted to character ## [1] 150 DBI::dbListTables(cattle_conn) ## [1] &quot;iris&quot; head(DBI::dbReadTable(cattle_conn, &quot;iris&quot;)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa DBI::dbDisconnect(cattle_conn) C.3.5 Remove the container sqlpetr::sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 References "],
["chapter-appendix-sql-quick-guide.html", "D APPENDIX D - Quick Guide to SQL D.1 Data Manipulation Langauge (DML) D.2 Data Definition Langauge (DDL) D.3 Data Control Language (DCL) D.4 Transaction Control Language (TCL)", " D APPENDIX D - Quick Guide to SQL SQL stands for Structured Query Language. It is a database language where we can perform certain operations on the existing database and we can use it create a new database. There are four main categories where the SQL commands fall into: DML, DDL, DCL, and TCL. D.1 Data Manipulation Langauge (DML) These four SQL commands deal with the manipulation of data in the database. For everyday analytical work, these are the commands that you will use the most. 1. SELECT 2. INSERT 3. UPDATE 4. DELETE D.2 Data Definition Langauge (DDL) It consists of the SQL commands that can be used to define a database schema. The DDL commands include: 1. CREATE 2. ALTER 3. TRUNCATE 4. COMMENT 5. RENAME 6. DROP D.3 Data Control Language (DCL) The DCL commands deals with user rights, permissions and other controls in database management system. 1. GRANT 2. REVOKE D.4 Transaction Control Language (TCL) These commands deal with the control over transaction within the database. Transaction combines a set of tasks into single execution. 1. SET TRANSACTION 2. SAVEPOINT 3. ROLLBACK 4. COMMIT "],
["chapter-appendix-dplyr-functions.html", "E Dplyr functions and SQL cross-walk", " E Dplyr functions and SQL cross-walk Where are these covered and should they be included? Dplyr Function description SQL Clause Where Category all_equal() all.equal() Flexible equality comparison for data frames Two-table verbs all_vars() any_vars() Apply predicate to all variables scoped-Operate on a selection of variables arrange() Arrange rows by variables ORDER BY 13.1.4 (21) Basic single-table verbs arrange_all() arrange_at() arrange_if() Arrange rows by a selection of variables ORDER BY scoped-Operate on a selection of variables auto_copy() Copy tables to same source, if necessary Remote tables between() Do values in a numeric vector fall in specified range? Vector functions bind_rows() bind_cols() combine() Efficiently bind multiple data frames by row and column Two-table verbs case_when() A general vectorised if Vector functions coalesce() Find first non-missing element Vector functions compute() collect() collapse() Force computation of a database query Remote tables copy_to() Copy a local data frame to a remote src Remote tables cumall() cumany() cummean() Cumulativate versions of any, all, and mean Vector functions desc() Descending order Vector functions distinct() Return rows with matching conditions SELECT distinct * Basic single-table verbs distinct() Select distinct/unique rows SELECT distinct {colname1,…colnamen} Basic single-table verbs do() Do anything NA Basic single-table verbs explain() show_query() Explain details of a tbl Remote tables filter_all() filter_if() filter_at() Filter within a selection of variables scoped-Operate on a selection of variables funs() Create a list of functions calls. scoped-Operate on a selection of variables group_by() ungroup() Objects exported from other packages GROUP BY no ungroup Basic single-table verbs group_by_all() group_by_at() group_by_if() Group by a selection of variables scoped-Operate on a selection of variables groups() group_vars() Return grouping variables Metadata ident() Flag a character vector as SQL identifiers Remote tables if_else() Vectorised if Vector functions inner_join() left_join() right_join() full_join() semi_join() anti_join() Join two tbls together Two-table verbs inner_join()left_join() right_join() full_join() semi_join() anti_join() Join data frame tbls Two-table verbs intersect() union() union_all() setdiff() setequal() Set operations Two-table verbs lead() lag() Lead and lag. Vector functions mutate() transmute() Add new variables SELECT computed_value computed_name 11.5.2 (13) Basic single-table verbs n() The number of observations in the current group. Vector functions n_distinct() Efficiently count the number of unique values in a set of vector Vector functions na_if() Convert values to NA Vector functions near() Compare two numeric vectors Vector functions nth() first() last() Extract the first, last or nth value from a vector Vector functions order_by() A helper function for ordering window function output Vector functions pull() Pull out a single variable SELECT column_name; Basic single-table verbs recode() recode_factor() Recode values Vector functions row_number() ntile() min_rank() dense_rank() percent_rank() cume_dist() Windowed rank functions. Vector functions rowwise() Group input by rows Other backends sample_n() sample_frac() Sample n rows from a table ORDER BY RANDOM() LIMIT 10 Basic single-table verbs select() rename() Select/rename variables by name SELECT column_name alias_name 9.1.8 (11) Basic single-table verbs select_all() rename_all() select_if() rename_if() select_at() rename_at() Select and rename a selection of variables scoped-Operate on a selection of variables slice() Select rows by position SELECT row_number() over (partition by expression(s) order_by exp) Basic single-table verbs sql() SQL escaping. Remote tables src_mysql() src_postgres() src_sqlite() Source for database backends Remote tables summarise_all() summarise_if() summarise_at() summarize_all() summarize_if() summarize_at() mutate_all() mutate_if() mutate_at() transmute_all() transmute_if() transmute_at() Summarise and mutate multiple columns. scoped-Operate on a selection of variables summarize() Reduces multiple values down to a single value SELECT aggregate_functions GROUP BY 11.5.1 (13) Basic single-table verbs tally() count()add_tally() add_count() Count/tally observations by group GROUP BY 9.1.6 (11) Single-table helpers tbl() is.tbl() as.tbl() Create a table from a data source Remote tables top_n() Select top (or bottom) n rows (by value) ORDER BY VALUE {DESC} LIMIT 10 Single-table helpers vars() Select variables scoped-Operate on a selection of variables "],
["chapter-appendix-dbi-functions.html", "F DBI package functions - coverage", " F DBI package functions - coverage Where are these covered and should the by included? DBI 1st time Call Example/Notes DBIConnct 6.3.2 (04) in sp_get_postgres_connection dbAppendTable dbCreateTable dbDisconnect 6.4n (04) dbDisconnect(con) dbExecute 10.4.2 (13) Executes a statement and returns the number of rows affected. dbExecute() comes with a default implementation (which should work with most backends) that calls dbSendStatement(), then dbGetRowsAffected(), ensuring that the result is always free-d by dbClearResult(). dbExistsTable dbExistsTable(con,‘actor’) dbFetch 17.1 (72) dbFetch(rs) dbGetException dbGetInfo dbGetInfo(con) dbGetQuery 10.4.1 (13) dbGetQuery(con,‘select * from store;’) dbIsReadOnly dbIsReadOnly(con) dbIsValid dbIsValid(con) dbListFields 6.3.3 (04) DBI::dbListFields(con, “mtcars”) dbListObjects dbListObjects(con) dbListTables 6.3.2 (04) DBI::dbListTables(con, con) dbReadTable 8.1.2 DBI::dbReadTable(con, “rental”) dbRemoveTable dbSendQuery 17.1 (72) rs &lt;- dbSendQuery(con, “SELECT * FROM mtcars WHERE cyl = 4”) dbSendStatement The dbSendStatement() method only submits and synchronously executes the SQL data manipulation statement (e.g., UPDATE, DELETE, INSERT INTO, DROP TABLE, …) to the database engine. dbWriteTable 6.3.3 (04) dbWriteTable(con, “mtcars”, mtcars, overwrite = TRUE) "],
["chapter-appendix-additional-resources.html", "G Appendix Additional resources G.1 Editing this book G.2 Docker alternatives G.3 Docker and R G.4 Documentation for Docker and PostgreSQL G.5 SQL and dplyr G.6 More Resources", " G Appendix Additional resources G.1 Editing this book Here are instructions for editing this book G.2 Docker alternatives Choosing between Docker and Vagrant (Zait 2017) G.3 Docker and R Noam Ross’ talk on Docker for the UseR (Ross 2018b) and his Slides (Ross 2018a) give a lot of context and tips. Good Docker tutorials An introductory Docker tutorial (Srivastav 2018) A Docker curriculum (Hall 2018) Scott Came’s materials about Docker and R on his website (Came 2018) and at the 2018 UseR Conference focus on R inside Docker. It’s worth studying the ROpensci Docker tutorial (ROpenSciLabs 2018) G.4 Documentation for Docker and PostgreSQL The Postgres image documentation (Docker 2018d) PostgreSQL &amp; Docker documentation (Docker 2018d) Dockerize PostgreSQL (Docker 2018b) Usage examples of PostgreSQL with Docker WARNING-EXPIRED CERTIFICATE 2018-12-20 G.5 SQL and dplyr Why SQL is not for analysis but dplyr is (Nishida 2016) Data Manipulation with dplyr (With 50 Examples) (ListenData.com 2016) G.6 More Resources David Severski describes some key elements of connecting to databases with R for MacOS users (Severski 2018) This tutorial picks up ideas and tips from Ed Borasky’s Data Science pet containers (Borasky 2018), which creates a framework based on that Hack Oregon example and explains why this repo is named pet-sql. References "],
["references.html", "References", " References "]
]
