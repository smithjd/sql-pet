[
<<<<<<< HEAD
["dplyr-to-sql-translations.html", "G Dplyr to SQL translations G.1 Overview", " G Dplyr to SQL translations This Appendix is based on the work of Dewey Dunnington ((???)(http://twitter.com/paleolimbot)) which he published here: https://apps.fishandwhistle.net/archives/1503 https://rud.is/b/2019/04/10/lost-in-sql-translation-charting-dbplyr-mapped-sql-function-support-across-all-backends/ G.1 Overview These packages are called in this Appendix: library(tidyverse) library(dbplyr) library(gt) library(here) list the DBI functions that are available: names(sql_translate_env(simulate_dbi())) ## [1] &quot;-&quot; &quot;:&quot; &quot;!&quot; ## [4] &quot;!=&quot; &quot;(&quot; &quot;{&quot; ## [7] &quot;*&quot; &quot;/&quot; &quot;&amp;&quot; ## [10] &quot;&amp;&amp;&quot; &quot;%%&quot; &quot;%&gt;%&quot; ## [13] &quot;%in%&quot; &quot;^&quot; &quot;+&quot; ## [16] &quot;&lt;&quot; &quot;&lt;=&quot; &quot;==&quot; ## [19] &quot;&gt;&quot; &quot;&gt;=&quot; &quot;|&quot; ## [22] &quot;||&quot; &quot;abs&quot; &quot;acos&quot; ## [25] &quot;acosh&quot; &quot;as.character&quot; &quot;as.double&quot; ## [28] &quot;as.integer&quot; &quot;as.numeric&quot; &quot;asin&quot; ## [31] &quot;asinh&quot; &quot;atan&quot; &quot;atan2&quot; ## [34] &quot;atanh&quot; &quot;between&quot; &quot;c&quot; ## [37] &quot;case_when&quot; &quot;ceil&quot; &quot;ceiling&quot; ## [40] &quot;coalesce&quot; &quot;cos&quot; &quot;cosh&quot; ## [43] &quot;cot&quot; &quot;coth&quot; &quot;desc&quot; ## [46] &quot;exp&quot; &quot;floor&quot; &quot;if&quot; ## [49] &quot;if_else&quot; &quot;ifelse&quot; &quot;is.na&quot; ## [52] &quot;is.null&quot; &quot;log&quot; &quot;log10&quot; ## [55] &quot;na_if&quot; &quot;nchar&quot; &quot;pmax&quot; ## [58] &quot;pmin&quot; &quot;round&quot; &quot;sign&quot; ## [61] &quot;sin&quot; &quot;sinh&quot; &quot;sql&quot; ## [64] &quot;sqrt&quot; &quot;str_detect&quot; &quot;str_length&quot; ## [67] &quot;str_replace_all&quot; &quot;str_to_lower&quot; &quot;str_to_upper&quot; ## [70] &quot;str_trim&quot; &quot;substr&quot; &quot;tan&quot; ## [73] &quot;tanh&quot; &quot;tolower&quot; &quot;toupper&quot; ## [76] &quot;trimws&quot; &quot;xor&quot; &quot;max&quot; ## [79] &quot;mean&quot; &quot;min&quot; &quot;n&quot; ## [82] &quot;n_distinct&quot; &quot;sum&quot; &quot;var&quot; ## [85] &quot;cume_dist&quot; &quot;cummax&quot; &quot;cummean&quot; ## [88] &quot;cummin&quot; &quot;cumsum&quot; &quot;dense_rank&quot; ## [91] &quot;first&quot; &quot;lag&quot; &quot;last&quot; ## [94] &quot;lead&quot; &quot;max&quot; &quot;mean&quot; ## [97] &quot;min&quot; &quot;min_rank&quot; &quot;n&quot; ## [100] &quot;n_distinct&quot; &quot;nth&quot; &quot;ntile&quot; ## [103] &quot;order_by&quot; &quot;percent_rank&quot; &quot;rank&quot; ## [106] &quot;row_number&quot; &quot;sum&quot; &quot;var&quot; sql_translate_env(simulate_dbi()) ## &lt;sql_variant&gt; ## scalar: -, :, !, !=, (, {, *, /, &amp;, &amp;&amp;, %%, %&gt;%, %in%, ^, +, &lt;, ## scalar: &lt;=, ==, &gt;, &gt;=, |, ||, abs, acos, acosh, as.character, ## scalar: as.double, as.integer, as.numeric, asin, asinh, atan, ## scalar: atan2, atanh, between, c, case_when, ceil, ceiling, ## scalar: coalesce, cos, cosh, cot, coth, desc, exp, floor, if, ## scalar: if_else, ifelse, is.na, is.null, log, log10, na_if, ## scalar: nchar, pmax, pmin, round, sign, sin, sinh, sql, sqrt, ## scalar: str_detect, str_length, str_replace_all, str_to_lower, ## scalar: str_to_upper, str_trim, substr, tan, tanh, tolower, ## scalar: toupper, trimws, xor ## aggregate: max, mean, min, n, n_distinct, sum, var ## window: cume_dist, cummax, cummean, cummin, cumsum, dense_rank, ## window: first, lag, last, lead, max, mean, min, min_rank, n, ## window: n_distinct, nth, ntile, order_by, percent_rank, rank, ## window: row_number, sum, var source(here(&quot;book-src&quot;, &quot;dbplyr-sql-function-translation.R&quot;)) Each of the following dbplyr back ends may have a slightly different translation: translations %&gt;% filter(!is.na(sql)) %&gt;% count(variant) ## # A tibble: 13 x 2 ## variant n ## &lt;chr&gt; &lt;int&gt; ## 1 dbi 163 ## 2 hive 180 ## 3 impala 184 ## 4 mssql 192 ## 5 mysql 113 ## 6 odbc 163 ## 7 odbc_access 186 ## 8 odbc_postgresql 184 ## 9 oracle 180 ## 10 postgres 1 ## 11 sqlite 120 ## 12 teradata 190 ## 13 test 163 Only one postgres translation produces an output: psql &lt;- translations %&gt;% filter(!is.na(sql), variant == &quot;postgres&quot;) %&gt;% select(r, n_args, sql) %&gt;% arrange(r) psql %&gt;% gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', Arial, sans-serif; } #cqpqwqagrn .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #000000; font-size: 16px; background-color: #FFFFFF; /* table.background.color */ width: auto; /* table.width */ border-top-style: solid; /* table.border.top.style */ border-top-width: 2px; /* table.border.top.width */ border-top-color: #A8A8A8; /* table.border.top.color */ } #cqpqwqagrn .gt_heading { background-color: #FFFFFF; /* heading.background.color */ border-bottom-color: #FFFFFF; } #cqpqwqagrn .gt_title { color: #000000; font-size: 125%; /* heading.title.font.size */ padding-top: 4px; /* heading.top.padding */ padding-bottom: 1px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #cqpqwqagrn .gt_subtitle { color: #000000; font-size: 85%; /* heading.subtitle.font.size */ padding-top: 1px; padding-bottom: 4px; /* heading.bottom.padding */ border-top-color: #FFFFFF; border-top-width: 0; } #cqpqwqagrn .gt_bottom_border { border-bottom-style: solid; /* heading.border.bottom.style */ border-bottom-width: 2px; /* heading.border.bottom.width */ border-bottom-color: #A8A8A8; /* heading.border.bottom.color */ } #cqpqwqagrn .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; padding-top: 4px; padding-bottom: 4px; } #cqpqwqagrn .gt_col_heading { color: #000000; background-color: #FFFFFF; /* column_labels.background.color */ font-size: 16px; /* column_labels.font.size */ font-weight: initial; /* column_labels.font.weight */ vertical-align: middle; padding: 10px; margin: 10px; } #cqpqwqagrn .gt_sep_right { border-right: 5px solid #FFFFFF; } #cqpqwqagrn .gt_group_heading { padding: 8px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #cqpqwqagrn .gt_empty_group_heading { padding: 0.5px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #cqpqwqagrn .gt_striped tr:nth-child(even) { background-color: #f2f2f2; } #cqpqwqagrn .gt_row { padding: 10px; /* row.padding */ margin: 10px; vertical-align: middle; } #cqpqwqagrn .gt_stub { border-right-style: solid; border-right-width: 2px; border-right-color: #A8A8A8; padding-left: 12px; } #cqpqwqagrn .gt_stub.gt_row { background-color: #FFFFFF; } #cqpqwqagrn .gt_summary_row { background-color: #FFFFFF; /* summary_row.background.color */ padding: 6px; /* summary_row.padding */ text-transform: inherit; /* summary_row.text_transform */ } #cqpqwqagrn .gt_first_summary_row { border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; } #cqpqwqagrn .gt_table_body { border-top-style: solid; /* field.border.top.style */ border-top-width: 2px; /* field.border.top.width */ border-top-color: #A8A8A8; /* field.border.top.color */ border-bottom-style: solid; /* field.border.bottom.style */ border-bottom-width: 2px; /* field.border.bottom.width */ border-bottom-color: #A8A8A8; /* field.border.bottom.color */ } #cqpqwqagrn .gt_footnote { font-size: 90%; /* footnote.font.size */ padding: 4px; /* footnote.padding */ } #cqpqwqagrn .gt_sourcenote { font-size: 90%; /* sourcenote.font.size */ padding: 4px; /* sourcenote.padding */ } #cqpqwqagrn .gt_center { text-align: center; } #cqpqwqagrn .gt_left { text-align: left; } #cqpqwqagrn .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #cqpqwqagrn .gt_font_normal { font-weight: normal; } #cqpqwqagrn .gt_font_bold { font-weight: bold; } #cqpqwqagrn .gt_font_italic { font-style: italic; } #cqpqwqagrn .gt_super { font-size: 65%; } #cqpqwqagrn .gt_footnote_glyph { font-style: italic; font-size: 65%; } r n_args sql c() 0 NULL the postgres variant fails for various reasons: psql_errors &lt;- translations %&gt;% filter(variant == &quot;postgres&quot;) error_list &lt;- tibble( function_name = psql_errors$fun_name, r = psql_errors$r, errors = psql_errors %&gt;% pluck(&quot;errors&quot;)) nrow(error_list) ## [1] 555 gt(head(error_list, n = 15)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', Arial, sans-serif; } #sohyhvhgeg .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #000000; font-size: 16px; background-color: #FFFFFF; /* table.background.color */ width: auto; /* table.width */ border-top-style: solid; /* table.border.top.style */ border-top-width: 2px; /* table.border.top.width */ border-top-color: #A8A8A8; /* table.border.top.color */ } #sohyhvhgeg .gt_heading { background-color: #FFFFFF; /* heading.background.color */ border-bottom-color: #FFFFFF; } #sohyhvhgeg .gt_title { color: #000000; font-size: 125%; /* heading.title.font.size */ padding-top: 4px; /* heading.top.padding */ padding-bottom: 1px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #sohyhvhgeg .gt_subtitle { color: #000000; font-size: 85%; /* heading.subtitle.font.size */ padding-top: 1px; padding-bottom: 4px; /* heading.bottom.padding */ border-top-color: #FFFFFF; border-top-width: 0; } #sohyhvhgeg .gt_bottom_border { border-bottom-style: solid; /* heading.border.bottom.style */ border-bottom-width: 2px; /* heading.border.bottom.width */ border-bottom-color: #A8A8A8; /* heading.border.bottom.color */ } #sohyhvhgeg .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; padding-top: 4px; padding-bottom: 4px; } #sohyhvhgeg .gt_col_heading { color: #000000; background-color: #FFFFFF; /* column_labels.background.color */ font-size: 16px; /* column_labels.font.size */ font-weight: initial; /* column_labels.font.weight */ vertical-align: middle; padding: 10px; margin: 10px; } #sohyhvhgeg .gt_sep_right { border-right: 5px solid #FFFFFF; } #sohyhvhgeg .gt_group_heading { padding: 8px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #sohyhvhgeg .gt_empty_group_heading { padding: 0.5px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #sohyhvhgeg .gt_striped tr:nth-child(even) { background-color: #f2f2f2; } #sohyhvhgeg .gt_row { padding: 10px; /* row.padding */ margin: 10px; vertical-align: middle; } #sohyhvhgeg .gt_stub { border-right-style: solid; border-right-width: 2px; border-right-color: #A8A8A8; padding-left: 12px; } #sohyhvhgeg .gt_stub.gt_row { background-color: #FFFFFF; } #sohyhvhgeg .gt_summary_row { background-color: #FFFFFF; /* summary_row.background.color */ padding: 6px; /* summary_row.padding */ text-transform: inherit; /* summary_row.text_transform */ } #sohyhvhgeg .gt_first_summary_row { border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; } #sohyhvhgeg .gt_table_body { border-top-style: solid; /* field.border.top.style */ border-top-width: 2px; /* field.border.top.width */ border-top-color: #A8A8A8; /* field.border.top.color */ border-bottom-style: solid; /* field.border.bottom.style */ border-bottom-width: 2px; /* field.border.bottom.width */ border-bottom-color: #A8A8A8; /* field.border.bottom.color */ } #sohyhvhgeg .gt_footnote { font-size: 90%; /* footnote.font.size */ padding: 4px; /* footnote.padding */ } #sohyhvhgeg .gt_sourcenote { font-size: 90%; /* sourcenote.font.size */ padding: 4px; /* sourcenote.padding */ } #sohyhvhgeg .gt_center { text-align: center; } #sohyhvhgeg .gt_left { text-align: left; } #sohyhvhgeg .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #sohyhvhgeg .gt_font_normal { font-weight: normal; } #sohyhvhgeg .gt_font_bold { font-weight: bold; } #sohyhvhgeg .gt_font_italic { font-style: italic; } #sohyhvhgeg .gt_super { font-size: 65%; } #sohyhvhgeg .gt_footnote_glyph { font-style: italic; font-size: 65%; } function_name r errors - `-`() Error in `-`(): argument \"x\" is missing, with no default : `:`() Error in `:`(): argument \"from\" is missing, with no default ! !NULL Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"character\"' != `!=`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default ( (NULL) Error in eval_bare(x, .env): argument \"x\" is missing, with no default { {} Error in eval_bare(x, .env): argument \"x\" is missing, with no default * `*`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default / `/`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default &amp; `&amp;`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default &amp;&amp; `&amp;&amp;`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default %% `%%`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default %&gt;% `%&gt;%`() Error in expr[[3L]]: subscript out of bounds %in% `%in%`() Error in is.sql(table): argument \"table\" is missing, with no default ^ `^`() Error: Invalid number of args to SQL POWER. Expecting 2 + `+`() Error in eval_bare(x, .env): argument \"x\" is missing, with no default unique_error_list &lt;- unique(error_list$errors) %&gt;% as_tibble() ## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `tibble::enframe(name = NULL)` instead. ## This warning is displayed once per session. gt(unique_error_list) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', Arial, sans-serif; } #ihebfvnxvb .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #000000; font-size: 16px; background-color: #FFFFFF; /* table.background.color */ width: auto; /* table.width */ border-top-style: solid; /* table.border.top.style */ border-top-width: 2px; /* table.border.top.width */ border-top-color: #A8A8A8; /* table.border.top.color */ } #ihebfvnxvb .gt_heading { background-color: #FFFFFF; /* heading.background.color */ border-bottom-color: #FFFFFF; } #ihebfvnxvb .gt_title { color: #000000; font-size: 125%; /* heading.title.font.size */ padding-top: 4px; /* heading.top.padding */ padding-bottom: 1px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #ihebfvnxvb .gt_subtitle { color: #000000; font-size: 85%; /* heading.subtitle.font.size */ padding-top: 1px; padding-bottom: 4px; /* heading.bottom.padding */ border-top-color: #FFFFFF; border-top-width: 0; } #ihebfvnxvb .gt_bottom_border { border-bottom-style: solid; /* heading.border.bottom.style */ border-bottom-width: 2px; /* heading.border.bottom.width */ border-bottom-color: #A8A8A8; /* heading.border.bottom.color */ } #ihebfvnxvb .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; padding-top: 4px; padding-bottom: 4px; } #ihebfvnxvb .gt_col_heading { color: #000000; background-color: #FFFFFF; /* column_labels.background.color */ font-size: 16px; /* column_labels.font.size */ font-weight: initial; /* column_labels.font.weight */ vertical-align: middle; padding: 10px; margin: 10px; } #ihebfvnxvb .gt_sep_right { border-right: 5px solid #FFFFFF; } #ihebfvnxvb .gt_group_heading { padding: 8px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #ihebfvnxvb .gt_empty_group_heading { padding: 0.5px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #ihebfvnxvb .gt_striped tr:nth-child(even) { background-color: #f2f2f2; } #ihebfvnxvb .gt_row { padding: 10px; /* row.padding */ margin: 10px; vertical-align: middle; } #ihebfvnxvb .gt_stub { border-right-style: solid; border-right-width: 2px; border-right-color: #A8A8A8; padding-left: 12px; } #ihebfvnxvb .gt_stub.gt_row { background-color: #FFFFFF; } #ihebfvnxvb .gt_summary_row { background-color: #FFFFFF; /* summary_row.background.color */ padding: 6px; /* summary_row.padding */ text-transform: inherit; /* summary_row.text_transform */ } #ihebfvnxvb .gt_first_summary_row { border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; } #ihebfvnxvb .gt_table_body { border-top-style: solid; /* field.border.top.style */ border-top-width: 2px; /* field.border.top.width */ border-top-color: #A8A8A8; /* field.border.top.color */ border-bottom-style: solid; /* field.border.bottom.style */ border-bottom-width: 2px; /* field.border.bottom.width */ border-bottom-color: #A8A8A8; /* field.border.bottom.color */ } #ihebfvnxvb .gt_footnote { font-size: 90%; /* footnote.font.size */ padding: 4px; /* footnote.padding */ } #ihebfvnxvb .gt_sourcenote { font-size: 90%; /* sourcenote.font.size */ padding: 4px; /* sourcenote.padding */ } #ihebfvnxvb .gt_center { text-align: center; } #ihebfvnxvb .gt_left { text-align: left; } #ihebfvnxvb .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #ihebfvnxvb .gt_font_normal { font-weight: normal; } #ihebfvnxvb .gt_font_bold { font-weight: bold; } #ihebfvnxvb .gt_font_italic { font-style: italic; } #ihebfvnxvb .gt_super { font-size: 65%; } #ihebfvnxvb .gt_footnote_glyph { font-style: italic; font-size: 65%; } value Error in `-`(): argument \"x\" is missing, with no default Error in `:`(): argument \"from\" is missing, with no default Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"character\"' Error in eval_bare(x, .env): argument \"x\" is missing, with no default Error in expr[[3L]]: subscript out of bounds Error in is.sql(table): argument \"table\" is missing, with no default Error: Invalid number of args to SQL POWER. Expecting 2 Error: Invalid number of args to SQL ABS. Expecting 1 Error: Invalid number of args to SQL ACOS. Expecting 1 Error: Invalid number of args to SQL ACOSH. Expecting 1 Error in enexpr(x): argument \"x\" is missing, with no default Error: Invalid number of args to SQL ASIN. Expecting 1 Error: Invalid number of args to SQL ASINH. Expecting 1 Error: Invalid number of args to SQL ATAN. Expecting 1 Error: Invalid number of args to SQL ATAN2. Expecting 2 Error: Invalid number of args to SQL ATANH. Expecting 1 NA No cases provided Error: Invalid number of args to SQL CEIL. Expecting 1 Error: Invalid number of args to SQL COS. Expecting 1 Error: Invalid number of args to SQL COSH. Expecting 1 Error: Invalid number of args to SQL COTH. Expecting 1 Error: Invalid number of args to SQL EXP. Expecting 1 Error: Invalid number of args to SQL FLOOR. Expecting 1 Error in eval_bare(x, .env): argument \"cond\" is missing, with no default Error in sql_if(condition, true, false): argument \"condition\" is missing, with no default Error in sql_if(test, yes, no): argument \"test\" is missing, with no default Error: Invalid number of args to SQL NULL_IF. Expecting 2 Error: Invalid number of args to SQL LENGTH. Expecting 1 Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteString' for signature '\"PostgreSQLConnection\", \"character\"' Error: Invalid number of args to SQL SIGN. Expecting 1 Error: Invalid number of args to SQL SIN. Expecting 1 Error: Invalid number of args to SQL SINH. Expecting 1 Error: Invalid number of args to SQL SQRT. Expecting 1 Error in enexpr(x): argument \"string\" is missing, with no default Error in eval_bare(x, .env): argument \"string\" is missing, with no default Error in substr(): argument \"stop\" is missing, with no default Error: Invalid number of args to SQL TAN. Expecting 1 Error: Invalid number of args to SQL TANH. Expecting 1 Error: Invalid number of args to SQL LOWER. Expecting 1 Error: Invalid number of args to SQL UPPER. Expecting 1 Error: Invalid number of args to SQL TRIM. Expecting 1 Error in escape(x): argument \"x\" is missing, with no default Error in order_by %||% win_current_order(): argument \"order_by\" is missing, with no default Error in is.null(vars) || is.character(vars): argument \"order_by\" is missing, with no default Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"ident\"' The == function across variant dbplyr backends equal = translations %&gt;% filter(fun_name == &quot;==&quot;) equal_list &lt;- tibble( variant = equal$variant, n_args = equal$n_args, r = equal$r, sql = equal$sql, errors = equal %&gt;% pluck(&quot;errors&quot;)) %&gt;% arrange(variant, n_args) %&gt;% filter(between(n_args,1,3)) equal_list %&gt;% gt() html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', Arial, sans-serif; } #lghnetfgzu .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #000000; font-size: 16px; background-color: #FFFFFF; /* table.background.color */ width: auto; /* table.width */ border-top-style: solid; /* table.border.top.style */ border-top-width: 2px; /* table.border.top.width */ border-top-color: #A8A8A8; /* table.border.top.color */ } #lghnetfgzu .gt_heading { background-color: #FFFFFF; /* heading.background.color */ border-bottom-color: #FFFFFF; } #lghnetfgzu .gt_title { color: #000000; font-size: 125%; /* heading.title.font.size */ padding-top: 4px; /* heading.top.padding */ padding-bottom: 1px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #lghnetfgzu .gt_subtitle { color: #000000; font-size: 85%; /* heading.subtitle.font.size */ padding-top: 1px; padding-bottom: 4px; /* heading.bottom.padding */ border-top-color: #FFFFFF; border-top-width: 0; } #lghnetfgzu .gt_bottom_border { border-bottom-style: solid; /* heading.border.bottom.style */ border-bottom-width: 2px; /* heading.border.bottom.width */ border-bottom-color: #A8A8A8; /* heading.border.bottom.color */ } #lghnetfgzu .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; padding-top: 4px; padding-bottom: 4px; } #lghnetfgzu .gt_col_heading { color: #000000; background-color: #FFFFFF; /* column_labels.background.color */ font-size: 16px; /* column_labels.font.size */ font-weight: initial; /* column_labels.font.weight */ vertical-align: middle; padding: 10px; margin: 10px; } #lghnetfgzu .gt_sep_right { border-right: 5px solid #FFFFFF; } #lghnetfgzu .gt_group_heading { padding: 8px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #lghnetfgzu .gt_empty_group_heading { padding: 0.5px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #lghnetfgzu .gt_striped tr:nth-child(even) { background-color: #f2f2f2; } #lghnetfgzu .gt_row { padding: 10px; /* row.padding */ margin: 10px; vertical-align: middle; } #lghnetfgzu .gt_stub { border-right-style: solid; border-right-width: 2px; border-right-color: #A8A8A8; padding-left: 12px; } #lghnetfgzu .gt_stub.gt_row { background-color: #FFFFFF; } #lghnetfgzu .gt_summary_row { background-color: #FFFFFF; /* summary_row.background.color */ padding: 6px; /* summary_row.padding */ text-transform: inherit; /* summary_row.text_transform */ } #lghnetfgzu .gt_first_summary_row { border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; } #lghnetfgzu .gt_table_body { border-top-style: solid; /* field.border.top.style */ border-top-width: 2px; /* field.border.top.width */ border-top-color: #A8A8A8; /* field.border.top.color */ border-bottom-style: solid; /* field.border.bottom.style */ border-bottom-width: 2px; /* field.border.bottom.width */ border-bottom-color: #A8A8A8; /* field.border.bottom.color */ } #lghnetfgzu .gt_footnote { font-size: 90%; /* footnote.font.size */ padding: 4px; /* footnote.padding */ } #lghnetfgzu .gt_sourcenote { font-size: 90%; /* sourcenote.font.size */ padding: 4px; /* sourcenote.padding */ } #lghnetfgzu .gt_center { text-align: center; } #lghnetfgzu .gt_left { text-align: left; } #lghnetfgzu .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #lghnetfgzu .gt_font_normal { font-weight: normal; } #lghnetfgzu .gt_font_bold { font-weight: bold; } #lghnetfgzu .gt_font_italic { font-style: italic; } #lghnetfgzu .gt_super { font-size: 65%; } #lghnetfgzu .gt_footnote_glyph { font-style: italic; font-size: 65%; } variant n_args r sql errors dbi 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default dbi 2 arg1 == arg2 \"arg1\" = \"arg2\" NA dbi 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) hive 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default hive 2 arg1 == arg2 `arg1` = `arg2` NA hive 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) impala 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default impala 2 arg1 == arg2 `arg1` = `arg2` NA impala 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) mssql 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default mssql 2 arg1 == arg2 `arg1` = `arg2` NA mssql 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) mysql 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default mysql 2 arg1 == arg2 `arg1` = `arg2` NA mysql 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) odbc 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default odbc 2 arg1 == arg2 `arg1` = `arg2` NA odbc 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) odbc_access 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default odbc_access 2 arg1 == arg2 `arg1` = `arg2` NA odbc_access 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) odbc_postgresql 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default odbc_postgresql 2 arg1 == arg2 `arg1` = `arg2` NA odbc_postgresql 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) oracle 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default oracle 2 arg1 == arg2 `arg1` = `arg2` NA oracle 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) postgres 1 ==arg1 NA Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"ident\"' postgres 2 arg1 == arg2 NA Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"ident\"' postgres 3 `==`(arg1, arg2, arg3) NA Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'dbQuoteIdentifier' for signature '\"PostgreSQLConnection\", \"ident\"' sqlite 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default sqlite 2 arg1 == arg2 `arg1` = `arg2` NA sqlite 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) teradata 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default teradata 2 arg1 == arg2 `arg1` = `arg2` NA teradata 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) test 1 ==arg1 NA Error in eval_bare(x, .env): argument \"y\" is missing, with no default test 2 arg1 == arg2 `arg1` = `arg2` NA test 3 `==`(arg1, arg2, arg3) NA Error in `==`(arg1, arg2, arg3): unused argument (arg3) odbc_postgres works on the whole list of SQL functions psql &lt;- translations %&gt;% filter(!is.na(sql), variant == &quot;odbc_postgresql&quot;) %&gt;% select(r, n_args, sql) %&gt;% arrange(r) psql %&gt;% gt html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', Arial, sans-serif; } #oqiqinrmgt .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #000000; font-size: 16px; background-color: #FFFFFF; /* table.background.color */ width: auto; /* table.width */ border-top-style: solid; /* table.border.top.style */ border-top-width: 2px; /* table.border.top.width */ border-top-color: #A8A8A8; /* table.border.top.color */ } #oqiqinrmgt .gt_heading { background-color: #FFFFFF; /* heading.background.color */ border-bottom-color: #FFFFFF; } #oqiqinrmgt .gt_title { color: #000000; font-size: 125%; /* heading.title.font.size */ padding-top: 4px; /* heading.top.padding */ padding-bottom: 1px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #oqiqinrmgt .gt_subtitle { color: #000000; font-size: 85%; /* heading.subtitle.font.size */ padding-top: 1px; padding-bottom: 4px; /* heading.bottom.padding */ border-top-color: #FFFFFF; border-top-width: 0; } #oqiqinrmgt .gt_bottom_border { border-bottom-style: solid; /* heading.border.bottom.style */ border-bottom-width: 2px; /* heading.border.bottom.width */ border-bottom-color: #A8A8A8; /* heading.border.bottom.color */ } #oqiqinrmgt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; padding-top: 4px; padding-bottom: 4px; } #oqiqinrmgt .gt_col_heading { color: #000000; background-color: #FFFFFF; /* column_labels.background.color */ font-size: 16px; /* column_labels.font.size */ font-weight: initial; /* column_labels.font.weight */ vertical-align: middle; padding: 10px; margin: 10px; } #oqiqinrmgt .gt_sep_right { border-right: 5px solid #FFFFFF; } #oqiqinrmgt .gt_group_heading { padding: 8px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #oqiqinrmgt .gt_empty_group_heading { padding: 0.5px; color: #000000; background-color: #FFFFFF; /* stub_group.background.color */ font-size: 16px; /* stub_group.font.size */ font-weight: initial; /* stub_group.font.weight */ border-top-style: solid; /* stub_group.border.top.style */ border-top-width: 2px; /* stub_group.border.top.width */ border-top-color: #A8A8A8; /* stub_group.border.top.color */ border-bottom-style: solid; /* stub_group.border.bottom.style */ border-bottom-width: 2px; /* stub_group.border.bottom.width */ border-bottom-color: #A8A8A8; /* stub_group.border.bottom.color */ vertical-align: middle; } #oqiqinrmgt .gt_striped tr:nth-child(even) { background-color: #f2f2f2; } #oqiqinrmgt .gt_row { padding: 10px; /* row.padding */ margin: 10px; vertical-align: middle; } #oqiqinrmgt .gt_stub { border-right-style: solid; border-right-width: 2px; border-right-color: #A8A8A8; padding-left: 12px; } #oqiqinrmgt .gt_stub.gt_row { background-color: #FFFFFF; } #oqiqinrmgt .gt_summary_row { background-color: #FFFFFF; /* summary_row.background.color */ padding: 6px; /* summary_row.padding */ text-transform: inherit; /* summary_row.text_transform */ } #oqiqinrmgt .gt_first_summary_row { border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; } #oqiqinrmgt .gt_table_body { border-top-style: solid; /* field.border.top.style */ border-top-width: 2px; /* field.border.top.width */ border-top-color: #A8A8A8; /* field.border.top.color */ border-bottom-style: solid; /* field.border.bottom.style */ border-bottom-width: 2px; /* field.border.bottom.width */ border-bottom-color: #A8A8A8; /* field.border.bottom.color */ } #oqiqinrmgt .gt_footnote { font-size: 90%; /* footnote.font.size */ padding: 4px; /* footnote.padding */ } #oqiqinrmgt .gt_sourcenote { font-size: 90%; /* sourcenote.font.size */ padding: 4px; /* sourcenote.padding */ } #oqiqinrmgt .gt_center { text-align: center; } #oqiqinrmgt .gt_left { text-align: left; } #oqiqinrmgt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #oqiqinrmgt .gt_font_normal { font-weight: normal; } #oqiqinrmgt .gt_font_bold { font-weight: bold; } #oqiqinrmgt .gt_font_italic { font-style: italic; } #oqiqinrmgt .gt_super { font-size: 65%; } #oqiqinrmgt .gt_footnote_glyph { font-style: italic; font-size: 65%; } r n_args sql -arg1 1 -`arg1` !arg1 1 NOT(`arg1`) !arg1 2 NOT(`arg1`, `arg2`) !arg1 3 NOT(`arg1`, `arg2`, `arg3`) !arg1 50 NOT(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) !NULL 0 NOT() (arg1) 1 (`arg1`) { arg1} 1 (`arg1`) abs(arg1) 1 ABS(`arg1`) acos(arg1) 1 ACOS(`arg1`) acosh(arg1) 1 ACOSH(`arg1`) all(arg1, arg2) 2 bool_and(`arg1`) OVER () all(arg1) 1 bool_and(`arg1`) OVER () any(arg1, arg2) 2 bool_or(`arg1`) OVER () any(arg1) 1 bool_or(`arg1`) OVER () arg1 - arg2 2 `arg1` - `arg2` arg1 != arg2 2 `arg1` != `arg2` arg1 * arg2 2 `arg1` * `arg2` arg1 &amp; arg2 2 `arg1` AND `arg2` arg1 &amp;&amp; arg2 2 `arg1` AND `arg2` arg1 %in% arg2 2 `arg1` IN `arg2` arg1 + arg2 2 `arg1` + `arg2` arg1 &lt; arg2 2 `arg1` &lt; `arg2` arg1 &lt;= arg2 2 `arg1` &lt;= `arg2` arg1 == arg2 2 `arg1` = `arg2` arg1 &gt; arg2 2 `arg1` &gt; `arg2` arg1 &gt;= arg2 2 `arg1` &gt;= `arg2` arg1 | arg2 2 `arg1` OR `arg2` arg1 || arg2 2 `arg1` OR `arg2` arg1/arg2 2 `arg1` / `arg2` arg1%%arg2 2 `arg1` % `arg2` arg1^arg2 2 POWER(`arg1`, `arg2`) as.character(arg1) 1 CAST(`arg1` AS TEXT) as.double(arg1) 1 CAST(`arg1` AS NUMERIC) as.integer(arg1) 1 CAST(`arg1` AS INTEGER) as.numeric(arg1) 1 CAST(`arg1` AS NUMERIC) asin(arg1) 1 ASIN(`arg1`) asinh(arg1) 1 ASINH(`arg1`) atan(arg1) 1 ATAN(`arg1`) atan2(arg1, arg2) 2 ATAN2(`arg1`, `arg2`) atanh(arg1) 1 ATANH(`arg1`) between(arg1, arg2, arg3) 3 `arg1` BETWEEN `arg2` AND `arg3` c() 0 NULL c(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 `arg1` c(arg1, arg2, arg3) 3 `arg1` c(arg1, arg2) 2 `arg1` c(arg1) 1 `arg1` ceil(arg1) 1 CEIL(`arg1`) ceiling(arg1) 1 CEIL(`arg1`) coalesce() 0 COALESCE() coalesce(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 COALESCE(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) coalesce(arg1, arg2, arg3) 3 COALESCE(`arg1`, `arg2`, `arg3`) coalesce(arg1, arg2) 2 COALESCE(`arg1`, `arg2`) coalesce(arg1) 1 COALESCE(`arg1`) cor(arg1, arg2) 2 CORR(`arg1`, `arg2`) OVER () cos(arg1) 1 COS(`arg1`) cosh(arg1) 1 COSH(`arg1`) cot(arg1) 1 1 / TAN(`arg1`) coth(arg1) 1 COTH(`arg1`) cov(arg1, arg2) 2 COVAR_SAMP(`arg1`, `arg2`) OVER () cume_dist() 0 cume_dist() OVER () cume_dist(arg1) 1 cume_dist() OVER (ORDER BY `arg1`) cummax(arg1, arg2) 2 max(`arg1`) OVER (ORDER BY `arg2` ROWS UNBOUNDED PRECEDING) cummax(arg1) 1 max(`arg1`) OVER (ROWS UNBOUNDED PRECEDING) cummean(arg1, arg2) 2 avg(`arg1`) OVER (ORDER BY `arg2` ROWS UNBOUNDED PRECEDING) cummean(arg1) 1 avg(`arg1`) OVER (ROWS UNBOUNDED PRECEDING) cummin(arg1, arg2) 2 min(`arg1`) OVER (ORDER BY `arg2` ROWS UNBOUNDED PRECEDING) cummin(arg1) 1 min(`arg1`) OVER (ROWS UNBOUNDED PRECEDING) cumsum(arg1, arg2) 2 sum(`arg1`) OVER (ORDER BY `arg2` ROWS UNBOUNDED PRECEDING) cumsum(arg1) 1 sum(`arg1`) OVER (ROWS UNBOUNDED PRECEDING) dense_rank() 0 dense_rank() OVER () dense_rank(arg1) 1 dense_rank() OVER (ORDER BY `arg1`) desc(arg1) 1 `arg1` DESC exp(arg1) 1 EXP(`arg1`) first(arg1, arg2) 2 first_value(`arg1`) OVER (ORDER BY `arg2`) first(arg1) 1 first_value(`arg1`) OVER () floor(arg1) 1 FLOOR(`arg1`) grepl(arg1, arg2) 2 (`arg2`) ~ (`arg1`) if (arg1) arg2 2 CASE WHEN (`arg1`) THEN (`arg2`) END if (arg1) arg2 else arg3 3 CASE WHEN (`arg1`) THEN (`arg2`) WHEN NOT(`arg1`) THEN (`arg3`) END if_else(arg1, arg2, arg3) 3 CASE WHEN (`arg1`) THEN (`arg2`) WHEN NOT(`arg1`) THEN (`arg3`) END ifelse(arg1, arg2, arg3) 3 CASE WHEN (`arg1`) THEN (`arg2`) WHEN NOT(`arg1`) THEN (`arg3`) END is.na(arg1) 1 ((`arg1`) IS NULL) is.null(arg1) 1 ((`arg1`) IS NULL) lag(arg1, arg2, arg3) 3 LAG(`arg1`, NULL, `arg3`) OVER () lag(arg1, arg2) 2 LAG(`arg1`, NULL, NULL) OVER () lag(arg1) 1 LAG(`arg1`, 1, NULL) OVER () last(arg1, arg2) 2 last_value(`arg1`) OVER (ORDER BY `arg2`) last(arg1) 1 last_value(`arg1`) OVER () lead(arg1, arg2, arg3) 3 LEAD(`arg1`, `arg2`, `arg3`) OVER () lead(arg1, arg2) 2 LEAD(`arg1`, `arg2`, NULL) OVER () lead(arg1) 1 LEAD(`arg1`, 1, NULL) OVER () log(arg1, arg2) 2 LOG(`arg1`) / LOG(`arg2`) log(arg1) 1 LN(`arg1`) log10(arg1) 1 LOG(`arg1`) max(arg1, arg2) 2 max(`arg1`) OVER () max(arg1) 1 max(`arg1`) OVER () mean(arg1, arg2) 2 avg(`arg1`) OVER () mean(arg1) 1 avg(`arg1`) OVER () min_rank() 0 rank() OVER () min_rank(arg1) 1 rank() OVER (ORDER BY `arg1`) min(arg1, arg2) 2 min(`arg1`) OVER () min(arg1) 1 min(`arg1`) OVER () n_distinct() 0 COUNT(DISTINCT ) OVER () n_distinct(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 COUNT(DISTINCT `arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) OVER () n_distinct(arg1, arg2, arg3) 3 COUNT(DISTINCT `arg1`, `arg2`, `arg3`) OVER () n_distinct(arg1, arg2) 2 COUNT(DISTINCT `arg1`, `arg2`) OVER () n_distinct(arg1) 1 COUNT(DISTINCT `arg1`) OVER () n() 0 COUNT(*) OVER () na_if(arg1, arg2) 2 NULL_IF(`arg1`, `arg2`) nchar(arg1) 1 LENGTH(`arg1`) nth(arg1, arg2, arg3) 3 nth_value(`arg1`, NULL) OVER (ORDER BY `arg3`) nth(arg1, arg2) 2 nth_value(`arg1`, NULL) OVER () ntile(arg1, arg2) 2 NTILE(NULL) OVER (ORDER BY `arg1`) order_by(arg1, arg2) 2 `arg2` paste() 0 CONCAT_WS(' ') paste(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 CONCAT_WS(' ', `arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) paste(arg1, arg2, arg3) 3 CONCAT_WS(' ', `arg1`, `arg2`, `arg3`) paste(arg1, arg2) 2 CONCAT_WS(' ', `arg1`, `arg2`) paste(arg1) 1 CONCAT_WS(' ', `arg1`) paste0() 0 CONCAT_WS('') paste0(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 CONCAT_WS('', `arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) paste0(arg1, arg2, arg3) 3 CONCAT_WS('', `arg1`, `arg2`, `arg3`) paste0(arg1, arg2) 2 CONCAT_WS('', `arg1`, `arg2`) paste0(arg1) 1 CONCAT_WS('', `arg1`) percent_rank() 0 percent_rank() OVER () percent_rank(arg1) 1 percent_rank() OVER (ORDER BY `arg1`) pmax() 0 MAX() pmax(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 MAX(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) pmax(arg1, arg2, arg3) 3 MAX(`arg1`, `arg2`, `arg3`) pmax(arg1, arg2) 2 MAX(`arg1`, `arg2`) pmax(arg1) 1 MAX(`arg1`) pmin() 0 MIN() pmin(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 MIN(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) pmin(arg1, arg2, arg3) 3 MIN(`arg1`, `arg2`, `arg3`) pmin(arg1, arg2) 2 MIN(`arg1`, `arg2`) pmin(arg1) 1 MIN(`arg1`) rank() 0 rank() OVER () rank(arg1) 1 rank() OVER (ORDER BY `arg1`) round(arg1, arg2) 2 ROUND((`arg1`) :: numeric, NULL) round(arg1) 1 ROUND((`arg1`) :: numeric, 0) row_number() 0 row_number() OVER () row_number(arg1) 1 row_number() OVER (ORDER BY `arg1`) sd(arg1, arg2) 2 stddev_samp(`arg1`) OVER () sd(arg1) 1 stddev_samp(`arg1`) OVER () sign(arg1) 1 SIGN(`arg1`) sin(arg1) 1 SIN(`arg1`) sinh(arg1) 1 SINH(`arg1`) sql(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 `arg1` sql(arg1, arg2, arg3) 3 `arg1` sql(arg1, arg2) 2 `arg1` sql(arg1) 1 `arg1` sqrt(arg1) 1 SQRT(`arg1`) str_detect(arg1, arg2) 2 STRPOS(`arg1`, `arg2`) &gt; 0 str_flatten(arg1, arg2) 2 STRING_AGG(`arg1`, `arg2`) OVER () str_length() 0 LENGTH() str_length(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 LENGTH(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) str_length(arg1, arg2, arg3) 3 LENGTH(`arg1`, `arg2`, `arg3`) str_length(arg1, arg2) 2 LENGTH(`arg1`, `arg2`) str_length(arg1) 1 LENGTH(`arg1`) str_locate(arg1, arg2) 2 STRPOS(`arg1`, `arg2`) str_replace_all(arg1, arg2, arg3) 3 REPLACE(`arg1`, `arg2`, `arg3`) str_to_lower() 0 LOWER() str_to_lower(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 LOWER(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) str_to_lower(arg1, arg2, arg3) 3 LOWER(`arg1`, `arg2`, `arg3`) str_to_lower(arg1, arg2) 2 LOWER(`arg1`, `arg2`) str_to_lower(arg1) 1 LOWER(`arg1`) str_to_upper() 0 UPPER() str_to_upper(arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10, arg11, arg12, arg13, arg14, arg15, arg16, arg17, arg18, arg19, arg20, arg21, arg22, arg23, arg24, arg25, arg26, arg27, arg28, arg29, arg30, arg31, arg32, arg33, arg34, arg35, arg36, arg37, arg38, arg39, arg40, arg41, arg42, arg43, arg44, arg45, arg46, arg47, arg48, arg49, arg50) 50 UPPER(`arg1`, `arg2`, `arg3`, `arg4`, `arg5`, `arg6`, `arg7`, `arg8`, `arg9`, `arg10`, `arg11`, `arg12`, `arg13`, `arg14`, `arg15`, `arg16`, `arg17`, `arg18`, `arg19`, `arg20`, `arg21`, `arg22`, `arg23`, `arg24`, `arg25`, `arg26`, `arg27`, `arg28`, `arg29`, `arg30`, `arg31`, `arg32`, `arg33`, `arg34`, `arg35`, `arg36`, `arg37`, `arg38`, `arg39`, `arg40`, `arg41`, `arg42`, `arg43`, `arg44`, `arg45`, `arg46`, `arg47`, `arg48`, `arg49`, `arg50`) str_to_upper(arg1, arg2, arg3) 3 UPPER(`arg1`, `arg2`, `arg3`) str_to_upper(arg1, arg2) 2 UPPER(`arg1`, `arg2`) str_to_upper(arg1) 1 UPPER(`arg1`) str_trim(arg1, arg2) 2 ((`arg1`)) str_trim(arg1) 1 LTRIM(RTRIM(`arg1`)) sum(arg1, arg2) 2 sum(`arg1`) OVER () sum(arg1) 1 sum(`arg1`) OVER () tan(arg1) 1 TAN(`arg1`) tanh(arg1) 1 TANH(`arg1`) tolower(arg1) 1 LOWER(`arg1`) toupper(arg1) 1 UPPER(`arg1`) trimws(arg1) 1 TRIM(`arg1`) var(arg1, arg2) 2 var_samp(`arg1`) OVER () var(arg1) 1 var_samp(`arg1`) OVER () xor(arg1, arg2) 2 `arg1` OR `arg2` AND NOT (`arg1` AND `arg2`) "]
=======
["index.html", "R, Databases, and Docker Chapter 1 Introduction 1.1 Using R to query a DBMS in your organization 1.2 Docker as a tool for UseRs 1.3 Who are we? 1.4 How did this project come about? 1.5 Navigation", " R, Databases, and Docker John David Smith, Sophie Yang, M. Edward (Ed) Borasky, Jim Tyhurst, Scott Came, Mary Anne Thygesen, Ian Frantz, and Dipti Muni 2019-04-07 Chapter 1 Introduction This chapter introduces: The motivation for this book and the strategies we have adopted How Docker can be used to set up a dbms to demonstrate access to a service like PostgreSQL from R Our team and how this project came about 1.1 Using R to query a DBMS in your organization Many R users (or useRs) live a dual life: in the vibrant open-source R community where R is created, improved, discussed, and taught. And then they go to work in a secured, complex, closed organizational environment where they may be on their own. Here is a request on the Rstudio community site for help that has been lightly edited to emphasize the generality that we see: Im trying to migrate some inherited scripts that [] to connect to a [] database to [] instead. Ive reviewed the https://db.rstudio.com docs and tried a number of configurations but havent been able to connect. Im in uncharted territory within my org, so havent been able to get much help internally. This book will help you create a hybrid environment on your machine that can mimic some of the uncharted territory in your organization. It goes far beyond the basic connection issues and covers issues that you face when you are finding your way around or writing queries to your organizations databases, not just when maintaining inherited scripts. Technology hurdles. The interfaces (passwords, packages, etc.) and gaps between R and a back end database are hidden from public view as a matter of security, so pinpointing exactly where a problem is can be difficult. A simulated environment such as we offer here can be an important learning resource. Scale issues. We see at least two types of scale issues. Handling large volumes of data so that performance issues must be a consideration requires a basic understanding of whats happening in the back end (which is necessarily hidden from view). Therefore mastering techniques for drawing samples or small batches of data are essential. In addition to their size, your organizations databases will often have structural characteristics that are complex and obscure. Data documentation is often incomplete and emphasizes operational characteristics, rather than analytic opportunities. A careful useR often needs to confirm the documentation on the fly and de-normalize data carefully. Use cases. R users frequently need to make sense of an organizations complex data structures and coding schemes to address incompletely formed questions so that informal exploratory data analysis has to be intuitive and fast. The technology details should not get in the way. Sharing and discussing exploratory and diagnostic retrieval techniquesis best in public, but is constrained by organizational requirements. We have found that PostgreSQL in a Docker container solves many of the foregoing problems. 1.2 Docker as a tool for UseRs Noam Rosss Docker for the UseR (Ross 2018a) suggests that there are four distinct Docker use-cases for useRs. Make a fixed working environment for reproducible analysis Access a service outside of R (e.g., PostgreSQL) Create an R based service (e.g., with plumber) Send our compute jobs to the cloud with minimal reconfiguration or revision This book explores #2 because it allows us to work on the database access issues described above and to practice on an industrial-scale DBMS. Docker is a comparatively easy way to simulate the relationship between an R/RStudio session and a database  all on on your machine (provided you have Docker installed and running). Running PostgreSQL on a Docker container avoids OS or system dependencies or conflicts that cause confusion and limit reproducibility. A Docker environment consumes relatively few resources. Our sandbox does much less but only includes PostgreSQL and sample data, so it takes up about 5% of the space taken up by the Vagrant environment that inspired this project. (Makubuya 2018) A simple Docker container such as the one used in our sandbox is easy to use and could be extended for other uses. Docker is a widely used technology for deploying applications in the cloud, so for many useRs its worth mastering. 1.3 Who are we? We have been collaborating on this book since the Summer of 2018, each of us chipping into the project as time permits: Dipti Muni - @deemuni Ian Franz - @ianfrantz Jim Tyhurst - @jimtyhurst John David Smith - @smithjd M. Edward (Ed) Borasky - @znmeb Maryanne Thygesen @maryannet Scott Came - @scottcame Sophie Yang - @SophieMYang 1.4 How did this project come about? We trace this book back to the June 2, 2018 Cascadia R Conf where Aaron Makubuya gave a presentation using Vagrant hosting (Makubuya 2018). After that John Smith, Ian Franz, and Sophie Yang had discussions after the monthly Data Discussion Meetups about the difficulties around setting up Vagrant (a virtual environment), connecting to a corporate database, and having realistic public environment to demo or practice the issues that come up behind corporate firewalls. Scott Cames tutorial on R and Docker (Came 2018) (an alternative to Vagrant) at the 2018 UseR Conference in Melbourne was provocative and it turned out he lived nearby. We re-connected with M. Edward (Ed) Borasky who had done extensive development for a Hack Oregon data science containerization project (Borasky 2018). 1.5 Navigation If this is the first bookdown (Xie 2016) book youve read, heres how to navigate the website. The controls on the upper left: there are four controls on the upper left. A hamburger menu: this toggles the table of contents on the left side of the page on or off. A magnifying glass: this toggles a search box on or off. A letter A: this lets you pick how you want the site to display. You have your choice of small or large text, a serif or sans-serif font, and a white, sepia or night theme. A pencil: this is the Edit button. This will take you to a GitHub edit dialog for the chapter youre reading. If youre a committer to the repository, youll be able to edit the source directly. If not, GitHub will fork a copy of the repository to your own account and youll be able to edit that version. Then you can make a pull request. The share buttons in the upper right hand corner. Theres one for Twitter, one for Facebook, and one that gives a menu of options, including LinkedIn. References "],
["chapter-basic-concepts.html", "Chapter 2 Basic Concepts 2.1 The big picture: R and the Docker / PostgreSQL playground on your machine 2.2 Your computer and its operating system 2.3 R 2.4 Our sqlpetr package 2.5 Docker 2.6 Normal and normalized data 2.7 Organizational DBMS 2.8 SQL", " Chapter 2 Basic Concepts This chapter introduces: The overall structure of our Docker-based PostgreSQL sandbox Basic concepts around each of the elements that make up our sandbox: tidy data, pipes, Docker, PostgreSQL, data representation, and our petsqlr package. 2.1 The big picture: R and the Docker / PostgreSQL playground on your machine Here is an overview of how R and Docker fit on your operating system in this books sandbox: R and Docker You run R from RStudio to set up Docker, launch PostgreSQL inside it and then send queries directly to PostgreSQL from R. (We provide more details about our sandbox environment in the chapter on mapping your environment. 2.2 Your computer and its operating system The playground that we construct in this book is designed so that some of the mysteries of accessing a corporate database are more visible  its all happening on your computer. The challenge, however, is that we know very little about your computer and its operating system. In the workshops weve given about this book, the details of individual computers have turned out to be diverse and difficult to pin down in advance. So there can be many issues, but not many basic concepts that we can highlight in advance. 2.3 R We assume a general familiarity with R and RStudio. RStudios Big Data workshop at the 2019 RStudio has an abundance of introductory material (Ruiz 2019). This book is Tidyverse-oriented, so we assume familiarity with the pipe operator, tidy data (Wickham 2014), dplyr, and techniques for tidying data (Wickham 2018). R connects to a database by means of a series of packages that work together. The following diagram from a big data workshop at the 2019 RStudio conference shows the big picture. The biggest difference in terms of retrieval strategies is between writing dplyr and native SQL code. Dplyr generates SQL-92 standard code; whereas you can write SQL code that leverages the specific language features of your DBMS when you write SQL code yourself. Rstudios DBMS architecture - slide # 33 2.4 Our sqlpetr package The sqlpetr package is the companion R package for this database tutorial. It has two classes of functions: Functions to install the dependencies needed to build the book and perform the operations covered in the tutorial, and Utilities for dealing with Docker and the PostgreSQL Docker image we use. sqlpetr has a pkgdown site at https://smithjd.github.io/sqlpetr/. 2.5 Docker Docker and the DevOps tools surrounding it have fostered a revolution in the way services are delivered over the internet. In this book, were piggybacking on a small piece of that revolution, Docker on the desktop. 2.5.1 Virtual machines and hypervisors A virtual machine is a machine that is running purely as software hosted by another real machine. To the user, a virtual machine looks just like a real one. But it has no processors, memory or I/O devices of its own - all of those are supplied and managed by the host. A virtual machine can run any operating system that will run on the hosts hardware. A Linux host can run a Windows virtual machine and vice versa. A hypervisor is the component of the host system software that manages virtual machines, usually called guests. Linux systems have a native hypervisor called Kernel Virtual Machine (kvm). And laptop, desktop and server processors from Intel and Advanced Micro Devices (AMD) have hardware that makes this hypervisor more efficient. Windows servers and Windows 10 Pro have a hypervisor called Hyper-V. Like kvm, Hyper-V can take advantage of the hardware in Intel and AMD processors. On Macintosh, there is a Hypervisor Framework (https://developer.apple.com/documentation/hypervisor) and other tools build on that. If this book is about Docker, why do we care about virtual machines and hypervisors? Docker is a Linux subsystem - it only runs on Linux laptops, desktops and servers. As well see shortly, if we want to run Docker on Windows or MacOS, well need a hypervisor, a Linux virtual machine and some glue logic to provide a Docker user experience equivalent to the one on a Linux system. 2.5.2 Containers A container is a set of processes running in an operating system. The host operating system is usually Linux, but other operating systems also can host containers. Unlike a virtual machine, the container has no operating system kernel of its own. If the host is running the Linux kernel, so is the container. And since the container OS is the same as the host OS, theres no need for a hypervisor or hardware to support the hypervisor. So a container is more efficient than a virtual machine. A container does have its own file system. From inside the container, this file system looks like a Linux file system, but it can use any Linux distro. For example, you can have an Ubuntu 18.04 LTS host running Ubuntu 14.04 LTS or Fedora 28 or CentOS 7 containers. The kernel will always be the host kernel, but the utilities and applications will be those from the container. 2.5.3 Docker itself While there are both older (lxc) and newer container tools, the one that has caught on in terms of widespread use is Docker (Docker 2019a). Docker is widely used on cloud providers to deploy services of all kinds. Using Docker on the desktop to deliver standardized packages, as we are doing in this book, is a secondary use case, but a common one. If youre using a Linux laptop / desktop, all you need to do is install Docker CE (Docker 2018a). However, most laptops and desktops dont run Linux - they run Windows or MacOS. As noted above, to use Docker on Windows or MacOS, you need a hypervisor and a Linux virtual machine. 2.5.4 Docker objects The Docker subsystem manages several kinds of objects - containers, images, volumes and networks. In this book, we are only using the basic command line tools to manage containers, images and volumes. Docker images are files that define a containers initial file system. You can find pre-built images on Docker Hub and the Docker Store - the base PostgreSQL image we use comes from Docker Hub (https://hub.docker.com/_/postgres/). If there isnt a Docker image that does exactly what you want, you can build your own by creating a Dockerfile and running docker build. We do this in Build the pet-sql Docker Image. Docker volumes  explain mount. 2.5.5 Hosting Docker on Windows machines There are two ways to get Docker on Windows. For Windows 10 Home and older versions of Windows, you need Docker Toolbox (Docker 2019e). Note that for Docker Toolbox, you need a 64-bit AMD or Intel processor with the virtualization hardware installed and enabled in the BIOS. For Windows 10 Pro, you have the Hyper-V virtualizer as standard equipment, and can use Docker for Windows (Docker 2019c). 2.5.6 Hosting Docker on macOS machines As with Windows, there are two ways to get Docker. For older Intel systems, youll need Docker Toolbox (Docker 2019d). Newer systems (2010 or later running at least macOS El Capitan 10.11) can run Docker for Mac (Docker 2019b). 2.5.7 Hosting Docker on UNIX machines Unix was the original host for both R and Docker. Unix-like commands show up. 2.6 Normal and normalized data 2.6.1 Tidy data Tidy data (Wickham 2014) is well-behaved from the point of view of analysis and tools in the Tidyverse (RStudio 2019). Tidy data is easier to think about and it is usually worthwhile to make the data tidy (Wickham 2018). Tidy data is roughly equivalent to third normal form as discussed below. 2.6.2 Design of normal data Data in a database is most often optimized to minimize storage space and increase performance while preserving integrity when adding, changing, or deleting data. The Wikipedia article on Database Normalization has a good introduction to the characteristics of normal data and the process of re-organizing it to meet those desirable criteria (Wikipedia 2019). The bottom line is that data normalization is practical although there are mathematical arguments for normalization based on the preservation of data integrity. 2.7 Organizational DBMS The organizational context of a database matters just as much as its design characteristics. The design of a database (or data model) may have been purchased from an external vendor or developed in-house. In either case time has a tendency to erode the original design concept so that the data you find in a DBMS may not quite match the original design specification. And the original design may or may not be well reflected in the current naming of tables, columns and other objects. Its a naive misconception to think that the data you are analyzing comes from the database even though you are retrieving it from your organizations DBMS. In fact it comes from the people who design, enter, manage, protect, and use your organizations data. In practice, a database administrator (DBA) is often a key point of contact in terms of access and may have stringent criteria for query performance. Make friends with your DBA. 2.8 SQL Although there are ANSI standards for SQL syntax, different implementations vary in enough details that Rs ability to customize queries for those implementations is very helpful. The tables in a DBMS correspond to a data frame in R, so interaction with a DBMS is fairly natural for useRs. SQL code is characterized by the fact that it describes what to retrieve, leaving the DBMS back end to determine how to do it. Therefore it has a batch feel. The pipe operator (%&gt;%, which is read as and then) is inherently procedural when its used with dplyr: it can be used to construct queries step-by-step. Once a test dplyr query has been executed, it is easy to inspect the results and add steps with the pipe operator to refine or expand the query. APPENDIX D - Quick Guide to SQL lists the different elements of the SQL language. 2.8.1 Data mapping between R vs SQL data types The following code shows how different elements of the R bestiary are translated to and from ANSI standard data types. Note that R factors are translated as TEXT so that missing levels are ignored on the SQL side. library(DBI) dbDataType(ANSI(), 1:5) ## [1] &quot;INT&quot; dbDataType(ANSI(), 1) ## [1] &quot;DOUBLE&quot; dbDataType(ANSI(), TRUE) ## [1] &quot;SMALLINT&quot; dbDataType(ANSI(), Sys.Date()) ## [1] &quot;DATE&quot; dbDataType(ANSI(), Sys.time()) ## [1] &quot;TIMESTAMP&quot; dbDataType(ANSI(), Sys.time() - as.POSIXct(Sys.Date())) ## [1] &quot;TIME&quot; dbDataType(ANSI(), c(&quot;x&quot;, &quot;abc&quot;)) ## [1] &quot;TEXT&quot; dbDataType(ANSI(), list(raw(10), raw(20))) ## [1] &quot;BLOB&quot; dbDataType(ANSI(), I(3)) ## [1] &quot;DOUBLE&quot; dbDataType(ANSI(), iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;DOUBLE&quot; &quot;TEXT&quot; The DBI specification provides extensive documentation that is worth digesting if you intend to work with a DBMS from R. As you work through the examples in this book, you will also want to refer to the following resources: RStudios Databases using R site describes many of the technical details involved. The RStudio community is an excellent place to ask questions or study what has been discussed previously. 2.8.2 PostgreSQL and connection parameters An important detail: We use a PostgreSQL database server running in a Docker container for the database functions. It is installed inside Docker, so you do not have to download or install it yourself. To connect to it, you have to define some parameters. These parameters are used in two places: When the Docker container is created, theyre used to initialize the database, and Whenever we connect to the database, we need to specify them to authenticate. We define the parameters in an environment file that R reads when starting up. The file is called .Renviron, and is located in your home directory. See the discussion of securing and using dbms credentials. 2.8.3 Connecting the R and DBMS environments Although everything happens on one machine in our Docker / PostgreSQL playground, in real life R and PostgreSQL (or other DBMS) will be in different environments on separate machines. How R connects them gives you control over where the work happens. You need to be aware of the differences beween the R and DBMS environments as well as how you can leverage the strengths of each one. Characteristics of local vs.server processing Dimension Local Remote Design purpose The R environment on your local machine is designed to be flexible and easy to use; ideal for data investigation. The DBMS environment is designed for large and complex databases where data integrity is more important than flexibility or ease of use. Processor power Your local machine has less memory, speed, and storage than the typical database server. Database servers are specialized, more expensive, and have more power. Memory constraint In R, query results must fit into memory. Servers have a lot of memory and write intermediate results to disk if needed without you knowing about it. Data crunching Data lives in the DBMS, so crunching it down locally requires you to pull it over the network. A DBMS has powerful data crunching capabilities once you know what you want and moves data over the server backbone to crunch it. Security Local control. Whether it is good or not depends on you. Responsibility of database administrators who set the rules. You play by their rules. Storage of intermediate results Very easy to save a data frame with intermediate results locally. May require extra privileges to save results in the database. Analytical resources Ecosystem of available R packages Extending SQL instruction set involves dbms-specific functions or R pseudo functions Collaboration One person working on a few data.frames. Many people collaborating on many tables. References "],
["chapter-how-to-use-this-book.html", "Chapter 3 How to use this book 3.1 Retrieve the code from GitHub 3.2 Read along, experiment as you go 3.3 Participating", " Chapter 3 How to use this book This chapter explains: Getting the code used in this book How you can contribute to the book project This book is full of examples that you can replicate on your computer. 3.1 Retrieve the code from GitHub The code to generate the book and the exercises it contains can be downloaded from this repo. 3.2 Read along, experiment as you go We have never been sure whether were writing an expository book or a massive tutorial. You may use it either way. The best way to learn the material we cover is to experiment. After the introductory chapters and the chapter that creates the persistent database, you can jump around and each chapter stands on its own. 3.3 Participating 3.3.1 Browsing the book If you just want to read the book and copy / paste code into your working environment, simply browse to https://smithjd.github.io/sql-pet. If you get stuck, or find things arent working, open an issue at https://github.com/smithjd/sql-pet/issues/new/. 3.3.2 Diving in If you want to experiment with the code in the book, run it in RStudio and interact with it, youll need to do two more things: Install the sqlpetr R package (Borasky et al. 2018). See https://smithjd.github.io/sqlpetr for the package documentation. Installation may take some time if it has to install or update packages not available on your computer. Clone the Git repository https://github.com/smithjd/sql-pet.git and open the project file sql-pet.Rproj in RStudio. Enjoy! References "],
["chapter-learning-goals.html", "Chapter 4 Learning Goals and Use Cases 4.1 Ask yourself, what are you aiming for? 4.2 Learning Goals 4.3 Imagining a DVD rental business 4.4 Use cases 4.5 Investigating a question using an organizations database", " Chapter 4 Learning Goals and Use Cases This chapter sets the context for the book by: Challenging you to think about your goals and expectations Imagining the setting where our sample database would be used Posing some imaginary use cases that a data analyst might face Discussing the different elements involved in answering questions from an organizations database 4.1 Ask yourself, what are you aiming for? Differences between production and data warehouse environments. Learning to keep your DBAs happy: You are your own DBA in this simulation, so you can wreak havoc and learn from it, but you can learn to be DBA-friendly here. In the end its the subject-matter experts that understand your data, but you have to work with your DBAs first. 4.2 Learning Goals After working through the code in this book, you can expect to be able to: Set up a PostgreSQL database in a Docker environment. Gain familiarity with the various ways of interacting with the Docker and PostgreSQL environments Run queries against PostgreSQL in an environment that simulates what you will find in a corporate setting. Understand techniques and some of the trade-offs between: queries aimed at exploration or informal investigation using dplyr (Wickham 2018); and queries that should be written in SQL, because performance is important due to the size of the database or the frequency with which a query is to be run. Understand the equivalence between dplyr and SQL queries, and how R translates one into the other. Gain familiarity with techniques that help you explore a database and verify its documentation. Gain familiarity with the standard metadata that a SQL database contains to describe its own contents. Understand some advanced SQL techniques. Gain some understanding of techniques for assessing query structure and performance. Understand enough about Docker to swap databases, e.g.Sports DB for the DVD rental database used in this tutorial. Or swap the database management system (DBMS), e.g.MySQL for PostgreSQL. 4.3 Imagining a DVD rental business Years ago, people rented videos on DVD disks and video stores were a big business. To understand the data base that we use in this book, try to imagine managing a video rental store like Movie Madness in Portland, Oregon. What data would be needed and what questions would you have to answer about the business? This tutorial uses the PostgreSQL version of dvd rental database which represents the transaction database for running a movie (e.g., dvd) rental business. The database can be downloaded here. Heres a glimpse of its structure, which we explore using several different methods: Entity Relationship diagram for the dvdrental database A data analyst uses the database abstraction and the practical business questions to make better decisions and solve problems. 4.4 Use cases Imagine that you have one of following several roles at our fictional company DVDs R Us and you have a following need to be met: As a data scientist, I want to know the distribution of number of rentals per month per customer, so that the Marketing department can create incentives for customers in 3 segments: Frequent Renters, Average Renters, Infrequent Renters. As the Director of Sales, I want to see the total number of rentals per month for the past 6 months and I want to know how fast our customer base is growing/shrinking per month for the past 6 months. As the Director of Marketing, I want to know which categories of DVDs are the least popular, so that I can create a campaign to draw attention to rarely used inventory. As a shipping clerk, I want to add rental information when I fulfill a shipment order. As the Director of Analytics, I want to test as much of the production R code in my shop as possible against a new release of the DBMS that the IT department is implementing next month. etc. 4.5 Investigating a question using an organizations database Need both familiarity with the data and a focus question An iterative process where the data resource can shape your understanding of the question the question you need to answer will frame how you see the data resource You need to go back and forth between the two, asking do I understand the question? do I understand the data? How well do you understand the data resource (in the DBMS)? Use all available documentation and understand its limits Use your own tools and skills to examine the data resource What is missing from the database: (columns, records, cells) Why is the data missing? How well do you understand the question you seek to answer? How general or specific is your question? How aligned is it with the purpose for which the database was designed and is being operated? How different are your assumptions and concerns from those of the people who enter and use the data on a day to day basis? References "],
["chapter-connect-docker-postgresql-r.html", "Chapter 5 Connecting Docker, PostgreSQL, and R 5.1 Verify that Docker is running 5.2 Remove previous containers if they exist 5.3 Connecting, reading and writing to PostgreSQL from R 5.4 Clean up", " Chapter 5 Connecting Docker, PostgreSQL, and R This chapter demonstrates how to: Run, clean-up and close PostgreSQL in Docker containers. Keep necessary credentials secret while being available to R when it executes. Interact with PostgreSQL when its running inside a Docker container. Read and write to PostgreSQL from R. Please install the sqlpetr package if not already installed: library(devtools) if (!require(sqlpetr)) { remotes::install_github( &quot;smithjd/sqlpetr&quot;, force = TRUE, build = FALSE, quiet = TRUE) } Note that when you install the package the first time, it will ask you to update the packages it uses and that can take some time. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 5.1 Verify that Docker is running Docker commands can be run from a terminal (e.g., the Rstudio Terminal pane) or with a system2() command. (We discuss the diffeent ways of interacting with Docker and other elements in your environment in a separate chapter.) The necessary functions to start, stop Docker containers and do other busy work are provided in the sqlpetr package. As time permits and curiosity dictates, feel free to look at those functions to see how they work. 5.1.1 Check that Docker is up and running Note: The sqlpetr package is written to accompany this book. The functions in the package are designed to help you focus on interacting with a dbms from R. You can ignore how they work until you are ready to delve into the details. They are all named to begin with sp_. The first time a function is called in the book, we provide a note explaining its use. The sp_check_that_docker_is_up function from the sqlpetr package checks whether Docker is up and running. If its not, then you need to install, launch or re-install Docker. sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 5.2 Remove previous containers if they exist Force remove the cattle and sql-pet containers if they exist (e.g., from prior experiments). The sp_docker_remove_container function from the sqlpetr package forcibly removes a Docker container. If it is running it will be forcibly terminated and removed. If it doesnt exist you wont get an error message. Note that the images out of which a container is built will still exist on your system. sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 We name containers cattle for throw-aways and pet for ones we treasure and keep around. :-) The sp_docker_remove_container function from the sqlpetr package creates a container and runs the PostgreSQL 10 image (docker.io/postgres:10) in it. The image will be downloaded if it doesnt exist locally. sp_make_simple_pg(&quot;cattle&quot;) The first time you run this, Docker downloads the PostgreSQL image, which takes a bit of time. Did it work? The following command should show that a container named cattle is running postgres:10. sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;5213500e798b postgres:10 \\&quot;docker-entrypoint.s\\&quot; 1 second ago Up Less than a second 5432/tcp, 0.0.0.0:5439-&gt;5439/tcp cattle&quot; The sp_docker_containers_tibble function from the sqlpetr package provides more on the containers that Docker is running. Basically this function creates a tibble of containers using docker ps. sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5213500e798b post docker 2019-04-0 2 seco 5432 Up Le 0B ( catt ## #  with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; 5.3 Connecting, reading and writing to PostgreSQL from R 5.3.1 Connecting to PostgreSQL The sp_make_simple_pg function we called above created a container from the postgres:10 library image downloaded from Docker Hub. As part of the process, it set the password for the PostgreSQL database superuser postgres to the value postgres. For simplicity, we are using a weak password at this point and its shown here and in the code in plain text. That is bad practice because user credentials should not be shared in open code like that. A subsequent chapter demonstrates how to store and use credentials to access the DBMS so that they are kept private. The sp_get_postgres_connection function from the sqlpetr package gets a DBI connection string to a PostgreSQL database, waiting if it is not ready. This function connects to an instance of PostgreSQL and we assign it to a symbol, con, for subsequent use. The connctions_tab = TRUE parameter opens a connections tab thats useful for navigating a database. Note that we are using port 5439 for PostgreSQL inside the container and published to localhost. Why? If you have PostgreSQL already running on the host or another container, it probably claimed port 5432, since thats the default. So we need to use a different port for our PostgreSQL container. con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;postgres&quot;, seconds_to_test = 30, connection_tab = TRUE ) If you have been executing the code from this tutorial, the database will not contain any tables yet, but you will be connected to the database: DBI::dbListTables(con) ## character(0) The Connections tab shows that you are connected but that the database has no tables in it: Connections tab - no tables 5.3.2 Interact with PostgreSQL Write mtcars to PostgreSQL DBI::dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) List the tables in the PostgreSQL database to show that mtcars is now there: DBI::dbListTables(con) ## [1] &quot;mtcars&quot; The Connections tab has not been updated, so it still shows no tables. When the code to connect to the database is executed again, the connections tab is updated. con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;postgres&quot;, seconds_to_test = 30, connection_tab = TRUE ) The Connections tab now shows: Clicking on the triangle on the left next to mtcars will list the tables fields. Thats equivalent to listing the fields with: DBI::dbListFields(con, &quot;mtcars&quot;) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; Here is the same information on the Connections tab: Clicking on the rectangle on the right of mtcars opens a View tab on the first 1,000 rows of a table. Thats equivalent to excuting this code to download the table from the DBMS to a local data frame: mtcars_df &lt;- DBI::dbReadTable(con, &quot;mtcars&quot;) The sp_print_df function from the sqlpetr package shows (or print) a data frame depending on appropriate output type. That is when running interactively or generating HTML it prints a DT::datatable() while it prints a knitr::kable() otherwise. sp_print_df(head(mtcars_df)) Interactively, you can also click on the mtcars table in the Connections tab to see: The number of rows and columns shown in the View pane depends on the size of the window. 5.4 Clean up Afterwards, always disconnect from the dbms: DBI::dbDisconnect(con) The Connection tab equivalent is to click on the connection icon next to Help on the Connctions tab. The sp_docker_stop function from the sqlpetr package stops the container given by the container_name parameter. Tell Docker to stop the cattle container: sp_docker_stop(&quot;cattle&quot;) The sp_docker_remove_container function from the sqlpetr package removes the container given by the container_name parameter. Tell Docker to remove the cattle container from its library of active containers: sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 Verify that cattle is gone: sp_docker_containers_tibble() ## # A tibble: 0 x 0 If we just stop the Docker container but dont remove it (as we did with the sp_docker_remove_container(\"cattle\") command), the cattle container will persist and we can start it up again later with sp_docker_start(\"cattle\"). In that case, mtcars would still be there and we could retrieve it from PostgreSQL again. Since sp_docker_remove_container(\"cattle\") has removed it, the updated database has been deleted. (There are enough copies of mtcars in the world, so no great loss.) "],
["chapter-setup-dvdrental-db.html", "Chapter 6 Create the dvdrental database in PostgreSQL in Docker 6.1 Overview 6.2 Verify that Docker is up and running 6.3 Clean up if appropriate 6.4 Build the pet-sql Docker image 6.5 Run the pet-sql Docker Image 6.6 Connect to PostgreSQL with R 6.7 Stop and start to demonstrate persistence 6.8 Cleaning up 6.9 Using the sql-pet container in the rest of the book", " Chapter 6 Create the dvdrental database in PostgreSQL in Docker NOTE: This Chapter walks through the all steps needed to setup the dvdrental database in Docker. All susequent chapters depend on this setup. If for some reason you need to setup the Docker database but dont want to step through this teaching version of the setup, you can use: source('book-src/setup-dvdrental-docker-container.R') This chapter demonstrates how to: Setup the dvdrental database in Docker Stop and start Docker container to demonstrate persistence Connect to and disconnect R from the dvdrental database Set up the environment for subsequent chapters 6.1 Overview In the last chapter we connected to PostgreSQL from R. Now we set up a realistic database named dvdrental. There are different approaches to doing this: this chapter sets it up in a way that doesnt show all the Docker details. These packages are called in this Chapter: library(tidyverse) library(DBI) library(RPostgres) library(glue) require(knitr) library(dbplyr) library(sqlpetr) library(bookdown) 6.2 Verify that Docker is up and running sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 6.3 Clean up if appropriate Force-remove the cattle and sql-pet containers if they exist (e.g., from a prior runs): sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 6.4 Build the pet-sql Docker image For the rest of the book we will be using a Docker image called postgres-dvdrental. To save space here in the book, weve created a function in sqlpetr to build this image, called sp_make_dvdrental_image. Vignette Building the dvdrental Docker Image describes the build process. sp_make_dvdrental_image(&quot;postgres-dvdrental&quot;) Did it work? We have a function that lists the images into a tibble! sp_docker_images_tibble() ## # A tibble: 2 x 7 ## image_id repository tag digest created created_at size ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 94c53381 postgres-dv latest &lt;none&gt; 18 hou 2019-04-06  293MB ## 2 200d7af0 postgres 10 sha256:3a397af7 11 day 2019-03-26  230MB 6.5 Run the pet-sql Docker Image Now we can run the image in a container and connect to the database. To run the image we use an sqlpetr function called sp_pg_docker_run sp_pg_docker_run( container_name = &quot;sql-pet&quot;, image_tag = &quot;postgres-dvdrental&quot;, postgres_password = &quot;postgres&quot; ) Did it work? sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1918fe2a68e7 post docker 2019-04-0 2 seco 5432 Up Le 0B ( sql- ## #  with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; 6.6 Connect to PostgreSQL with R Use the DBI package to connect to the dvdrental database in PostgreSQL. Remember the settings discussion about [keeping passwords hidden][Pause for some security considerations] con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) List the tables in the database and the fields in one of those tables. dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; Disconnect from the database: dbDisconnect(con) 6.7 Stop and start to demonstrate persistence Stop the container: sp_docker_stop(&quot;sql-pet&quot;) sp_docker_containers_tibble() ## # A tibble: 0 x 0 When we stopped sql-pet, it no longer appeared in the tibble. But the container is still there. sp_docker_containers_tibble by default only lists the running containers. But we can use the list_all option and see it: sp_docker_containers_tibble(list_all = TRUE) ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1918fe2a68e7 post docker 2019-04-0 9 seco &lt;NA&gt; Exite 74.9 sql- ## #  with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; Restart the container and verify that the dvdrental tables are still there: sp_docker_start(&quot;sql-pet&quot;) sp_docker_containers_tibble() ## # A tibble: 1 x 12 ## container_id image command created_at created ports status size names ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1918fe2a68e7 post docker 2019-04-0 11 sec 5432 Up Le 74.9 sql- ## #  with 3 more variables: labels &lt;chr&gt;, mounts &lt;chr&gt;, networks &lt;chr&gt; Connect to the dvdrental database in PostgreSQL: con &lt;- sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) Check that you can still see the fields in the rental table: dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; 6.8 Cleaning up Always have R disconnect from the database when youre done. dbDisconnect(con) Stop the sql-pet container: sp_docker_stop(&quot;sql-pet&quot;) Show that the container still exists even though its not running sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; 12 seconds ago Exited (0) Less than a second ago sql-pet Next time, you can just use this command to start the container: sp_docker_start(\"sql-pet\") And once stopped, the container can be removed with: sp_check_that_docker_is_up(\"sql-pet\") 6.9 Using the sql-pet container in the rest of the book After this point in the book, we assume that Docker is up and that we can always start up our sql-pet database with: sp_docker_start(\"sql-pet\") "],
["chapter-dbms-login-credentials.html", "Chapter 7 Securing and using your dbms log-in credentials 7.1 Set up the sql-pet Docker container 7.2 Storing your dbms credentials 7.3 Clean up", " Chapter 7 Securing and using your dbms log-in credentials This chapter demonstrates how to: Keep necessary credentials secret or at least invisible Interact with PostgreSQL using your stored dbms credentials Connecting to a dbms can be very frustrating at first. In many organizations, simply getting access credentials takes time and may involve jumping through multiple hoops. In addition, a dbms is terse or deliberately inscrutable when your credetials are incorrect. Thats a security strategy, not a limitation of your understanding or of your software. When R cant log you on to a dbms, you usually will have no information as to what went wrong. There are many different strategies for managing credentials. See Securing Credentials in RStudios Databases using R documentation for some alternatives to the method we adopt in this book. We provide more details about PostgreSQL Authentication in our sandbox environment in an appendix. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 7.1 Set up the sql-pet Docker container 7.1.1 Verify that Docker is running Check that Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 7.1.2 Start the Docker container: Start the sql-pet Docker container: sp_docker_start(&quot;sql-pet&quot;) 7.2 Storing your dbms credentials In previous chapters the connection string for connecting to the dbms has used default credentials specified in plain text as follows: user= 'postgres', password = 'postgres' When we call sp_get_postgres_connection below well use environment variables that R obtains from reading the .Renviron file when R starts up. This approach has two benefits: that file is not uploaded to GitHub and R looks for it in your default directory every time it loads. To see whether you have already created that file, use the R Studio Files tab to look at your home directory: That file should contain lines that look like the example below. Although in this example it contains the PostgreSQL default values for the username and password, they are obviously not secret. But this approach demonstrates where you should put secrets that R needs while not risking accidental uploaded to GitHub or some other public location.. Open your .Renviron file with this command: file.edit(\"~/.Renviron\") Or you can execute define_postgresql_params.R to create the file or you could copy / paste the following into your .Renviron file: DEFAULT_POSTGRES_PASSWORD=postgres DEFAULT_POSTGRES_USER_NAME=postgres Once that file is created, restart R, and after that R reads it every time it comes up. 7.2.1 Connect with Postgres using the Sys.getenv function Connect to the postgrSQL using the sp_get_postgres_connection function: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE) Once the connection object has been created, you can list all of the tables in the database: dbListTables(con) ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; 7.3 Clean up Afterwards, always disconnect from the dbms: dbDisconnect(con) Tell Docker to stop the sql-pet container: sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-dbms-queries-intro.html", "Chapter 8 Introduction to DBMS queries 8.1 Setup 8.2 Getting data from the database 8.3 Mixing dplyr and SQL 8.4 Examining a single table with R 8.5 Additional reading", " Chapter 8 Introduction to DBMS queries This chapter demonstrates how to: Get a glimpse of what tables are in the database and what fields a table contains Download all or part of a table from the dbms See how dplyr code is translated into SQL commands Get acquainted with some useful tools for investigating a single table Begin thinking about how to divide the work between your local R session and the dbms 8.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. If not go back to Chapter 7 sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 8.2 Getting data from the database As we show later on, the database serves as a store of data and as an engine for sub-setting, joining, and computation on the data. We begin with getting data from the dbms, or downloading data. 8.2.1 Finding out whats there Weve already seen the simplest way of getting a list of tables in a database with DBI functions that list tables and fields. Generate a vector listing the (public) tables in the database: tables &lt;- DBI::dbListTables(con) tables ## [1] &quot;actor_info&quot; &quot;customer_list&quot; ## [3] &quot;film_list&quot; &quot;nicer_but_slower_film_list&quot; ## [5] &quot;sales_by_film_category&quot; &quot;staff&quot; ## [7] &quot;sales_by_store&quot; &quot;staff_list&quot; ## [9] &quot;category&quot; &quot;film_category&quot; ## [11] &quot;country&quot; &quot;actor&quot; ## [13] &quot;language&quot; &quot;inventory&quot; ## [15] &quot;payment&quot; &quot;rental&quot; ## [17] &quot;city&quot; &quot;store&quot; ## [19] &quot;film&quot; &quot;address&quot; ## [21] &quot;film_actor&quot; &quot;customer&quot; Print a vector with all the fields (or columns or variables) in one specific table: DBI::dbListFields(con, &quot;film&quot;) ## [1] &quot;film_id&quot; &quot;title&quot; &quot;description&quot; ## [4] &quot;release_year&quot; &quot;language_id&quot; &quot;rental_duration&quot; ## [7] &quot;rental_rate&quot; &quot;length&quot; &quot;replacement_cost&quot; ## [10] &quot;rating&quot; &quot;last_update&quot; &quot;special_features&quot; ## [13] &quot;fulltext&quot; 8.2.2 Listing all the fields for all the tables The first example, DBI::dbListTables(con) returned 22 tables and the second example, DBI::dbListFields(con, \"film\") returns 7 fields. Here we combine the two calls to return a list of tables which has a list of all the fields in the table. The code block just shows the first two tables. table_columns &lt;- purrr::map(tables, ~ dbListFields(.,conn = con) ) Rename each list [[1]]  [[22]] to meaningful table name names(table_columns) &lt;- tables head(table_columns) ## $actor_info ## [1] &quot;actor_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;film_info&quot; ## ## $customer_list ## [1] &quot;id&quot; &quot;name&quot; &quot;address&quot; &quot;zip code&quot; &quot;phone&quot; &quot;city&quot; ## [7] &quot;country&quot; &quot;notes&quot; &quot;sid&quot; ## ## $film_list ## [1] &quot;fid&quot; &quot;title&quot; &quot;description&quot; &quot;category&quot; &quot;price&quot; ## [6] &quot;length&quot; &quot;rating&quot; &quot;actors&quot; ## ## $nicer_but_slower_film_list ## [1] &quot;fid&quot; &quot;title&quot; &quot;description&quot; &quot;category&quot; &quot;price&quot; ## [6] &quot;length&quot; &quot;rating&quot; &quot;actors&quot; ## ## $sales_by_film_category ## [1] &quot;category&quot; &quot;total_sales&quot; ## ## $staff ## [1] &quot;staff_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;address_id&quot; &quot;email&quot; ## [6] &quot;store_id&quot; &quot;active&quot; &quot;username&quot; &quot;password&quot; &quot;last_update&quot; ## [11] &quot;picture&quot; Later on well discuss how to get more extensive data about each table and column from the databases own store of metadata using a similar technique. As we go further the issue of scale will come up again and again: you need to be careful about how much data a call to the dbms will return, whether its a list of tables or a table that could have millions of rows. Its important to connect with people who own, generate, or are the subjects of the data. A good chat with people who own the data, generate it, or are the subjects can generate insights and set the context for your investigation of the database. The purpose for collecting the data or circumstances where it was collected may be buried far afield in an organization, but usually someone knows. The metadata discussed in a later chapter is essential but will only take you so far. There are different ways of just looking at the data, which we explore below. 8.2.3 Downloading an entire table There are many different methods of getting data from a DBMS, and well explore the different ways of controlling each one of them. DBI::dbReadTable will download an entire table into an R tibble. film_tibble &lt;- DBI::dbReadTable(con, &quot;film&quot;) str(film_tibble) ## &#39;data.frame&#39;: 1000 obs. of 13 variables: ## $ film_id : int 133 384 8 98 1 2 3 4 5 6 ... ## $ title : chr &quot;Chamber Italian&quot; &quot;Grosse Wonderful&quot; &quot;Airport Pollock&quot; &quot;Bright Encounters&quot; ... ## $ description : chr &quot;A Fateful Reflection of a Moose And a Husband who must Overcome a Monkey in Nigeria&quot; &quot;A Epic Drama of a Cat And a Explorer who must Redeem a Moose in Australia&quot; &quot;A Epic Tale of a Moose And a Girl who must Confront a Monkey in Ancient India&quot; &quot;A Fateful Yarn of a Lumberjack And a Feminist who must Conquer a Student in A Jet Boat&quot; ... ## $ release_year : int 2006 2006 2006 2006 2006 2006 2006 2006 2006 2006 ... ## $ language_id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ rental_duration : int 7 5 6 4 6 3 7 5 6 3 ... ## $ rental_rate : num 4.99 4.99 4.99 4.99 0.99 4.99 2.99 2.99 2.99 2.99 ... ## $ length : int 117 49 54 73 86 48 50 117 130 169 ... ## $ replacement_cost: num 15 20 16 13 21 ... ## $ rating : &#39;pq_mpaa_rating&#39; chr &quot;NC-17&quot; &quot;R&quot; &quot;R&quot; &quot;PG-13&quot; ... ## $ last_update : POSIXct, format: &quot;2013-05-26 14:50:58&quot; &quot;2013-05-26 14:50:58&quot; ... ## $ special_features: &#39;pq__text&#39; chr &quot;{Trailers}&quot; &quot;{\\&quot;Behind the Scenes\\&quot;}&quot; &quot;{Trailers}&quot; &quot;{Trailers}&quot; ... ## $ fulltext : &#39;pq_tsvector&#39; chr &quot;&#39;chamber&#39;:1 &#39;fate&#39;:4 &#39;husband&#39;:11 &#39;italian&#39;:2 &#39;monkey&#39;:16 &#39;moos&#39;:8 &#39;must&#39;:13 &#39;nigeria&#39;:18 &#39;overcom&#39;:14 &#39;reflect&#39;:5&quot; &quot;&#39;australia&#39;:18 &#39;cat&#39;:8 &#39;drama&#39;:5 &#39;epic&#39;:4 &#39;explor&#39;:11 &#39;gross&#39;:1 &#39;moos&#39;:16 &#39;must&#39;:13 &#39;redeem&#39;:14 &#39;wonder&#39;:2&quot; &quot;&#39;airport&#39;:1 &#39;ancient&#39;:18 &#39;confront&#39;:14 &#39;epic&#39;:4 &#39;girl&#39;:11 &#39;india&#39;:19 &#39;monkey&#39;:16 &#39;moos&#39;:8 &#39;must&#39;:13 &#39;pollock&#39;:2 &#39;tale&#39;:5&quot; &quot;&#39;boat&#39;:20 &#39;bright&#39;:1 &#39;conquer&#39;:14 &#39;encount&#39;:2 &#39;fate&#39;:4 &#39;feminist&#39;:11 &#39;jet&#39;:19 &#39;lumberjack&#39;:8 &#39;must&#39;:13 &#39;student&#39;:16 &#39;yarn&#39;:5&quot; ... Thats very simple, but if the table is large it may not be a good idea, since R is designed to keep the entire table in memory. Note that the first line of the str() output reports the total number of observations. 8.2.4 A table object that can be reused The dplyr::tbl function gives us more control over access to a table by enabling control over which columns and rows to download. It creates an object that might look like a data frame, but its actually a list object that dplyr uses for constructing queries and retrieving data from the DBMS. film_table &lt;- dplyr::tbl(con, &quot;film&quot;) class(film_table) ## [1] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; ## [4] &quot;tbl_lazy&quot; &quot;tbl&quot; 8.2.5 Controlling the number of rows returned The collect function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R. For more complex queries, the dplyr::collect() function provides a mechanism to indicate whats processed on on the dbms server and whats processed by R on the local machine. The chapter on Lazy Evaluation and Execution Environment discusses this issue in detail. film_table %&gt;% dplyr::collect(n = 3) %&gt;% dim ## [1] 3 13 film_table %&gt;% dplyr::collect(n = 500) %&gt;% dim ## [1] 500 13 8.2.6 Random rows from the dbms When the dbms contains many rows, a sample of the data may be plenty for your purposes. Although dplyr has nice functions to sample a data frame thats already in R (e.g., the sample_n and sample_frac functions), to get a sample from the dbms we have to use dbGetQuery to send native SQL to the database. To peek ahead, here is one example of a query that retrieves 20 rows from a 1% sample: one_percent_sample &lt;- DBI::dbGetQuery( con, &quot;SELECT film_id, title, rating FROM film TABLESAMPLE BERNOULLI(1) LIMIT 20; &quot; ) one_percent_sample ## film_id title rating ## 1 92 Bowfinger Gables NC-17 ## 2 97 Bride Intrigue G ## 3 128 Catch Amistad G ## 4 152 Circus Youth PG-13 ## 5 292 Excitement Eve G ## 6 493 Kane Exorcist R ## 7 511 Lawrence Love NC-17 ## 8 598 Mosquito Armageddon G ## 9 633 October Submarine PG-13 ## 10 694 Prejudice Oleander PG-13 ## 11 849 Storm Happiness NC-17 Exact sample of 100 records This technique depends on knowing the range of a record index, such as the film_id in the film table of our dvdrental database. Start by finding the min and max values. DBI::dbListFields(con, &quot;film&quot;) ## [1] &quot;film_id&quot; &quot;title&quot; &quot;description&quot; ## [4] &quot;release_year&quot; &quot;language_id&quot; &quot;rental_duration&quot; ## [7] &quot;rental_rate&quot; &quot;length&quot; &quot;replacement_cost&quot; ## [10] &quot;rating&quot; &quot;last_update&quot; &quot;special_features&quot; ## [13] &quot;fulltext&quot; film_df &lt;- DBI::dbReadTable(con, &quot;film&quot;) max(film_df$film_id) ## [1] 1000 min(film_df$film_id) ## [1] 1 Set the random number seed and draw the sample. set.seed(123) sample_rows &lt;- sample(1:1000, 100) film_table &lt;- dplyr::tbl(con, &quot;film&quot;) Run query with the filter verb listing the randomly sampled rows to be retrieved: film_sample &lt;- film_table %&gt;% dplyr::filter(film_id %in% sample_rows) %&gt;% dplyr::collect() str(film_sample) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 100 obs. of 13 variables: ## $ film_id : int 133 384 1 24 42 44 46 85 90 95 ... ## $ title : chr &quot;Chamber Italian&quot; &quot;Grosse Wonderful&quot; &quot;Academy Dinosaur&quot; &quot;Analyze Hoosiers&quot; ... ## $ description : chr &quot;A Fateful Reflection of a Moose And a Husband who must Overcome a Monkey in Nigeria&quot; &quot;A Epic Drama of a Cat And a Explorer who must Redeem a Moose in Australia&quot; &quot;A Epic Drama of a Feminist And a Mad Scientist who must Battle a Teacher in The Canadian Rockies&quot; &quot;A Thoughtful Display of a Explorer And a Pastry Chef who must Overcome a Feminist in The Sahara Desert&quot; ... ## $ release_year : int 2006 2006 2006 2006 2006 2006 2006 2006 2006 2006 ... ## $ language_id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ rental_duration : int 7 5 6 6 5 5 3 4 3 5 ... ## $ rental_rate : num 4.99 4.99 0.99 2.99 2.99 4.99 4.99 0.99 0.99 4.99 ... ## $ length : int 117 49 86 181 170 113 108 63 63 123 ... ## $ replacement_cost: num 15 20 21 20 11 ... ## $ rating : &#39;pq_mpaa_rating&#39; chr &quot;NC-17&quot; &quot;R&quot; &quot;PG&quot; &quot;R&quot; ... ## $ last_update : POSIXct, format: &quot;2013-05-26 14:50:58&quot; &quot;2013-05-26 14:50:58&quot; ... ## $ special_features: &#39;pq__text&#39; chr &quot;{Trailers}&quot; &quot;{\\&quot;Behind the Scenes\\&quot;}&quot; &quot;{\\&quot;Deleted Scenes\\&quot;,\\&quot;Behind the Scenes\\&quot;}&quot; &quot;{Trailers,\\&quot;Behind the Scenes\\&quot;}&quot; ... ## $ fulltext : &#39;pq_tsvector&#39; chr &quot;&#39;chamber&#39;:1 &#39;fate&#39;:4 &#39;husband&#39;:11 &#39;italian&#39;:2 &#39;monkey&#39;:16 &#39;moos&#39;:8 &#39;must&#39;:13 &#39;nigeria&#39;:18 &#39;overcom&#39;:14 &#39;reflect&#39;:5&quot; &quot;&#39;australia&#39;:18 &#39;cat&#39;:8 &#39;drama&#39;:5 &#39;epic&#39;:4 &#39;explor&#39;:11 &#39;gross&#39;:1 &#39;moos&#39;:16 &#39;must&#39;:13 &#39;redeem&#39;:14 &#39;wonder&#39;:2&quot; &quot;&#39;academi&#39;:1 &#39;battl&#39;:15 &#39;canadian&#39;:20 &#39;dinosaur&#39;:2 &#39;drama&#39;:5 &#39;epic&#39;:4 &#39;feminist&#39;:8 &#39;mad&#39;:11 &#39;must&#39;:14 &#39;rocki&#39;:21&quot;| __truncated__ &quot;&#39;analyz&#39;:1 &#39;chef&#39;:12 &#39;desert&#39;:21 &#39;display&#39;:5 &#39;explor&#39;:8 &#39;feminist&#39;:17 &#39;hoosier&#39;:2 &#39;must&#39;:14 &#39;overcom&#39;:15 &#39;pastr&quot;| __truncated__ ... 8.2.7 Sub-setting variables A table in the dbms may not only have many more rows than you want, but also many more columns. The select command controls which columns are retrieved. film_table %&gt;% dplyr::select(title, rating) %&gt;% head() ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## title rating ## &lt;chr&gt; &lt;S3: pq_mpaa_rating&gt; ## 1 Chamber Italian NC-17 ## 2 Grosse Wonderful R ## 3 Airport Pollock R ## 4 Bright Encounters PG-13 ## 5 Academy Dinosaur PG ## 6 Ace Goldfinger G Thats exactly equivalent to submitting the following SQL commands dirctly: DBI::dbGetQuery( con, &#39;SELECT &quot;title&quot;, &quot;rating&quot; FROM &quot;film&quot; LIMIT 6&#39;) ## title rating ## 1 Chamber Italian NC-17 ## 2 Grosse Wonderful R ## 3 Airport Pollock R ## 4 Bright Encounters PG-13 ## 5 Academy Dinosaur PG ## 6 Ace Goldfinger G We wont discuss dplyr methods for sub-setting variables, deriving new ones, or sub-setting rows based on the values found in the table, because they are covered well in other places, including: Comprehensive reference: https://dplyr.tidyverse.org/ Good tutorial: https://suzan.rbind.io/tags/dplyr/ In practice we find that, renaming variables is often quite important because the names in an SQL database might not meet your needs as an analyst. In the wild, you will find names that are ambiguous or overly specified, with spaces in them, and other problems that will make them difficult to use in R. It is good practice to do whatever renaming you are going to do in a predictable place like at the top of your code. The names in the dvdrental database are simple and clear, but if they were not, you might rename them for subsequent use in this way: tbl(con, &quot;film&quot;) %&gt;% ## CHANGE STUFF dplyr::rename(film_id_number = film_id, language_id_number = language_id) %&gt;% dplyr::select(film_id_number, title, language_id_number) %&gt;% # head() show_query() ## &lt;SQL&gt; ## SELECT &quot;film_id_number&quot;, &quot;title&quot;, &quot;language_id_number&quot; ## FROM (SELECT &quot;film_id&quot; AS &quot;film_id_number&quot;, &quot;title&quot;, &quot;description&quot;, &quot;release_year&quot;, &quot;language_id&quot; AS &quot;language_id_number&quot;, &quot;rental_duration&quot;, &quot;rental_rate&quot;, &quot;length&quot;, &quot;replacement_cost&quot;, &quot;rating&quot;, &quot;last_update&quot;, &quot;special_features&quot;, &quot;fulltext&quot; ## FROM &quot;film&quot;) &quot;pimymxxpkd&quot; Thats equivalent to the following SQL code: DBI::dbGetQuery( con, &#39;SELECT &quot;film_id_number&quot;, &quot;title&quot;, &quot;language_id_number&quot; FROM (SELECT &quot;film_id&quot; AS &quot;film_id_number&quot;, &quot;title&quot;, &quot;description&quot;, &quot;release_year&quot;, &quot;language_id&quot; AS &quot;language_id_number&quot;, &quot;rental_duration&quot;, &quot;rental_rate&quot;, &quot;length&quot;, &quot;replacement_cost&quot;, &quot;rating&quot;, &quot;last_update&quot;, &quot;special_features&quot;, &quot;fulltext&quot; FROM &quot;film&quot;) &quot;yhbysdoypk&quot; LIMIT 6&#39; ) ## film_id_number title language_id_number ## 1 133 Chamber Italian 1 ## 2 384 Grosse Wonderful 1 ## 3 8 Airport Pollock 1 ## 4 98 Bright Encounters 1 ## 5 1 Academy Dinosaur 1 ## 6 2 Ace Goldfinger 1 The one difference is that the SQL code returns a regular data frame and the dplyr code returns a tibble. Notice that the seconds are greyed out in the tibble display. 8.2.8 Translating dplyr code to SQL queries Where did the translations weve shown above come from? The show_query function shows how dplyr is translating your query to the dialect of the target dbms: film_table %&gt;% dplyr::tally() %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT COUNT(*) AS &quot;n&quot; ## FROM &quot;film&quot; Here is an extensive discussion of how dplyr code is translated into SQL: https://dbplyr.tidyverse.org/articles/sql-translation.html If you prefer to use SQL directly, rather than dplyr, you can submit SQL code to the DBMS through the DBI::dbGetQuery function: DBI::dbGetQuery( con, &#39;SELECT COUNT(*) AS &quot;n&quot; FROM &quot;film&quot; &#39; ) ## n ## 1 1000 When you create a report to run repeatedly, you might want to put that query into R markdown. That way you can also execute that SQL code in a chunk with the following header: {sql, connection=con, output.var = \"query_results\"} SELECT COUNT(*) AS &quot;n&quot; FROM &quot;film&quot;; Rmarkdown stores that query result in a tibble which can be printed by referring to it: query_results ## n ## 1 1000 8.3 Mixing dplyr and SQL When dplyr finds code that it does not know how to translate into SQL, it will simply pass it along to the dbms. Therefore you can interleave native commands that your dbms will understand in the middle of dplyr code. Consider this example thats derived from (Ruiz 2019): film_table %&gt;% dplyr::select_at(vars( -contains(&quot;_id&quot;))) %&gt;% dplyr::mutate(today = now()) %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;title&quot;, &quot;description&quot;, &quot;release_year&quot;, &quot;rental_duration&quot;, &quot;rental_rate&quot;, &quot;length&quot;, &quot;replacement_cost&quot;, &quot;rating&quot;, &quot;last_update&quot;, &quot;special_features&quot;, &quot;fulltext&quot;, NOW() AS &quot;today&quot; ## FROM (SELECT &quot;title&quot;, &quot;description&quot;, &quot;release_year&quot;, &quot;rental_duration&quot;, &quot;rental_rate&quot;, &quot;length&quot;, &quot;replacement_cost&quot;, &quot;rating&quot;, &quot;last_update&quot;, &quot;special_features&quot;, &quot;fulltext&quot; ## FROM &quot;film&quot;) &quot;yhbysdoypk&quot; That is native to PostgreSQL, not ANSI standard SQL. Verify that it works: film_table %&gt;% dplyr::select_at(vars( -contains(&quot;_id&quot;))) %&gt;% head() %&gt;% dplyr::mutate(today = now()) %&gt;% dplyr::collect() ## # A tibble: 6 x 12 ## title description release_year rental_duration rental_rate length ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Cham A Fateful  2006 7 4.99 117 ## 2 Gros A Epic Dra 2006 5 4.99 49 ## 3 Airp A Epic Tal 2006 6 4.99 54 ## 4 Brig A Fateful  2006 4 4.99 73 ## 5 Acad A Epic Dra 2006 6 0.99 86 ## 6 Ace  A Astoundi 2006 3 4.99 48 ## #  with 6 more variables: replacement_cost &lt;dbl&gt;, rating &lt;chr&gt;, ## # last_update &lt;dttm&gt;, special_features &lt;chr&gt;, fulltext &lt;chr&gt;, ## # today &lt;dttm&gt; 8.4 Examining a single table with R Dealing with a large, complex database highlights the utility of specific tools in R. We include brief examples that we find to be handy: Base R structure: str Printing out some of the data: datatable, kable, and View Summary statistics: summary glimpse in the tibble package, which is included in the tidyverse skim in the skimr package 8.4.1 str - a base package workhorse str is a workhorse function that lists variables, their type and a sample of the first few variable values. str(film_tibble) ## &#39;data.frame&#39;: 1000 obs. of 13 variables: ## $ film_id : int 133 384 8 98 1 2 3 4 5 6 ... ## $ title : chr &quot;Chamber Italian&quot; &quot;Grosse Wonderful&quot; &quot;Airport Pollock&quot; &quot;Bright Encounters&quot; ... ## $ description : chr &quot;A Fateful Reflection of a Moose And a Husband who must Overcome a Monkey in Nigeria&quot; &quot;A Epic Drama of a Cat And a Explorer who must Redeem a Moose in Australia&quot; &quot;A Epic Tale of a Moose And a Girl who must Confront a Monkey in Ancient India&quot; &quot;A Fateful Yarn of a Lumberjack And a Feminist who must Conquer a Student in A Jet Boat&quot; ... ## $ release_year : int 2006 2006 2006 2006 2006 2006 2006 2006 2006 2006 ... ## $ language_id : int 1 1 1 1 1 1 1 1 1 1 ... ## $ rental_duration : int 7 5 6 4 6 3 7 5 6 3 ... ## $ rental_rate : num 4.99 4.99 4.99 4.99 0.99 4.99 2.99 2.99 2.99 2.99 ... ## $ length : int 117 49 54 73 86 48 50 117 130 169 ... ## $ replacement_cost: num 15 20 16 13 21 ... ## $ rating : &#39;pq_mpaa_rating&#39; chr &quot;NC-17&quot; &quot;R&quot; &quot;R&quot; &quot;PG-13&quot; ... ## $ last_update : POSIXct, format: &quot;2013-05-26 14:50:58&quot; &quot;2013-05-26 14:50:58&quot; ... ## $ special_features: &#39;pq__text&#39; chr &quot;{Trailers}&quot; &quot;{\\&quot;Behind the Scenes\\&quot;}&quot; &quot;{Trailers}&quot; &quot;{Trailers}&quot; ... ## $ fulltext : &#39;pq_tsvector&#39; chr &quot;&#39;chamber&#39;:1 &#39;fate&#39;:4 &#39;husband&#39;:11 &#39;italian&#39;:2 &#39;monkey&#39;:16 &#39;moos&#39;:8 &#39;must&#39;:13 &#39;nigeria&#39;:18 &#39;overcom&#39;:14 &#39;reflect&#39;:5&quot; &quot;&#39;australia&#39;:18 &#39;cat&#39;:8 &#39;drama&#39;:5 &#39;epic&#39;:4 &#39;explor&#39;:11 &#39;gross&#39;:1 &#39;moos&#39;:16 &#39;must&#39;:13 &#39;redeem&#39;:14 &#39;wonder&#39;:2&quot; &quot;&#39;airport&#39;:1 &#39;ancient&#39;:18 &#39;confront&#39;:14 &#39;epic&#39;:4 &#39;girl&#39;:11 &#39;india&#39;:19 &#39;monkey&#39;:16 &#39;moos&#39;:8 &#39;must&#39;:13 &#39;pollock&#39;:2 &#39;tale&#39;:5&quot; &quot;&#39;boat&#39;:20 &#39;bright&#39;:1 &#39;conquer&#39;:14 &#39;encount&#39;:2 &#39;fate&#39;:4 &#39;feminist&#39;:11 &#39;jet&#39;:19 &#39;lumberjack&#39;:8 &#39;must&#39;:13 &#39;student&#39;:16 &#39;yarn&#39;:5&quot; ... 8.4.2 Always look at your data with head, View, or kable There is no substitute for looking at your data and R provides several ways to just browse it. The head function controls the number of rows that are displayed. Note that tail does not work against a database object. In every-day practice you would look at more than the default 6 rows, but here we wrap head around the data frame: sqlpetr::sp_print_df(head(film_tibble)) 8.4.3 The summary function in base The base packages summary function provides basic statistics that serve a unique diagnostic purpose in this context. For example, the following output shows that: * `film_id` is a number from 1 to 16,049. In a previous section, we ran the `str` function and saw that there are 16,044 observations in this table. Therefore, the `film_id` seems to be sequential from 1:16049, but there are 5 values missing from that sequence. _Exercise for the Reader_: Which 5 values from 1:16049 are missing from `film_id` values in the `film` table? (_Hint_: In the chapter on SQL Joins, you will learn the functions needed to answer this question.) * The number of NA&#39;s in the `return_date` column is a good first guess as to the number of DVDs rented out or lost as of 2005-09-02 02:35:22. summary(film_tibble) ## film_id title description release_year ## Min. : 1.0 Length:1000 Length:1000 Min. :2006 ## 1st Qu.: 250.8 Class :character Class :character 1st Qu.:2006 ## Median : 500.5 Mode :character Mode :character Median :2006 ## Mean : 500.5 Mean :2006 ## 3rd Qu.: 750.2 3rd Qu.:2006 ## Max. :1000.0 Max. :2006 ## language_id rental_duration rental_rate length ## Min. :1 Min. :3.000 Min. :0.99 Min. : 46.0 ## 1st Qu.:1 1st Qu.:4.000 1st Qu.:0.99 1st Qu.: 80.0 ## Median :1 Median :5.000 Median :2.99 Median :114.0 ## Mean :1 Mean :4.985 Mean :2.98 Mean :115.3 ## 3rd Qu.:1 3rd Qu.:6.000 3rd Qu.:4.99 3rd Qu.:149.2 ## Max. :1 Max. :7.000 Max. :4.99 Max. :185.0 ## replacement_cost rating last_update ## Min. : 9.99 Length:1000 Min. :2013-05-26 14:50:58 ## 1st Qu.:14.99 Class :pq_mpaa_rating 1st Qu.:2013-05-26 14:50:58 ## Median :19.99 Mode :character Median :2013-05-26 14:50:58 ## Mean :19.98 Mean :2013-05-26 14:50:58 ## 3rd Qu.:24.99 3rd Qu.:2013-05-26 14:50:58 ## Max. :29.99 Max. :2013-05-26 14:50:58 ## special_features fulltext ## Length:1000 Length:1000 ## Class :pq__text Class :pq_tsvector ## Mode :character Mode :character ## ## ## So the summary function is surprisingly useful as we first start to look at the table contents. 8.4.4 The glimpse function in the tibble package The tibble packages glimpse function is a more compact version of str: tibble::glimpse(film_tibble) ## Observations: 1,000 ## Variables: 13 ## $ film_id &lt;int&gt; 133, 384, 8, 98, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11 ## $ title &lt;chr&gt; &quot;Chamber Italian&quot;, &quot;Grosse Wonderful&quot;, &quot;Airport ## $ description &lt;chr&gt; &quot;A Fateful Reflection of a Moose And a Husband  ## $ release_year &lt;int&gt; 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, ## $ language_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ## $ rental_duration &lt;int&gt; 7, 5, 6, 4, 6, 3, 7, 5, 6, 3, 6, 3, 6, 6, 6, 4, ## $ rental_rate &lt;dbl&gt; 4.99, 4.99, 4.99, 4.99, 0.99, 4.99, 2.99, 2.99, ## $ length &lt;int&gt; 117, 49, 54, 73, 86, 48, 50, 117, 130, 169, 62, ## $ replacement_cost &lt;dbl&gt; 14.99, 19.99, 15.99, 12.99, 20.99, 12.99, 18.99 ## $ rating &lt;chr&gt; &quot;NC-17&quot;, &quot;R&quot;, &quot;R&quot;, &quot;PG-13&quot;, &quot;PG&quot;, &quot;G&quot;, &quot;NC-17&quot;, ## $ last_update &lt;dttm&gt; 2013-05-26 14:50:58, 2013-05-26 14:50:58, 2013 ## $ special_features &lt;chr&gt; &quot;{Trailers}&quot;, &quot;{\\&quot;Behind the Scenes\\&quot;}&quot;, &quot;{Trai ## $ fulltext &lt;chr&gt; &quot;&#39;chamber&#39;:1 &#39;fate&#39;:4 &#39;husband&#39;:11 &#39;italian&#39;:2  8.4.5 The skim function in the skimr package The skimr package has several functions that make it easy to examine an unknown data frame and assess what it contains. It is also extensible. library(skimr) ## ## Attaching package: &#39;skimr&#39; ## The following object is masked from &#39;package:knitr&#39;: ## ## kable ## The following object is masked from &#39;package:stats&#39;: ## ## filter skimr::skim(film_tibble) ## Warning: No summary functions for vectors of class: pq_mpaa_rating. ## Coercing to character ## Warning: No summary functions for vectors of class: pq__text. ## Coercing to character ## Warning: No summary functions for vectors of class: pq_tsvector. ## Coercing to character ## Skim summary statistics ## n obs: 1000 ## n variables: 13 ## ##  Variable type:character  ## variable missing complete n min max empty n_unique ## description 0 1000 1000 70 130 0 1000 ## fulltext 0 1000 1000 98 205 0 1000 ## rating 0 1000 1000 1 5 0 5 ## special_features 0 1000 1000 10 60 0 15 ## title 0 1000 1000 8 27 0 1000 ## ##  Variable type:integer  ## variable missing complete n mean sd p0 p25 p50 ## film_id 0 1000 1000 500.5 288.82 1 250.75 500.5 ## language_id 0 1000 1000 1 0 1 1 1 ## length 0 1000 1000 115.27 40.43 46 80 114 ## release_year 0 1000 1000 2006 0 2006 2006 2006 ## rental_duration 0 1000 1000 4.99 1.41 3 4 5 ## p75 p100 hist ## 750.25 1000  ## 1 1  ## 149.25 185  ## 2006 2006  ## 6 7  ## ##  Variable type:numeric  ## variable missing complete n mean sd p0 p25 p50 p75 ## rental_rate 0 1000 1000 2.98 1.65 0.99 0.99 2.99 4.99 ## replacement_cost 0 1000 1000 19.98 6.05 9.99 14.99 19.99 24.99 ## p100 hist ## 4.99  ## 29.99  ## ##  Variable type:POSIXct  ## variable missing complete n min max median ## last_update 0 1000 1000 2013-05-26 2013-05-26 2013-05-26 ## n_unique ## 1 skimr::skim_to_wide(film_tibble[,1:7]) #skimr doesn&#39;t like certain kinds of columns ## # A tibble: 7 x 17 ## type variable missing complete n min max empty n_unique mean ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 char descrip 0 1000 1000 70 130 0 1000 &lt;NA&gt; ## 2 char title 0 1000 1000 8 27 0 1000 &lt;NA&gt; ## 3 inte film_id 0 1000 1000 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot; 50 ## 4 inte languag 0 1000 1000 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;  ## 5 inte release 0 1000 1000 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;200 ## 6 inte rental_ 0 1000 1000 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;  ## 7 nume rental_ 0 1000 1000 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2.98 ## #  with 7 more variables: sd &lt;chr&gt;, p0 &lt;chr&gt;, p25 &lt;chr&gt;, p50 &lt;chr&gt;, ## # p75 &lt;chr&gt;, p100 &lt;chr&gt;, hist &lt;chr&gt; 8.4.6 Close the connection and shut down sql-pet Where you place the collect function matters. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) 8.5 Additional reading (Wickham 2018) (Baumer 2018) References "],
["chapter-lazy-evaluation-queries.html", "Chapter 9 Lazy Evaluation and Lazy Queries 9.1 Setup 9.2 R is lazy and comes with guardrails 9.3 Lazy evaluation and lazy queries 9.4 When does a lazy query trigger data retrieval? 9.4.3 # Source: lazy query [?? x 4] 9.4.3 # Database: postgres [postgres@localhost:5439/dvdrental] 9.4.3 title length rating category 9.4.3 9.5 Other resources", " Chapter 9 Lazy Evaluation and Lazy Queries This chapter: Reviews lazy loading, lazy evaluation and lazy query execution Demonstrates how dplyr code gets executed (and how R determines what is translated to SQL and what is processed locally by R) Offers some further resources on lazy loading, evaluation, execution, etc. 9.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to those instructions to configure your environment. Otherwise, start your sql-pet container: sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 9.2 R is lazy and comes with guardrails By design, R is both a language and an interactive development environment (IDE). As a language, R tries to be as efficient as possible. As an IDE, R creates some guardrails to make it easy and safe to work with your data. For example getOption(\"max.print\") prevents R from printing more rows of data than you want to handle in an interactive session, with a default of 99999 lines, which may or may not suit you. On the other hand SQL is a Structured Query Language (SQL): a standard computer language for relational database management and data manipulation..1 SQL has various database-specific Interactive Development Environments (IDEs), such as pgAdmin for PostgreSQL. Roger Peng explains in R Programming for Data Science that: R has maintained the original S philosophy, which is that it provides a language that is both useful for interactive work, but contains a powerful programming language for developing new tools. This is complicated when R interacts with SQL. In a vignette for dbplyr Hadley Wickham explains: The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database on the remote server, not in R on your local machine. When working with databases, dplyr tries to be as lazy as possible: It never pulls data into R unless you explicitly ask for it. It delays doing any work until the last possible moment: it collects together everything you want to do and then sends it to the database in one step. Exactly when, which, and how much data is returned from the dbms is the topic of this chapter. Exactly how the data is represented in the dbms and then translated to a data frame is discussed in the DBI specification. Eventually, if you are interacting with a dbms from R you will need to understand the differences between lazy loading, lazy evaluation, and lazy queries. 9.2.1 Lazy loading Lazy loading is always used for code in packages but is optional (selected by the package maintainer) for datasets in packages.2 Lazy loading means that the code for a particular function doesnt actually get loaded into memory until the last minute  when its actually being used. 9.2.2 Lazy evaluation Essentially Lazy evaluation is a programming strategy that allows a symbol to be evaluated only when needed.3 That means that lazy evaluation is about symbols such as function arguments4 when they are evaluated. Tidy evaluation complicates lazy evaluation.5 9.2.3 Lazy Queries When you create a \"lazy\" query, youre creating a pointer to a set of conditions on the database, but the query isnt actually run and the data isnt actually loaded until you call \"next\" or some similar method to actually fetch the data and load it into an object.6 9.3 Lazy evaluation and lazy queries 9.3.1 dplyr connection objects As introduced in the previous chapter, the dplyr::tbl function creates an object that might look like a data frame in that when you enter it on the command line, it prints a bunch of rows from the dbms table. But it is actually a list object that dplyr uses for constructing queries and retrieving data from the DBMS. The following code illustrates these issues. The dplyr::tbl function creates the connection object that we store in an object named film_table: film_table &lt;- dplyr::tbl(con, &quot;film&quot;) At first glance, it acts like a data frame when you print it, although it only prints 10 of the tables 1,000 rows: film_table ## # Source: table&lt;film&gt; [?? x 13] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## film_id title description release_year language_id rental_duration ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 133 Cham A Fateful  2006 1 7 ## 2 384 Gros A Epic Dra 2006 1 5 ## 3 8 Airp A Epic Tal 2006 1 6 ## 4 98 Brig A Fateful  2006 1 4 ## 5 1 Acad A Epic Dra 2006 1 6 ## 6 2 Ace  A Astoundi 2006 1 3 ## 7 3 Adap A Astoundi 2006 1 7 ## 8 4 Affa A Fanciful 2006 1 5 ## 9 5 Afri A Fast-Pac 2006 1 6 ## 10 6 Agen A Intrepid 2006 1 3 ## #  with more rows, and 7 more variables: rental_rate &lt;dbl&gt;, length &lt;int&gt;, ## # replacement_cost &lt;dbl&gt;, rating &lt;chr&gt;, last_update &lt;dttm&gt;, ## # special_features &lt;chr&gt;, fulltext &lt;chr&gt; However, notice that the first output line shows ??, rather than providing the number of rows in the table. Similarly, the next to last line shows:  with more rows, and 7 more variables whereas the output for a normal tbl of this film data would say:  with more 1,000, and 7 more variables So even though film_table is a tbl, its also a tbl_PqConnection: class(film_table) ## [1] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; ## [4] &quot;tbl_lazy&quot; &quot;tbl&quot; It is not just a normal tbl of data. We can see that from the structure of film_table: str(film_table) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;PqConnection&#39; [package &quot;RPostgres&quot;] with 3 slots ## .. .. ..@ ptr :&lt;externalptr&gt; ## .. .. ..@ bigint : chr &quot;integer64&quot; ## .. .. ..@ typnames:&#39;data.frame&#39;: 437 obs. of 2 variables: ## .. .. .. ..$ oid : int [1:437] 16 17 18 19 20 21 22 23 24 25 ... ## .. .. .. ..$ typname: chr [1:437] &quot;bool&quot; &quot;bytea&quot; &quot;char&quot; &quot;name&quot; ... ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_PqConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 2 ## ..$ x : &#39;ident&#39; chr &quot;film&quot; ## ..$ vars: chr [1:13] &quot;film_id&quot; &quot;title&quot; &quot;description&quot; &quot;release_year&quot; ... ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_base_remote&quot; &quot;op_base&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... It has only two rows! The first row contains all the information in the con object, which contains information about all the tables and objects in the database: film_table$src$con@typnames$typname[380:437] ## [1] &quot;customer&quot; &quot;_customer&quot; ## [3] &quot;actor_actor_id_seq&quot; &quot;actor&quot; ## [5] &quot;_actor&quot; &quot;category_category_id_seq&quot; ## [7] &quot;category&quot; &quot;_category&quot; ## [9] &quot;film_film_id_seq&quot; &quot;film&quot; ## [11] &quot;_film&quot; &quot;pg_toast_16434&quot; ## [13] &quot;film_actor&quot; &quot;_film_actor&quot; ## [15] &quot;film_category&quot; &quot;_film_category&quot; ## [17] &quot;actor_info&quot; &quot;_actor_info&quot; ## [19] &quot;address_address_id_seq&quot; &quot;address&quot; ## [21] &quot;_address&quot; &quot;city_city_id_seq&quot; ## [23] &quot;city&quot; &quot;_city&quot; ## [25] &quot;country_country_id_seq&quot; &quot;country&quot; ## [27] &quot;_country&quot; &quot;customer_list&quot; ## [29] &quot;_customer_list&quot; &quot;film_list&quot; ## [31] &quot;_film_list&quot; &quot;inventory_inventory_id_seq&quot; ## [33] &quot;inventory&quot; &quot;_inventory&quot; ## [35] &quot;language_language_id_seq&quot; &quot;language&quot; ## [37] &quot;_language&quot; &quot;nicer_but_slower_film_list&quot; ## [39] &quot;_nicer_but_slower_film_list&quot; &quot;payment_payment_id_seq&quot; ## [41] &quot;payment&quot; &quot;_payment&quot; ## [43] &quot;rental_rental_id_seq&quot; &quot;rental&quot; ## [45] &quot;_rental&quot; &quot;sales_by_film_category&quot; ## [47] &quot;_sales_by_film_category&quot; &quot;staff_staff_id_seq&quot; ## [49] &quot;staff&quot; &quot;_staff&quot; ## [51] &quot;pg_toast_16529&quot; &quot;store_store_id_seq&quot; ## [53] &quot;store&quot; &quot;_store&quot; ## [55] &quot;sales_by_store&quot; &quot;_sales_by_store&quot; ## [57] &quot;staff_list&quot; &quot;_staff_list&quot; The second row contains a list of the columns in the film table, among other things: film_table$ops$vars ## [1] &quot;film_id&quot; &quot;title&quot; &quot;description&quot; ## [4] &quot;release_year&quot; &quot;language_id&quot; &quot;rental_duration&quot; ## [7] &quot;rental_rate&quot; &quot;length&quot; &quot;replacement_cost&quot; ## [10] &quot;rating&quot; &quot;last_update&quot; &quot;special_features&quot; ## [13] &quot;fulltext&quot; film_table holds information needed to get the data from the film table, but film_table does not hold the data itself. In the following sections, we will examine more closely this relationship between the film_table object and the data in the databases film table. 9.4 When does a lazy query trigger data retrieval? 9.4.1 Create a black box query for experimentation To illustrate the different issues involved in data retrieval, we create more connection objects to link to two other tables. film_category_table &lt;- tbl(con, &quot;film_category&quot;) %&gt;% select(-last_update) The film_category table has 1,000 rows and 2 columns because we dropped last_update which is a column name that appears in more than one table and will just mess things up (and we dont really care when the category was updated). category_table &lt;- tbl(con, &quot;category&quot;) %&gt;% select(-last_update) %&gt;% rename(category = name) The category_table table has 16 rows. Here is a typical string of dplyr verbs strung together with the magrittr %&gt;% pipe command that will be used to tease out the several different behaviors that a lazy query has when passed to different R functions. This query joins three connection objects into a query well call Q: film_table &lt;- tbl(con, &quot;film&quot;) Q &lt;- film_table %&gt;% dplyr::left_join(film_category_table, by = c(&quot;film_id&quot; = &quot;film_id&quot;)) %&gt;% dplyr::left_join(category_table, by = c(&quot;category_id&quot; = &quot;category_id&quot;)) %&gt;% dplyr::select(title, length, rating, category) The str function gives us a hint at how R is collecting information that can be used to construct and execute a query later on: str(Q, max.level = 2) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;PqConnection&#39; [package &quot;RPostgres&quot;] with 3 slots ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_PqConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 4 ## ..$ name: chr &quot;select&quot; ## ..$ x :List of 4 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_join&quot; &quot;op_double&quot; &quot;op&quot; ## ..$ dots:List of 4 ## .. ..- attr(*, &quot;class&quot;)= chr &quot;quosures&quot; ## ..$ args: list() ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_select&quot; &quot;op_single&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... 9.4.2 Experiment overview Think of Q as a black box for the moment. The following examples will show how Q is interpreted differently by different functions. Its important to remember in the following discussion that the and then operator (%&gt;%) actually wraps the subsequent code inside the preceding code so that Q %&gt;% print() is equivalent to print(Q). Notation A single green check indicates that some rows are returned. Two green checks indicate that all the rows are returned. The red X indicates that no rows are returned. R code Result Q %&gt;% print() Prints x rows; same as just entering Q Q %&gt;% dplyr::as_tibble() Forces Q to be a tibble Q %&gt;% head() Prints the first 6 rows Q %&gt;% tail() Error: tail() is not supported by sql sources Q %&gt;% length() Counts the rows in Q Q %&gt;% str() Shows the top 3 levels of the object Q Q %&gt;% nrow() Attempts to determine the number of rows Q %&gt;% dplyr::tally() Counts all the rows  on the dbms side Q %&gt;% dplyr::collect(n = 20) Prints 20 rows Q %&gt;% dplyr::collect(n = 20) %&gt;% head() Prints 6 rows Q %&gt;% ggplot Plots a barchart Q %&gt;% dplyr::show_query() Translates the lazy query object into SQL The next chapter will discuss how to build queries and how to explore intermediate steps. But first, the following subsections provide a more detailed discussion of each row in the preceding table. 9.4.3 Q %&gt;% print() Remember that Q %&gt;% print() is equivalent to print(Q) and the same as just entering Q on the command line. We use the magrittr pipe operator here, because chaining functions highlights how the same object behaves differently in each use. Q %&gt;% print() ## # Source: lazy query [?? x 4] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## title length rating category ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Academy Dinosaur 86 PG Documentary ## 2 Ace Goldfinger 48 G Horror ## 3 Adaptation Holes 50 NC-17 Documentary ## 4 Affair Prejudice 117 G Horror ## 5 African Egg 130 G Family ## 6 Agent Truman 169 PG Foreign ## 7 Airplane Sierra 62 PG-13 Comedy ## 8 Airport Pollock 54 R Horror ## 9 Alabama Devil 114 PG-13 Horror ## 10 Aladdin Calendar 63 NC-17 Sports ## #  with more rows R retrieves 10 observations and 3 columns. In its role as IDE, R has provided nicely formatted output that is similar to what it prints for a tibble, with descriptive information about the dataset and each column: 9.4.3 # Source: lazy query [?? x 4] 9.4.3 # Database: postgres [postgres@localhost:5439/dvdrental] 9.4.3 title length rating category 9.4.3 R has not determined how many rows are left to retrieve as it shows with [?? x 4] and ... with more rows in the data summary. 9.4.4 Q %&gt;% dplyr::as_tibble() In contrast to print(), the as_tibble() function causes R to download the whole table, using tibbles default of displaying only the first 10 rows. Q %&gt;% dplyr::as_tibble() ## # A tibble: 1,000 x 4 ## title length rating category ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Academy Dinosaur 86 PG Documentary ## 2 Ace Goldfinger 48 G Horror ## 3 Adaptation Holes 50 NC-17 Documentary ## 4 Affair Prejudice 117 G Horror ## 5 African Egg 130 G Family ## 6 Agent Truman 169 PG Foreign ## 7 Airplane Sierra 62 PG-13 Comedy ## 8 Airport Pollock 54 R Horror ## 9 Alabama Devil 114 PG-13 Horror ## 10 Aladdin Calendar 63 NC-17 Sports ## #  with 990 more rows 9.4.5 Q %&gt;% head() The head() function is very similar to print but has a different max.print value. Q %&gt;% head() ## # Source: lazy query [?? x 4] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## title length rating category ## &lt;chr&gt; &lt;int&gt; &lt;S3: pq_mpaa_rating&gt; &lt;chr&gt; ## 1 Academy Dinosaur 86 PG Documentary ## 2 Ace Goldfinger 48 G Horror ## 3 Adaptation Holes 50 NC-17 Documentary ## 4 Affair Prejudice 117 G Horror ## 5 African Egg 130 G Family ## 6 Agent Truman 169 PG Foreign 9.4.6 Q %&gt;% tail() Produces an error, because Q does not hold all of the data, so it is not possible to list the last few items from the table: try( Q %&gt;% tail(), silent = FALSE, outFile = stdout() ) ## Error : tail() is not supported by sql sources 9.4.7 Q %&gt;% length() Because the Q object is relatively complex, using str() on it prints many lines. You can glimpse whats going on with length(): Q %&gt;% length() ## [1] 2 9.4.8 Q %&gt;% str() Looking inside shows some of whats going on (three levels deep): Q %&gt;% str(max.level = 3) ## List of 2 ## $ src:List of 2 ## ..$ con :Formal class &#39;PqConnection&#39; [package &quot;RPostgres&quot;] with 3 slots ## ..$ disco: NULL ## ..- attr(*, &quot;class&quot;)= chr [1:4] &quot;src_PqConnection&quot; &quot;src_dbi&quot; &quot;src_sql&quot; &quot;src&quot; ## $ ops:List of 4 ## ..$ name: chr &quot;select&quot; ## ..$ x :List of 4 ## .. ..$ name: chr &quot;join&quot; ## .. ..$ x :List of 2 ## .. .. ..- attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... ## .. ..$ y :List of 2 ## .. .. ..- attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... ## .. ..$ args:List of 4 ## .. ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_join&quot; &quot;op_double&quot; &quot;op&quot; ## ..$ dots:List of 4 ## .. ..$ : language ~title ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x5641c2f300e0&gt; ## .. ..$ : language ~length ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x5641c2f300e0&gt; ## .. ..$ : language ~rating ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x5641c2f300e0&gt; ## .. ..$ : language ~category ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x5641c2f300e0&gt; ## .. ..- attr(*, &quot;class&quot;)= chr &quot;quosures&quot; ## ..$ args: list() ## ..- attr(*, &quot;class&quot;)= chr [1:3] &quot;op_select&quot; &quot;op_single&quot; &quot;op&quot; ## - attr(*, &quot;class&quot;)= chr [1:5] &quot;tbl_PqConnection&quot; &quot;tbl_dbi&quot; &quot;tbl_sql&quot; &quot;tbl_lazy&quot; ... 9.4.9 Q %&gt;% nrow() Notice the difference between nrow() and tally(). The nrow functions returns NA and does not execute a query: Q %&gt;% nrow() ## [1] NA 9.4.10 Q %&gt;% dplyr::tally() The tally function actually counts all the rows. Q %&gt;% dplyr::tally() ## # Source: lazy query [?? x 1] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## n ## &lt;S3: integer64&gt; ## 1 1000 The nrow() function knows that Q is a list. On the other hand, the tally() function tells SQL to go count all the rows. Notice that Q results in 1,000 rows  the same number of rows as film. 9.4.11 Q %&gt;% dplyr::collect() The dplyr::collect function triggers a call to the DBI:dbFetch() function behind the scenes, which forces R to download a specified number of rows: Q %&gt;% dplyr::collect(n = 20) ## # A tibble: 20 x 4 ## title length rating category ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Academy Dinosaur 86 PG Documentary ## 2 Ace Goldfinger 48 G Horror ## 3 Adaptation Holes 50 NC-17 Documentary ## 4 Affair Prejudice 117 G Horror ## 5 African Egg 130 G Family ## 6 Agent Truman 169 PG Foreign ## 7 Airplane Sierra 62 PG-13 Comedy ## 8 Airport Pollock 54 R Horror ## 9 Alabama Devil 114 PG-13 Horror ## 10 Aladdin Calendar 63 NC-17 Sports ## 11 Alamo Videotape 126 G Foreign ## 12 Alaska Phantom 136 PG Music ## 13 Ali Forever 150 PG Horror ## 14 Alice Fantasia 94 NC-17 Classics ## 15 Alien Center 46 NC-17 Foreign ## 16 Alley Evolution 180 NC-17 Foreign ## 17 Alone Trip 82 R Music ## 18 Alter Victory 57 PG-13 Animation ## 19 Amadeus Holy 113 PG Action ## 20 Amelie Hellfighters 79 R Music Q %&gt;% dplyr::collect(n = 20) %&gt;% head() ## # A tibble: 6 x 4 ## title length rating category ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Academy Dinosaur 86 PG Documentary ## 2 Ace Goldfinger 48 G Horror ## 3 Adaptation Holes 50 NC-17 Documentary ## 4 Affair Prejudice 117 G Horror ## 5 African Egg 130 G Family ## 6 Agent Truman 169 PG Foreign The dplyr::collect function triggers the creation of a tibble and controls the number of rows that the DBMS sends to R. Notice that head only prints 6 of the 20 rows that R has retrieved. If you do not provide a value for the n argument, all of the rows will be retrieved into your R workspace. 9.4.12 Q %&gt;% ggplot Passing the Q object to ggplot executes the query and plots the result. Q %&gt;% ggplot2::ggplot(aes(category)) + geom_bar() + coord_flip() Its obvious that when creating our phony dvdrental datbase, phony films were assigned to a category pretty randomly. 9.4.13 Q %&gt;% dplyr::show_query() Q %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;title&quot;, &quot;length&quot;, &quot;rating&quot;, &quot;category&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;film_id&quot; AS &quot;film_id&quot;, &quot;TBL_LEFT&quot;.&quot;title&quot; AS &quot;title&quot;, &quot;TBL_LEFT&quot;.&quot;description&quot; AS &quot;description&quot;, &quot;TBL_LEFT&quot;.&quot;release_year&quot; AS &quot;release_year&quot;, &quot;TBL_LEFT&quot;.&quot;language_id&quot; AS &quot;language_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_duration&quot; AS &quot;rental_duration&quot;, &quot;TBL_LEFT&quot;.&quot;rental_rate&quot; AS &quot;rental_rate&quot;, &quot;TBL_LEFT&quot;.&quot;length&quot; AS &quot;length&quot;, &quot;TBL_LEFT&quot;.&quot;replacement_cost&quot; AS &quot;replacement_cost&quot;, &quot;TBL_LEFT&quot;.&quot;rating&quot; AS &quot;rating&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_LEFT&quot;.&quot;special_features&quot; AS &quot;special_features&quot;, &quot;TBL_LEFT&quot;.&quot;fulltext&quot; AS &quot;fulltext&quot;, &quot;TBL_LEFT&quot;.&quot;category_id&quot; AS &quot;category_id&quot;, &quot;TBL_RIGHT&quot;.&quot;category&quot; AS &quot;category&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;film_id&quot; AS &quot;film_id&quot;, &quot;TBL_LEFT&quot;.&quot;title&quot; AS &quot;title&quot;, &quot;TBL_LEFT&quot;.&quot;description&quot; AS &quot;description&quot;, &quot;TBL_LEFT&quot;.&quot;release_year&quot; AS &quot;release_year&quot;, &quot;TBL_LEFT&quot;.&quot;language_id&quot; AS &quot;language_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_duration&quot; AS &quot;rental_duration&quot;, &quot;TBL_LEFT&quot;.&quot;rental_rate&quot; AS &quot;rental_rate&quot;, &quot;TBL_LEFT&quot;.&quot;length&quot; AS &quot;length&quot;, &quot;TBL_LEFT&quot;.&quot;replacement_cost&quot; AS &quot;replacement_cost&quot;, &quot;TBL_LEFT&quot;.&quot;rating&quot; AS &quot;rating&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_LEFT&quot;.&quot;special_features&quot; AS &quot;special_features&quot;, &quot;TBL_LEFT&quot;.&quot;fulltext&quot; AS &quot;fulltext&quot;, &quot;TBL_RIGHT&quot;.&quot;category_id&quot; AS &quot;category_id&quot; ## FROM &quot;film&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN (SELECT &quot;film_id&quot;, &quot;category_id&quot; ## FROM &quot;film_category&quot;) &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;film_id&quot; = &quot;TBL_RIGHT&quot;.&quot;film_id&quot;) ## ) &quot;TBL_LEFT&quot; ## LEFT JOIN (SELECT &quot;category_id&quot;, &quot;name&quot; AS &quot;category&quot; ## FROM (SELECT &quot;category_id&quot;, &quot;name&quot; ## FROM &quot;category&quot;) &quot;sqfdkcwewt&quot;) &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;category_id&quot; = &quot;TBL_RIGHT&quot;.&quot;category_id&quot;) ## ) &quot;xjkijbsyva&quot; Hand-written SQL code to do the same job will probably look a lot nicer and could be more efficient, but functionally dplyr does the job. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) 9.5 Other resources Benjamin S. Baumer. 2017. A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data. https://arxiv.org/abs/1708.07073 dplyr Reference documentation: Remote tables. https://dplyr.tidyverse.org/reference/index.html#section-remote-tables Data Carpentry. SQL Databases and R. https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html https://www.techopedia.com/definition/1245/structured-query-language-sql https://cran.r-project.org/doc/manuals/r-release/R-ints.html#Lazy-loading https://colinfay.me/lazyeval/ http://adv-r.had.co.nz/Functions.html#function-arguments https://colinfay.me/tidyeval-1/ https://www.quora.com/What-is-a-lazy-query "],
["chapter-lazy-evaluation-and-timing.html", "Chapter 10 Lazy Evaluation and Execution Environment 10.1 Setup 10.2 Other resources", " Chapter 10 Lazy Evaluation and Execution Environment This chapter: Builds on the lazy loading discussion in the previous chapter Demonstrates how the use of the dplyr::collect() creates a boundary between code that is sent to a dbms and code that is executed locally 10.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to those instructions to configure your environment. Otherwise, start your sql-pet container: sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) Define two tables to use in a simple query to use in the following discussion. rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) customer_table &lt;- dplyr::tbl(con, &quot;customer&quot;) Here is a simple string of dplyr verbs similar to the query used to illustrate issues in the last chapter: Q &lt;- rental_table %&gt;% dplyr::left_join(customer_table, by = c(&quot;customer_id&quot; = &quot;customer_id&quot;)) %&gt;% dplyr::select(rental_date, email) Q ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## rental_date email ## &lt;dttm&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 tommy.collazo@sakilacustomer.org ## 2 2005-05-24 23:03:39 manuel.murrell@sakilacustomer.org ## 3 2005-05-24 23:04:41 andrew.purdy@sakilacustomer.org ## 4 2005-05-24 23:05:21 delores.hansen@sakilacustomer.org ## 5 2005-05-24 23:08:07 nelson.christenson@sakilacustomer.org ## 6 2005-05-24 23:11:53 cassandra.walters@sakilacustomer.org ## 7 2005-05-24 23:31:46 minnie.romero@sakilacustomer.org ## 8 2005-05-25 00:00:40 ellen.simpson@sakilacustomer.org ## 9 2005-05-25 00:02:21 danny.isom@sakilacustomer.org ## 10 2005-05-25 00:09:02 april.burns@sakilacustomer.org ## #  with more rows Note that in the previous example we follow this books convention of creating a connection object to each table and fully qualifying function names (e.g., specifying the package). In practice, its possible and convenient to use more abbreviated notation. Q &lt;- tbl(con, &quot;rental&quot;) %&gt;% left_join(tbl(con, &quot;customer&quot;), by = c(&quot;customer_id&quot; = &quot;customer_id&quot;)) %&gt;% select(rental_date, email) Q ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## rental_date email ## &lt;dttm&gt; &lt;chr&gt; ## 1 2005-05-24 22:54:33 tommy.collazo@sakilacustomer.org ## 2 2005-05-24 23:03:39 manuel.murrell@sakilacustomer.org ## 3 2005-05-24 23:04:41 andrew.purdy@sakilacustomer.org ## 4 2005-05-24 23:05:21 delores.hansen@sakilacustomer.org ## 5 2005-05-24 23:08:07 nelson.christenson@sakilacustomer.org ## 6 2005-05-24 23:11:53 cassandra.walters@sakilacustomer.org ## 7 2005-05-24 23:31:46 minnie.romero@sakilacustomer.org ## 8 2005-05-25 00:00:40 ellen.simpson@sakilacustomer.org ## 9 2005-05-25 00:02:21 danny.isom@sakilacustomer.org ## 10 2005-05-25 00:09:02 april.burns@sakilacustomer.org ## #  with more rows 10.1.1 Experiment overview Think of Q as a black box for the moment. The following examples will show how Q is interpreted differently by different functions. Its important to remember in the following discussion that the and then operator (%&gt;%) actually wraps the subsequent code inside the preceding code so that Q %&gt;% print() is equivalent to print(Q). Notation Symbol Explanation A single green check indicates that some rows are returned. Two green checks indicate that all the rows are returned. The red X indicates that no rows are returned. R code Result Time-based, execution environment issues Qc &lt;- Q %&gt;% count(email, sort = TRUE) Extends the lazy query object The next chapter will discuss how to build queries and how to explore intermediate steps. But first, the following subsections provide a more detailed discussion of each row in the preceding table. 10.1.2 Time-based, execution environment issues Remember that if the expression is assigned to an object, it is not executed. If an expression is entered on the command line or appears in your script by itself, a print() function is implied. These two are different: Q %&gt;% count(email) Q_query &lt;- Q %&gt;% count(email) This behavior is the basis of a useful debugging and development process where queries are built up incrementally. 10.1.3 Q %&gt;% more dplyr Because the following statement implies a print() function at the end, we can run it repeatedly, adding dplyr expressions, and only get 10 rows back. Every time we add a dplyr expression to a chain, R will rewrite the SQL code. For example: Q %&gt;% count(email) ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## email n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 harold.martino@sakilacustomer.org 32 ## 2 sean.douglass@sakilacustomer.org 23 ## 3 bob.pfeiffer@sakilacustomer.org 24 ## 4 jo.fowler@sakilacustomer.org 20 ## 5 raul.fortier@sakilacustomer.org 20 ## 6 annette.olson@sakilacustomer.org 24 ## 7 jeanne.lawson@sakilacustomer.org 27 ## 8 diane.collins@sakilacustomer.org 35 ## 9 cindy.fisher@sakilacustomer.org 29 ## 10 shelly.watts@sakilacustomer.org 26 ## #  with more rows As we understand more about the data, we simply add dplyr expressions to pinpoint what we are looking for: Q %&gt;% count(email) %&gt;% filter(n &gt; 40) %&gt;% arrange(email) ## # Source: lazy query [?? x 2] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## # Ordered by: email ## email n ## &lt;chr&gt; &lt;S3: integer64&gt; ## 1 clara.shaw@sakilacustomer.org 42 ## 2 eleanor.hunt@sakilacustomer.org 46 ## 3 karl.seal@sakilacustomer.org 45 ## 4 marcia.dean@sakilacustomer.org 42 ## 5 tammy.sanders@sakilacustomer.org 41 When all the accumulated dplyr verbs are executed, they are submitted to the dbms and the number of rows that are returned follow the same rules as discussed above. ### Interspersing SQL and dplyr rental_table %&gt;% mutate(rental_date = date(rental_date)) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_id&quot;, DATE(&quot;rental_date&quot;) AS &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update&quot; ## FROM &quot;rental&quot; rental_table %&gt;% mutate(rental_date = date(rental_date)) ## # Source: lazy query [?? x 7] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## rental_id rental_date inventory_id customer_id return_date ## &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; ## 1 2 2005-05-24 1525 459 2005-05-28 19:40:33 ## 2 3 2005-05-24 1711 408 2005-06-01 22:12:39 ## 3 4 2005-05-24 2452 333 2005-06-03 01:43:41 ## 4 5 2005-05-24 2079 222 2005-06-02 04:33:21 ## 5 6 2005-05-24 2792 549 2005-05-27 01:32:07 ## 6 7 2005-05-24 3995 269 2005-05-29 20:34:53 ## 7 8 2005-05-24 2346 239 2005-05-27 23:33:46 ## 8 9 2005-05-25 2580 126 2005-05-28 00:22:40 ## 9 10 2005-05-25 1824 399 2005-05-31 22:44:21 ## 10 11 2005-05-25 4443 142 2005-06-02 20:56:02 ## #  with more rows, and 2 more variables: staff_id &lt;int&gt;, ## # last_update &lt;dttm&gt; try(rental_table %&gt;% mutate(rental_date = lubridate::date(rental_date)) ) ## Error in lubridate::date(rental_date) : object &#39;rental_date&#39; not found rental_table %&gt;% collect() %&gt;% mutate(rental_date = lubridate::date(rental_date)) ## # A tibble: 16,044 x 7 ## rental_id rental_date inventory_id customer_id return_date ## &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; ## 1 2 2005-05-24 1525 459 2005-05-28 19:40:33 ## 2 3 2005-05-24 1711 408 2005-06-01 22:12:39 ## 3 4 2005-05-24 2452 333 2005-06-03 01:43:41 ## 4 5 2005-05-24 2079 222 2005-06-02 04:33:21 ## 5 6 2005-05-24 2792 549 2005-05-27 01:32:07 ## 6 7 2005-05-24 3995 269 2005-05-29 20:34:53 ## 7 8 2005-05-24 2346 239 2005-05-27 23:33:46 ## 8 9 2005-05-25 2580 126 2005-05-28 00:22:40 ## 9 10 2005-05-25 1824 399 2005-05-31 22:44:21 ## 10 11 2005-05-25 4443 142 2005-06-02 20:56:02 ## #  with 16,034 more rows, and 2 more variables: staff_id &lt;int&gt;, ## # last_update &lt;dttm&gt; to_char &lt;- function(date, fmt) {return(fmt)} rental_table %&gt;% mutate(rental_date = to_char(rental_date, &quot;YYYY-MM&quot;)) %&gt;% show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_id&quot;, TO_CHAR(&quot;rental_date&quot;, &#39;YYYY-MM&#39;) AS &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update&quot; ## FROM &quot;rental&quot; rental_table %&gt;% mutate(rental_date = to_char(rental_date, &quot;YYYY-MM&quot;)) ## # Source: lazy query [?? x 7] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## rental_id rental_date inventory_id customer_id return_date ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; ## 1 2 2005-05 1525 459 2005-05-28 19:40:33 ## 2 3 2005-05 1711 408 2005-06-01 22:12:39 ## 3 4 2005-05 2452 333 2005-06-03 01:43:41 ## 4 5 2005-05 2079 222 2005-06-02 04:33:21 ## 5 6 2005-05 2792 549 2005-05-27 01:32:07 ## 6 7 2005-05 3995 269 2005-05-29 20:34:53 ## 7 8 2005-05 2346 239 2005-05-27 23:33:46 ## 8 9 2005-05 2580 126 2005-05-28 00:22:40 ## 9 10 2005-05 1824 399 2005-05-31 22:44:21 ## 10 11 2005-05 4443 142 2005-06-02 20:56:02 ## #  with more rows, and 2 more variables: staff_id &lt;int&gt;, ## # last_update &lt;dttm&gt; 10.1.4 Many handy R functions cant be translated to SQL It just so happens that PostgreSQL has a date function that does the same thing as the date function in the lubridate package. In the following code the date function is executed by PostreSQL. rental_table %&gt;% mutate(rental_date = date(rental_date)) ## # Source: lazy query [?? x 7] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## rental_id rental_date inventory_id customer_id return_date ## &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; ## 1 2 2005-05-24 1525 459 2005-05-28 19:40:33 ## 2 3 2005-05-24 1711 408 2005-06-01 22:12:39 ## 3 4 2005-05-24 2452 333 2005-06-03 01:43:41 ## 4 5 2005-05-24 2079 222 2005-06-02 04:33:21 ## 5 6 2005-05-24 2792 549 2005-05-27 01:32:07 ## 6 7 2005-05-24 3995 269 2005-05-29 20:34:53 ## 7 8 2005-05-24 2346 239 2005-05-27 23:33:46 ## 8 9 2005-05-25 2580 126 2005-05-28 00:22:40 ## 9 10 2005-05-25 1824 399 2005-05-31 22:44:21 ## 10 11 2005-05-25 4443 142 2005-06-02 20:56:02 ## #  with more rows, and 2 more variables: staff_id &lt;int&gt;, ## # last_update &lt;dttm&gt; If we specify that we want to use the lubridate version (or any number of other R functions) they are passed to the dbms unless we explicitly tell dplyr to stop translating and bring the results back to the R environment for local processing. try(rental_table %&gt;% collect() %&gt;% mutate(rental_date = lubridate::date(rental_date))) ## # A tibble: 16,044 x 7 ## rental_id rental_date inventory_id customer_id return_date ## &lt;int&gt; &lt;date&gt; &lt;int&gt; &lt;int&gt; &lt;dttm&gt; ## 1 2 2005-05-24 1525 459 2005-05-28 19:40:33 ## 2 3 2005-05-24 1711 408 2005-06-01 22:12:39 ## 3 4 2005-05-24 2452 333 2005-06-03 01:43:41 ## 4 5 2005-05-24 2079 222 2005-06-02 04:33:21 ## 5 6 2005-05-24 2792 549 2005-05-27 01:32:07 ## 6 7 2005-05-24 3995 269 2005-05-29 20:34:53 ## 7 8 2005-05-24 2346 239 2005-05-27 23:33:46 ## 8 9 2005-05-25 2580 126 2005-05-28 00:22:40 ## 9 10 2005-05-25 1824 399 2005-05-31 22:44:21 ## 10 11 2005-05-25 4443 142 2005-06-02 20:56:02 ## #  with 16,034 more rows, and 2 more variables: staff_id &lt;int&gt;, ## # last_update &lt;dttm&gt; 10.1.5 Further lazy execution examples See more examples of lazy execution here. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) 10.2 Other resources Benjamin S. Baumer. 2017. A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data. https://arxiv.org/abs/1708.07073 dplyr Reference documentation: Remote tables. https://dplyr.tidyverse.org/reference/index.html#section-remote-tables Data Carpentry. SQL Databases and R. https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html "],
["chapter-dbi-package-sql.html", "Chapter 11 DBI package and SQL 11.1 Setup 11.2 SQL in R Markdown 11.3 DBI Package 11.4 Dividing the work between R on your machine and the DBMS", " Chapter 11 DBI package and SQL This chapter: Introduces more DBI functions and demonstrates techniques for submitting SQL to the dbms Illustrates some of the differences between writing dplyr commands and SQL Suggests some strategies for dividing the work between your local R session and the dbms 11.1 Setup The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(dbplyr) require(knitr) library(bookdown) library(sqlpetr) If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to those instructions to configure your environment. Otherwise, start your sql-pet container: sqlpetr::sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sqlpetr::sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 11.2 SQL in R Markdown When you create a report to run repeatedly, you might want to put that query into R markdown. See the discussion of multiple language engines in R Markdown. That way you can also execute that SQL code in a chunk with the following header: {sql, connection=con, output.var = \"query_results\"} SELECT &quot;staff_id&quot;, COUNT(*) AS &quot;n&quot; FROM &quot;rental&quot; GROUP BY &quot;staff_id&quot;; Rmarkdown stored that query result in a tibble: query_results ## staff_id n ## 1 2 8004 ## 2 1 8040 11.3 DBI Package In this chapter we touched on a number of functions from the DBI Package. The table in file 96b shows other functions in the package. The Chapter column references a section in the book if we have used it. film_table &lt;- tbl(con, &quot;film&quot;) 11.3.1 Retrieve the whole table SQL code that is submitted to a database is evaluated all at once7. To think through an SQL query, you can use dplyr to build it up step by step and then convert it to SQL code. Or you can use an IDE such as pgAdmin to develop your SQL code. Once you have the SQL code, the following R code demonstrates how to use dbSendQuery to submit SQL from your R environment. result_set &lt;- DBI::dbSendQuery(con, &#39;SELECT &quot;title&quot;, &quot;rental_duration&quot;, &quot;length&quot; FROM &quot;film&quot; WHERE (&quot;rental_duration&quot; &gt; 5.0 AND &quot;length&quot; &gt; 117.0)&#39;) long_rental_films &lt;- DBI::dbFetch(result_set) str(long_rental_films) ## &#39;data.frame&#39;: 202 obs. of 3 variables: ## $ title : chr &quot;African Egg&quot; &quot;Alamo Videotape&quot; &quot;Alaska Phantom&quot; &quot;Alley Evolution&quot; ... ## $ rental_duration: int 6 6 6 6 6 7 6 7 6 6 ... ## $ length : int 130 126 136 180 181 179 119 127 170 162 ... DBI::dbClearResult(result_set) The dbFetch function returns a data.frame, so you dont have dplyrs guardrails that manage the amount of data returned to your workspace. You need to manage the amount of data yourself, using the n = argument of dbFetch to specify the maximum number of records to retrieve per fetch. In the code above, we did not specify n, so dbFetch returned all pending records as the default behavior. When you are finished using the result set object, remember to free all of the associated resources with dbClearResult, as shown in the code above for the result_set variable. 11.3.2 Or a chunk at a time The following code demonstrates using the n argument to dbFetch to specify the maximum number of rows to return. Normally, you would pick some fixed number of records to return each time, but this code shows that you can vary the number of records returned by each call to dbFetch. result_set &lt;- dbSendQuery(con, &#39;SELECT &quot;title&quot;, &quot;rental_duration&quot;, &quot;length&quot; FROM &quot;film&quot; WHERE (&quot;rental_duration&quot; &gt; 5.0 AND &quot;length&quot; &gt; 117.0)&#39;) set.seed(5439) chunk_num &lt;- 0 while (!dbHasCompleted(result_set)) { chunk_num &lt;- chunk_num + 1 chunk &lt;- dbFetch(result_set, n = sample(7:13,1)) # print(nrow(chunk)) chunk$chunk_num &lt;- chunk_num if (!chunk_num %% 9) {print(chunk)} } ## title rental_duration length chunk_num ## 1 Graduate Lord 7 156 9 ## 2 Grease Youth 7 135 9 ## 3 Greedy Roots 7 166 9 ## 4 Greek Everyone 7 176 9 ## 5 Grinch Massage 7 150 9 ## 6 Groundhog Uncut 6 139 9 ## 7 Half Outfield 6 146 9 ## 8 Hamlet Wisdom 7 146 9 ## 9 Harold French 6 168 9 ## 10 Hedwig Alter 7 169 9 ## 11 Holes Brannigan 7 128 9 ## title rental_duration length chunk_num ## 1 Speakeasy Date 6 165 18 ## 2 Speed Suit 7 124 18 ## 3 Spinal Rocky 7 138 18 ## 4 Spirit Flintstones 7 149 18 ## 5 Steers Armageddon 6 140 18 ## 6 Stock Glass 7 160 18 ## 7 Story Side 7 163 18 ## 8 Streak Ridgemont 7 132 18 ## 9 Sweden Shining 6 176 18 ## 10 Tadpole Park 6 155 18 ## 11 Talented Homicide 6 173 18 ## 12 Telemark Heartbreakers 6 152 18 dbClearResult(result_set) 11.4 Dividing the work between R on your machine and the DBMS They work together. 11.4.1 Make the server do as much work as you can show_query as a first draft of SQL. May or may not use SQL code submitted directly. 11.4.2 Criteria for choosing between dplyr and native SQL This probably belongs later in the book. performance considerations: first get the right data, then worry about performance Trade offs between leaving the data in PostgreSQL vs whats kept in R: browsing the data larger samples and complete tables using what you know to write efficient queries that do most of the work on the server Where you place the collect function matters. Here is a typical string of dplyr verbs strung together with the magrittr %&gt;% pipe command that will be used to tease out the several different behaviors that a lazy query has when passed to different R functions. This query joins three connection objects into a query well call Q: rental_table &lt;- dplyr::tbl(con, &quot;rental&quot;) staff_table &lt;- dplyr::tbl(con, &quot;staff&quot;) # the &#39;staff&#39; table has 2 rows customer_table &lt;- dplyr::tbl(con, &quot;customer&quot;) # the &#39;customer&#39; table has 599 rows Q &lt;- rental_table %&gt;% dplyr::left_join(staff_table, by = c(&quot;staff_id&quot; = &quot;staff_id&quot;)) %&gt;% dplyr::rename(staff_email = email) %&gt;% dplyr::left_join(customer_table, by = c(&quot;customer_id&quot; = &quot;customer_id&quot;)) %&gt;% dplyr::rename(customer_email = email) %&gt;% dplyr::select(rental_date, staff_email, customer_email) Q %&gt;% dplyr::show_query() ## &lt;SQL&gt; ## SELECT &quot;rental_date&quot;, &quot;staff_email&quot;, &quot;customer_email&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name.x&quot;, &quot;last_name.x&quot;, &quot;address_id.x&quot;, &quot;staff_email&quot;, &quot;store_id.x&quot;, &quot;active.x&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot;, &quot;store_id.y&quot;, &quot;first_name.y&quot;, &quot;last_name.y&quot;, &quot;email&quot; AS &quot;customer_email&quot;, &quot;address_id.y&quot;, &quot;activebool&quot;, &quot;create_date&quot;, &quot;last_update&quot;, &quot;active.y&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.x&quot; AS &quot;last_update.x&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;staff_email&quot; AS &quot;staff_email&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active.x&quot;, &quot;TBL_LEFT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_LEFT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.y&quot; AS &quot;last_update.y&quot;, &quot;TBL_LEFT&quot;.&quot;picture&quot; AS &quot;picture&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_RIGHT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active.y&quot; ## FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name&quot;, &quot;last_name&quot;, &quot;address_id&quot;, &quot;email&quot; AS &quot;staff_email&quot;, &quot;store_id&quot;, &quot;active&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.x&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_RIGHT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.y&quot;, &quot;TBL_RIGHT&quot;.&quot;picture&quot; AS &quot;picture&quot; ## FROM &quot;rental&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;staff&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;staff_id&quot; = &quot;TBL_RIGHT&quot;.&quot;staff_id&quot;) ## ) &quot;duklxmckvk&quot;) &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;customer&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;rzlkihfkca&quot;) &quot;ecshftlgbp&quot; Here is the SQL query formatted for readability: SELECT &quot;rental_date&quot;, &quot;staff_email&quot;, &quot;customer_email&quot; FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name.x&quot;, &quot;last_name.x&quot;, &quot;address_id.x&quot;, &quot;staff_email&quot;, &quot;store_id.x&quot;, &quot;active.x&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot;, &quot;store_id.y&quot;, &quot;first_name.y&quot;, &quot;last_name.y&quot;, &quot;email&quot; AS &quot;customer_email&quot;, &quot;address_id.y&quot;, &quot;activebool&quot;, &quot;create_date&quot;, &quot;last_update&quot;, &quot;active.y&quot; FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.x&quot; AS &quot;last_update.x&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name.x&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;staff_email&quot; AS &quot;staff_email&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id.x&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active.x&quot;, &quot;TBL_LEFT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_LEFT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_LEFT&quot;.&quot;last_update.y&quot; AS &quot;last_update.y&quot;, &quot;TBL_LEFT&quot;.&quot;picture&quot; AS &quot;picture&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name.y&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id.y&quot;, &quot;TBL_RIGHT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_RIGHT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active.y&quot; FROM (SELECT &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer_id&quot;, &quot;return_date&quot;, &quot;staff_id&quot;, &quot;last_update.x&quot;, &quot;first_name&quot;, &quot;last_name&quot;, &quot;address_id&quot;, &quot;email&quot; AS &quot;staff_email&quot;, &quot;store_id&quot;, &quot;active&quot;, &quot;username&quot;, &quot;password&quot;, &quot;last_update.y&quot;, &quot;picture&quot; FROM (SELECT &quot;TBL_LEFT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_LEFT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_LEFT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_LEFT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.x&quot;, &quot;TBL_RIGHT&quot;.&quot;first_name&quot; AS &quot;first_name&quot; , &quot;TBL_RIGHT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_RIGHT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_RIGHT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_RIGHT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_RIGHT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;username&quot; AS &quot;username&quot;, &quot;TBL_RIGHT&quot;.&quot;password&quot; AS &quot;password&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.y&quot;, &quot;TBL_RIGHT&quot;.&quot;picture&quot; AS &quot;picture&quot; FROM &quot;rental&quot; AS &quot;TBL_LEFT&quot; LEFT JOIN &quot;staff&quot; AS &quot;TBL_RIGHT&quot; ON ( &quot;TBL_LEFT&quot;.&quot;staff_id&quot; = &quot;TBL_RIGHT&quot;.&quot;staff_id&quot; )) &quot;ymdofxkiex&quot;) &quot;TBL_LEFT&quot; LEFT JOIN &quot;customer&quot; AS &quot;TBL_RIGHT&quot; ON ( &quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot; )) &quot;exddcnhait&quot;) &quot;aohfdiedlb&quot; Hand-written SQL code to do the same job will probably look a lot nicer and could be more efficient, but functionally dplyr does the job. GQ &lt;- dbGetQuery( con, &quot;select r.rental_date, s.email staff_email,c.email customer_email from rental r left outer join staff s on r.staff_id = s.staff_id left outer join customer c on r.customer_id = c.customer_id &quot; ) But because Q hasnt been executed, we can add to it. This behavior is the basis for a useful debugging and development process where queries are built up incrementally. Where you place the collect function matters. DBI::dbDisconnect(con) sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) From Rs perspective. Actually there are 4 steps behind the scenes. "],
["chapter-sql-inserting-rows.html", "Chapter 12 Inserting rows into the DVDRENTAL database 12.1 Setup 12.2 Making up data for Join Examples 12.3 SQL Multi-Row Insert Data Syntax 12.4 SQL Multi-Row Insert Data Example 12.5 DPLYR Multi-Row Insert Data Example", " Chapter 12 Inserting rows into the DVDRENTAL database This chapter demonstrates how to: Insert rows do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies 12.1 Setup These packages are called in almost every chapter of the book: Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; 40 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R. Need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 12.2 Making up data for Join Examples Each chapter in the book stands on its own. If you have worked through the code blocks in this chapter in a previous session, you created some new customer records in order to work through material in the rest of the chapter. The DVD rental database data is too clean to demonstrate some join concepts. To dirty the data, this chapter performs a number of database operations on data tables that a data analyst is typically restricted from doing in the real world. Deleting records from tables. Inserting records from tables. Enabling and disabling table constraints. In our Docker environment, you have no restrictions on the database operations you can perform. In the next couple of code blocks, we delete the new data and then recreate the data for the join examples in this next chapter. 12.2.1 SQL Delete Data Syntax DELETE FROM &lt;source&gt; WHERE &lt;where_clause&gt;; 12.2.2 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental databases highest customer_id = 599. dbExecute() always returns a scalar numeric that specifies the number of rows affected by the statement. dbExecute( con, &quot;delete from customer where customer_id &gt;= 600; &quot; ) ## [1] 0 The number above tells us how many rows were actually deleted from the customer table. 12.2.3 Delete New Practice Store from the Store Table. In the next code block we delete out the new stores that were added when the book was compliled or added working through the exercises. Out of the box, the DVD rental databases highest store_id = 2. dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 0 12.2.4 SQL Single Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. The column list is the list of column names on the table and the corresponding list of values must have the correct data type. The following code block returns the CUSTOMER column names and data types. customer_cols &lt;- dbGetQuery( con, &quot;select table_name, column_name, ordinal_position, data_type from information_schema.columns where table_catalog = &#39;dvdrental&#39; and table_name = &#39;customer&#39; ;&quot; ) sp_print_df(customer_cols) In the next code block, we insert Sophie as a new customer into the customer table via a SQL insert statement. The columns list clause has three id columns, customer_id, store_id, and address_id. The customer_id is a primary key column and the other two look like foreign key columns. For now, we are interested in getting some new customers into the customer table. We look at the relations between the customer and the store tables later in this chapter. dbExecute( con, &quot; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) &quot; ) ## [1] 1 The number above should be 1 indicating that one record was inserted. new_customers &lt;- dbGetQuery(con ,&quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 12.2.5 Primary Key Constraint Error Message For the new customers, we are concerned with not violating the PK and FK constraints. In the next SQL code block, we try and reinsert the newly created customer record inserted above. Instead of having the code block fail, it throws a duplicate key exception error message. If you knit the document, the exception error message is thrown to the R Markdown tab. dbExecute(con, &quot; do $$ DECLARE v_customer_id INTEGER; begin v_customer_id = 600; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(v_customer_id,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE ,now(),now()::date,1); exception when unique_violation then raise notice &#39;SQLERRM = %, customer_id = %&#39;, SQLERRM, v_customer_id; when others then raise &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 The number above shows how many rows were inserted. To ensure that the thrown error message is part of the book, the error message is shown below. NOTICE: SQLERRM = duplicate key value violates unique constraint &quot;customer_pkey&quot;, customer_id = 600 CONTEXT: PL/pgSQL function inline_code_block line 12 at RAISE 12.2.6 R Exercise: Inserting a Single Row via a Dataframe In the following code block replace Sophie Yang with your name where appropriate. Note: The last data frame parameter sets the stringsAsFactors is FALSE. Databases do not have a native FACTOR type. The dataframe column names must match the table column names. The dbWriteTable function needs append = true to actually insert the new row. The dbWriteTable function has an option overwrite. It is set to FALSE by default. If it is set to TRUE, the table is first truncated before the row is inserted. No write occurs if both overwrite and append = FALSE. df &lt;- data.frame( customer_id = 601 , store_id = 2 , first_name = &quot;Sophie&quot; , last_name = &quot;Yang&quot; , email = &quot;sophie.yang@sakilacustomer.org&quot; , address_id = 1 , activebool = TRUE , create_date = Sys.Date() , last_update = Sys.time() , active = 1 , stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df, append = TRUE, row.names = FALSE) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 12.3 SQL Multi-Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list1&gt;, ... &lt;values listn&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns (&lt;values list&gt;) : values assoicated with the column list. Postgres and some other flavors of SQL allow multiple rows to be inserted at a time. The syntax is identical to the Single Row syntax, but includes multiple (&lt;values list&gt;) clauses separated by commas. Note that each value list is enclosed it a set of parenthesis. The following code block illustrates the SQL multi-row insert. Note that the customer_id column takes on sequential values to satisfy the PK constraint. 12.4 SQL Multi-Row Insert Data Example # dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(602,4,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE ,now()::date,now()::date,1) ,(603,5,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE ,now()::date,now()::date,1) ,(604,6,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE ,now()::date,now()::date,1) ;&quot; ) ## [1] 3 12.5 DPLYR Multi-Row Insert Data Example The Postgres R multi-row insert is similar to the single row insert. The single column values are converted to a vector of values. 12.5.1 R Exercise: Inserting Multiple Rows via a Dataframe Replace the two first_name, last_name, and email column values with your own made up values in the following code block. The output should be all of our new customers, customer_id = {600 - 606}. customer_id &lt;- c(605, 606) store_id &lt;- c(3, 4) first_name &lt;- c(&quot;John&quot;, &quot;Ian&quot;) last_name &lt;- c(&quot;Smith&quot;, &quot;Frantz&quot;) email &lt;- c(&quot;john.smith@sakilacustomer.org&quot;, &quot;ian.frantz@sakilacustomer.org&quot;) address_id &lt;- c(3, 4) activebool &lt;- c(TRUE, TRUE) create_date &lt;- c(Sys.Date(), Sys.Date()) last_update &lt;- c(Sys.time(), Sys.time()) active &lt;- c(1, 1) df2 &lt;- data.frame(customer_id, store_id, first_name, last_name, email, address_id, activebool, create_date, last_update, active, stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df2, append = TRUE, row.names = FALSE ) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) Confirm that the two new rows, customer_id = { 605, 606} are in the output. The next two code block show all the rows in the store and staff tables. Notice that neither table has a staff_id or a manager_staff_id = 10. We will attempt to insert such a row in the upcoming code blocks. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) staff &lt;- dbGetQuery(con ,&quot;select staff_id, first_name, last_name, address_id, email, store_id from staff;&quot;) sp_print_df(staff) 12.5.2 Creating a Messy Store Row A new store row is needed to illustrate a right outer join in a future code block. However, one cannot insert/update a row into the store table with a manager_staff_id = 10 because of a foreign key constraint on the manager_staff_id column. The manager_staff_id value must satisfy two conditions before the database will allow the new store row to be inserted into the table when the table constraints are enabled.: The manager_staff_id must be unique when inserted into the store table. The manager_staff_id must match a staff table staff_id value. Next we show both error messages: The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 1, but fails with a unique constraint error message. The manager_staff_id = 1 already exists in the store table. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 1; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 Error in result_create(conn@ptr, statement) : Failed to prepare query: server closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request. The number above should be 0 and indicates no row was inserted. The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 10, but fails with a foreign key constraint error message because there does not exist a staff table row with staff_id = 10. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 10; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 NOTICE: SQLERRM = insert or update on table &quot;store&quot; violates foreign key constraint &quot;store_manager_staff_id_fkey&quot;, manager_staff_id = 10 CONTEXT: PL/pgSQL function inline_code_block line 9 at RAISE Again, the number above should be 0 and indicates no row was inserted. The following three code blocks disables all the database constraints on the store table Inserts the store row with store_id = 10 via a dataframe. Re-enabes the database constraints on the store table # dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 df &lt;- data.frame( store_id = 10 , manager_staff_id = 10 , address_id = 10 , last_update = Sys.time() ) dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, row.names = FALSE) dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 The zeros after the dbExecute code blocks indicate that the dbExecute calls did not alter any rows on the table. In the next code block we confirm our new row, store_id = 10, was actually inserted. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) Diconnect from the db: dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-dplyr-data.html", "Chapter 13 SQL &amp; dplyr joins additional data 13.1 Making up data for Join Examples 13.2 SQL Multi-Row Insert Data Syntax 13.3 SQL Multi-Row Insert Data Example 13.4 DPLYR Multi-Row Insert Data Example 13.5 Create a film record", " Chapter 13 SQL &amp; dplyr joins additional data This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies These packages are called in almost every chapter of the book: Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; 46 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R. Need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 13.1 Making up data for Join Examples Each chapter in the book stands on its own. If you have worked through the code blocks in this chapter in a previous session, you created some new customer records in order to work through material in the rest of the chapter. The DVD rental database data is too clean to demonstrate some join concepts. To dirty the data, this chapter performs a number of database operations on data tables that a data analyst is typically restricted from doing in the real world. Deleting records from tables. Inserting records from tables. Enabling and disabling table constraints. In our Docker environment, you have no restrictions on the database operations you can perform. In the next couple of code blocks, we delete the new data and then recreate the data for the join examples in this next chapter. 13.1.1 SQL Delete Data Syntax DELETE FROM &lt;source&gt; WHERE &lt;where_clause&gt;; 13.1.2 Delete New Practice Store from the Store Table. In the next code block we delete out the new stores that were added when the book was compliled or added working through the exercises. Out of the box, the DVD rental databases highest store_id = 2. dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 13.1.3 Delete film 1001, Sophies Choice, records in film_category, rental, inventory, and film The records need to be deleted in a specific order to not violate constraints. dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 0 dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 0 dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 0 dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 0 13.1.4 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental databases highest customer_id = 599. 13.1.5 Delete New Practice Customers from the Customer table. In the next code block we delete out the new customers that were added when the book was compliled or added while working through the chapter. Out of the box, the DVD rental databases highest customer_id = 599. dbExecute() always returns a scalar numeric that specifies the number of rows affected by the statement. dbExecute( con, &quot;delete from customer where customer_id &gt;= 600; &quot; ) ## [1] 7 The number above tells us how many rows were actually deleted from the customer table. 13.1.6 SQL Single Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns &lt;values list&gt; : values assoicated with the column list. The column list is the list of column names on the table and the corresponding list of values must have the correct data type. The following code block returns the CUSTOMER column names and data types. customer_cols &lt;- dbGetQuery( con, &quot;select table_name, column_name, ordinal_position, data_type from information_schema.columns where table_catalog = &#39;dvdrental&#39; and table_name = &#39;customer&#39; ;&quot; ) sp_print_df(customer_cols) In the next code block, we insert Sophie as a new customer into the customer table via a SQL insert statement. The columns list clause has three id columns, customer_id, store_id, and address_id. The customer_id is a primary key column and the other two look like foreign key columns. For now, we are interested in getting some new customers into the customer table. We look at the relations between the customer and the store tables later in this chapter. dbExecute( con, &quot; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(600,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE,now(),now()::date,1) &quot; ) ## [1] 1 The number above should be 1 indicating that one record was inserted. new_customers &lt;- dbGetQuery(con ,&quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 13.1.7 Primary Key Constraint Error Message For the new customers, we are concerned with not violating the PK and FK constraints. In the next SQL code block, we try and reinsert the newly created customer record inserted above. Instead of having the code block fail, it throws a duplicate key exception error message. If you knit the document, the exception error message is thrown to the R Markdown tab. dbExecute(con, &quot; do $$ DECLARE v_customer_id INTEGER; begin v_customer_id = 600; insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(v_customer_id,3,&#39;Sophie&#39;,&#39;Yang&#39;,&#39;sophie.yang@sakilacustomer.org&#39;,1,TRUE ,now(),now()::date,1); exception when unique_violation then raise notice &#39;SQLERRM = %, customer_id = %&#39;, SQLERRM, v_customer_id; when others then raise &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 The number above shows how many rows were inserted. To ensure that the thrown error message is part of the book, the error message is shown below. NOTICE: SQLERRM = duplicate key value violates unique constraint &quot;customer_pkey&quot;, customer_id = 600 CONTEXT: PL/pgSQL function inline_code_block line 12 at RAISE 13.1.8 R Exercise: Inserting a Single Row via a Dataframe In the following code block replace Sophie Yang with your name where appropriate. Note: The last data frame parameter sets the stringsAsFactors is FALSE. Databases do not have a native FACTOR type. The dataframe column names must match the table column names. The dbWriteTable function needs append = true to actually insert the new row. The dbWriteTable function has an option overwrite. It is set to FALSE by default. If it is set to TRUE, the table is first truncated before the row is inserted. No write occurs if both overwrite and append = FALSE. df &lt;- data.frame( customer_id = 601 , store_id = 2 , first_name = &quot;Sophie&quot; , last_name = &quot;Yang&quot; , email = &quot;sophie.yang@sakilacustomer.org&quot; , address_id = 1 , activebool = TRUE , create_date = Sys.Date() , last_update = Sys.time() , active = 1 , stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df, append = TRUE, row.names = FALSE) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) 13.2 SQL Multi-Row Insert Data Syntax INSERT INTO &lt;target&gt; &lt;column_list&gt; VALUES &lt;values list1&gt;, ... &lt;values listn&gt;; &lt;target&gt; : target table/view &lt;column list&gt; : csv list of columns (&lt;values list&gt;) : values assoicated with the column list. Postgres and some other flavors of SQL allow multiple rows to be inserted at a time. The syntax is identical to the Single Row syntax, but includes multiple (&lt;values list&gt;) clauses separated by commas. Note that each value list is enclosed it a set of parenthesis. The following code block illustrates the SQL multi-row insert. Note that the customer_id column takes on sequential values to satisfy the PK constraint. 13.3 SQL Multi-Row Insert Data Example # dbExecute( con, &quot;insert into customer (customer_id,store_id,first_name,last_name,email,address_id,activebool ,create_date,last_update,active) values(602,4,&#39;John&#39;,&#39;Smith&#39;,&#39;john.smith@sakilacustomer.org&#39;,2,TRUE ,now()::date,now()::date,1) ,(603,5,&#39;Ian&#39;,&#39;Frantz&#39;,&#39;ian.frantz@sakilacustomer.org&#39;,3,TRUE ,now()::date,now()::date,1) ,(604,6,&#39;Ed&#39;,&#39;Borasky&#39;,&#39;ed.borasky@sakilacustomer.org&#39;,4,TRUE ,now()::date,now()::date,1) ;&quot; ) ## [1] 3 13.4 DPLYR Multi-Row Insert Data Example The Postgres R multi-row insert is similar to the single row insert. The single column values are converted to a vector of values. 13.4.1 R Exercise: Inserting Multiple Rows via a Dataframe Replace the two first_name, last_name, and email column values with your own made up values in the following code block. The output should be all of our new customers, customer_id = {600 - 606}. customer_id &lt;- c(605, 606) store_id &lt;- c(3, 4) first_name &lt;- c(&quot;John&quot;, &quot;Ian&quot;) last_name &lt;- c(&quot;Smith&quot;, &quot;Frantz&quot;) email &lt;- c(&quot;john.smith@sakilacustomer.org&quot;, &quot;ian.frantz@sakilacustomer.org&quot;) address_id &lt;- c(3, 4) activebool &lt;- c(TRUE, TRUE) create_date &lt;- c(Sys.Date(), Sys.Date()) last_update &lt;- c(Sys.time(), Sys.time()) active &lt;- c(1, 1) df2 &lt;- data.frame(customer_id, store_id, first_name, last_name, email, address_id, activebool, create_date, last_update, active, stringsAsFactors = FALSE ) dbWriteTable(con, &quot;customer&quot;, value = df2, append = TRUE, row.names = FALSE ) new_customers &lt;- dbGetQuery(con , &quot;select customer_id,store_id,first_name,last_name from customer where customer_id &gt;= 600;&quot;) sp_print_df(new_customers) Confirm that the two new rows, customer_id = { 605, 606} are in the output. The next two code block show all the rows in the store and staff tables. Notice that neither table has a staff_id or a manager_staff_id = 10. We will attempt to insert such a row in the upcoming code blocks. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) staff &lt;- dbGetQuery(con ,&quot;select staff_id, first_name, last_name, address_id, email, store_id from staff;&quot;) sp_print_df(staff) 13.4.2 Creating a Messy Store Row A new store row is needed to illustrate a right outer join in a future code block. However, one cannot insert/update a row into the store table with a manager_staff_id = 10 because of a foreign key constraint on the manager_staff_id column. The manager_staff_id value must satisfy two conditions before the database will allow the new store row to be inserted into the table when the table constraints are enabled.: The manager_staff_id must be unique when inserted into the store table. The manager_staff_id must match a staff table staff_id value. Next we show both error messages: The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 1, but fails with a unique constraint error message. The manager_staff_id = 1 already exists in the store table. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 1; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 Error in result_create(conn@ptr, statement) : Failed to prepare query: server closed the connection unexpectedly This probably means the server terminated abnormally before or while processing the request. The number above should be 0 and indicates no row was inserted. The next code block attempts to insert a new store, store_id = 10, with manager_staff_id = 10, but fails with a foreign key constraint error message because there does not exist a staff table row with staff_id = 10. dbExecute(con, &quot; do $$ DECLARE v_manager_staff_id INTEGER; begin v_manager_staff_id = 10; insert into store (store_id,manager_staff_id,address_id,last_update) values (10,v_manager_staff_id,10,now()::date); exception when foreign_key_violation then raise notice &#39;SQLERRM = %, manager_staff_id = %&#39;, SQLERRM, v_manager_staff_id; when others then raise notice &#39;SQLERRM = % SQLSTATE =%&#39;, SQLERRM, SQLSTATE; end; $$ language &#39;plpgsql&#39;;&quot;) ## [1] 0 NOTICE: SQLERRM = insert or update on table &quot;store&quot; violates foreign key constraint &quot;store_manager_staff_id_fkey&quot;, manager_staff_id = 10 CONTEXT: PL/pgSQL function inline_code_block line 9 at RAISE Again, the number above should be 0 and indicates no row was inserted. The following three code blocks disables all the database constraints on the store table Inserts the store row with store_id = 10 via a dataframe. Re-enabes the database constraints on the store table # dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 df &lt;- data.frame( store_id = 10 , manager_staff_id = 10 , address_id = 10 , last_update = Sys.time() ) dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, row.names = FALSE) dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 The zeros after the dbExecute code blocks indicate that the dbExecute calls did not alter any rows on the table. In the next code block we confirm our new row, store_id = 10, was actually inserted. stores &lt;- dbGetQuery(con,&quot;select * from store;&quot;) sp_print_df(stores) 13.5 Create a film record dbExecute( con, &quot;insert into film (film_id,title,description,release_year,language_id ,rental_duration,rental_rate,length,replacement_cost,rating ,last_update,special_features,fulltext) values(1001,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;orphaned language_id=10&#39;,2018,1 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ,(1002,&#39;Sophie&#39;&#39;s Choice&#39;,&#39;orphaned language_id=10&#39;,2018,1 ,7,4.99,120,14.99,&#39;PG&#39; ,now()::date,&#39;{Trailers}&#39;,&#39;&#39;) ; &quot;) ## [1] 2 dbExecute( con, &quot;insert into film_category (film_id,category_id,last_update) values(1001,6,now()::date) ,(1001,7,now()::date) ,(1002,6,now()::date) ,(1002,7,now()::date) ;&quot;) ## [1] 4 dbExecute( con, &quot;insert into inventory (inventory_id,film_id,store_id,last_update) values(4582,1001,1,now()::date) ,(4583,1001,2,now()::date) ;&quot;) ## [1] 2 dbExecute( con, &quot;insert into rental (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update) values(16050,now()::date - interval &#39;1 week&#39;,4582,600,now()::date,1,now()::date) ;&quot;) ## [1] 1 Diconnect from the db: dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-dplyr-joins.html", "Chapter 14 SQL &amp; dplyr joins 14.1 Joins 14.2 Natural Join is a Delayed Time Bomb 14.3 Join Templates 14.4 Inner Joins 14.5 Left Joins 14.6 Why Include one of the Inner Join Key columns? 14.7 Right Joins 14.8 Full Join 14.9 Semi Join 14.10 Anti Joins 14.11 Non-Equi-Join Example", " Chapter 14 SQL &amp; dplyr joins This chapter demonstrates how to: Use primary and foreign keys to retrieve specific rows of a table Do different kinds of join queries Exercises Query the database to get basic information about each dvdrental story How to interact with the database using different strategies Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; 52 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) source(file = here::here(&#39;book-src/sql_pet_data.R&#39;), echo = TRUE) ## ## &gt; dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 4 ## ## &gt; dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from customer where customer_id &gt;= 600;&quot;) ## [1] 7 ## ## &gt; dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into customer\\n (customer_id,store_id,first_name,last_name,email,address_id,activebool\\n ,create_date,last_update,active)\\n ...&quot; ... [TRUNCATED] ## [1] 5 ## ## &gt; dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; df &lt;- data.frame(store_id = 10, manager_staff_id = 10, ## + address_id = 10, last_update = Sys.time()) ## ## &gt; dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, ## + row.names = FALSE) ## ## &gt; dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; dbExecute(con, &quot;insert into film\\n (film_id,title,description,release_year,language_id\\n ,rental_duration,rental_rate,length,replacement_cost,rati ...&quot; ... [TRUNCATED] ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into film_category\\n (film_id,category_id,last_update)\\n values(1001,6,now()::date)\\n ,(1001,7,now()::date)\\n ;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into inventory\\n (inventory_id,film_id,store_id,last_update)\\n values(4582,1001,1,now()::date)\\n ,(4583,1001,2,now()::date ...&quot; ... [TRUNCATED] ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into rental\\n (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update)\\n values(16050,now()::date ...&quot; ... [TRUNCATED] ## [1] 1 14.1 Joins In section SQL Quick Start Simple Retrieval, there is a brief discussion of databases and third normal form (3NF). One of the goals of normalization is to eliminate redundant data being kept in multiple tables and having each table contain a very granular level of detail. If a record then needs to be updated, it is updated in one table instead of multiple tables improving overall system performance. This also helps simplify and maintain referential integrity between tables. Normalization breaks data down and JOINs denormalize the data and builds it back up. The tables are typically related via a primary key - foreign key relationship. The PostgreSQL database enforces the primary and foreign key constraints in the DVD rental database. 14.1.1 Join Types The diagram above shows the hierarchy of the different types of joins. In the boxes above: The joins are based on a single column from the two tables, the left and right tables. Joins can be based on multiple columns from both tables. The L. and R. are aliases for the left and right table names. Often the joining columns have the same name as in the Natural Join, L.col1 = R.col1 However, the joining column names can be different L.col1 = R.col2. All dplyr joins are based on equality between the table columns, L.col1 = R.col2. See the fuzzyjoin package for non-equality column conditions. SQL supports non-equality column conditions. Non-equality column conditions are rare. Equi Joins are a subset of the Inner Join. For this tutorial, we can think of joins as either an Inner/Equi Join or an Outer Join. For those interested though, the typical Venn diagrams can be found here. 14.1.2 Graphic illustration of Join types This book is focused on data retrieval from a dbms such as is found inside an organiztion, and the discussion and examples are built around the dvdrental database. However, its always helpful to remember the basic SQL concepts. For this we refer to Jenny Bryans Join Cheat Sheet, which is part of a UBC STAT 545A and 547M course on Data wrangling, exploration, and analysis with R. 14.1.3 Join Syntax The table below shows the two R join function call formats, standalone function call and pipe function call and the corresponding SQL join format. Join dplyr sql inner inner_join(customer_tbl, rental_tbl, by = customer_id, suffix = c(.c, .r)) from customer c join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% inner_join(rental_tbl, by = customer_id, suffix = c(.c, .r)) left left_join(customer_tbl, rental_tbl, by = customer_id, suffix = c(.c, .r)) from customer c left outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% left_join(rental_tbl, by = customer_id, suffix = c(.c, .r)) right right_join(customer_tbl, rental_tbl, by = customer_id, suffix = c(.c, .r)) from customer c right outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% right_join(rental_tbl, by = customer_id, suffix = c(.c, .r)) full full_join(customer_tbl, rental_tbl, by = customer_id, suffix = c(.c, .r)) from customer c full outer join rental r on c.customer_id = r.customer_id customer_tbl %&gt;% full_join(rental_tbl, by = customer_id, suffix = c(.c, .r)) semi semi_join(customer_tbl, rental_tbl, by = customer_id) customer_tbl %&gt;% semi_join(rental_tbl, by = customer_id) anti anti_join(customer_tbl, rental_tbl, by = customer_id) 14.1.4 Join Tables The dplyr join documentation describes two different types of joins, mutating and filtering joins. For those coming to R with a SQL background, the mutating documentation is misleading in one respect. Here is the inner_join documentation: inner_join() return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned. The misleading part is and all the columns from x and y. If the join column is KEY, SQL will return x.KEY and y.KEY. dplyr returns just KEY, the KEY from the driving table. This is important if you are translating SQL to R because SQL developers will reference both columns x.KEY and y.KEY. One needs to mutate the y.KEY column. This difference should become clear in the outer join examples. In the next couple of examples, we will use a small sample of the customer and store table data from the database to illustrate the diffent joins. In the dplyr::*_join verbs, the by and suffix parameters are included because they help document the actual join and the source of join columns. If the suffix parameter is excluded, it defaults to .x to refer to the first table and .y for the second table. If the dplyr pipe has many joins, the suffix parameter makes it clearer which table the column came from. In the next code block, we perform a Cartesian join to illustrate the default suffix behavior. Note that: every column has a suffix of x or y except the key column; and the column values may or may not be the same based on the column name without the suffix. If one has a lot of joins in the pipeline with tables that have many duplicate column names, it is difficult to keep track of the source of the column. store_table &lt;- DBI::dbReadTable(con, &quot;store&quot;) store_table$key &lt;- 1 cartesian_join &lt;- inner_join(store_table, store_table, by = (&#39;key&#39; = &#39;key&#39;)) %&gt;% select(-key, -last_update.x, -last_update.y) sp_print_df(cartesian_join) The suffix parameter helps distinguish the duplicate column names as shown in the next example. cartesian_join2 &lt;- dplyr::inner_join( store_table, store_table, by = (&#39;key&#39; = &#39;key&#39;), suffix = c(&#39;.store1&#39;, &#39;.store2&#39;) ) %&gt;% select(-key, -last_update.store1, -last_update.store2) sp_print_df(cartesian_join2) 14.2 Natural Join is a Delayed Time Bomb The dplyr default join is a natural join, joining tables on common column names. One of many links why one should not use natural joins can be found here. If two tables are joined via a natural join on column C1 the join continues to work as long as no additional common columns are added to either table. If a new column C2 is added to one of the tables and C2 already exists in the other table, BOOM!, the delayed time bomb goes off. The natural join still executes, doesnt throw any errors, but the returned result set may be smaller, much smaller, than before the new C2 column was added. 14.2.1 SQL Customer store_id Distribution The next code block calculates the store_id distribution in the customer and store tables across all their rows. The results will be used in following sections to validate different join result sets. store_distribution_sql &lt;- dbGetQuery( con, &quot;select &#39;customer&#39; tbl, store_id, count(*) count from customer group by store_id union select &#39;store&#39; tbl, store_id, count(*) count from store group by store_id order by tbl, store_id;&quot; ) sp_print_df(store_distribution_sql) 14.2.2 Sample Customer and Store Join Data The following code block extracts sample customer and the store data. The customer data is restricted to 10 rows to illustrate the different joins. The 10 rows are used in the detail examples in order to perform a sanity check that the join is actually working. Each detail example is followed by an aggregated summary across all rows of customer and store tables. sample_customers &lt;- dbGetQuery( con, &quot;select customer_id, first_name, last_name, store_id from customer where customer_id between 595 and 604&quot; ) stores &lt;- dbGetQuery(con, &quot;select * from store;&quot;) sp_print_df(sample_customers) sp_print_df(stores) 14.2.3 dplyr store_id distribution Exercise Execute and Review the output from the code block below. Union and arrange the output to match the SQL output in the previous code block. customer_table &lt;- DBI::dbReadTable(con, &quot;customer&quot;) store_table &lt;- DBI::dbReadTable(con, &quot;store&quot;) customer_summary &lt;- customer_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;customer&#39;) %&gt;% select(table,store_id,count) store_summary &lt;- store_table %&gt;% group_by(store_id) %&gt;% summarize(count=n()) %&gt;% mutate(table=&#39;store&#39;) %&gt;% select(table,store_id,count) sp_print_df(customer_summary) sp_print_df(store_summary) ## UNION the two summary tables and ARRANGE the output to match the SQL output from the previouse code block 14.3 Join Templates In this section we perform various joins using dplyr and SQL. Each dplyr code block has three purposes. Show working detail/summary data join examples. The code blocks can be used as templates for beginning more complex dplyr pipelines. The code blocks show the number of joins performed. In these examples, the customer is always the left table and store is always the right table. The join condition shown in the by parameter by = c(&#39;store_id&#39;=&#39;store_id&#39;) is on the common foreign - primary key column store_id. This is technically an equi-join condition which makes our joins 1-to-1 and keeps the result set small. In multi-column joins, each language_id would be replaced with a vector of column names used in the join by position. Note the column names do not need to be identical by position. The suffix parameter is a way to distinguish the same column name in the joined tables. The suffixes are usually a single letter to represent the name of the table. 14.4 Inner Joins For a conceptual refresher see: inner_join(superheroes, publishers) inner_join(publishers, superheroes) 14.4.1 SQL Inner Join Details For an inner join between two tables, it doesnt matter which table is on the left, the first table, and which is on the right, the second table, because join conditions on both tables must be satisfied. Reviewing the table below shows the inner join on our 10 sample customers and 3 store records returned only 6 rows. The inner join detail shows only rows with matching store_ids. customer_store_details_sij &lt;- dbGetQuery( con, &quot;select &#39;ij&#39; join_type, customer_id, first_name, last_name, c.store_id c_store_id, s.store_id s_store_id, s.manager_staff_id, s.address_id from customer c join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot; ) sp_print_df(customer_store_details_sij) 14.4.2 dplyr Inner Join Details customer_ij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604) %&gt;% mutate(join_type = &#39;ij&#39;) %&gt;% rename(s_address_id = address_id.y) %&gt;% select( join_type, customer_id, first_name, last_name, store_id, store_id, manager_staff_id, s_address_id ) sp_print_df(customer_ij) Compare the output from the SQL and dplyr version. The SQL output has a c_store_id and a s_store_id column and the dplyr output only has store_id. In this case, because it is an inner join, it doesnt matter because the store_id in the customer table and the store_id in the store table will always be the same. 14.4.3 SQL Inner Join Summary Note that the store_id is available from both the customer and store tables, selected by c.store_id, s.store_id, in the select clause. customer_store_summay_sij &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id, s.store_id s_store_id, count(*) n from customer c join store s on c.store_id = s.store_id group by c.store_id,s.store_id;&quot; ) sp_print_df(customer_store_summay_sij) 14.4.4 dplyr Inner Join Summary In the previous SQL code block, c. and s. were used in the inner join as table aliases. The dplyr suffix is similar to the SQL table alias. The role of the dplyr suffix and the SQL alias is to disambiguate duplicate table and column names referenced. customer_store_summary_dij &lt;- customer_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;ij&quot;, c_store_id = if_else(is.na(customer_id), customer_id, store_id), s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% group_by(join_type, c_store_id, s_store_id) %&gt;% summarize(n = n()) sp_print_df(customer_store_summary_dij) 14.5 Left Joins For a conceptual refresher see: left_join(superheroes, publishers) left_join(publishers, superheroes) 14.5.1 SQL Left Join Details The SQL block below shows all 10 sample customer rows in the detail output which join to 2 of the 3 rows in the store table, where the customer table is on the left and is the driving table. All the rows with customer store_id greater than 2 have null/blank store column values. customer_store_details_sloj &lt;- dbGetQuery( con, &quot;select &#39;loj&#39; join_type, customer_id, first_name, last_name, c.store_id c_store_id, s.store_id s_store_id, s.manager_staff_id, s.address_id from customer c left join store s on c.store_id = s.store_id where customer_id between 595 and 604;&quot; ) sp_print_df(customer_store_details_sloj) 14.5.2 dplyr Left Join Details The next code block shows the left join details. Note that the s_store_id column is derived via the mutate function, but not shown in the output below. Without the s_store_id column, it might accidentally be assumed that the store.store_id = customer.store_id when the store.store_id values are actually NULL/NA based on the output without the s_store_id column. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604) %&gt;% mutate(join_type = &quot;loj&quot;, s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% rename(s_address_id = address_id.y) %&gt;% select( join_type, customer_id, first_name, last_name, store_id, manager_staff_id, s_address_id ) sp_print_df(customer_store_detail_dloj) The following code block includes the derived s_store_id value. The output makes it explicit that the s_store_id value is missing. The sp_print_df function is replaced with the print function to show the actual NA values. customer_store_detail_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604) %&gt;% mutate( join_type = &quot;loj&quot;, s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id)) %&gt;% rename(c_store_id = store_id, s_address_id = address_id.y) %&gt;% select( customer_id, first_name, last_name, c_store_id, s_store_id, manager_staff_id, s_address_id ) print(customer_store_detail_dloj) ## customer_id first_name last_name c_store_id s_store_id manager_staff_id ## 1 595 Terrence Gunderson 1 1 1 ## 2 596 Enrique Forsythe 1 1 1 ## 3 597 Freddie Duggan 1 1 1 ## 4 598 Wade Delvalle 1 1 1 ## 5 599 Austin Cintron 2 2 2 ## 6 600 Sophie Yang 3 NA NA ## 7 601 Sophie Yang 2 2 2 ## 8 602 John Smith 4 NA NA ## 9 603 Ian Frantz 5 NA NA ## 10 604 Ed Borasky 6 NA NA ## s_address_id ## 1 1 ## 2 1 ## 3 1 ## 4 1 ## 5 2 ## 6 NA ## 7 2 ## 8 NA ## 9 NA ## 10 NA In the remaining examples, the dplyr code blocks will show both the customer and store store_id values with the either c_ or s_ store_id prefix . The sp_print_df function returns the SQL NULL and R NA values as blanks. 14.5.3 SQL Left Join Summary For a left outer join between two tables, it does matter which table is on the left and which is on the right, because every row in the left table is returned when there is no where/filter condition. The second table returns row column values if the join condition exists or null collumn values if the join condition does not exist. The left join is the most frequently used join type. Note that SQL returns the store_id from both the customer and store tables, due to c.store_id, s.store_id, in the select clause. customer_store_summary_sloj &lt;- dbGetQuery( con, &quot;select c.store_id c_store_id, s.store_id s_store_id, count(*) loj from customer c left join store s on c.store_id = s.store_id group by c.store_id, s.store_id order by c.store_id;&quot; ) sp_print_df(customer_store_summary_sloj) The lojs column returns the number of rows found on the store_id, from the customer table and the store table if on both tables, rows 1 - 2. The right table, the store table returned blank/NA, when the key only exists in the customer table, rows 3 - 6. The left outer join always returns all rows from the left table, the driving/key table, if not reduced via a filter()/where clause. All inner join rows can reference all columns/derived columns specified in the select clause from both the left and right tables. All rows from the left table, the outer table, without a matching row on the right returns all the columns/derived column values specified in the select clause from the left, but the values from right table have all values of NA. 14.5.4 dplyr Left Join Summary The dplyr outer join verbs do not return the non-driving table join values. Compare the mutate verb parameter, s_store_id, in the code block below with s.store_id in the equivalent SQL code block above. customer_store_summary_dloj &lt;- customer_table %&gt;% left_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;loj&quot;, s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% group_by(join_type, store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% rename(c_store_id = store_id) %&gt;% select(join_type, c_store_id, s_store_id, n) sp_print_df(customer_store_summary_dloj) print(customer_store_summary_dloj) ## # A tibble: 6 x 4 ## # Groups: join_type, c_store_id [6] ## join_type c_store_id s_store_id n ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 loj 1 1 326 ## 2 loj 2 2 274 ## 3 loj 3 NA 1 ## 4 loj 4 NA 1 ## 5 loj 5 NA 1 ## 6 loj 6 NA 1 14.6 Why Include one of the Inner Join Key columns? It is not uncommon to have many many tables joined together as a series of left outer joins. If the inner join key column is included in the output, one knows that the inner join condition was met or not. If the key column is not shown and non-key columns are shown from the inner table, they may actually be null. It is often the case that a long series of left outer joins just join on the key column to get one value out of the table to join to the next table in the series. One can think of the two components of an inner join as a transaction that is either in: an open state with no matching rows in the inner table; or a closed state with one or more matching rows in the inner table. Assume that we have a four DVD rental step process represented via table A, B, C, and D left outer joined together. Summing the null and non-null keys together across all four tables gives a quick snap shot of the business in the four different steps. We will review this concept in some detail in one of the future exercises. 14.7 Right Joins 14.7.1 SQL Right Join Details The SQL block below shows only our sample customer rows, (customer_id between 595 and 604). The driving table is on the right, the store table. Only six of the 10 sample customer rows appear which have store_id = {1, 2}. All three store rows appear, row_id = {1, 2, 10}. The right join is the least frequently used join type. customer_store_detail_sroj &lt;- dbGetQuery( con, &quot;select &#39;roj&#39; join_type, customer_id, first_name, last_name, c.store_id c_store_id, s.store_id s_store_id, s.manager_staff_id, s.address_id from customer c right join store s on c.store_id = s.store_id where coalesce(customer_id,595) between 595 and 604;&quot; ) sp_print_df(customer_store_detail_sroj) Compare the SQL left join where clause where customer_id between 595 and 604 with the SQL right join where clause where coalesce(customer_id,595) between 595 and 604 The customer table is the driving table in the left join and always returns all rows from the customer table on the left that match the join and satisfy the where clause. The store table is the driving table in the right join and always returns all rows from the store table on the right that match the join and satisfy the where clause. The right outer join condition shown always returns the store.store_id=10 row. Since the customer table does not have the corresponding row to join to, the right outer join returns a customer row with all null column values. The coalesce is a NULL if-then-else test. If the customer_id is null, it returns 595 to prevent the store_id = 10 row from being dropped from the result set. The right outer join clause can be rewritten as where customer_id between 595 and 604 or customer_id is null; See the next dplyr code block to see the alternative where clause shown above. 14.7.2 dplyr Right Join Details customer_store_detail_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate( join_type = &quot;roj&quot;, c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename( s_store_id = store_id, s_address_id = address_id.y ) %&gt;% select( customer_id, first_name, last_name, s_store_id, c_store_id, manager_staff_id, s_address_id ) sp_print_df(customer_store_detail_droj) 14.7.3 SQL Right Outer Join Summary customer_store_summary_sroj &lt;- dbGetQuery( con, &quot;select &#39;roj&#39; join_type, c.store_id c_store_id, s.store_id s_store_id, count(*) rojs from customer c right outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id;&quot; ) sp_print_df(customer_store_summary_sroj) The rojs column returns the number of rows found on the keys from the right table, store, and the left table, the customer table. The right outer join always returns all rows from the right table, the driving/key table, if not reduced via a filter()/where clause. Right outer join returns all the columns/derived columns specified in the select clause from both the left and right tables. All rows from the right table, the outer table, without a matching row on the left returns all the columns/derived column values specified in the select clause from the right, but the values from left table have all values of NA. For example, see the row above where store.store_id = 10 and c_store_id is NULL. 14.7.4 dplyr Right Join Summary customer_store_summary_droj &lt;- customer_table %&gt;% right_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;)), all = store_table) %&gt;% mutate( c_store_id = if_else(is.na(customer_id),customer_id, store_id), join_type = &quot;rojs&quot; ) %&gt;% group_by(join_type, store_id, c_store_id) %&gt;% summarize(n = n()) %&gt;% rename(s_store_id = store_id) %&gt;% select(join_type, s_store_id, c_store_id, n) sp_print_df(customer_store_summary_droj) 14.8 Full Join For a conceptual refresher see: full_join(superheroes, publishers) 14.8.1 SQL Full Join Details The full outer join is a combination of the left and right outer joins and returns all matched and unmatched rows from the ON clause. The matched rows return their table column values and the unmatched rows return NULL column values. This can result in a very large result set. The next SQL block implements a full outer join and returns 11 rows. Change the Show entries field from 10 to 25 to see all the entries. customer_store_details_sfoj &lt;- dbGetQuery( con, &quot;select &#39;foj&#39; join_type, c.customer_id, c.first_name, c.last_name, c.store_id c_store_id, s.store_id s_store_id, s.manager_staff_id,s.address_id from customer c full outer join store s on c.store_id = s.store_id where coalesce(c.customer_id,595) between 595 and 604;&quot; ) sp_print_df(customer_store_details_sfoj) 14.8.2 dplyr Full Join Details customer_store_detail_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter((customer_id &gt;= 595 &amp; customer_id &lt;= 604) | is.na(customer_id)) %&gt;% mutate( join_type = &quot;roj&quot;, c_store_id = if_else(is.na(customer_id), customer_id, store_id) ) %&gt;% rename( s_store_id = store_id, s_address_id = address_id.y ) %&gt;% select(customer_id, first_name, last_name, s_store_id, c_store_id, manager_staff_id, s_address_id) sp_print_df(customer_store_detail_dfoj) 14.8.3 SQL Full Join Summary The result set below is ordered by the store.store_id. customer_store_summary_sfoj &lt;- dbGetQuery( con, &quot;select &#39;foj&#39; join_type, c.store_id c_store_id, s.store_id s_store_id, count(*) fojs from customer c full outer join store s on c.store_id = s.store_id group by c.store_id,s.store_id order by s.store_id,c.store_id;&quot; ) sp_print_df(customer_store_summary_sfoj) 14.8.4 dplyr Full Join Summary The full outer join summary has seven rows. Store_id = {1, 2} values appear in both tables. Store_id = {3 - 6} appear only in the customer table which is on the left. Store_id = 10 appears only in the store table which is on the right. customer_store_summary_dfoj &lt;- customer_table %&gt;% full_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate( join_type = &quot;fojs&quot;, c_store_id = if_else(is.na(customer_id), customer_id, store_id), s_store_id = if_else(is.na(manager_staff_id), manager_staff_id, store_id) ) %&gt;% group_by(join_type, c_store_id, s_store_id) %&gt;% summarize(n = n()) %&gt;% arrange(s_store_id) sp_print_df(customer_store_summary_dfoj) 14.9 Semi Join For a conceptual refresher see: semi_join(publishers, superheroes) Below is the dplyr semi_join documentation: semi_join() return all rows from x where there are matching values in y, keeping just columns from x. A semi join differs from an inner join because an inner join will return one row of x for each matching row of y, where a semi join will never duplicate rows of x. The semi join always returns one and only one row from the x table that satisfies the inner join condition. If we look at one key value on both x and y where the x table has 1 x.key row and y has n y.key rows, then the inner join returns n x.key rows, (1-to-n), and the semi-join returns just one x.key row, (1-to-1). 14.9.1 SQL Semi Join Customer to Store SQL does not have an explicit semi join key word. The semi join reduces relationships from 1-to-n to 1-to-1. SQL uses an EXISTS - subquery syntax to implement the semi join. 14.9.1.1 SQL EXISTS and Correlated SubQuery Syntax SELECT * FROM table1 l WHERE EXISTS(SELECT 1 FROM table2 r WHERE l.c = r.c) The EXISTS keyword checks if one or more rows satisfy the SELECT clause enclosed in parenthesis, the correlated subquery. The r.c column from table2, the inner/right table, is correlated to the l.c column from table1, the outer/left table. For all the table1 rows where the EXISTS clause returns TRUE, the table1 rows are returned. There is no way to reference table2 columns in the outer select, hence the semi join. All the previous joins were mutating joins, meaning the joins resulted in a blending of columns from both tables. A semi join only returns rows from a single table and is a filtering join. The mutating examples included a count column to show the 1-to-n relationships. Filtering joins are 1-to-1 and the count column is dropped in the following examples. customer_store_ssj &lt;- dbGetQuery( con, &quot;select &#39;sj&#39; join_type, customer_id, first_name, last_name, c.store_id c_store_id from customer c where customer_id &gt; 594 and exists( select 1 from store s where c.store_id = s.store_id ); ;&quot;) sp_print_df(customer_store_ssj) Note that this returned the six rows from the customer table that satisfied the c.store_id = s.store_id join condition. It is the same as the SQL Inner Join example earlier, but without the store columns. All the relationships are 1-to-1. 14.9.2 dplyr Semi Join Customer to Store The corresponding dplyr version is shown in the next code block. customer_store_dsj &lt;- customer_table %&gt;% semi_join(store_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% filter(customer_id &gt;= 595 &amp; customer_id &lt;= 604 ) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type, customer_id, first_name, last_name, store_id, store_id) sp_print_df(customer_store_dsj) 14.9.3 SQL Semi Join Store to Customer In the following Semi Join, the driving table is switched to the store table and our 10 sample customers as the right table. store_customer_detail_ssj &lt;- dbGetQuery( con, &quot;select &#39;sj&#39; join_type, s.store_id s_store_id, s.manager_staff_id, s.address_id from store s where EXISTS( select 1 from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) ;&quot;) sp_print_df(store_customer_detail_ssj) Here we see that we get the two rows from the store table that satisfy the s.store_id = c.store_id condition, where store_id = {1, 2}. In this example the relationship between store and customer is 1-to-n, but we do not know that from the output. 14.9.4 dplyr Semi Join Store to Customer The corresponding dplyr version is shown in the next code block. Note that the filter condition on the customer table has been removed because the semi_join does not return any customer columns. store_customer_dsj &lt;- store_table %&gt;% semi_join(customer_table, by = c(&quot;store_id&quot; = &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &#39;sj&#39;) %&gt;% select(join_type, store_id, manager_staff_id, address_id) sp_print_df(store_customer_dsj) 14.9.5 SQL Semi Join Store to Customer Take 2 In the Semi Join Customer to Store examples, we saw four rows with store_id = 1 and two rows with store_id = 2. The EXISTS key word is replaced with a count of the matching rows. store_customer_detail_ssj2 &lt;- dbGetQuery( con, &quot;select &#39;sj&#39; join_type, s.store_id s_store_id, s.manager_staff_id, s.address_id from store s where (select count(*) from customer c where c.store_id = s.store_id and c.customer_id between 595 and 604 ) in (2, 4) ;&quot;) sp_print_df(store_customer_detail_ssj2) To generalize the test above, replace in (2, 4) with &gt; 0. 14.10 Anti Joins For a conceptual refresher see: anti_join(superheroes, publishers) anti_join(publishers, superheroes) A semi join returns rows from one table that has one or more matching rows in the other table. The anti join returns rows from one table that has no matching rows in the other table. 14.10.0.1 dplyr::anti_join The anti join is an outer join without the inner joined rows. It only returns the rows from the driving table that do not have a matching row from the other table. customer_store_aj &lt;- customer_table %&gt;% filter(customer_id &gt; 594) %&gt;% anti_join(store_table, by = c(&quot;store_id&quot;, &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) %&gt;% mutate(join_type = &quot;anti_join&quot;) sp_print_df(customer_store_aj) All of the rows returned from the customer table have store_id = {3 - 6} which do not exist in the store_id. 14.10.0.2 SQL anti Join 1, NOT EXISTS and Correlated subquery SQL doesnt have an anti join key word. Here are three different ways to achieve the same result. This is the negation of the same construct used in the semi join discusion. The anti-join tests for 0 matches instead of 1 or more matches for the semi-join. rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where not exists ( select 1 from store s where s.store_id = c.store_id ) order by c.customer_id&quot; ) sp_print_df(rs) 14.10.0.3 SQL anti Join 2, Left Outer Join where NULL on Right rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id ajs from customer c left outer join store s on c.store_id = s.store_id where s.store_id is null order by c.customer_id;&quot; ) sp_print_df(rs) 14.10.0.4 SQL anti Join 3, ID in driving table and NOT IN lookup table rs &lt;- dbGetQuery( con, &quot;select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id from customer c where c.store_id NOT IN (select store_id from store) order by c.customer_id;&quot; ) sp_print_df(rs) 14.11 Non-Equi-Join Example All the previous examples are equi-joins, which is the most common type of join. The next example is made up and shows a &lt;= join. The store table is used. Assume that the store_id actually represents some distance. The example shows all distances &lt;= to all other distances. store_store_slej &lt;- dbGetQuery( con, &quot;select &#39;lej&#39; join_type, s1.store_id starts, s2.store_id stops, s2.store_id - s1.store_id delta from store s1 join store s2 on s1.store_id &lt;= s2.store_id order by s1.store_id;&quot; ) sp_print_df(store_store_slej) 14.11.1 dplyr Non-equi Join dplyr doesnt currently support a non-equi join. In the by parameter, one can not change the = to &lt;= as shown below. {r} store_store_slej &lt;- store_table %&gt;% inner_join(store_table, by = c(&quot;store_id&quot; &lt;= &quot;store_id&quot;), suffix(c(&quot;.c&quot;, &quot;.s&quot;))) The above code block throws the following error message. Error: `by` must be a (named) character vector, list, or NULL for natural joins (not recommended in production code), not logical Call `rlang::last_error()` to see a backtrace The explanation below is from here, a Stack Overflow discussion that was posted Nov 25, 2017. In by = c(\"col1\" = \"col2\"), = is not the equality operator, but an assignment operator (the equality operator in R is ==). The expression inside c(...) creates a named character vector (name: col1 value: col2) that dplyr uses for the join. Nowhere do you define the kind of comparison that is made during the join. The comparison is hard-coded in dplyr. I dont think dplyr supports non-equi joins (yet). # disconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-metadata-exercises.html", "Chapter 15 SQL Metadata exercises 15.1 Table Structures 15.2 Table Column Metadata 15.3 Primary and Foreign Key Constraints 15.4 We need documentation and/or a DBA.", " Chapter 15 SQL Metadata exercises This chapter demonstrates: Finding table column metadata for any specific table Finding the primary and foreign keys for any specific table Reusing SQL via parameterization Why understanding the contents of a database requires a team approach. Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; 58 seconds ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 15.1 Table Structures 15.1.1 Customer Columns In an earlier chapter we used functions dbListTable and dbListFields from the DBI package to get a list of tables and the fields in a table. Below we list out the columns from the customer table. dbListFields(con, &quot;customer&quot;) ## [1] &quot;customer_id&quot; &quot;store_id&quot; &quot;first_name&quot; &quot;last_name&quot; &quot;email&quot; ## [6] &quot;address_id&quot; &quot;activebool&quot; &quot;create_date&quot; &quot;last_update&quot; &quot;active&quot; A couple of things immediately jump out based on the column names: There are three *_id columns, customer_id, store_id, and address_id. ID columns are typically an integer type. It is common convention to have the table primary key column(s) at the beginning of the table or a set of columns at the beginning of the table that make the row unique. Just looking at the column names, one cannot tell if the customer is uniquely identified by just the customer_id or the customer_id + store_id. Are there customers who visit both stores? Based on the column names, it looks like there are three string/character columns, first_name, last_name, and email. What are the sizes of these colums? There are two dates, create_date and last_update. There are two active columns, activebool and active. The activebool looks like it is a boolean column. What type of column is active, integer or text? Databases maintains a data dictionary of metadata on all the database objects. SQL databases have two useful tables for getting table and table column information, information_schema.tables and information_schema.columns. AS an example, the following code block returns a summary of the number of tables and views in the differnt schemas. The tables and views associated with DVD Rentals are in the public table_schema. The metadata of the tables and views in the public table_schema are contained in the information_schema. The information_schema provides information about all of the tables, views, columns, and procedures in the entire database, not just DVD Rentals. We are interested in the tables and columns views. info_schema &lt;- dbGetQuery(con ,&quot;Select t.table_catalog ,t.table_schema ,t.table_name ,t.table_type from information_schema.tables t where t.table_schema = &#39;information_schema&#39; and table_name in (&#39;tables&#39;,&#39;columns&#39;) &quot;) sp_print_df(info_schema) 15.2 Table Column Metadata The next code block uses the information_schema.columns to return column information from any table in the Dvdrental database. This code block is an example of a parameterized R function, sp_tbl_descr, sql pet table description. Sp_tbl_descr uses the dvdrental.information_schema.columns table to return some of the metadata on a dvdrental table. The function is restricted to the dvdrenatal database, see the where clause and c.table_catalog = 'dvdrental'. The function has one parameter passed it, table_name. Parameter substitution occurs in the where clause, and c.table_name = $1. The paramter substituion variable syntax depends on the vendor. The dbGetQuery documentation shows con &lt;- dbConnect(RSQLite::SQLite(), &quot;:memory:&quot;) dbGetQuery(con, &quot;SELECT COUNT(*) FROM mtcars WHERE cyl = ?&quot;, param = list(1:8)) 15.2.1 sp_tbl_descr  Parameterized Table Description Function sp_tbl_descr &lt;- function (table_name) { dbGetQuery( con, &quot;select btrim(c.table_name) table_name, c.ordinal_position seq , c.column_name COL_NAME , case when c.udt_name = &#39;varchar&#39; then c.udt_name || case when c.character_maximum_length is not null then &#39;(&#39;||cast(c.character_maximum_length as varchar)||&#39;)&#39; else &#39;&#39; end when c.udt_name like (&#39;int%&#39;) then c.udt_name ||&#39;-&#39;||cast(c.numeric_precision as varchar) else c.udt_name end COL_TYPE , c.is_nullable is_null -- , c.column_default -- , t.table_catalog ,t.table_schema from dvdrental.information_schema.columns c join information_schema.tables t on c.table_name = t.table_name where 1 = 1 and c.table_catalog = &#39;dvdrental&#39; and c.table_name = $1&quot; ,table_name ) } The next code block returns the customer metadata via a call to the previous function. sp_tbl_descr(&#39;customer&#39;) ## table_name seq col_name col_type is_null table_schema ## 1 customer 1 customer_id int4-32 NO public ## 2 customer 2 store_id int2-16 NO public ## 3 customer 3 first_name varchar(45) NO public ## 4 customer 4 last_name varchar(45) NO public ## 5 customer 5 email varchar(50) YES public ## 6 customer 6 address_id int2-16 NO public ## 7 customer 7 activebool bool NO public ## 8 customer 8 create_date date NO public ## 9 customer 9 last_update timestamp YES public ## 10 customer 10 active int4-32 YES public The metadata tells us the length of the three varchar, variable length, columns. We can see that our two date columns are of different types, date and timestamp. is_null=NO tells us the column is required to have a value non-null value. is_null=YESotherwise it can be null. The activebool is either true or false. Without a definitive description of the column, we will assume that the customer is active, activebool=true or inactive, activebool=false. The active column, an int4 data type, can take on a large set of values. Why would an application need two active indicators? 15.3 Primary and Foreign Key Constraints The database or application designers implement constraints to help maintain referential integrity and improve database performance. One is the implementation of a primary key which must be unique for each row in the table. The primary key is usually defined as the first column. On occasion the primary key consists of multiple columns and none of these columns can be null. Looking back to the customer columns, what is the customer table primary key, customer_id or customer_id + store_id? The other constraint is a foreign key constraint which is one or more columns in one table that make up a primary key in another table. From the DVD Rental ERD, here, one can see that out of the 15 tables in the ERD, all but two tables have a single column primary key, film_category and the film_actor tables have two columns that define the primary key. The primary key columns have an asterisk to the left of the column name. For the single column keys, the primary key column is the name of the table suffixed with _id. The customer primary key is just customer_id column. Is the customer.store_id a foreign key to the store table? Based on ERD, the customer.store_id is not a foreign key to the store table. The next code block uses many information_schema objects to return a tables primary and foreign keys for any table in the Dvdrental database. This code block is another example of a parameterized R function, sp_tbl_pk_fk, sql pet table primary key and foreign keys. Not all tables are required to have a primary key. If a table has one The function returns one or more columns that make up the table primary key. The function also returns any other table that has a foreign key reference to the table. The function is restricted to the Dvdrenatal database, see the where clause and c.table_catalog = 'dvdrental'. The function is restricted to the public schema where the Dvd rental table/views are kept, see the where clause c.table_schema = public. The function has one parameter passed it, table_name. Parameter substitution occurs in the where clause, AND (c.table_name = $1 or coalesce(c2.table_name, '') = $1). The paramter substituion occurs to see if the table_name passed has a primary key or refereced as a foreign table. 15.3.1 sp_tbl_pk_fk  Parameterized Table Primary Foreign Key(s) Function sp_tbl_pk_fk_sql &lt;- function(table_name) { dbGetQuery(con ,&quot;SELECT c.table_name ,kcu.column_name ,c.constraint_name ,c.constraint_type ,coalesce(c2.table_name, &#39;&#39;) ref_table ,coalesce(kcu2.column_name, &#39;&#39;) ref_table_col FROM information_schema.tables t LEFT JOIN information_schema.table_constraints c ON t.table_catalog = c.table_catalog AND t.table_schema = c.table_schema AND t.table_name = c.table_name LEFT JOIN information_schema.key_column_usage kcu ON c.constraint_schema = kcu.constraint_schema AND c.constraint_name = kcu.constraint_name LEFT JOIN information_schema.referential_constraints rc ON c.constraint_schema = rc.constraint_schema AND c.constraint_name = rc.constraint_name LEFT JOIN information_schema.table_constraints c2 ON rc.unique_constraint_schema = c2.constraint_schema AND rc.unique_constraint_name = c2.constraint_name LEFT JOIN information_schema.key_column_usage kcu2 ON c2.constraint_schema = kcu2.constraint_schema AND c2.constraint_name = kcu2.constraint_name AND kcu.ordinal_position = kcu2.ordinal_position WHERE c.constraint_type IN (&#39;PRIMARY KEY&#39;, &#39;FOREIGN KEY&#39;) AND c.table_catalog = &#39;dvdrental&#39; AND c.table_schema = &#39;public&#39; AND (c.table_name = $1 or coalesce(c2.table_name, &#39;&#39;) = $1) ORDER BY c.table_name,c.constraint_type desc&quot; ,param = list(table_name) ) } 15.3.2 Customer primary and foreign key constraints The next code block returns the customer primary and foreign key metadata via a call to the previous function. sp_tbl_pk_fk_sql(&#39;customer&#39;) ## table_name column_name constraint_name constraint_type ## 1 customer customer_id customer_pkey PRIMARY KEY ## 2 customer address_id customer_address_id_fkey FOREIGN KEY ## 3 payment customer_id payment_customer_id_fkey FOREIGN KEY ## 4 rental customer_id rental_customer_id_fkey FOREIGN KEY ## ref_table ref_table_col ## 1 ## 2 address address_id ## 3 customer customer_id ## 4 customer customer_id The table above tells us: The customer has customer_id as the primary key which matches the ERD. The customer address_id is a foreign key to the address table, the ref_table column and joins on the ref_table_col, address_id. The payment and rental tables have customer_id as a foreign key back to the customer table. The ERD matches the Primary and Foreign Key information in the table above. 15.4 We need documentation and/or a DBA. The output above shows that the store_id column is not part of the customer primary key and it isnt foreign key to the store table. Some possible explanations are: The ERD is incomplete or it excluded some foreign keys to highlight other relationships. The SQL above is wrong. The customer-store foreign key constraint was just missed. On large systems this is not out of the realm of possibilities. The customer-store foreign key constraint was diabled. The customer-store foreign key constraint was designed out of the system. The DBA team or project documentation may help explain The true relation between the customer and store tables. Why there are two customer active columns, activebool and active. Some possible explanation for the two active columns are: The application vendor adds new functionality resulting in new columns being added to a table dropping a table and migrating the old data into one or more new tables splitting a table into one or more tables Sometimes applications are migrated from one vendors RDBMS to a different vedors RDBMS which usually introduces some kind of incompatability. A company has its own DBAs add columns to a table to reflect new business requirements. All the existing records are updated to reconstruct the new data for the new columns or All the existing columns are defaulted to a single value. There is a break in the meaning of the new columns between the existing records and new records. The business DBAs add new columns are added to tables to reflect some new business requirements. New columns are typically added to the end of the table. If a table is wide and the new column is at the end, it is very easy to miss the new column when having to scroll across the screen to find it. See figure 1 here for another ERD. What does this ERD tell us about the relationship between the customer and store tables? See the customer table column description here. What can we learn about the active column from this link? 15.4.1 Other Table Column Metadata In the next code block, change the function parameter to different table names to get the associated column metadata. If necessary, uncomment the dbListTable line to get a list of table names. #dbListTables(con) sp_tbl_descr(&#39;customer&#39;) ## table_name seq col_name col_type is_null table_schema ## 1 customer 1 customer_id int4-32 NO public ## 2 customer 2 store_id int2-16 NO public ## 3 customer 3 first_name varchar(45) NO public ## 4 customer 4 last_name varchar(45) NO public ## 5 customer 5 email varchar(50) YES public ## 6 customer 6 address_id int2-16 NO public ## 7 customer 7 activebool bool NO public ## 8 customer 8 create_date date NO public ## 9 customer 9 last_update timestamp YES public ## 10 customer 10 active int4-32 YES public 15.4.2 Other Table PK FK In the next code block, change the function parameter to different table names to get the associated PK and FK associated wih the table. #dbListTables(con) sp_tbl_pk_fk_sql(&#39;customer&#39;) ## table_name column_name constraint_name constraint_type ## 1 customer customer_id customer_pkey PRIMARY KEY ## 2 customer address_id customer_address_id_fkey FOREIGN KEY ## 3 payment customer_id payment_customer_id_fkey FOREIGN KEY ## 4 rental customer_id rental_customer_id_fkey FOREIGN KEY ## ref_table ref_table_col ## 1 ## 2 address address_id ## 3 customer customer_id ## 4 customer customer_id "],
["chapter-sql-joins-exercises.html", "Chapter 16 SQL Joins Exercises 16.1 Exercise Instructions 16.2 Dplyr tables 16.3 Overview Exercise 16.4 Exercises 16.5 Diconnect from the db and clean up", " Chapter 16 SQL Joins Exercises This chapter contains questions one may be curious about or asked about the DVD Rental business. The goal of the exercises is extracting useful or questionable insights from one or more tables. Each exercise has has some or all of the following parts. The question. The tables used to answer the question. A hidden SQL code block showing the desired output. Click the code button to see the SQL code. A table of derived values or renamed columns shown in the SQL block to facilitate replicating the desired dplyr solution. Abbreviated column names are used to squeeze in more columns into the answer to reduce scrolling across the screen. A replication section where you recreate the desired output using dplyr syntax. Most columns come directly out of the tables. Each replication code block has three commented function calls sp_tbl_descr(store) describes a table, store sp_tbl_pk_fk(table_name) shows a tables primary and foreign keys sp_print_df(table_rows_sql) shows table row counts. To keep the exercises concentrated on the joins, all derived dates drop their timestamp. SQL syntax: date_column::DATE Dplyr syntax: as.date(date_column) 16.1 Exercise Instructions Manually execute all the code blocks up-to the SQL Union Exercise. Most of the exercises can be performed in any order. There are function exercises that create a function followed by another code block to call the function in the previous exercise. Use the Show Document Outline, CTL-Shift-O, to navigate to the different exercises. Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;1918fe2a68e7 postgres-dvdrental \\&quot;docker-entrypoint.s\\&quot; About a minute ago Up 3 seconds 5432/tcp, 0.0.0.0:5439-&gt;5439/tcp sql-pet&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; About a minute ago Up 3 seconds 5432/tcp, 0.0.0.0:5439-&gt;5439/tcp sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 16.2 Dplyr tables All the tables defined in the DVD Rental System will fit into memory which is rarely the case when working with a database. Instead of loading all the DVD Rental System tables into memory via a DBI::dbReadTable, each table is loaded into an R object named TableName_table, via a dplyr::tbl call. actor_table &lt;- dplyr::tbl(con,actor) source(here::here(&#39;book-src&#39;,&#39;dvdrental-table-declarations.R&#39;),echo=FALSE) The following code block deletes and inserts records into the different tables used in the exercises in this chpater. The techniques used in this code block are discussed in detail in the appendix, ??add link here.?? source(file=here(&#39;book-src/sql_pet_data.R&#39;),echo=FALSE) 16.3 Overview Exercise When joining many tables, it is helpful to have the number of rows from each table as an initial sanity check that the joins are returning a reasonable number of rows. 16.3.1 1. How many rows are in each table? table_rows_sql &lt;- dbGetQuery( con, &quot;select * from ( select &#39;actor&#39; tbl_name,count(*) from actor union select &#39;category&#39; tbl_name,count(*) from category union select &#39;film&#39; tbl_name,count(*) from film union select &#39;film_actor&#39; tbl_name,count(*) from film_actor union select &#39;film_category&#39; tbl_name,count(*) from film_category union select &#39;language&#39; tbl_name,count(*) from language union select &#39;inventory&#39; tbl_name,count(*) from inventory union select &#39;rental&#39; tbl_name,count(*) from rental union select &#39;payment&#39; tbl_name,count(*) from payment union select &#39;staff&#39; tbl_name,count(*) from staff union select &#39;customer&#39; tbl_name,count(*) from customer union select &#39;address&#39; tbl_name,count(*) from address union select &#39;city&#39; tbl_name,count(*) from city union select &#39;country&#39; tbl_name,count(*) from country union select &#39;store&#39; tbl_name,count(*) from store ) counts order by tbl_name ; &quot; ) sp_print_df(table_rows_sql) 16.3.1.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) table_rows_dplyr &lt;- as.data.frame(actor_table %&gt;% mutate(name = &quot;actor&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n())) %&gt;% union(as.data.frame(address_table %&gt;% mutate(name = &quot;address&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% arrange(name) sp_print_df(table_rows_dplyr) 16.4 Exercises 16.4.1 1. Where is the DVD Rental Business located? To answer this question we look at the store, address, city, and country tables to answer this question. store_locations_sql &lt;- dbGetQuery(con, &quot;select s.store_id ,a.address ,c.city ,a.district ,a.postal_code ,c2.country ,s.last_update from store s join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_locations_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. 16.4.1.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_locations_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(store_locations_dplyr) 16.4.2 2. List Each Store and the Staff Contact Information? To answer this question we look at the store, staff, address, city, and country tables. store_employees_sql &lt;- dbGetQuery(con, &quot;select st.store_id ,s.first_name ,s.last_name ,s.email ,a.phone ,a.address ,c.city ,a.district ,a.postal_code ,c2.country from store st left join staff s on st.manager_staff_id = s.staff_id left join address a on s.address_id = a.address_id left join city c on a.city_id = c.city_id left join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_employees_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each, Mike Hillyer and Jon Stephens respectively. The store in the United States has no employees yet. 16.4.2.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_employees_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(store_employees_dplyr) 16.4.3 3. How Many Active, Inactive, and Total Customers Does the DVD Rental Business Have? To answer this question we look at the customer table. In a previous chapter we observed that there are two columns, activebool and active. We consider active = 1 as active. customer_cnt_sql &lt;- dbGetQuery(con, &quot;SELECT sum(case when active = 1 then 1 else 0 end) active ,sum(case when active = 0 then 1 else 0 end) inactive ,count(*) total from customer &quot;) sp_print_df(customer_cnt_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each. The store in the United States has no employees yet. The business has 604 international customers, 589 are active and 15 inactive. 16.4.3.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_cnt_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customer_cnt_dplyr) 16.4.4 4. How Many and What Percent of Customers Are From Each Country? To answer this question we look at the customer, address, city, and country tables. customers_sql &lt;- dbGetQuery(con, &quot;select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country order by count(*) desc &quot;) sp_print_df(customers_sql) Based on the table above, the DVD Rental business has customers in 118 countries. The DVD Rental business cannot have many walk in customers. It may possibly use a mail order distribution model. For an international company, how are the different currencies converted to a standard currency? Looking at the ERD, there is no currency conversion rate. 16.4.4.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customers_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customers_dplyr) 16.4.5 5 What Countries Constitute the Top 25% of the Customer Base? Using the previous code, add two new columns. One column shows a running total and the second column shows a running percentage. Order the data by count then by country. To answer this question we look at the customer, address, city, and country tables again. country_sql &lt;- dbGetQuery(con, &quot;select active,country,count ,sum(count) over (order by count desc,country rows between unbounded preceding and current row) running_total , pct ,sum(pct) over (order by pct desc,country rows between unbounded preceding and current row) running_pct from (-- Start of inner SQL Block select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country ) ctry -- End of inner SQL Block order by count desc,country &quot;) sp_print_df(country_sql) The top 25% of the customer base are from India, China, the United States, and Japan. The next six countries, the top 10, Mexico, Brazil, Russian Federation, Philipines, Indonesia, and Turkey round out the top 50% of the businesses customer base. 16.4.5.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) country_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(country_dplyr) 16.4.6 6. How many customers are in Australia and Canada? To answer this question we use the results from the previous exercise. country_au_ca_sql &lt;- country_sql %&gt;% filter(country == &#39;Australia&#39; | country == &#39;Canada&#39;) sp_print_df(country_au_ca_sql) There are 10 customers in Austrailia and Canada where the brick and mortar stores are located. The 20 customers are less than 2% of the world wide customer base. 16.4.6.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) country_au_ca_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(country_au_ca_dplyr) 16.4.7 7. How Many Languages? With an international customer base, how many languages does the DVD Rental business distribute DVDs in. To answer this question we look at the language table. languages_sql &lt;- dbGetQuery(con, &quot; select * from language &quot;) sp_print_df(languages_sql) DVDs are distributed in six languages. 16.4.7.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) # languages_dplyr &lt;- as.data.frame(&quot;code me&quot;) # # sp_print_df(language_table) 16.4.8 8. What is the distribution of DVDs by Language To answer this question we look at the language and film tables. language_distribution_sql &lt;- dbGetQuery(con, &#39; select l.language_id,name &quot;language&quot;,count(f.film_id) from language l left join film f on l.language_id = f.language_id group by l.language_id,name order by l.language_id &#39;) sp_print_df(language_distribution_sql) This is a surprise. For an international customer base, the entire stock of 1001 DVDs are in English only. 16.4.8.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) language_distribution_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(language_distribution_dplyr) 16.4.9 9. What are the number of rentals and rented amount by store, by month? To answer this question we look at the rental, inventory, and film tables to answer this question. store_rentals_by_mth_sql &lt;- dbGetQuery(con, &quot;select * ,sum(rental_amt) over (order by yyyy_mm,store_id rows between unbounded preceding and current row) running_rental_amt from (select yyyy_mm,store_id,rentals,rental_amt ,sum(rentals) over(partition by yyyy_mm order by store_id) mo_rentals ,sum(rental_amt) over (partition by yyyy_mm order by store_id) mo_rental_amt from (select to_char(rental_date,&#39;yyyy-mm&#39;) yyyy_mm ,i.store_id,count(*) rentals, sum(f.rental_rate) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by to_char(rental_date,&#39;yyyy-mm&#39;),i.store_id ) as details ) as mo_running order by yyyy_mm,store_id &quot;) sp_print_df(store_rentals_by_mth_sql) The current entry, row 11, is our new rental row we added to show the different joins in a previous chapter. 16.4.9.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_rentals_by_mth_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(head(store_rentals_by_mth_dplyr, n=25)) 16.4.10 10. Rank Films Based on the Number of Times Rented and Associated Revenue To answer this question we look at the rental, inventory, and film tables. film_rank_sql &lt;- dbGetQuery(con, &quot;select f.film_id,f.title,f.rental_rate,count(*) count,f.rental_rate * count(*) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.film_id,f.title,f.rental_rate order by count(*) desc&quot;) sp_print_df(film_rank_sql) The most frequently rented movie, 34 times, is Bucket Brotherhood followed by Rocketeer Mother, 33 times. 16.4.10.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rank_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_rank_dplyr) 16.4.11 11 What is the rental distribution/DVD for the top two rented films? From the previous exercise we know that the top two films are Bucket Brotherhood and Rocketeer Mother. To answer this question we look at the rental, inventory, and film tables again. Instead of looking at the film level, we need to drill down to the individual dvds for each film to answer this question. film_rank2_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id,count(*) from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where i.film_id in (103,738) group by i.store_id,i.film_id,f.title,i.inventory_id&quot;) sp_print_df(film_rank2_sql) The Bucket Brotherhood and Rocketeer Mother DVDs are equally distributed between the two stores, 4 dvds each per film. The Bucket Brotherhood was rented 17 times from both stores. The Rocketeer Mother was rented 15 times from store 1 and 18 times from store 2. 16.4.11.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rank2_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_rank2_dplyr) 16.4.12 12. List staffing information for store 1 associated with the Bucket Brother rentals? To answer this question we look at the rental, inventory, film, staff, address, city, and country tables. film_103_details_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id inv_id,i.store_id inv_store_id ,r.rental_date::date rented,r.return_date::date returned ,s.staff_id,s.store_id staff_store_id,concat(s.first_name,&#39; &#39;,s.last_name) staff,ctry.country from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join staff s on r.staff_id = s.staff_id join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where i.film_id in (103) and r.rental_date::date between &#39;2005-05-01&#39;::date and &#39;2005-06-01&#39;::date order by r.rental_date &quot;) sp_print_df(film_103_details_sql) In a previous exercise we saw that store 1 based in Canada and store 2 based in Austrailia each had one employee, staff_id 1 and 2 respectively. We see that Mike from store 1, Canada, had transactions in store 1 and store 2 on 5/25/2005. Similarly Jon from store 2, Australia, had transaction in store 2 and store 1 on 5/31/2005. Is this phsically possible, or a key in error? 16.4.12.1 Replicate the output above using dplyr syntax. column mapping definition inv_id inventory.inventory_id inv_store_id inventory.store_id rented rental.rental_date returned rental.return_date staff_store_id store.store_id staff first_name+last_name # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_103_details_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_103_details_dplyr) 16.4.13 13. Which film(s) have never been rented To answer this question we look at the film, inventory and rental tables. never_rented_dvds_sql &lt;- dbGetQuery(con, &#39;select i.store_id,f.film_id, f.title,f.description, i.inventory_id from film f join inventory i on f.film_id = i.film_id left join rental r on i.inventory_id = r.inventory_id where r.inventory_id is null &#39; ) sp_print_df(never_rented_dvds_sql) There are only two movies that have not been rented, Academy Dinousaur and Sophies Choice. 16.4.13.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) never_rented_dvds_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(never_rented_dvds_dplyr) 16.4.14 14. How many films are in each film rating? To answer this question we look at the film table to answer this question. film_ratings_sql &lt;- dbGetQuery(con, &#39;select f.rating,count(*) from film f group by f.rating order by count(*) desc &#39; ) sp_print_df(film_ratings_sql) There are 5 ratings and all 5 have roughly 200 movies. 16.4.14.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_ratings_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_ratings_dplyr) 16.4.15 15. What are the different film categories? To answer this question we look at the category table to answer this question. film_categories_sql &lt;- dbGetQuery(con, &#39;select * from category&#39; ) sp_print_df(film_categories_sql) There are 16 different categories 16.4.15.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_categories_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_categories_dplyr) 16.4.16 16. How many DVDs are in each film categeory? To answer this question we look at the category table again. film_categories2_sql &lt;- dbGetQuery(con, &#39;select c.name,count(*) count from category c join film_category fc on c.category_id = fc.category_id group by c.name order by count(*) desc &#39; ) sp_print_df(film_categories2_sql) There are 16 film categories. The highest category, Sports, has 77 films followed by the International category which has 76 film. What is an example of an international category film where all films are currently in English? 16.4.16.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_categories2_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_categories2_dplyr) 16.4.17 17. Which films are listed in multiple categories? To answer this question we look at the film, film_category and category tables. multiple_categories_sql &lt;- dbGetQuery(con, &#39;select f.film_id, f.title,c.name from film_category fc join film f on fc.film_id = f.film_id join category c on fc.category_id = c.category_id where fc.film_id in (select fc.film_id from film f join film_category fc on f.film_id = fc.film_id group by fc.film_id having count(*) &gt; 1 ) &#39; ) sp_print_df(multiple_categories_sql) There is only one film which has two categories, Sophies Choice. 16.4.17.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) multiple_categories_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(multiple_categories_dplyr) 16.4.18 18. Which DVDs are in one stores inventory but not the other In the table below we show the first 10 rows. To answer this question we look at the inventory and film tables. dvd_in_1_store_sql &lt;- dbGetQuery( con, &quot; -- select store1,count(count1) films_not_in_store_2,sum(coalesce(count1,0)) dvds_not_in_store_1 -- ,store2,count(count2) films_not_in_store_1,sum(coalesce(count2,0)) dvds_not_in_store_2 -- from ( select coalesce(i1.film_id,i2.film_id) film_id,f.title,f.rental_rate ,1 store1,coalesce(i1.count,0) count1 ,2 store2,coalesce(i2.count,0) count2 -- dvd inventory in store 1 from (select film_id,store_id,count(*) count from inventory where store_id = 1 group by film_id,store_id ) as i1 full outer join -- dvd inventory in store 2 (select film_id,store_id,count(*) count from inventory where store_id = 2 group by film_id,store_id ) as i2 on i1.film_id = i2.film_id join film f on coalesce(i1.film_id,i2.film_id) = f.film_id where i1.film_id is null or i2.film_id is null order by f.title -- ) as src -- group by store1,store2 &quot; ) if(HEAD_N &gt; 0) { sp_print_df(head(dvd_in_1_store_sql,n=HEAD_N)) } else { sp_print_df(dvd_in_1_store_sql) } Store 1 has 196 films, (576 dvds), that are not in store 2. Store 2 has 199 films, (607 dvds), that are not in store 1. 16.4.18.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) inv_tbl1 &lt;- inventory_table %&gt;% filter(store_id == 1 ) %&gt;% group_by(film_id) %&gt;% summarise(count=n()) inv_tbl2 &lt;- inventory_table %&gt;% filter(store_id == 2 ) %&gt;% group_by(film_id) %&gt;% summarise(count=n()) dvd_in_1_store_dplyr &lt;- as.data.frame(&quot;code me&quot;) if(HEAD_N &gt; 0) { sp_print_df(head(dvd_in_1_store_dplyr,n=HEAD_N)) } else { sp_print_df(dvd_in_1_store_dplyr) } 16.4.19 19. Which films are not tracked in inventory? To answer this question we look at the film and rental tables. films_no_inventory_sql &lt;- dbGetQuery(con, &quot; select f.film_id,title,rating,rental_rate,replacement_cost from film f left outer join inventory i on f.film_id = i.film_id where i.film_id is null; &quot;) if(HEAD_N &gt; 0) { sp_print_df(head(films_no_inventory_sql,n=HEAD_N)) } else { sp_print_df(films_no_inventory_sql) } There are 42 films that do not exist in inventory or in either store. These may be DVDs that have been ordered but the business has not received them. Looking at the price and the replacement cost, it doesnt look like there is any rhyme or reason to the setting of the price. 16.4.19.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) films_no_inventory_dplyr &lt;- as.data.frame(&quot;code me&quot;) if(HEAD_N &gt; 0) { sp_print_df(head(films_no_inventory_dplyr,n=HEAD_N)) } else { sp_print_df(films_no_inventory_dplyr) } 16.4.20 20 List film categories in descending accounts receivable. To answer this question we look at the rental, inventory, film, film_category and category tables. film_category_AR_rank_sql &lt;- dbGetQuery(con, &quot; select category,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select c.name category, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join film_category fc on f.film_id = fc.film_id join category c on fc.category_id = c.category_id group by c.name ) src &quot;) sp_print_df(film_category_AR_rank_sql) There are 16 film categories. The top three categories based on highest AR amounts are Sports, Drama, and Sci-Fi. The total number of rentals are 16046 with an AR amount of 47221.54. 16.4.20.1 Replicate the output above using dplyr syntax. column mapping definition category category.name ar f.rental_rate running_ar accumulated ar amounts based on ratings rentals number of rentals associated with the rating running_rentals running rating rentals # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_category_AR_rank_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_category_AR_rank_dplyr) 16.4.21 21. List film ratings in descending accounts receivable order. To answer this question we look at the rental, inventory, and film tables. film_rating_rank_sql &lt;- dbGetQuery(con, &quot;select rating,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select f.rating, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.rating ) as src &quot;) sp_print_df(film_rating_rank_sql) There are 5 film ratings. The total number of rentals are 16045 with an AR amount of 47216.55. Why do the film categories revenue and film rating revenue amounts and counts differ, 16046 and 47221.54? 16.4.21.1 Replicate the output above using dplyr syntax. column mapping definition rating film.rating ar f.rental_rate running_ar accumulated ar amounts based on ratings rentals number of rentals associated with the rating running_rentals running rating rentals # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rating_rank_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(film_rating_rank_dplyr) 16.4.22 22. How many rentals were returned on time, returned late, never returned? To answer this question we look at the rental, inventory, and film tables. returned_sql &lt;- dbGetQuery(con, &quot;with details as (select case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_days ,case when r.return_date is null then 1 else 0 end not_rtn from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id ) select sum(case when rtn_days &lt;= 0 then 1 else 0 end) on_time ,sum(case when rtn_days &gt; 0 then 1 else 0 end) late ,sum(not_rtn) not_rtn ,count(*) rented ,round(100. * sum(case when rtn_days &lt;= 0 then 1 else 0 end)/count(*),2) on_time_pct ,round(100. * sum(case when rtn_days &gt; 0 then 1 else 0 end)/count(*),2) late_pct ,round(100. * sum(not_rtn)/count(*),2) not_rtn_pct from details &quot;) sp_print_df(returned_sql) To date 53.56% of the rented DVDs were returned on time, 45.30% were returned late, and 1.14% were never returned. 16.4.22.1 Replicate the output above using dplyr syntax. column mapping definition on_time number of DVDs where rental.return_date &lt;= rental.rental_date + film.rental_duration late number of DVDs where rental.return_date &gt; rental.rental_date + film.rental_duration not_rtn number of DVDs not returned; rental.return_date is null rented number of DVDs rented. on_time_pct Percent of DVDs returned on time late_pct Percent of DVDs returned late not_rtn_pct Percent of DVDs not returned. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) returned_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(returned_dplyr) 16.4.23 23. Are there duplicate customers? To answer this question we look at the customer, address, city, and country tables. We assume that if the customer first and last name match in two different rows, then it is a duplicate customer. customer_dupes_sql &lt;- dbGetQuery( con, &quot;select cust.customer_id id ,cust.store_id store ,concat(cust.first_name,&#39; &#39;,cust.last_name) customer ,cust.email -- ,a.phone ,a.address ,c.city ,a.postal_code zip ,a.district ,ctry.country from customer cust join address a on cust.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where concat(cust.first_name,cust.last_name) in (select concat(first_name,last_name) from customer group by concat(first_name,last_name) having count(*) &gt;1 ) &quot;) sp_print_df(customer_dupes_sql) Sophie is the only duplicate customer. The only difference between the two records is the store. Record 600 is associated with store 3, which has no employees, and 601 is associated with store 2 16.4.23.1 Replicate the output above using dplyr syntax. column mapping definition id customer.customer_id store customer.store_id customer first_name + last_name zip address.postal_code # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_dupes_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customer_dupes_dplyr) 16.4.24 24. Which customers have never rented a movie? To answer this question we look at the customer and rental tables. customer_no_rentals_sql &lt;- dbGetQuery( con, &quot;select c.customer_id id ,c.first_name ,c.last_name ,c.email ,a.phone ,city.city ,ctry.country ,c.active ,c.create_date -- ,c.last_update from customer c left join rental r on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on a.city_id = city.city_id left join country ctry on city.country_id = ctry.country_id where r.rental_id is null order by c.customer_id &quot; ) sp_print_df(customer_no_rentals_sql) We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. column mapping definition id customer.customer_id 16.4.24.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_no_rentals_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customer_no_rentals_dplyr) 16.4.25 25. Who are the top 5 customers with the most rentals and associated payments? This exercise uses the customer, rental, and payment tables. customer_top_rentals_sql &lt;- dbGetQuery( con, &quot;select c.customer_id id,c.store_id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,min(rental_date)::date mn_rental_dt ,max(rental_date)::date mx_rental_dt ,sum(COALESCE(p.amount,0.)) paid ,count(r.rental_id) rentals from customer c left join rental r on c.customer_id = r.customer_id left join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ,c.store_id order by count(r.rental_id) desc limit 5 &quot; ) sp_print_df(customer_top_rentals_sql) The top 5 customers all rented between 41 to 46 DVDs. Three of the top 5 rented about 14 DVDs per month over a three month period. The other two customers 41 and 42 DVDs per 12 months. 16.4.25.1 Replicate the output above using dplyr column mapping definition id customer.customer_id customer first_name + last_name mn_rental_dt minimum renal date mx_rental_dt maximum rental date paid paid amount rentals customer rentals Use the dplyr inner_join verb to find the top 5 customers who have rented the most movies. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_top_rentals_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(head(customer_top_rentals_dplyr,n=5)) 16.4.26 26. Combine the top 5 rental customers, (40 or more rentals), and zero rental customers To answer this question we look at the customer, rental, and payments tables again. customer_rental_high_low_sql &lt;- dbGetQuery( con, &quot;select c.customer_id id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name having count(r.rental_id) = 0 or count(r.rental_id) &gt; 40 order by count(r.rental_id) desc &quot; ) sp_print_df(customer_rental_high_low_sql) We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. 16.4.26.1 Replicate the output above using dplyr syntax. Column Mapping Definition id customer.customer_id customer first_name + last_name rentals customer rentals payments customer payments paid_amt payment.amount aggregated payment amount # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_rental_high_low_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customer_rental_high_low_dplyr) 16.4.27 27. Who are the top-n1 and bottom-n2 customers? The issue with the two previous reports is that the top end is hardcoded, rentals &gt; 40. Over time, the current customers will always be in the top section and new customers will get added. Another way of looking at the previous report is to show just the top and bottom 5 customers. Parameterize the previous exercise to show the top 5 and bottom 5 customers. To answer this question we look at the customer, rental, and payments tables again. customer_rentals_hi_low_sql &lt;- function(high_n,low_n) { customer_rental_high_low_sql &lt;- dbGetQuery(con, &quot;select * from ( select * ,ROW_NUMBER() OVER(ORDER BY rentals desc) rent_hi_low ,ROW_NUMBER() OVER(ORDER BY rentals ) rent_low_hi FROM ( select c.customer_id id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid_amt from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ) as summary ) row_nums where rent_hi_low &lt;= $1 or rent_low_hi &lt;= $2 order by rent_hi_low &quot; ,c(high_n,low_n) ) return (customer_rental_high_low_sql) } The next code block executes a sql version of such a function. With top_n = 5 and bot_n = 5, it replicates the hard coded version of the previous exercise. With top_n = 5 and bot_n = 0, it gives a top 5 report. With top_n = 0 and bot_n = 5, the report returns the bottom 5. Change the two parameters to see the output from the different combinations. top_n = 5 bot_n = 5 sp_print_df(customer_rentals_hi_low_sql(top_n,bot_n)) 16.4.27.1 Replicate the function above use dplyr syntax. Column Mapping Definition id customer.customer_id cust_cnt customer count rentals customer rentals payments customer payments paid_amt payment.amount aggregated payment amount rent_hi_low sequence with 1 = customer with highest rentals rent_low_hi sequence with 1 = customer with the lowest rentals # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_rentals_hi_low_dplr &lt;- function(high_n,low_n) { return(as.data.frame(&quot;code me&quot;)) } top_n = 5 bot_n = 5 sp_print_df(customer_rentals_hi_low_dplr(top_n,bot_n)) 16.4.28 28. How much has each store collected? How are the stores performing? The SQL code shows the payments made to each store in the business. store_payments_sql &lt;- dbGetQuery( con, &quot;select s.store_id,sum(p.amount) amount,count(*) cnt from payment p join staff s on p.staff_id = s.staff_id group by store_id order by 2 desc ; &quot; ) sp_print_df(store_payments_sql) Each store collected just over 30,000 in revenue and each store had about 7300 rentals. 16.4.28.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_payments_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(store_payments_dplyr) 16.4.29 29. What is the business distribution of payments? To answer this question we look at the rental, payment, inventory, and film tables to answer this question. As a sanity check, we first check the number of rentals and amount payments. rentals_payments_sql &lt;- dbGetQuery(con, &quot;select &#39;rentals&#39; rec_type, count(*) cnt_amt from rental union select &#39;payments&#39; rec_type, sum(amount) from payment &quot;) sp_print_df(rentals_payments_sql) business_payment_dist_sql &lt;- dbGetQuery( con, &quot;select no_pay_rec_due ,no_pay_rec_cnt ,round(100.0 * no_pay_rec_cnt/rentals,2) no_pay_rec_pct ,rate_eq_paid ,rate_eq_paid_cnt ,round(100.0 * rate_eq_paid_cnt/rentals,2) rate_eq_paid_pct ,rate_lt_paid ,rate_lt_over_paid ,rate_lt_paid_cnt ,round(100.0 * rate_lt_paid_cnt/rentals,2) rate_lt_paid_pct ,rate_gt_paid_due ,rate_gt_paid_cnt ,round(100.0 * rate_gt_paid_cnt/rentals,2) rate_gt_paid_pct ,rentals ,rate_eq_paid_cnt + rate_lt_paid_cnt + rate_gt_paid_cnt payments ,round(100.0 * (no_pay_rec_cnt + rate_eq_paid_cnt + rate_lt_paid_cnt + rate_gt_paid_cnt)/rentals ,2) pct ,rate_eq_paid + rate_lt_paid + rate_lt_over_paid amt_paid ,no_pay_rec_due + rate_gt_paid_due amt_due from ( select sum(case when p.rental_id is null then rental_rate else 0 end ) no_pay_rec_due ,sum(case when p.rental_id is null then 1 else 0 end) no_pay_rec_cnt ,sum(case when f.rental_rate = p.amount then p.amount else 0 end) rate_eq_paid ,sum(case when f.rental_rate = p.amount then 1 else 0 end ) rate_eq_paid_cnt ,sum(case when f.rental_rate &lt; p.amount then f.rental_rate else 0 end) rate_lt_paid ,sum(case when f.rental_rate &lt; p.amount then p.amount-f.rental_rate else 0 end) rate_lt_over_paid ,sum(case when f.rental_rate &lt; p.amount then 1 else 0 end) rate_lt_paid_cnt ,sum(case when f.rental_rate &gt; p.amount then f.rental_rate - p.amount else 0 end ) rate_gt_paid_due ,sum(case when f.rental_rate &gt; p.amount then 1 else 0 end ) rate_gt_paid_cnt ,count(*) rentals FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id ) as details ;&quot; ) # Rental counts sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;cnt&quot;),rentals)) # Payments sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;paid&quot;))) # Not paid amounts sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;due&quot;))) # Rental payments sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;pct&quot;))) These are interesting results. 09.06% of the total records have no associated payment record in the amount of 4302.47 49.39% of the rentals have been fully paid in full, 23397.75. 41.40% of the rentals have collected more than the rental amount by 18456.75 00.15% of the rentals have collected less than the rental amount by 67.76. The no_pay_rec_cnt + rate_gt_paid_cnt, \\(1453 + 24 = 1477\\) is the number of rentals which have not been paid in full. The total outstanding balance is \\(4302.47 + 67.76 = 4370.23\\) With over 40 percent over collection, someone needs to find out what is wrong with the collection process. Many customers are owed credits or free rentals. 16.4.29.1 Replicate the output above using dplyr syntax. This table describes the columns in the code block answer that follows. There are payment records where the charged amount, rental rate, is less than the amount paid. These payments are split into two pieces, rate_lt_paid and rate_lt_over_paid. The rate_lt_paid is rental rate amount. The rate_lt_over_paid is the paid amount - rental rate, the over paid amount. Column Mapping Definition no_pay_rec_cnt number of DVD rentals without an associated payment record. rate_eq_paid_cnt number of DVD payments that match the film rental rate. rate_lt_paid_cnt number of DVD rental with rental rate less than the amount paid. rate_gt_paid_cnt number of DVD rentals with rental rate greater than the film rental rate. rentals number of rental records analyzed rate_eq_paid amount paid where the rate charged = amount paid rate_lt_paid amount paid where the rate charged &lt; rate_lt_over_paid rate charged &lt; amount paid; This represents the amount over paid amt_paid Total amount paid no_pay_rec_due DVD rentals charges due without a payment record rate_gt_paid_due DVD rentals charged due with a payment record amt_due Total amount due and not collected. no_pay_rec_pct Percent of rentals without a payment record. rate_lt_paid_pct Percent of rentals where the rental charge is less than the paid amount rate_gt_paid_pct Percent of rentals where the rental charge is greater than the paid amount pct Sum of percentages # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) business_payment_dist_dplyr &lt;- as.data.frame(&quot;code me&quot;) # Rental counts sp_print_df(business_payment_dist_dplyr) 16.4.29.2 Bad data analysis Here are the sanity check numbers calculated at the beginning of this exercise. rec_type cnt_amt payments 61312.04 rentals 16045.00 Note that the sanity check numbers above, do not match the numbers above. If you query returned the numbers above, use the following result set ot see where the differences exist. rs &lt;- dbGetQuery( con, &quot;SELECT &#39;correct join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id,p.amount FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id where r.rental_id = 4591 UNION SELECT &#39;incorrect join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id,p.amount FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id where r.rental_id = 4591 and p.customer_id != 182 ;&quot;) sp_print_df(head(rs)) 16.4.30 30. Which customers have the highest open amounts? From the previous exercise, we know that there are 1477 missing payment records or not fully paid payment records. List the top 5 customers from each category base on balance due amounts. To answer this question we look at the rental, payment, inventory, film and customer tables to answer this question. customer_open_amts_sql &lt;- dbGetQuery( con, &quot; select customer_id ,concat(first_name,&#39; &#39;,last_name) customer ,pay_record ,rental_amt ,paid_amt ,due_amt ,cnt ,rn from (select c.customer_id ,c.first_name ,c.last_name ,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end Pay_record ,sum(f.rental_rate) rental_amt ,sum(coalesce(p.amount,0)) paid_amt ,sum(f.rental_rate - coalesce(p.amount,0)) due_amt ,count(*) cnt ,row_number() over (partition by case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end order by sum(f.rental_rate - coalesce(p.amount,0)) desc,c.customer_id) rn FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id INNER JOIN customer c ON r.customer_id = c.customer_id WHERE f.rental_rate &gt; coalesce(p.amount, 0) group by c.customer_id,c.first_name,c.last_name,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end ) as src where rn &lt;= 5 -- and Pay_record = &#39;No&#39; or Pay_record = &#39;Yes&#39; order by Pay_record,rn &quot;) sp_print_df(customer_open_amts_sql) From the previous exercise we see that the number of rentals that have not been paid in full is 1477. There are 24 records that have a payment record, pay_record = Yes, all have a 0 paid amount. There are 1453 DVDs rented out that have no payment record. The top 3 customers have 10 DVDs each that have not been paid. 16.4.30.1 Replicate the output above using dplyr syntax. column definition mapping customer first_name + last_name Pay_record Payment record exists Y/N case when p.amount is null then No else Yes end rental_amt aggrgated film.rental_rate paid_amt aggregated payment.amount due_amt aggregated film.rental_rate - payment.amount cnt number of rentals/customer rn row number # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_open_amts_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(customer_open_amts_dplyr) 16.4.31 31. What is the business cash flow? In the previous exercise we saw that about 50% of the rentals collected the correct amount and 40% of the rentals over collected. The last 10% were never collected. Calculate the number of days it took before the payment was collected and the amount collected? To answer this question we look at the rental, customer, payment, inventory, payment and film tables to answer this question. cash_flow_sql &lt;- dbGetQuery(con, &quot;SELECT payment_date - exp_rtn_dt payment_days ,sum(coalesce(amount, charges)) paid_or_due ,count(*) late_returns FROM ( SELECT payment_date::DATE ,(r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::DATE exp_rtn_dt ,p.amount ,f.rental_rate charges ,r.rental_date ,r.return_date FROM rental r LEFT JOIN customer c ON c.customer_id = r.customer_id LEFT JOIN address a ON c.address_id = a.address_id LEFT JOIN city ON city.city_id = a.city_id LEFT JOIN country ctry ON ctry.country_id = city.country_id LEFT JOIN inventory i ON r.inventory_id = i.inventory_id LEFT JOIN payment p ON c.customer_id = p.customer_id AND p.rental_id = r.rental_id LEFT JOIN film f ON i.film_id = f.film_id WHERE return_date &gt; (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::DATE ) AS src GROUP BY payment_date - exp_rtn_dt ORDER BY payment_date - exp_rtn_dt DESC&quot;) sp_print_df(cash_flow_sql) Wow those are really generous terms. Customers are paying 1.2 to 1.7 years after they returned the DVD. This business is in serious financial trouble! 16.4.31.1 Replicate the output above using dplyr syntax. column definition mapping paid_or_due paid amt associated with rental or the rental_rate ifelse(is.na(amount),rental_rate,amount) payment_days days til payment payment_date - rental_date # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) cash_flow_dplyr &lt;- as.data.frame(&quot;code me&quot;) sp_print_df(cash_flow_dplyr) 16.4.32 32. Customer information Create a function that takes a customer id and returns customer address information films rented and returned information customer payment information The hidden code block implements such a function in SQL. To answer this question we look at the rental, customer, address, city,country,inventory,paymentandfilm` tables to answer this question. customer_details_fn_sql &lt;- function(cust_id) { customer_details_sql &lt;- dbGetQuery(con, &quot;select c.customer_id id,concat(first_name,&#39; &#39;,c.last_name) customer ,c.email,a.phone,a.address,address2,city.city,a.postal_code,ctry.country ,c.store_id cust_store_id ,i.store_id inv_store_id ,f.film_id ,f.title ,r.rental_date::date rented ,r.return_date::date returned ,(r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date exp_rtn_dt ,case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_stat ,case when r.rental_id is null then null -- dvd returned when r.return_date is null then 1 else 0 end not_rtn ,payment_date::date pay_dt ,f.rental_rate charges ,p.amount paid ,p.amount-f.rental_rate delta ,p.staff_id pay_staff_id ,payment_date::date - rental_date::date pay_days ,r.rental_id,i.inventory_id,payment_id from customer c left join rental r on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on city.city_id = a.city_id left join country ctry on ctry.country_id = city.country_id left join inventory i on r.inventory_id = i.inventory_id left join payment p on c.customer_id = p.customer_id and p.rental_id = r.rental_id left join film f on i.film_id = f.film_id where c.customer_id = $1 order by id,rented desc &quot; ,cust_id ) return(customer_details_sql) } The following code block executes the customer function. Change the cust_id value to see differnt customers. cust_id &lt;- 600 sp_print_df( customer_details_fn_sql(cust_id)) 16.4.32.1 Replicate the output above using dplyr syntax. column definition mapping id customer_id customer first_name + last_name exp_rtn_dt expected return date rental.rental_date + film.rental_duration rtn_stat return status rental.return_date - (rental.rental_date + film duration) not_rtn dvd not returned null if rental_id is null;not rented; 1 return_date null else 0 pay_dt payment_date delta payment.amount-film.rental_rate pay_staff_id payment.staff_id payment.staff_id pay_days days til payment payment_date - rental_date # sp_tbl_descr(&#39;store&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_details_fn_dplyr &lt;- function(cust_id) { customer_details_dplyr &lt;- as.data.frame(&quot;code me&quot;) return(customer_details_dplyr) } Use the following code block to test the dplyr function. cust_id &lt;- 601 sp_print_df(customer_details_fn_dplyr(cust_id)) 16.5 Diconnect from the db and clean up dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-sql-joins-exercises-answered.html", "Chapter 17 SQL Joins Exercises Answered 17.1 Exercise Instructions 17.2 Dplyr tables 17.3 Oveview Exercise 17.4 Exercises 17.5 Different strategies for interacting with the database", " Chapter 17 SQL Joins Exercises Answered This chapter contains questions one may be curious about or asked about the DVD Rental business. The goal of the exercises is extracting useful or questionable insights from one or more tables. Each exercise has has some or all of the following parts. The question. The tables used to answer the question. A hidden SQL code block showing the desired output. Click the code button to see the SQL code. A table of derived values or renamed columns shown in the SQL block to facilitate replicating the desired dplyr solution. Abbreviated column names are used to squeeze in more columns into the answer to reduce scrolling across the screen. A replication section where you recreate the desired output using dplyr syntax. Most columns come directly out of the tables. Each replication code block has three commented function calls sp_tbl_descr(store) describes a table, store sp_tbl_pk_fk(table_name) shows a tables primary and foreign keys sp_print_df(table_rows_sql) shows table row counts. To keep the exercises concentrated on the joins, all derived dates drop their timestamp. SQL syntax: date_column::DATE Dplyr syntax: as.date(date_colun) 17.1 Exercise Instructions Manually execute all the code blocks up-to the SQL Union Exercise. Most of the exercises can be performed in any order. There are function exercises that create a function followed by another code block to call the function in the previous exercise. Use the Show Document Outline, CTL-Shift-O, to navigate to the different exercises. Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; About a minute ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 17.2 Dplyr tables All the tables defined in the DVD Rental System will fit into memory which is rarely the case when working with a database. Instead of loading all the DVD Rental System tables into memory via a DBI::dbReadTable, each table is loaded into an R object named TableName_table, via a dplyr::tbl call. actor_table &lt;- dplyr::tbl(con,actor) source(here(&#39;book-src&#39;,&#39;dvdrental-table-declarations.R&#39;), echo = FALSE) The key difference between the DBI::dbTableRead and the dplyr::tbl reference is the first is not lazy and the second one is lazy. The following code block deletes and inserts records into the different tables used in the exercises in this chpater. The techniques used in this code block are discussed in detail in the appendix, ??add link here.?? source(file=here::here(&#39;book-src&#39;,&#39;sql_pet_data.R&#39;),echo=FALSE) 17.3 Oveview Exercise When joining many tables, it is helpful to have the number of rows from each table as an initial sanity check that the joins are returning a reasonable number of rows. 17.3.1 1. How many rows are in each table? table_rows_sql &lt;- dbGetQuery(con, &quot;select * from ( select &#39;actor&#39; tbl_name,count(*) from actor union select &#39;category&#39; tbl_name,count(*) from category union select &#39;film&#39; tbl_name,count(*) from film union select &#39;film_actor&#39; tbl_name,count(*) from film_actor union select &#39;film_category&#39; tbl_name,count(*) from film_category union select &#39;language&#39; tbl_name,count(*) from language union select &#39;inventory&#39; tbl_name,count(*) from inventory union select &#39;rental&#39; tbl_name,count(*) from rental union select &#39;payment&#39; tbl_name,count(*) from payment union select &#39;staff&#39; tbl_name,count(*) from staff union select &#39;customer&#39; tbl_name,count(*) from customer union select &#39;address&#39; tbl_name,count(*) from address union select &#39;city&#39; tbl_name,count(*) from city union select &#39;country&#39; tbl_name,count(*) from country union select &#39;store&#39; tbl_name,count(*) from store ) counts order by tbl_name ; &quot;) sp_print_df(table_rows_sql) 17.3.1.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) # sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) table_rows_dplyr &lt;- as.data.frame(actor_table %&gt;% mutate(name = &quot;actor&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n())) %&gt;% union(as.data.frame(address_table %&gt;% mutate(name = &quot;address&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union (as.data.frame(category_table %&gt;% mutate(name = &quot;category&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(country_table %&gt;% mutate(name = &quot;city&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(country_table %&gt;% mutate(name = &quot;country&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(customer_table %&gt;% mutate(name = &quot;customer&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(film_table %&gt;% mutate(name = &quot;film&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(film_actor_table %&gt;% mutate(name = &quot;film_actor&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(film_category_table %&gt;% mutate(name = &quot;film_category&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(inventory_table %&gt;% mutate(name = &quot;inventory&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(language_table %&gt;% mutate(name = &quot;language&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(rental_table %&gt;% mutate(name = &quot;rental&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(payment_table %&gt;% mutate(name = &quot;payment&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(staff_table %&gt;% mutate(name = &quot;staff&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% union(as.data.frame(store_table %&gt;% mutate(name = &quot;store&quot;) %&gt;% group_by(name) %&gt;% summarize(rows = n()))) %&gt;% arrange(name) sp_print_df(table_rows_dplyr) 17.4 Exercises 17.4.1 1. Where is the DVD Rental Business located? To answer this question we look at the store, address, city, and country tables to answer this question. store_locations_sql &lt;- dbGetQuery(con, &quot;select s.store_id ,a.address ,c.city ,a.district ,a.postal_code ,c2.country ,s.last_update from store s join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_locations_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. 17.4.1.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_locations_dplyr &lt;- store_table %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;), suffix(c(&quot;.s&quot;, &quot;.a&quot;))) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% select(store_id, address, city, district, postal_code, country, last_update.x) %&gt;% collect() sp_print_df(store_locations_dplyr) 17.4.2 2. List each store and the staff contact information? To answer this question we look at the store, staff, address, city, and country tables. store_employees_sql &lt;- dbGetQuery(con, &quot;select st.store_id ,s.first_name ,s.last_name ,s.email ,a.phone ,a.address ,c.city ,a.district ,a.postal_code ,c2.country from store st left join staff s on st.manager_staff_id = s.staff_id left join address a on s.address_id = a.address_id left join city c on a.city_id = c.city_id left join country c2 on c.country_id = c2.country_id &quot;) sp_print_df(store_employees_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each, Mike Hillyer and Jon Stephens respectively. The store in the United States has no employees yet. 17.4.2.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_employees_dplyr &lt;- store_table %&gt;% left_join(staff_table, by = c(manager_staff_id = &quot;staff_id&quot;), suffix(c(&quot;sto&quot;, &quot;sta&quot;))) %&gt;% left_join(address_table, by = c(address_id.y = &quot;address_id&quot;), suffix(c(&quot;.sta&quot;, &quot;.a&quot;))) %&gt;% left_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.sta&quot;, &quot;.city&quot;))) %&gt;% left_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.city&quot;, &quot;.cnt&quot;))) %&gt;% select(store_id.x, first_name, last_name, email, phone, address, city, district, postal_code, country) %&gt;% collect() sp_print_df(store_employees_dplyr) 17.4.3 3. How many active, inactive, and total customers does the DVD rental business have? To answer this question we look at the customer table. In a previous chapter we observed that there are two columns, activebool and active. We consider active = 1 as active. customer_cnt_sql &lt;- dbGetQuery(con, &quot;SELECT sum(case when active = 1 then 1 else 0 end) active ,sum(case when active = 0 then 1 else 0 end) inactive ,count(*) total from customer &quot;) sp_print_df(customer_cnt_sql) Our DVD Rental business is international and operates in three countries, Canada, Austraila, and the United States. Each country has one store. The stores in Canada and Austrailia have one employee each. The store in the United States has no employees yet. The business has 604 international customers, 589 are active and 15 inactive. 17.4.3.1 Replicate the output above using dplyr syntax. customer_cnt_dplyr &lt;- customer_table %&gt;% mutate(inactive = ifelse(active == 0, 1, 0)) %&gt;% summarize(active = sum(active), inactive = sum(inactive), total = n()) %&gt;% collect() ## Warning: Missing values are always removed in SQL. ## Use `SUM(x, na.rm = TRUE)` to silence this warning ## Warning: Missing values are always removed in SQL. ## Use `SUM(x, na.rm = TRUE)` to silence this warning sp_print_df(customer_cnt_dplyr) 17.4.4 4. How many and what percent of customers are from each country? To answer this question we look at the customer, address, city, and country tables. customers_sql &lt;- dbGetQuery(con, &quot;select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country order by count(*) desc &quot;) sp_print_df(customers_sql) Based on the table above, the DVD Rental business has customers in 118 countries. The DVD Rental business cannot have many walk in customers. It may possibly use a mail order distribution model. For an international company, how are the different currencies converted to a standard currency? Looking at the ERD, there is no currency conversion rate. 17.4.4.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) cust_cnt &lt;- customer_table %&gt;% summarize(rows = n()) %&gt;% collect() customers_dplyr &lt;- customer_table %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;), suffix(c(&quot;.s&quot;, &quot;.a&quot;))) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% group_by(active, country) %&gt;% summarize(count = n()) %&gt;% mutate(total = cust_cnt$rows # nrow(customer_table) , pct = round(100 * count/total, 4)) %&gt;% arrange(desc(count)) %&gt;% select(active, country, count, pct) %&gt;% collect() sp_print_df(customers_dplyr) 17.4.5 5. What countries constitute the top 25% of the customer base? Using the previous code, add two new columns. One column shows a running total and the second column shows a running percentage. Order the data by count then by country. To answer this question we look at the customer, address, city, and country tables again. country_sql &lt;- dbGetQuery(con, &quot;select active,country,count ,sum(count) over (order by count desc,country rows between unbounded preceding and current row) running_total , pct ,sum(pct) over (order by pct desc,country rows between unbounded preceding and current row) running_pct from (-- Start of inner SQL Block select c.active,country.country,count(*) count ,round(100 * count(*) / sum(count(*)) over(),4) as pct from customer c join address a on c.address_id = a.address_id join city on a.city_id = city.city_id join country on city.country_id = country.country_id group by c.active,country ) ctry -- End of inner SQL Block order by count desc,country &quot;) sp_print_df(country_sql) The top 25% of the customer base are from India, China, the United States, and Japan. The next six countries, the top 10, Mexico, Brazil, Russian Federation, Philipines, Indonesia, and Turkey round out the top 50% of the businesses customer base. 17.4.5.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) cust_cnt &lt;- customer_table %&gt;% summarize(rows = n()) %&gt;% collect() country_dplyr &lt;- customer_table %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;), suffix(c(&quot;.s&quot;, &quot;.a&quot;))) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% group_by(active, country) %&gt;% summarize(count = n()) %&gt;% mutate(total = cust_cnt$rows, pct = round(100 * count/total, 4), csp = 1) %&gt;% arrange(desc(count)) %&gt;% group_by(csp) %&gt;% mutate(running_pct = cumsum(pct), running_total = cumsum(count)) %&gt;% select(csp, active, country, count, running_total, pct, running_pct) %&gt;% collect() sp_print_df(country_dplyr) 17.4.6 6. How many customers are in Australia and Canada? To answer this question we use the results from the previous exercise. country_au_ca_sql &lt;- country_sql %&gt;% filter(country == &quot;Australia&quot; | country == &quot;Canada&quot;) sp_print_df(country_au_ca_sql) There are 10 customers in Austrailia and Canada where the brick and mortar stores are located. The 20 customers are less than 2% of the world wide customer base. 17.4.6.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) country_au_ca_dplyr &lt;- country_dplyr %&gt;% filter(country == &quot;Australia&quot; | country == &quot;Canada&quot;) sp_print_df(country_au_ca_dplyr) 17.4.7 7. How many languages? With an international customer base, how many languages does the DVD Rental business distribute DVDs in. To answer this question we look at the language table. languages_sql &lt;- dbGetQuery(con, &quot; select * from language &quot;) sp_print_df(languages_sql) DVDs are distributed in six languages. 17.4.7.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) languages_dplyr &lt;- language_table %&gt;% collect() sp_print_df(languages_dplyr) 17.4.8 8. What is the distribution of DVDs by Language To answer this question we look at the language and film tables. language_distribution_sql &lt;- dbGetQuery(con, &quot; select l.language_id,name \\&quot;language\\&quot;,count(f.film_id) from language l left join film f on l.language_id = f.language_id group by l.language_id,name order by l.language_id &quot;) sp_print_df(language_distribution_sql) This is a surprise. For an international customer base, the entire stock of 1001 DVDs are in English only. 17.4.8.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) language_distribution_dplyr &lt;- language_table %&gt;% left_join(film_table, by = c(language_id = &quot;language_id&quot;), suffix(c(&quot;.s&quot;, &quot;.a&quot;))) %&gt;% group_by(language_id, name) %&gt;% summarize(count = sum(ifelse(!is.na(title), 1, 0)), na.rm = TRUE) %&gt;% collect() ## Warning: Missing values are always removed in SQL. ## Use `SUM(x, na.rm = TRUE)` to silence this warning sp_print_df(language_distribution_dplyr) 17.4.9 9. What are the number of rentals and rented amount by store, by month? To answer this question we look at the rental, inventory, and film tables to answer this question. store_rentals_by_mth_sql &lt;- dbGetQuery(con, &quot;select * ,sum(rental_amt) over (order by yyyy_mm,store_id rows between unbounded preceding and current row) running_rental_amt from (select yyyy_mm,store_id,rentals,rental_amt ,sum(rentals) over(partition by yyyy_mm order by store_id) mo_rentals ,sum(rental_amt) over (partition by yyyy_mm order by store_id) mo_rental_amt from (select to_char(rental_date,&#39;yyyy-mm&#39;) yyyy_mm ,i.store_id,count(*) rentals, sum(f.rental_rate) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by to_char(rental_date,&#39;yyyy-mm&#39;),i.store_id ) as details ) as mo_running order by yyyy_mm,store_id &quot;) sp_print_df(store_rentals_by_mth_sql) The current entry, row 11, is our new rental row we added to show the different joins in a previous chapter. 17.4.9.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_rentals_by_mth_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;), suffix(c(&quot;.r&quot;, &quot;.i&quot;))) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.i&quot;, &quot;.f&quot;))) %&gt;% mutate(YYYY_MM = to_char(rental_date, &quot;YYYY-MM&quot;), running_total = &quot;running_total&quot;) %&gt;% group_by(running_total, YYYY_MM, store_id) %&gt;% summarise(rentals = n(), rental_amt = sum(rental_rate, na.rm = TRUE)) %&gt;% mutate(mo_rentals = order_by(store_id, cumsum(rentals)), mo_rental_amt = order_by(store_id, cumsum(rental_amt))) %&gt;% group_by(running_total) %&gt;% arrange(YYYY_MM, store_id) %&gt;% mutate(running_rental_amt = cumsum(rental_amt)) %&gt;% select(-running_total) %&gt;% collect() sp_print_df(head(store_rentals_by_mth_dplyr, n = 25)) 17.4.10 10. Rank films based on the number of times rented and associated revenue To answer this question we look at the rental, inventory, and film tables. film_rank_sql &lt;- dbGetQuery(con, &quot;select f.film_id,f.title,f.rental_rate,count(*) count,f.rental_rate * count(*) rental_amt from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.film_id,f.title,f.rental_rate order by count(*) desc&quot;) sp_print_df(film_rank_sql) The most frequently rented movie, 34 times, is Bucket Brotherhood followed by Rocketeer Mother, 33 times. 17.4.10.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rank_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;), suffix(c(&quot;.r&quot;, &quot;.i&quot;))) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;.i&quot;))) %&gt;% group_by(film_id, title, rental_rate) %&gt;% summarize(count = n(), rental_amt = sum(rental_rate)) %&gt;% arrange(desc(count)) %&gt;% collect() ## Warning: Missing values are always removed in SQL. ## Use `SUM(x, na.rm = TRUE)` to silence this warning sp_print_df(film_rank_dplyr) 17.4.11 11. What is the rental distribution/DVD for the top two rented films? From the previous exercise we know that the top two films are Bucket Brotherhood and Rocketeer Mother. To answer this question we look at the rental, inventory, and film tables again. Instead of looking at the film level, we need to drill down to the individual dvds for each film to answer this question. film_rank2_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id,count(*) from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where i.film_id in (103,738) group by i.store_id,i.film_id,f.title,i.inventory_id&quot;) sp_print_df(film_rank2_sql) The Bucket Brotherhood and Rocketeer Mother DVDs are equally distributed between the two stores, 4 dvds each per film. The Bucket Brotherhood was rented 17 times from both stores. The Rocketeer Mother was rented 15 times from store 1 and 18 times from store 2. 17.4.11.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rank2_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;), suffix(c(&quot;.r&quot;, &quot;.i&quot;))) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;.i&quot;))) %&gt;% filter(film_id %in% c(103, 738)) %&gt;% group_by(store_id, film_id, title, inventory_id) %&gt;% summarize(count = n()) %&gt;% arrange(film_id, store_id, inventory_id) %&gt;% collect() sp_print_df(film_rank2_dplyr) 17.4.12 12. List staffing information for store 1 associated with the Bucket Brother rentals? To answer this question we look at the rental, inventory, film, staff, address, city, and country tables. film_103_details_sql &lt;- dbGetQuery(con, &quot;select i.store_id,i.film_id,f.title,i.inventory_id inv_id,i.store_id inv_store_id ,r.rental_date::date rented,r.return_date::date returned ,s.staff_id,s.store_id staff_store_id,concat(s.first_name,&#39; &#39;,s.last_name) staff,ctry.country from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join staff s on r.staff_id = s.staff_id join address a on s.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where i.film_id in (103) and r.rental_date::date between &#39;2005-05-01&#39;::date and &#39;2005-06-01&#39;::date order by r.rental_date &quot;) sp_print_df(film_103_details_sql) In a previous exercise we saw that store 1 based in Canada and store 2 based in Austrailia each had one employee, staff_id 1 and 2 respectively. We see that Mike from store 1, Canada, had transactions in store 1 and store 2 on 5/25/2005. Similarly Jon from store 2, Australia, had transaction in store 2 and store 1 on 5/31/2005. Is this phsically possible, or a key in error? 17.4.12.1 Replicate the output above using dplyr syntax. column mapping definition inv_id inventory.inventory_id inv_store_id inventory.store_id rented rental.rental_date returned rental.return_date staff_store_id store.store_id staff first_name+last_name # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_103_details_dplyr &lt;- inventory_table %&gt;% filter(film_id == 103) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;r&quot;))) %&gt;% inner_join(rental_table, by = c(inventory_id = &quot;inventory_id&quot;), suffix(c(&quot;.i&quot;, &quot;r&quot;))) %&gt;% filter(rental_date &lt; &quot;2005-06-01&quot;) %&gt;% inner_join(staff_table, by = c(staff_id = &quot;staff_id&quot;), suffix(c(&quot;.x&quot;, &quot;r&quot;))) %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;), suffix(c(&quot;.a&quot;, &quot;r&quot;))) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.c&quot;, &quot;a&quot;))) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.ctry&quot;, &quot;city&quot;))) %&gt;% mutate(rented = Date(rental_date), returned = Date(return_date), staff = paste0(first_name, &quot; &quot;, last_name)) %&gt;% rename(inv_store = store_id.x, staff_store_id = store_id.y, inv_id = inventory_id) %&gt;% select(inv_store, film_id, title, inv_id, rented, returned, staff_id, staff_store_id, staff, country) %&gt;% arrange(rented) %&gt;% collect() sp_print_df(film_103_details_dplyr) 17.4.13 13. Which film(s) have never been rented To answer this question we look at the film, inventory and rental tables. never_rented_dvds_sql &lt;- dbGetQuery(con, &quot;select i.store_id,f.film_id, f.title,f.description, i.inventory_id from film f join inventory i on f.film_id = i.film_id left join rental r on i.inventory_id = r.inventory_id where r.inventory_id is null &quot;) sp_print_df(never_rented_dvds_sql) There are only two movies that have not been rented, Academy Dinousaur and Sophies Choice. 17.4.13.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) never_rented_dvds_dplyr &lt;- film_table %&gt;% inner_join(inventory_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;.i&quot;))) %&gt;% anti_join(rental_table, by = c(&quot;inventory_id&quot;, &quot;inventory_id&quot;), suffix(c(&quot;.i&quot;, &quot;.r&quot;))) %&gt;% select(film_id, title, description, inventory_id) %&gt;% collect() sp_print_df(never_rented_dvds_dplyr) 17.4.14 14. How many films are in each film rating? To answer this question we look at the film table to answer this question. film_ratings_sql &lt;- dbGetQuery(con, &quot;select f.rating,count(*) from film f group by f.rating order by count(*) desc &quot;) sp_print_df(film_ratings_sql) There are 5 ratings and all 5 have roughly 200 movies. 17.4.14.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_ratings_dplyr &lt;- film_table %&gt;% group_by(rating) %&gt;% summarize(count = n()) %&gt;% arrange(desc(count)) %&gt;% collect() sp_print_df(film_ratings_dplyr) 17.4.15 15. What are the different film categories? To answer this question we look at the category table to answer this question. film_categories_sql &lt;- dbGetQuery(con, &quot;select * from category&quot;) sp_print_df(film_categories_sql) There are 16 different categories 17.4.15.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_categories_dplyr &lt;- category_table %&gt;% collect() sp_print_df(film_categories_dplyr) 17.4.16 16. How many DVDs are in each film categeory? To answer this question we look at the category table again. film_categories2_sql &lt;- dbGetQuery(con, &quot;select c.name,count(*) count from category c join film_category fc on c.category_id = fc.category_id group by c.name order by count(*) desc &quot;) sp_print_df(film_categories2_sql) There are 16 film categories. The highest category, Sports, has 77 films followed by the International category which has 76 film. What is an example of an international category film where all films are currently in English? 17.4.16.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_categories2_dplyr &lt;- category_table %&gt;% inner_join(film_category_table, by = c(category_id = &quot;category_id&quot;), suffix(c(&quot;.c&quot;, &quot;.fc&quot;))) %&gt;% group_by(name) %&gt;% summarise(count = n()) %&gt;% arrange(desc(count)) %&gt;% collect() sp_print_df(film_categories2_dplyr) 17.4.17 17. Which films are listed in multiple categories? To answer this question we look at the film, film_category and category tables. multiple_categories_sql &lt;- dbGetQuery(con, &quot;select f.film_id, f.title,c.name from film_category fc join film f on fc.film_id = f.film_id join category c on fc.category_id = c.category_id where fc.film_id in (select fc.film_id from film f join film_category fc on f.film_id = fc.film_id group by fc.film_id having count(*) &gt; 1 ) &quot;) sp_print_df(multiple_categories_sql) There is only one film which has two categories, Sophies Choice. 17.4.17.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) multiple_categories_dplyr &lt;- # compute films with multiple categories film_table %&gt;% inner_join(film_category_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;.fc&quot;))) %&gt;% group_by(film_id, title) %&gt;% summarise(count = n()) %&gt;% filter(count &gt; 1) %&gt;% # get the category ids inner_join(film_category_table, by = c(film_id = &quot;film_id&quot;), suffix(c(&quot;.f&quot;, &quot;.fc&quot;))) %&gt;% # get the category names inner_join(category_table, by = c(category_id = &quot;category_id&quot;)) %&gt;% select(film_id, title, name) %&gt;% collect() sp_print_df(multiple_categories_dplyr) 17.4.18 18. Which DVDs are in one stores inventory but not the other In the table below we show the first 10 rows. To answer this question we look at the inventory and film tables. dvd_in_1_store_sql &lt;- dbGetQuery(con, &quot; -- select store1,count(count1) films_not_in_store_2,sum(coalesce(count1,0)) dvds_not_in_store_1 -- ,store2,count(count2) films_not_in_store_1,sum(coalesce(count2,0)) dvds_not_in_store_2 -- from ( select coalesce(i1.film_id,i2.film_id) film_id,f.title,f.rental_rate ,1 store1,coalesce(i1.count,0) count1 ,2 store2,coalesce(i2.count,0) count2 -- dvd inventory in store 1 from (select film_id,store_id,count(*) count from inventory where store_id = 1 group by film_id,store_id ) as i1 full outer join -- dvd inventory in store 2 (select film_id,store_id,count(*) count from inventory where store_id = 2 group by film_id,store_id ) as i2 on i1.film_id = i2.film_id join film f on coalesce(i1.film_id,i2.film_id) = f.film_id where i1.film_id is null or i2.film_id is null order by f.title -- ) as src -- group by store1,store2 &quot;) if (HEAD_N &gt; 0) { sp_print_df(head(dvd_in_1_store_sql, n = HEAD_N)) } else { sp_print_df(dvd_in_1_store_sql) } Store 1 has 196 films, (576 dvds), that are not in store 2. Store 2 has 199 films, (607 dvds), that are not in store 1. 17.4.18.1 Replicate the output above using dplyr syntax. The following code isnt working yet. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) inv_tbl1 &lt;- inventory_table %&gt;% filter(store_id == 1) %&gt;% group_by(film_id) %&gt;% summarise(count = n()) inv_tbl2 &lt;- inventory_table %&gt;% filter(store_id == 2) %&gt;% group_by(film_id) %&gt;% summarise(count = n()) dvd_in_1_store_dplyr &lt;- inv_tbl1 %&gt;% full_join(inv_tbl2, by = c(&quot;film_id&quot;, &quot;film_id&quot;), suffix(c(&quot;.i1&quot;, &quot;.i2&quot;))) %&gt;% filter(is.na(count.x) | is.na(count.y)) %&gt;% # filter(is.na(count.x + count.y)) %&gt;% #this works also mutate_all(funs(ifelse(is.na(.), 0, .))) %&gt;% inner_join(film_table, by = c(&quot;film_id&quot;, &quot;film_id&quot;), copy = TRUE) %&gt;% mutate(store_id1 = 1, store_id2 = 2) %&gt;% select(film_id, title, rental_rate, store_id1, count.x, store_id2, count.y) %&gt;% arrange(film_id) %&gt;% collect() ## Warning: funs() is soft deprecated as of dplyr 0.8.0 ## please use list() instead ## ## # Before: ## funs(name = f(.) ## ## # After: ## list(name = ~f(.)) ## This warning is displayed once per session. if (HEAD_N &gt; 0) { sp_print_df(head(dvd_in_1_store_dplyr, n = HEAD_N)) } else { sp_print_df(dvd_in_1_store_dplyr) } 17.4.19 19. Which films are not tracked in inventory? To answer this question we look at the film and rental tables. films_no_inventory_sql &lt;- dbGetQuery(con, &quot; select f.film_id,title,rating,rental_rate,replacement_cost from film f left outer join inventory i on f.film_id = i.film_id where i.film_id is null; &quot;) if (HEAD_N &gt; 0) { sp_print_df(head(films_no_inventory_sql, n = HEAD_N)) } else { sp_print_df(films_no_inventory_sql) } There are 42 films that do not exist in inventory or in either store. These may be DVDs that have been ordered but the business has not received them. Looking at the price and the replacement cost, it doesnt look like there is any rhyme or reason to the setting of the price. 17.4.19.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) films_no_inventory_dplyr &lt;- film_table %&gt;% anti_join(inventory_table, by = (c(film_id = &quot;film_id&quot;))) %&gt;% select(film_id, title, rating, rental_rate, replacement_cost) %&gt;% collect() if (HEAD_N &gt; 0) { sp_print_df(head(films_no_inventory_dplyr, n = HEAD_N)) } else { sp_print_df(films_no_inventory_dplyr) } 17.4.20 20. List film categories in descending accounts receivable. To answer this question we look at the rental, inventory, film, film_category and category tables. film_category_AR_rank_sql &lt;- dbGetQuery(con, &quot; select category,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select c.name category, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join film_category fc on f.film_id = fc.film_id join category c on fc.category_id = c.category_id group by c.name ) src &quot;) sp_print_df(film_category_AR_rank_sql) There are 16 film categories. The top three categories based on highest AR amounts are Sports, Drama, and Sci-Fi. The total number of rentals are 16046 with an AR amount of 47221.54. 17.4.20.1 Replicate the output above using dplyr syntax. column mapping definition category category.name ar f.rental_rate running_ar accumulated ar amounts based on ratings rentals number of rentals associated with the rating running_rentals running rating rentals # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_category_AR_rank_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;)) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% inner_join(film_category_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% inner_join(category_table, by = c(category_id = &quot;category_id&quot;)) %&gt;% group_by(name) %&gt;% summarize(rentals = n(), AR = sum(rental_rate, na.rm = TRUE)) %&gt;% arrange(desc(AR)) %&gt;% mutate(running_ar = cumsum(AR), running_rentals = cumsum(rentals)) %&gt;% rename(category = name) %&gt;% select(category, AR, running_ar, rentals, running_rentals) %&gt;% collect() sp_print_df(film_category_AR_rank_dplyr) 17.4.21 21. List film ratings in descending accounts receivable order. To answer this question we look at the rental, inventory, and film tables. film_rating_rank_sql &lt;- dbGetQuery(con, &quot;select rating,AR ,sum(AR) over (order by AR desc rows between unbounded preceding and current row) running_AR ,rentals ,sum(rentals) over (order by AR desc rows between unbounded preceding and current row) running_rentals from (select f.rating, sum(f.rental_rate) AR, count(*) rentals from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id group by f.rating ) as src &quot;) sp_print_df(film_rating_rank_sql) There are 5 film ratings. The total number of rentals are 16045 with an AR amount of 47216.55. Why do the film categories revenue and film rating revenue amounts and counts differ, 16046 and 47221.54? 17.4.21.1 Replicate the output above using dplyr syntax. column mapping definition rating film.rating ar f.rental_rate running_ar accumulated ar amounts based on ratings rentals number of rentals associated with the rating running_rentals running rating rentals # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) film_rating_rank_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;)) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% group_by(rating) %&gt;% summarize(rentals = n(), AR = sum(rental_rate, na.rm = TRUE)) %&gt;% arrange(desc(AR)) %&gt;% mutate(running_ar = cumsum(AR), running_rentals = cumsum(rentals)) %&gt;% select(rating, AR, running_ar, rentals, running_rentals) %&gt;% collect() sp_print_df(film_rating_rank_dplyr) 17.4.22 22. How many rentals were returned on time, returned late, never returned? To answer this question we look at the rental, inventory, and film tables. returned_sql &lt;- dbGetQuery(con, &quot;with details as (select case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_days ,case when r.return_date is null then 1 else 0 end not_rtn from rental r join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id ) select sum(case when rtn_days &lt;= 0 then 1 else 0 end) on_time ,sum(case when rtn_days &gt; 0 then 1 else 0 end) late ,sum(not_rtn) not_rtn ,count(*) rented ,round(100. * sum(case when rtn_days &lt;= 0 then 1 else 0 end)/count(*),2) on_time_pct ,round(100. * sum(case when rtn_days &gt; 0 then 1 else 0 end)/count(*),2) late_pct ,round(100. * sum(not_rtn)/count(*),2) not_rtn_pct from details &quot;) sp_print_df(returned_sql) To date 53.56% of the rented DVDs were returned on time, 45.30% were returned late, and 1.14% were never returned. 17.4.22.1 Replicate the output above using dplyr syntax. column mapping definition on_time number of DVDs where rental.return_date &lt;= rental.rental_date + film.rental_duration late number of DVDs where rental.return_date &gt; rental.rental_date + film.rental_duration not_rtn number of DVDs not returned; rental.return_date is null rented number of DVDs rented. on_time_pct Percent of DVDs returned on time late_pct Percent of DVDs returned late not_rtn_pct Percent of DVDs not returned. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) returned_dplyr &lt;- rental_table %&gt;% inner_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;)) %&gt;% inner_join(film_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% mutate(rtn_days = date(return_date) - (date(rental_date) + rental_duration), not_returned = ifelse(is.na(return_date), 1, 0)) %&gt;% summarize(on_time = sum(ifelse(rtn_days &lt;= 0, 1, 0), na.rm = TRUE), late = sum(ifelse(rtn_days &gt; 0, 1, 0), na.rm = TRUE), not_rtn = sum(not_returned), rented = n()) %&gt;% mutate(on_time_pct = round(100 * on_time/rented, 2), late_pct = round(100 * late/rented, 2), not_rtn_pct = round(100 * not_rtn/rented, 2)) %&gt;% collect() ## Warning: Missing values are always removed in SQL. ## Use `SUM(x, na.rm = TRUE)` to silence this warning sp_print_df(returned_dplyr) 17.4.23 23. Are there duplicate customers? To answer this question we look at the customer, address, city, and country tables. We assume that if the customer first and last name match in two different rows, then it is a duplicate customer. customer_dupes_sql &lt;- dbGetQuery(con, &quot;select cust.customer_id id ,cust.store_id store ,concat(cust.first_name,&#39; &#39;,cust.last_name) customer ,cust.email -- ,a.phone ,a.address ,c.city ,a.postal_code zip ,a.district ,ctry.country from customer cust join address a on cust.address_id = a.address_id join city c on a.city_id = c.city_id join country ctry on c.country_id = ctry.country_id where concat(cust.first_name,cust.last_name) in (select concat(first_name,last_name) from customer group by concat(first_name,last_name) having count(*) &gt;1 ) &quot;) sp_print_df(customer_dupes_sql) Sophie is the only duplicate customer. The only difference between the two records is the store. Record 600 is associated with store 3, which has no employees, and 601 is associated with store 2 17.4.23.1 Replicate the output above using dplyr syntax. column mapping definition id customer.customer_id store customer.store_id customer first_name + last_name zip address.postal_code # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_dupes_dplyr &lt;- customer_table %&gt;% group_by(first_name, last_name) %&gt;% summarize(n = n()) %&gt;% filter(n &gt; 1) %&gt;% inner_join(customer_table, by = c(first_name = &quot;first_name&quot;, last_name = &quot;last_name&quot;)) %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;), suffix(c(&quot;.s&quot;, &quot;.a&quot;))) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;), suffix(c(&quot;.a&quot;, &quot;.c&quot;))) %&gt;% mutate(customer = paste0(first_name, last_name, sep = &quot; &quot;)) %&gt;% group_by(customer) %&gt;% rename(id = customer_id, store = store_id, zip = postal_code) %&gt;% select(id, store, customer, email, address, city, zip, district, country) %&gt;% collect() sp_print_df(customer_dupes_dplyr) 17.4.24 24. Which customers have never rented a movie? To answer this question we look at the customer and rental tables. customer_no_rentals_sql &lt;- dbGetQuery(con, &quot;select c.customer_id id ,c.first_name ,c.last_name ,c.email ,a.phone ,city.city ,ctry.country ,c.active ,c.create_date -- ,c.last_update from customer c left join rental r on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on a.city_id = city.city_id left join country ctry on city.country_id = ctry.country_id where r.rental_id is null order by c.customer_id &quot;) sp_print_df(customer_no_rentals_sql) We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. column mapping definition id customer.customer_id 17.4.24.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_no_rentals_dplyr &lt;- customer_table %&gt;% anti_join(rental_table, by = &quot;customer_id&quot;) %&gt;% inner_join(address_table, by = c(address_id = &quot;address_id&quot;)) %&gt;% inner_join(city_table, by = c(city_id = &quot;city_id&quot;)) %&gt;% inner_join(country_table, by = c(country_id = &quot;country_id&quot;)) %&gt;% rename(id = customer_id) %&gt;% select(id, first_name, last_name, email, phone, active, city, country, create_date) %&gt;% collect() sp_print_df(customer_no_rentals_dplyr) 17.4.25 25. Who are the top 5 customers with the most rentals and associated payments? This exercise uses the customer, rental, and payment tables. customer_top_rentals_sql &lt;- dbGetQuery(con, &quot;select c.customer_id id,c.store_id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,min(rental_date)::date mn_rental_dt ,max(rental_date)::date mx_rental_dt ,sum(COALESCE(p.amount,0.)) paid ,count(r.rental_id) rentals from customer c left join rental r on c.customer_id = r.customer_id left join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ,c.store_id order by count(r.rental_id) desc limit 5 &quot;) sp_print_df(customer_top_rentals_sql) The top 5 customers all rented between 41 to 46 DVDs. Three of the top 5 rented about 14 DVDs per month over a three month period. The other two customers 41 and 42 DVDs per 12 months. 17.4.25.1 Replicate the output above using dplyr syntax column mapping definition id customer.customer_id customer first_name + last_name mn_rental_dt minimum renal date mx_rental_dt maximum rental date paid paid amount rentals customer rentals Use the dplyr inner_join verb to find the top 5 customers who have rented the most movies. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_top_rentals_dplyr &lt;- customer_table %&gt;% left_join(rental_table, by = c(customer_id = &quot;customer_id&quot;), suffix(c(&quot;.c&quot;, &quot;.r&quot;))) %&gt;% left_join(payment_table, by = c(rental_id = &quot;rental_id&quot;), suffix(c(&quot;r&quot;, &quot;p&quot;))) %&gt;% mutate(customer = paste(first_name, last_name, sep = &quot; &quot;)) %&gt;% group_by(customer_id.x, customer, store_id) %&gt;% summarize(rentals = n(), paid = sum(ifelse(is.na(amount), 0, amount), na.rm = TRUE), mn_rental_dt = Date(min(rental_date, na.rm = TRUE)), mx_rental_dt = Date(max(rental_date, na.rm = TRUE))) %&gt;% arrange(desc(rentals)) %&gt;% rename(id = customer_id.x) %&gt;% select(id, store_id, customer, mn_rental_dt, mx_rental_dt, paid, rentals) %&gt;% collect() sp_print_df(head(customer_top_rentals_dplyr, n = 5)) 17.4.26 26. Combine the top 5 rental customers, (40 or more rentals), and zero rental customers To answer this question we look at the customer, rental, and payments tables again. customer_rental_high_low_sql &lt;- dbGetQuery(con, &quot;select c.customer_id id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name having count(r.rental_id) = 0 or count(r.rental_id) &gt; 40 order by count(r.rental_id) desc &quot;) sp_print_df(customer_rental_high_low_sql) We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. We see that there are four new customers who have never rented a movie. These four customers are in the countries that have a manned store. 17.4.26.1 Replicate the output above using dplyr syntax. Column Mapping Definition id customer.customer_id customer first_name + last_name rentals customer rentals payments customer payments paid_amt payment.amount aggregated payment amount # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_rental_high_low_dplyr &lt;- customer_table %&gt;% left_join(rental_table, by = c(customer_id = &quot;customer_id&quot;), suffix(c(&quot;.c&quot;, &quot;.r&quot;))) %&gt;% left_join(payment_table, by = c(rental_id = &quot;rental_id&quot;), suffix(c(&quot;r&quot;, &quot;p&quot;))) %&gt;% mutate(customer = paste(first_name, last_name, sep = &quot; &quot;), rented = if_else(is.na(rental_id), 0, 1), paid = if_else(is.na(payment_id), 0, 1)) %&gt;% group_by(customer_id.x, customer, rented) %&gt;% summarize(cust_cnt = n(), rentals = sum(rented, na.rm = TRUE), payments = sum(paid, na.rm = TRUE), paid_amt = sum(ifelse(is.na(amount), 0, amount), na.rm = TRUE)) %&gt;% filter(rentals == 0 | rentals &gt; 40) %&gt;% rename(id = customer_id.x) %&gt;% select(id, customer, cust_cnt, rentals, payments, paid_amt) %&gt;% arrange(desc(rentals)) %&gt;% collect() sp_print_df(customer_rental_high_low_dplyr) 17.4.27 27. Who are the top-n1 and bottom-n2 customers? The issue with the two previous reports is that the top end is hardcoded, rentals &gt; 40. Over time, the current customers will always be in the top section and new customers will get added. Another way of looking at the previous report is to show just the top and bottom 5 customers. Parameterize the previous exercise to show the top 5 and bottom 5 customers. To answer this question we look at the customer, rental, and payments tables again. customer_rentals_hi_low_sql &lt;- function(con, high_n, low_n) { customer_rental_high_low_sql &lt;- dbGetQuery(con, &quot;select * from ( select * ,ROW_NUMBER() OVER(ORDER BY rentals desc) rent_hi_low ,ROW_NUMBER() OVER(ORDER BY rentals ) rent_low_hi FROM ( select c.customer_id id ,concat(c.first_name,&#39; &#39;,c.last_name) customer ,count(*) cust_cnt ,count(r.rental_id) rentals ,count(p.payment_id) payments ,sum(coalesce(p.amount,0)) paid_amt from customer c left outer join rental r on c.customer_id = r.customer_id left outer join payment p on r.rental_id = p.rental_id group by c.customer_id ,c.first_name ,c.last_name ) as summary ) row_nums where rent_hi_low &lt;= $1 or rent_low_hi &lt;= $2 order by rent_hi_low &quot;, c(high_n, low_n)) return(customer_rental_high_low_sql) } The next code block executes a sql version of such a function. With top_n = 5 and bot_n = 5, it replicates the hard coded version of the previous exercise. With top_n = 5 and bot_n = 0, it gives a top 5 report. With top_n = 0 and bot_n = 5, the report returns the bottom 5. Change the two parameters to see the output from the different combinations. top_n = 5 bot_n = 5 sp_print_df(customer_rentals_hi_low_sql(con,top_n,bot_n)) 17.4.27.1 Replicate the function above use dplyr syntax. Column Mapping Definition id customer.customer_id cust_cnt customer count rentals customer rentals payments customer payments paid_amt payment.amount aggregated payment amount rent_hi_low sequence with 1 = customer with highest rentals rent_low_hi sequence with 1 = customer with the lowest rentals # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) # Parameters con: database connection high_n: top n customers low_n: bottom # n customers customer_rentals_hi_low_dplr &lt;- function(con, high_n, low_n) { customer_table &lt;- tbl(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) payment_table &lt;- tbl(con, &quot;payment&quot;) customer_rental_loj_hi_low_d &lt;- customer_table %&gt;% left_join(rental_table, by = c(customer_id = &quot;customer_id&quot;), suffix(c(&quot;.c&quot;, &quot;.r&quot;))) %&gt;% left_join(payment_table, by = c(rental_id = &quot;rental_id&quot;), suffix(c(&quot;r&quot;, &quot;p&quot;))) %&gt;% mutate(customer = paste(first_name, last_name, sep = &quot; &quot;), rented = if_else(is.na(rental_id), 0, 1), paid = if_else(is.na(payment_id), 0, 1)) %&gt;% group_by(customer_id.x, customer, rented) %&gt;% summarize(cust_cnt = n(), rentals = sum(rented, na.rm = TRUE), payments = sum(paid, na.rm = TRUE), paid_amt = sum(ifelse(is.na(amount), 0, amount), na.rm = TRUE)) %&gt;% rename(id = customer_id.x) %&gt;% select(id, customer, cust_cnt, rentals, payments, paid_amt) %&gt;% arrange(desc(rentals)) %&gt;% collect() # Add the rankings customer_rental_loj_hi_low_d &lt;- cbind(customer_rental_loj_hi_low_d, rent_hi_low = 1:nrow(customer_rental_loj_hi_low_d), rent_low_hi = nrow(customer_rental_loj_hi_low_d):1) customer_rental_loj_hi_low_d %&gt;% filter(rent_hi_low &lt;= high_n | rent_low_hi &lt;= low_n) %&gt;% arrange(rent_hi_low) } The next code block executes your dplyr version of such a function. With top_n = 5 and bot_n = 5, it replicates the hard coded version of the previous exercise. With top_n = 5 and bot_n = 0, it gives a top 5 report. With top_n = 0 and bot_n = 5, the report returns the bottom 5. Change the two parameters to see the output from the different combinations. # con is the connection string opened at the top of the file. top_n = 5 bot_n = 5 sp_print_df(customer_rentals_hi_low_dplr(con,top_n,bot_n)) 17.4.28 28. How much has each store collected? How are the stores performing? The SQL code shows the payments made to each store in the business. store_payments_sql &lt;- dbGetQuery(con, &quot;select s.store_id,sum(p.amount) amount,count(*) cnt from payment p join staff s on p.staff_id = s.staff_id group by store_id order by 2 desc ; &quot;) sp_print_df(store_payments_sql) Each store collected just over 30,000 in revenue and each store had about 7300 rentals. 17.4.28.1 Replicate the output above using dplyr syntax. # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) store_payments_dplyr &lt;- payment_table %&gt;% inner_join(staff_table, by = c(&quot;staff_id&quot;, &quot;staff_id&quot;)) %&gt;% group_by(staff_id) %&gt;% summarize(amount = sum(amount, na.rm = TRUE), cnt = n()) %&gt;% arrange(desc(amount)) %&gt;% collect() sp_print_df(store_payments_dplyr) 17.4.29 29. What is the business distribution of payments? To answer this question we look at the rental, payment, inventory, and film tables to answer this question. As a sanity check, we first check the number of rentals and amount payments. rentals_payments_sql &lt;- dbGetQuery(con, &quot;select &#39;rentals&#39; rec_type, count(*) cnt_amt from rental union select &#39;payments&#39; rec_type, sum(amount) from payment &quot;) sp_print_df(rentals_payments_sql) business_payment_dist_sql &lt;- dbGetQuery( con, &quot;select no_pay_rec_due ,no_pay_rec_cnt ,round(100.0 * no_pay_rec_cnt/rentals,2) no_pay_rec_pct ,rate_eq_paid ,rate_eq_paid_cnt ,round(100.0 * rate_eq_paid_cnt/rentals,2) rate_eq_paid_pct ,rate_lt_paid ,rate_lt_over_paid ,rate_lt_paid_cnt ,round(100.0 * rate_lt_paid_cnt/rentals,2) rate_lt_paid_pct ,rate_gt_paid_due ,rate_gt_paid_cnt ,round(100.0 * rate_gt_paid_cnt/rentals,2) rate_gt_paid_pct ,rentals ,rate_eq_paid_cnt + rate_lt_paid_cnt + rate_gt_paid_cnt payments ,round(100.0 * (no_pay_rec_cnt + rate_eq_paid_cnt + rate_lt_paid_cnt + rate_gt_paid_cnt)/rentals ,2) pct ,rate_eq_paid + rate_lt_paid + rate_lt_over_paid amt_paid ,no_pay_rec_due + rate_gt_paid_due amt_due from ( select sum(case when p.rental_id is null then rental_rate else 0 end ) no_pay_rec_due ,sum(case when p.rental_id is null then 1 else 0 end) no_pay_rec_cnt ,sum(case when f.rental_rate = p.amount then p.amount else 0 end) rate_eq_paid ,sum(case when f.rental_rate = p.amount then 1 else 0 end ) rate_eq_paid_cnt ,sum(case when f.rental_rate &lt; p.amount then f.rental_rate else 0 end) rate_lt_paid ,sum(case when f.rental_rate &lt; p.amount then p.amount-f.rental_rate else 0 end) rate_lt_over_paid ,sum(case when f.rental_rate &lt; p.amount then 1 else 0 end) rate_lt_paid_cnt ,sum(case when f.rental_rate &gt; p.amount then f.rental_rate - p.amount else 0 end ) rate_gt_paid_due ,sum(case when f.rental_rate &gt; p.amount then 1 else 0 end ) rate_gt_paid_cnt ,count(*) rentals FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id ) as details ;&quot; ) # Rental counts sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;cnt&quot;),rentals)) # Payments sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;paid&quot;))) # Not paid amounts sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;due&quot;))) # Rental payments sp_print_df(business_payment_dist_sql %&gt;% select(ends_with(&quot;pct&quot;))) These are interesting results. 09.06% of the total records have no associated payment record in the amount of 4302.47 49.39% of the rentals have been fully paid in full, 23397.75. 41.40% of the rentals have collected more than the rental amount by 18456.75 00.15% of the rentals have collected less than the rental amount by 67.76. The no_pay_rec_cnt + rate_gt_paid_cnt, \\(1453 + 24 = 1477\\) is the number of rentals which have not been paid in full. The total outstanding balance is \\(4302.47 + 67.76 = 4370.23\\) With over 40 percent over collection, someone needs to find out what is wrong with the collection process. Many customers are owed credits or free rentals. 17.4.29.1 Replicate the output above using dplyr syntax. This table describes the columns in the code block answer that follows. There are payment records where the charged amount, rental rate, is less than the amount paid. These payments are split into two pieces, rate_lt_paid and rate_lt_over_paid. The rate_lt_paid is rental rate amount. The rate_lt_over_paid is the paid amount - rental rate, the over paid amount. Column Mapping Definition no_pay_rec_cnt number of DVD rentals without an associated payment record. rate_eq_paid_cnt number of DVD payments that match the film rental rate. rate_lt_paid_cnt number of DVD rental with rental rate less than the amount paid. rate_gt_paid_cnt number of DVD rentals with rental rate greater than the film rental rate. rentals number of rental records analyzed rate_eq_paid amount paid where the rate charged = amount paid rate_lt_paid amount paid where the rate charged &lt; rate_lt_over_paid rate charged &lt; amount paid; This represents the amount over paid amt_paid Total amount paid no_pay_rec_due DVD rentals charges due without a payment record rate_gt_paid_due DVD rentals charged due with a payment record amt_due Total amount due and not collected. no_pay_rec_pct Percent of rentals without a payment record. rate_lt_paid_pct Percent of rentals where the rental charge is less than the paid amount rate_gt_paid_pct Percent of rentals where the rental charge is greater than the paid amount pct Sum of percentages # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) business_payment_dist_dplyr &lt;- rental_table %&gt;% left_join(payment_table, by = c(&quot;rental_id&quot;, &quot;rental_id&quot;, &quot;customer_id&quot;, &quot;customer_id&quot;), suffix = c(&quot;.r&quot;, &quot;.p&quot;)) %&gt;% inner_join(inventory_table, by = c(&quot;inventory_id&quot;, &quot;inventory_id&quot;), suffix = c(&quot;.r&quot;, &quot;.i&quot;)) %&gt;% inner_join(film_table, by = c(&quot;film_id&quot;, &quot;film_id&quot;), suffix = c(&quot;.i&quot;, &quot;.f&quot;)) %&gt;% summarize(rentals = n(), no_pay_rec_due = sum(ifelse(is.na(payment_id), rental_rate, 0), na.rm = TRUE), no_pay_rec_cnt = sum(ifelse(is.na(payment_id), 1, 0), na.rm = TRUE), rate_eq_paid = sum(ifelse(rental_rate == amount, amount, 0), na.rm = TRUE), rate_eq_paid_cnt = sum(ifelse(rental_rate == amount, 1, 0), na.rm = TRUE), rental_amt = sum(ifelse(rental_rate &lt; amount, rental_rate, 0), na.rm = TRUE), rate_lt_paid = sum(ifelse(rental_rate &lt; amount, rental_rate, 0), na.rm = TRUE), rate_lt_over_paid = sum(ifelse(rental_rate &lt; amount, amount - rental_rate, 0), na.rm = TRUE), rate_lt_paid_cnt = sum(ifelse(rental_rate &lt; amount, 1, 0), na.rm = TRUE), rate_gt_paid_due = sum(ifelse(amount &lt; rental_rate, rental_rate - amount, 0), na.rm = TRUE), rate_gt_paid_cnt = sum(ifelse(amount &lt; rental_rate, 1, 0), na.rm = TRUE)) %&gt;% mutate(no_pay_rec_pct = round(100 * no_pay_rec_cnt/rentals, 2), rate_eq_paid_pct = round(100 * rate_eq_paid_cnt/rentals, 2), rate_lt_paid_pct = round(100 * rate_lt_paid_cnt/rentals, 2), rate_gt_paid_pct = round(100 * rate_gt_paid_cnt/rentals, 2), payments = rate_eq_paid_cnt + rate_lt_paid_cnt + rate_gt_paid_cnt, amt_paid = rate_eq_paid + rate_lt_over_paid + rental_amt, pct = no_pay_rec_pct + rate_eq_paid_pct + rate_lt_paid_pct + rate_gt_paid_pct, amt_due = no_pay_rec_due + rate_gt_paid_due) %&gt;% select(no_pay_rec_due, no_pay_rec_cnt, no_pay_rec_pct, rate_eq_paid, rate_eq_paid_cnt, rate_eq_paid_pct, rate_lt_paid, rate_lt_over_paid, rate_lt_paid_cnt, rate_lt_paid_pct, rate_gt_paid_due, rate_gt_paid_cnt, rate_gt_paid_pct, rentals, payments, pct, amt_paid, amt_due) %&gt;% collect() # Rental counts sp_print_df(business_payment_dist_dplyr %&gt;% select(ends_with(&quot;cnt&quot;), rentals)) # Payments sp_print_df(business_payment_dist_dplyr %&gt;% select(ends_with(&quot;paid&quot;))) # Not paid amounts sp_print_df(business_payment_dist_dplyr %&gt;% select(ends_with(&quot;due&quot;))) # Rental payments sp_print_df(business_payment_dist_dplyr %&gt;% select(ends_with(&quot;pct&quot;))) 17.4.29.2 Bad data analysis Here are the sanity check numbers calculated at the beginning of this exercise. rec_type cnt_amt payments 61312.04 rentals 16045.00 Note that the sanity check numbers above, do not match the numbers above. If you query returned the numbers above, use the following result set ot see where the differences exist. rs &lt;- dbGetQuery( con, &quot;SELECT &#39;correct join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id,p.amount FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id where r.rental_id = 4591 UNION SELECT &#39;incorrect join&#39; hint,r.rental_id,r.customer_id,p.customer_id payment_customer_id,p.rental_id payment_rental_id,p.amount FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id where r.rental_id = 4591 and p.customer_id != 182 ;&quot;) sp_print_df(head(rs)) 17.4.30 30. Which customers have the highest open amounts? From the previous exercise, we know that there are 1477 missing payment records or not fully paid payment records. List the top 5 customers from each category base on balance due amounts. To answer this question we look at the rental, payment, inventory, film and customer tables to answer this question. customer_open_amts_sql &lt;- dbGetQuery(con, &quot; select customer_id ,concat(first_name,&#39; &#39;,last_name) customer ,pay_record ,rental_amt ,paid_amt ,due_amt ,cnt ,rn from (select c.customer_id ,c.first_name ,c.last_name ,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end Pay_record ,sum(f.rental_rate) rental_amt ,sum(coalesce(p.amount,0)) paid_amt ,sum(f.rental_rate - coalesce(p.amount,0)) due_amt ,count(*) cnt ,row_number() over (partition by case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end order by sum(f.rental_rate - coalesce(p.amount,0)) desc,c.customer_id) rn FROM rental r LEFT JOIN payment p ON r.rental_id = p.rental_id and r.customer_id = p.customer_id INNER JOIN inventory i ON r.inventory_id = i.inventory_id INNER JOIN film f ON i.film_id = f.film_id INNER JOIN customer c ON r.customer_id = c.customer_id WHERE f.rental_rate &gt; coalesce(p.amount, 0) group by c.customer_id,c.first_name,c.last_name,case when p.amount is null then &#39;No&#39; else &#39;Yes&#39; end ) as src where rn &lt;= 5 -- and Pay_record = &#39;No&#39; or Pay_record = &#39;Yes&#39; order by Pay_record,rn &quot;) sp_print_df(customer_open_amts_sql) From the previous exercise we see that the number of rentals that have not been paid in full is 1477. There are 24 records that have a payment record, pay_record = Yes, all have a 0 paid amount. There are 1453 DVDs rented out that have no payment record. The top 3 customers have 10 DVDs each that have not been paid. 17.4.30.1 Replicate the output above using dplyr syntax. column definition mapping customer first_name + last_name Pay_record Payment record exists Y/N case when p.amount is null then No else Yes end rental_amt aggrgated film.rental_rate paid_amt aggregated payment.amount due_amt aggregated film.rental_rate - payment.amount cnt number of rentals/customer rn row number # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_open_amts_dplyr &lt;- rental_table %&gt;% left_join(payment_table, by = c(&quot;rental_id&quot;, &quot;rental_id&quot;, &quot;customer_id&quot;, &quot;customer_id&quot;), suffix = c(&quot;.r&quot;, &quot;.p&quot;)) %&gt;% inner_join(inventory_table, by = c(&quot;inventory_id&quot;, &quot;inventory_id&quot;), suffix = c(&quot;.r&quot;, &quot;.i&quot;)) %&gt;% inner_join(film_table, by = c(&quot;film_id&quot;, &quot;film_id&quot;), suffix = c(&quot;.i&quot;, &quot;.f&quot;)) %&gt;% inner_join(customer_table, by = c(customer_id = &quot;customer_id&quot;)) %&gt;% filter(rental_rate &gt; ifelse(is.na(amount), 0, amount)) %&gt;% mutate(customer = paste0(first_name, &quot; &quot;, last_name), pay_record = ifelse(is.na(amount), &quot;No&quot;, &quot;Yes&quot;), paid = ifelse(is.na(amount), 0, amount)) %&gt;% group_by(customer_id, customer, pay_record) %&gt;% summarize(rental_amt = sum(rental_rate, na.rm = TRUE), paid_amt = sum(paid, na.rm = TRUE), due_amt = sum(rental_rate - paid, na.rm = TRUE), cnt = n()) %&gt;% arrange(pay_record, desc(due_amt)) %&gt;% group_by(pay_record) %&gt;% mutate(id = row_number()) %&gt;% filter(id &lt;= 5) %&gt;% select(customer_id, customer, pay_record, rental_amt, paid_amt, due_amt, cnt, id) %&gt;% collect() sp_print_df(customer_open_amts_dplyr) 17.4.31 31. What is the business cash flow? In the previous exercise we saw that about 50% of the rentals collected the correct amount and 40% of the rentals over collected. The last 10% were never collected. Calculate the number of days it took before the payment was collected and the amount collected? To answer this question we look at the rental, customer, payment, inventory, payment and film tables to answer this question. cash_flow_sql &lt;- dbGetQuery(con, &quot;SELECT payment_date - exp_rtn_dt payment_days ,sum(coalesce(amount, charges)) paid_or_due ,count(*) late_returns FROM ( SELECT payment_date::DATE ,(r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::DATE exp_rtn_dt ,p.amount ,f.rental_rate charges ,r.rental_date ,r.return_date FROM rental r LEFT JOIN customer c ON c.customer_id = r.customer_id LEFT JOIN address a ON c.address_id = a.address_id LEFT JOIN city ON city.city_id = a.city_id LEFT JOIN country ctry ON ctry.country_id = city.country_id LEFT JOIN inventory i ON r.inventory_id = i.inventory_id LEFT JOIN payment p ON c.customer_id = p.customer_id AND p.rental_id = r.rental_id LEFT JOIN film f ON i.film_id = f.film_id WHERE return_date &gt; (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::DATE ) AS src GROUP BY payment_date - exp_rtn_dt ORDER BY payment_date - exp_rtn_dt DESC&quot;) sp_print_df(cash_flow_sql) Wow those are really generous terms. Customers are paying 1.2 to 1.7 years after they returned the DVD. This business is in serious financial trouble! 17.4.31.1 Replicate the output above using dplyr syntax. column definition mapping paid_or_due paid amt associated with rental or the rental_rate ifelse(is.na(amount),rental_rate,amount) payment_days days til payment payment_date - rental_date # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) cash_flow_dplyr &lt;- rental_table %&gt;% left_join(payment_table, by = c(rental_id = &quot;rental_id&quot;, customer_id = &quot;customer_id&quot;)) %&gt;% left_join(inventory_table, by = (&quot;inventory_id&quot; = &quot;inventory_id&quot;)) %&gt;% left_join(film_table, by = (&quot;film_id&quot; = &quot;film_id&quot;)) %&gt;% mutate(pay_dt = date(payment_date), exp_rtn_dt = date(rental_date) + rental_duration, rdate = date(rental_date), payment_days = date(payment_date) - (date(rental_date) + rental_duration)) %&gt;% filter(return_date &gt; exp_rtn_dt) %&gt;% group_by(payment_days) %&gt;% summarize(paid_or_due = sum(ifelse(is.na(amount), rental_rate, amount), na.rm = TRUE), late_returns = n()) %&gt;% arrange(desc(payment_days)) %&gt;% select(payment_days, paid_or_due, late_returns) %&gt;% collect() sp_print_df(cash_flow_dplyr) 17.4.32 32. Customer information Create a function that takes a customer id and returns customer address information films rented and returned information customer payment information The hidden code block implements such a function in SQL. To answer this question we look at the rental, customer, address, city,country,inventory,paymentandfilm` tables to answer this question. customer_details_fn_sql &lt;- function(cust_id) { customer_details_sql &lt;- dbGetQuery(con, &quot;select c.customer_id id,concat(first_name,&#39; &#39;,c.last_name) customer ,c.email,a.phone,a.address,address2,city.city,a.postal_code,ctry.country ,c.store_id cust_store_id ,i.store_id inv_store_id ,f.film_id ,f.title ,r.rental_date::date rented ,r.return_date::date returned ,(r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date exp_rtn_dt ,case when r.return_date is null then null else r.return_date::date - (r.rental_date + INTERVAL &#39;1 day&#39; * f.rental_duration)::date end rtn_stat ,case when r.rental_id is null then null -- dvd returned when r.return_date is null then 1 else 0 end not_rtn ,payment_date::date pay_dt ,f.rental_rate charges ,p.amount paid ,p.amount-f.rental_rate delta ,p.staff_id pay_staff_id ,payment_date::date - rental_date::date pay_days ,r.rental_id,i.inventory_id,payment_id from customer c left join rental r on c.customer_id = r.customer_id left join address a on c.address_id = a.address_id left join city on city.city_id = a.city_id left join country ctry on ctry.country_id = city.country_id left join inventory i on r.inventory_id = i.inventory_id left join payment p on c.customer_id = p.customer_id and p.rental_id = r.rental_id left join film f on i.film_id = f.film_id where c.customer_id = $1 order by id,rented desc &quot;, cust_id) return(customer_details_sql) } The following code block executes the customer function. Change the cust_id value to see differnt customers. cust_id &lt;- 600 sp_print_df( customer_details_fn_sql(cust_id)) 17.4.32.1 Replicate the output above using dplyr syntax. column definition mapping id customer_id customer first_name + last_name exp_rtn_dt expected return date rental.rental_date + film.rental_duration rtn_stat return status rental.return_date - (rental.rental_date + film duration) not_rtn dvd not returned null if rental_id is null;not rented; 1 return_date null else 0 pay_dt payment_date delta payment.amount-film.rental_rate pay_staff_id payment.staff_id payment.staff_id pay_days days til payment payment_date - rental_date # sp_tbl_descr(&#39;table_name&#39;) sp_tbl_pk_fk(&#39;table_name&#39;) # sp_print_df(table_rows_sql) customer_details_fn_dplyr &lt;- function(cust_id) { customer_details_dplyr &lt;- customer_table %&gt;% left_join(rental_table, by = c(customer_id = &quot;customer_id&quot;)) %&gt;% left_join(address_table, by = c(address_id = &quot;address_id&quot;)) %&gt;% left_join(city_table, by = c(city_id = &quot;city_id&quot;)) %&gt;% left_join(country_table, by = c(country_id = &quot;country_id&quot;)) %&gt;% left_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;)) %&gt;% mutate(inv_store_id = store_id.y) %&gt;% left_join(payment_table, by = c(customer_id = &quot;customer_id&quot;, rental_id = &quot;rental_id&quot;)) %&gt;% left_join(film_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% filter(customer_id == cust_id) %&gt;% mutate(customer = paste0(first_name, &quot; &quot;, last_name), exp_rtn_dt = date(rental_date) + rental_duration, rtn_days = date(return_date) - (date(rental_date) + rental_duration), rented = Date(rental_date), returned = Date(return_date), not_rtn = ifelse(is.na(rental_id), rental_id, ifelse(is.na(return_date), 1, 0)), delta = amount - rental_rate, pay_days = date(payment_date) - (date(rental_date) + rental_duration)) %&gt;% rename(id = customer_id, cust_store_id = store_id.x, charges = rental_rate, paid = amount, pay_dt = payment_date, pay_staff_id = staff_id.y) %&gt;% select(id, customer, email, phone, address, address2, city, postal_code, country, cust_store_id, inv_store_id, film_id, title, rented, returned, exp_rtn_dt, rtn_days, not_rtn, pay_dt, charges, paid, delta, pay_staff_id, pay_days, film_id, rental_id, inventory_id, payment_id) %&gt;% collect() return(customer_details_dplyr) } Use the following code block to test the dplyr function. cust_id &lt;- 601 sp_print_df(customer_details_fn_dplyr(cust_id)) 17.5 Different strategies for interacting with the database select examples dbGetQuery returns the entire result set as a data frame. For large returned datasets, complex or inefficient SQL statements, this may take a long time. dbSendQuery: parses, compiles, creates the optimized execution plan. dbFetch: Execute optimzed execution plan and return the dataset. dbClearResult: remove pending query results from the database to your R environment 17.5.1 1. dbGetQuery Versus dbSendQuery+dbFetch+dbClearResult How many customers are there in the DVD Rental System? rs1 &lt;- dbGetQuery(con, &quot;select * from customer;&quot;) sp_print_df(head(rs1)) fetch &lt;- 0 rows &lt;- 0 pco &lt;- dbSendQuery(con, &quot;select * from customer;&quot;) while (!dbHasCompleted(pco)) { rs2 &lt;- dbFetch(pco, n = 100) fetch &lt;- fetch + 1 rows &lt;- rows + nrow(rs2) print(paste0(&quot;fetch=&quot;, fetch, &quot; fetched rows=&quot;, nrow(rs2), &quot; running rows fetched=&quot;, rows)) # add additional code to process fetched records } ## [1] &quot;fetch=1 fetched rows=100 running rows fetched=100&quot; ## [1] &quot;fetch=2 fetched rows=100 running rows fetched=200&quot; ## [1] &quot;fetch=3 fetched rows=100 running rows fetched=300&quot; ## [1] &quot;fetch=4 fetched rows=100 running rows fetched=400&quot; ## [1] &quot;fetch=5 fetched rows=100 running rows fetched=500&quot; ## [1] &quot;fetch=6 fetched rows=100 running rows fetched=600&quot; ## [1] &quot;fetch=7 fetched rows=4 running rows fetched=604&quot; dbClearResult(pco) sp_print_df(head(rs2)) 17.5.2 2. Dplyr write results to the database example smy_customer_details_dplyr &lt;- customer_table %&gt;% left_join(rental_table, by = c(customer_id = &quot;customer_id&quot;)) %&gt;% left_join(address_table, by = c(address_id = &quot;address_id&quot;)) %&gt;% left_join(city_table, by = c(city_id = &quot;city_id&quot;)) %&gt;% left_join(country_table, by = c(country_id = &quot;country_id&quot;)) %&gt;% left_join(inventory_table, by = c(inventory_id = &quot;inventory_id&quot;)) %&gt;% mutate(inv_store_id = store_id.y) %&gt;% left_join(payment_table, by = c(customer_id = &quot;customer_id&quot;, rental_id = &quot;rental_id&quot;)) %&gt;% left_join(film_table, by = c(film_id = &quot;film_id&quot;)) %&gt;% mutate(customer = paste0(first_name, &quot; &quot;, last_name), exp_rtn_dt = date(rental_date) + rental_duration, rtn_days = date(return_date) - (date(rental_date) + rental_duration), rented = Date(rental_date), returned = Date(return_date), not_rtn = ifelse(is.na(rental_id), rental_id, ifelse(is.na(return_date), 1, 0)), delta = amount - rental_rate, pay_days = date(payment_date) - (date(rental_date) + rental_duration)) %&gt;% rename(id = customer_id, cust_store_id = store_id.x, charges = rental_rate, paid = amount, pay_dt = payment_date, pay_staff_id = staff_id.y) %&gt;% select(id, customer, email, phone, address, address2, city, postal_code, country, cust_store_id, inv_store_id, film_id, title, rented, returned, exp_rtn_dt, rtn_days, not_rtn, pay_dt, charges, paid, delta, pay_staff_id, pay_days, film_id, rental_id, inventory_id, payment_id) # drop table if (db_has_table(con, &quot;smy_compute_exercise&quot;)) { db_drop_table(con, &quot;smy_compute_exercise&quot;) } # create database tabe compute(smy_customer_details_dplyr, name = &quot;smy_compute_exercise&quot;, temporary = FALSE) ## # Source: table&lt;smy_compute_exercise&gt; [?? x 27] ## # Database: postgres [postgres@localhost:5439/dvdrental] ## id customer email phone address address2 city postal_code country ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 341 Peter M pete 7189 1217 K &quot;&quot; Ede 504 Nether ## 2 341 Peter M pete 7189 1217 K &quot;&quot; Ede 504 Nether ## 3 341 Peter M pete 7189 1217 K &quot;&quot; Ede 504 Nether ## 4 341 Peter M pete 7189 1217 K &quot;&quot; Ede 504 Nether ## 5 342 Harold  haro 6976 1293 N &quot;&quot; Boa  71583 Brazil ## 6 343 Douglas doug 8956 785 Va &quot;&quot; Mexi 36170 Mexico ## 7 343 Douglas doug 8956 785 Va &quot;&quot; Mexi 36170 Mexico ## 8 343 Douglas doug 8956 785 Va &quot;&quot; Mexi 36170 Mexico ## 9 344 Henry B henr 6453 1516 E &quot;&quot; Nuku 46069 Tonga ## 10 344 Henry B henr 6453 1516 E &quot;&quot; Nuku 46069 Tonga ## #  with more rows, and 18 more variables: cust_store_id &lt;int&gt;, ## # inv_store_id &lt;int&gt;, film_id &lt;int&gt;, title &lt;chr&gt;, rented &lt;date&gt;, ## # returned &lt;date&gt;, exp_rtn_dt &lt;date&gt;, rtn_days &lt;int&gt;, not_rtn &lt;dbl&gt;, ## # pay_dt &lt;dttm&gt;, charges &lt;dbl&gt;, paid &lt;dbl&gt;, delta &lt;dbl&gt;, ## # pay_staff_id &lt;int&gt;, pay_days &lt;int&gt;, rental_id &lt;int&gt;, ## # inventory_id &lt;int&gt;, payment_id &lt;int&gt; # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) knitr::knit_exit() "],
["chapter-anti-join-cost-comparisons.html", "Chapter 18 Anti-join cost comparisons 18.1 SQL anti join Costs 18.2 dplyr Anti joins", " Chapter 18 Anti-join cost comparisons Verify Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; Verify pet DB is available, it may be stopped. sp_show_all_docker_containers() ## CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ## 1918fe2a68e7 postgres-dvdrental &quot;docker-entrypoint.s&quot; About a minute ago Exited (0) 2 seconds ago sql-pet Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the database with R # need to wait for Docker &amp; Postgres to come up before connecting. con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) source(file=here(&#39;book-src/sql_pet_data.R&#39;),echo=TRUE) ## ## &gt; dbExecute(con, &quot;delete from film_category where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from rental where rental_id &gt;= 16050;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from inventory where film_id &gt;= 1001;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;delete from film where film_id &gt;= 1001;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;delete from customer where customer_id &gt;= 600;&quot;) ## [1] 5 ## ## &gt; dbExecute(con, &quot;delete from store where store_id &gt; 2;&quot;) ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into customer\\n (customer_id,store_id,first_name,last_name,email,address_id,activebool\\n ,create_date,last_update,active)\\n ...&quot; ... [TRUNCATED] ## [1] 5 ## ## &gt; dbExecute(con, &quot;ALTER TABLE store DISABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; df &lt;- data.frame(store_id = 10, manager_staff_id = 10, ## + address_id = 10, last_update = Sys.time()) ## ## &gt; dbWriteTable(con, &quot;store&quot;, value = df, append = TRUE, ## + row.names = FALSE) ## ## &gt; dbExecute(con, &quot;ALTER TABLE store ENABLE TRIGGER ALL;&quot;) ## [1] 0 ## ## &gt; dbExecute(con, &quot;insert into film\\n (film_id,title,description,release_year,language_id\\n ,rental_duration,rental_rate,length,replacement_cost,rati ...&quot; ... [TRUNCATED] ## [1] 1 ## ## &gt; dbExecute(con, &quot;insert into film_category\\n (film_id,category_id,last_update)\\n values(1001,6,now()::date)\\n ,(1001,7,now()::date)\\n ;&quot;) ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into inventory\\n (inventory_id,film_id,store_id,last_update)\\n values(4582,1001,1,now()::date)\\n ,(4583,1001,2,now()::date ...&quot; ... [TRUNCATED] ## [1] 2 ## ## &gt; dbExecute(con, &quot;insert into rental\\n (rental_id,rental_date,inventory_id,customer_id,return_date,staff_id,last_update)\\n values(16050,now()::date ...&quot; ... [TRUNCATED] ## [1] 1 Explain plans here 18.1 SQL anti join Costs sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c left outer join store s on c.store_id = s.store_id where s.store_id is null group by customer_id, first_name, last_name, c.store_id order by c.customer_id;&quot; ) sql_aj2 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c where c.store_id NOT IN (select store_id from store) group by customer_id, first_name, last_name, c.store_id order by c.customer_id;&quot; ) sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select &#39;aj&#39; join_type, customer_id, first_name, last_name, c.store_id,count(*) ajs from customer c where not exists (select s.store_id from store s where s.store_id = c.store_id) group by customer_id, first_name, last_name, c.store_id order by c.customer_id &quot; ) 18.1.0.0.1 SQL Costs print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=33.28..38.53 rows=300 width=266) (actual time=0.396..0.400 rows=4 loops=1) print(glue(&quot;sql_aj2 not in costs=&quot;, sql_aj2[1, 1])) ## sql_aj2 not in costs=GroupAggregate (cost=29.86..35.11 rows=300 width=262) (actual time=0.336..0.339 rows=4 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=GroupAggregate (cost=33.28..38.53 rows=300 width=262) (actual time=0.365..0.369 rows=4 loops=1) 18.2 dplyr Anti joins In this next section we look at two methods to implemnt an anti join in dplyr. customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) # Method 1. dplyr anti_join daj1 &lt;- anti_join(customer_table, rental_table, by = &quot;customer_id&quot;, suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT * FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## ## WHERE NOT EXISTS ( ## SELECT 1 FROM &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## WHERE (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## )) &quot;ahwfiyasld&quot; ## ## &lt;PLAN&gt; ## Hash Anti Join (cost=510.99..552.63 rows=300 width=334) ## Hash Cond: (&quot;TBL_LEFT&quot;.customer_id = &quot;TBL_RIGHT&quot;.customer_id) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) ## -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=2) customer_table &lt;- tbl(con, &quot;customer&quot;) # DBI::dbReadTable(con, &quot;customer&quot;) rental_table &lt;- tbl(con, &quot;rental&quot;) # DBI::dbReadTable(con, &quot;rental&quot;) # Method 2. dplyr loj with NA daj2 &lt;- left_join(customer_table, rental_table, by = c(&quot;customer_id&quot;, &quot;customer_id&quot;), suffix = c(&quot;.c&quot;, &quot;.r&quot;)) %&gt;% filter(is.na(rental_id)) %&gt;% select(c(&quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot;)) %&gt;% explain() ## &lt;SQL&gt; ## SELECT &quot;first_name&quot;, &quot;last_name&quot;, &quot;email&quot; ## FROM (SELECT &quot;TBL_LEFT&quot;.&quot;customer_id&quot; AS &quot;customer_id&quot;, &quot;TBL_LEFT&quot;.&quot;store_id&quot; AS &quot;store_id&quot;, &quot;TBL_LEFT&quot;.&quot;first_name&quot; AS &quot;first_name&quot;, &quot;TBL_LEFT&quot;.&quot;last_name&quot; AS &quot;last_name&quot;, &quot;TBL_LEFT&quot;.&quot;email&quot; AS &quot;email&quot;, &quot;TBL_LEFT&quot;.&quot;address_id&quot; AS &quot;address_id&quot;, &quot;TBL_LEFT&quot;.&quot;activebool&quot; AS &quot;activebool&quot;, &quot;TBL_LEFT&quot;.&quot;create_date&quot; AS &quot;create_date&quot;, &quot;TBL_LEFT&quot;.&quot;last_update&quot; AS &quot;last_update.c&quot;, &quot;TBL_LEFT&quot;.&quot;active&quot; AS &quot;active&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_id&quot; AS &quot;rental_id&quot;, &quot;TBL_RIGHT&quot;.&quot;rental_date&quot; AS &quot;rental_date&quot;, &quot;TBL_RIGHT&quot;.&quot;inventory_id&quot; AS &quot;inventory_id&quot;, &quot;TBL_RIGHT&quot;.&quot;return_date&quot; AS &quot;return_date&quot;, &quot;TBL_RIGHT&quot;.&quot;staff_id&quot; AS &quot;staff_id&quot;, &quot;TBL_RIGHT&quot;.&quot;last_update&quot; AS &quot;last_update.r&quot; ## FROM &quot;customer&quot; AS &quot;TBL_LEFT&quot; ## LEFT JOIN &quot;rental&quot; AS &quot;TBL_RIGHT&quot; ## ON (&quot;TBL_LEFT&quot;.&quot;customer_id&quot; = &quot;TBL_RIGHT&quot;.&quot;customer_id&quot;) ## ) &quot;txeusoqilr&quot; ## WHERE (((&quot;rental_id&quot;) IS NULL)) ## ## &lt;PLAN&gt; ## Hash Right Join (cost=22.48..375.33 rows=80 width=334) ## Hash Cond: (&quot;TBL_RIGHT&quot;.customer_id = &quot;TBL_LEFT&quot;.customer_id) ## Filter: (&quot;TBL_RIGHT&quot;.rental_id IS NULL) ## -&gt; Seq Scan on rental &quot;TBL_RIGHT&quot; (cost=0.00..310.44 rows=16044 width=6) ## -&gt; Hash (cost=14.99..14.99 rows=599 width=338) ## -&gt; Seq Scan on customer &quot;TBL_LEFT&quot; (cost=0.00..14.99 rows=599 width=338) In this example, the dplyr anti_join verb is 1.4113447 to 22.7308719 times more expensive than the left outer join with a null condition. sql_aj1 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c left outer join rental r on c.customer_id = r.customer_id where r.customer_id is null group by c.customer_id order by c.customer_id;&quot; ) sp_print_df(sql_aj1) sql_aj1 ## QUERY PLAN ## 1 GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=16.001..16.006 rows=4 loops=1) ## 2 Group Key: c.customer_id ## 3 -&gt; Sort (cost=564.97..565.72 rows=300 width=4) (actual time=15.993..15.994 rows=4 loops=1) ## 4 Sort Key: c.customer_id ## 5 Sort Method: quicksort Memory: 25kB ## 6 -&gt; Hash Anti Join (cost=510.99..552.63 rows=300 width=4) (actual time=15.972..15.976 rows=4 loops=1) ## 7 Hash Cond: (c.customer_id = r.customer_id) ## 8 -&gt; Seq Scan on customer c (cost=0.00..14.99 rows=599 width=4) (actual time=0.023..0.217 rows=604 loops=1) ## 9 -&gt; Hash (cost=310.44..310.44 rows=16044 width=2) (actual time=15.373..15.374 rows=16045 loops=1) ## 10 Buckets: 16384 Batches: 1 Memory Usage: 661kB ## 11 -&gt; Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=2) (actual time=0.016..7.596 rows=16045 loops=1) ## 12 Planning time: 0.345 ms ## 13 Execution time: 16.095 ms sql_aj3 &lt;- dbGetQuery( con, &quot;explain analyze select c.customer_id,count(*) lojs from customer c where not exists (select customer_id from rental r where c.customer_id = r.customer_id) group by c.customer_id &quot; ) print(glue(&quot;sql_aj1 loj-null costs=&quot;, sql_aj1[1, 1])) ## sql_aj1 loj-null costs=GroupAggregate (cost=564.97..570.22 rows=300 width=12) (actual time=16.001..16.006 rows=4 loops=1) print(glue(&quot;sql_aj3 not exist costs=&quot;, sql_aj3[1, 1])) ## sql_aj3 not exist costs=HashAggregate (cost=554.13..557.13 rows=300 width=12) (actual time=15.650..15.657 rows=4 loops=1) "],
["chapter-sql-quick-start.html", "Chapter 19 SQL Quick start - simple retrieval 19.1 Intro 19.2 SQL Commands 19.3 SQL SELECT Quick Start 19.4 Paradigm Shift from R-Dplyr to SQL", " Chapter 19 SQL Quick start - simple retrieval This chapter demonstrates: Several elementary SQL statements SQL databases and 3rd normal form 19.1 Intro Coverage in this book. There are many SQL tutorials that are available. For example, we are drawing some materials from a tutorial we recommend. In particular, we will not replicate the lessons there, which you might want to complete. Instead, we are showing strategies that are recommended for R users. That will include some translations of queries that are discussed there. https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html Very good intro. How is ours different? Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE) colFmt &lt;- function(x,color) { # x string # color outputFormat = knitr::opts_knit$get(&quot;rmarkdown.pandoc.to&quot;) if(outputFormat == &#39;latex&#39;) paste(&quot;\\\\textcolor{&quot;,color,&quot;}{&quot;,x,&quot;}&quot;,sep=&quot;&quot;) else if(outputFormat == &#39;html&#39;) paste(&quot;&lt;font color=&#39;&quot;,color,&quot;&#39;&gt;&quot;,x,&quot;&lt;/font&gt;&quot;,sep=&quot;&quot;) else x } # sample call # * `r colFmt(&#39;Cover inline tables in future section&#39;,&#39;red&#39;)` Moved this from 11-elementary-queries dplyr_summary_df &lt;- read.delim( &#39;11-dplyr_sql_summary_table.tsv&#39;, header = TRUE, sep = &#39;\\t&#39;, as.is = TRUE ) sp_print_df(dplyr_summary_df) ## Databases and Third Normal Form - 3NF Most relational database applications are designed to be third normal form like, 3NF. The key benefits of 3NF are speedy on-line transactional processing, OLTP. improved referential integrity, reduce modification anomalies that can occur during an insert, update, or delete operation. reduced storage, elimination of redundant data. 3NF is great for database application input performance, but not so great for getting the data back out for the data analyst or report writer. As a data analyst, you might get the ubiquitous Excel spreadsheet with all the information needed to start an Exploratory Data Analysis, EDA. The spreadsheet may have provider, patient, diagnosis, procedure, and insurance information all neatly arranged on a single row. At least neatly when compared to the same information stored in the database, in at least 5 tables. For this tutorial, the most important thing to know about 3NF is that the data you are looking for gets spread across many many tables. Working in a relational database requires you to find the many many different tables that contains your data. Understand the relationships that tie the tables together correctly to ensure that data is not dropped or duplicated. Data that is dropped or duplicated can either over or understate your aggregated numeric values. hospital-billing-erd https://www.smartdraw.com/entity-relationship-diagram/examples/hospital-billing-entity-relationship-diagram/ Real life applications have 100s or even 1000s of tables supporting the application. The goal is to transform the application data model into a useful data analysis model using the DDL and DML SQL statements. 19.2 SQL Commands SQL commands fall into four categories. SQL Category Definition DDL:Data Definition Language DBAs execute these commands to define objects in the database. DML:Data Manipulation Language Users and developers execute these commands to investigate data. DCL:Data Control Language DBAs execute these commands to grant/revoke access to TCL:Transaction Control Language Developers execute these commands when developing applications. Data analysts use the SELECT DML command to learn interesting things about the data stored in the database. Applications are used to control the insert, update, and deletion of data in the database. Data users can update the database objects via the application which enforces referential integrity in the database. Data users should never directly update data application database objects. Leave this task to the developers and DBAs. DBAs can setup a sandbox within the database for a data analyst. The application(s) do not maintain the data in the sandbox. The sql-pet database is tiny, but for the purposes of these exercises, we assume that data so large that it will not easily fit into the memory of your laptop. This tutorial focuses on the most frequently used SQL statement, the SQL SELECT statement. A SQL SELECT statement consists of 1 to 6 clauses. SQL Clause DPLYR Verb SQL Description SELECT SELECT() Contains a list of column names from an object or a derived value. mutate() FROM Contains a list of related tables from which the SELECT list of columns is derived. WHERE filter() Provides the filter conditions the objects in the FROM clause must meet. GROUP BY group_by() Contains a list rollup aggregation columns. HAVING Provides the filter condition on the the GROUP BY clause. ORDER BY arrange() Contains a list of column names indicating the order of the column value. Each column can be either ASCending or DEScending. The foundation of the SQL language is based set theory and the result of a SQL SELECT statement is referred to as a result set. A SQL SELECT statement is guaranteed to return the same set of data, but not necessarily in the same order. However, in practice, the result set is usually in the same order. SQL SELECT statements can be broken up into two categories, SELECT detail statements and SELECT aggregate statements. SELECT DETAIL SELECT AGGREGATE select det_col1det_coln select det_agg1, agg1,,aggn from same from same where same where same group by det_agg1 having order by same order by same The difference between the two statements is the AGGREGATE has select clause has one or more detail columns, det_agg1, on which values get aggregated against/rolled up to. select clause zero or more aggregated values, agg1, , aggn group by clause is required and matches the one or more detail columns, det_agg1. having clause is optional and adds a filter condition on one or more agg1  aggn values. 19.3 SQL SELECT Quick Start This section focuses on getting new SQL users familiar with the six SQL query clauses and a single table. SQL queries from multiple tables are discussed in the JOIN section of this tutorial. The JOIN section resolves the issue introduced with 3NF, the splitting of data into many many tables, back into a denormalaized format similar to the Excel spreadsheet. The DBI::dbGetQuery function is used to submit SQL SELECT statements to the PostgreSQL database. At a minimum it requires two parameters, a connection object and a SQL SELECT statement. In the following section we only look at SELECT DETAIL statements. 19.3.1 SELECT Clause: Column Selection  Vertical Partioning of Data 19.3.1.1 1. Simplest SQL query: All rows and all columns from a single table. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store; &quot;) kable(rs,caption = &#39;select all columns&#39;) Table 19.1: select all columns store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-04-07 14:12:50 19.3.1.2 2. Same Query as 1, but only show first two columns; rs &lt;- DBI::dbGetQuery( con, &quot; select STORE_ID, manager_staff_id from store; &quot;) kable(rs,caption = &#39;select first two columns only&#39;) Table 19.2: select first two columns only store_id manager_staff_id 1 1 2 2 10 10 19.3.1.3 3. Same Query as 2, but reverse the column order dvdrental=# select manager_staff_id,store_id from store; rs &lt;- DBI::dbGetQuery( con, &quot; select manager_staff_id,store_id from store; &quot;) kable(rs,caption = &#39;reverse the column order&#39;) Table 19.3: reverse the column order manager_staff_id store_id 1 1 2 2 10 10 19.3.1.4 4. Rename Columns  SQL column alias in the result set rs &lt;- DBI::dbGetQuery( con, &quot; select manager_staff_id mgr_sid,store_id st_id from store; &quot;) kable(rs,caption = &#39;Rename Columns&#39;) Table 19.4: Rename Columns mgr_sid st_id 1 1 2 2 10 10 The manager_staff_id has changed to mgr_sid. store_id has changed to st_id. Note that the column names have changed in the result set only, not in the actual database table. The DBA&#39;s will not allow a space or other special characters in a database table column name. Some motivations for aliasing the result set column names are 1. Some database table column names are not user friendly. 2. When multiple tables are joined, the column names may be the same in one or more tables and one needs to distinguish between the column names from the different tables. 19.3.1.5 5. Adding Meta Data Columns to the Result Set rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;derived column&#39; showing ,* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; &quot;) kable(rs,caption = &#39;Adding Meta Data Columns&#39;) Table 19.5: Adding Meta Data Columns showing store_id manager_staff_id address_id last_update db user dtts derived column 1 1 1 2006-02-15 09:57:12 dvdrental postgres 2019/04/07 21:12:52 derived column 2 2 2 2006-02-15 09:57:12 dvdrental postgres 2019/04/07 21:12:52 derived column 10 10 10 2019-04-07 14:12:50 dvdrental postgres 2019/04/07 21:12:52 All the previous examples easily fit on a single line. This one is longer. Each column is entered on its own line, indented past the select keyword, and preceeded by a comma. 1. The showing column is a hard coded string surrounded by single quotes. Note that single quotes are for hard coded values and double quotes are for column aliases. 2. The db and dtts, date timestamp, are new columns generated from PostgreSQL System Information Functions. 3. Note that `user` is not a function call, no parenthesis. 19.3.2 SQL Comments SQL supports both a single line comment, preceed the line with two dashes, --, and a C like block comment, \\*  */. 19.3.2.1 6. Single line comment  rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;single line comment, dtts&#39; showing ,* ,current_database() db ,user -- ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts from store; &quot;) kable(rs,caption = &#39;Sincle line comment&#39;) Table 19.6: Sincle line comment showing store_id manager_staff_id address_id last_update db user single line comment, dtts 1 1 1 2006-02-15 09:57:12 dvdrental postgres single line comment, dtts 2 2 2 2006-02-15 09:57:12 dvdrental postgres single line comment, dtts 10 10 10 2019-04-07 14:12:50 dvdrental postgres The dtts line is commented out with the two dashes and is dropped from the end of the result set columns. 19.3.2.2 7. Multi-line comment /**/ rs &lt;- DBI::dbGetQuery( con, &quot; select &#39;block comment drop db, user, and dtts&#39; showing ,* /* ,current_database() db ,user ,to_char(now(),&#39;YYYY/MM/DD HH24:MI:SS&#39;) dtts */ from store; &quot;) kable(rs,caption = &#39;Multi-line comment&#39;) Table 19.7: Multi-line comment showing store_id manager_staff_id address_id last_update block comment drop db, user, and dtts 1 1 1 2006-02-15 09:57:12 block comment drop db, user, and dtts 2 2 2 2006-02-15 09:57:12 block comment drop db, user, and dtts 10 10 10 2019-04-07 14:12:50 The three columns db, user, and dtts, between the /\\* and \\*/ have been commented and no longer appear as the end columns of the result set. 19.3.3 FROM Clause The FROM clause contains one or more datasets, usually database tables/views, from which the SELECT columns are derived. For now, in the examples, we are only using a single table. If the database reflects a relational model, your data is likely spread out over several tables. The key take away when beginning your analysis is to pick the table that has most of the data that you need for your analysis. This table becomes your main or driving table to build your SQL query statement around. After identifying your driving table, potentially save yourself a lot of time and heart ache, review any view that is built on your driving table. If one or more exist, especially, if vendor built, may already have the additional information needed for your analysis. Insert SQL here or link to Views dependent on what In this tutorial, there is only a single user hitting the database and row/table locking is not necessary and considered out of scope. 19.3.3.1 Table Uses A table can be used more than once in a FROM clause. These are self-referencing tables. An example is an EMPLOYEE table which contains a foriegn key to her manager. Her manager also has a foriegn key to her manager, etc up the corporate ladder. In the example above, the EMPLOYEE table plays two roles, employee and manager. The next line shows the FROM clause showing the same table used twice. FROM EMPLOYEE EE, EMPLOYEE MGR The EE and MGR are aliases for the EMPLOYEE table and represent the different roles the EMPLOYEE table plays. Since all the column names are exactly the same for the EE and MGR role, the column names need to be prefixed with their role alias, e.g., SELECT MGR.EE_NAME, EE.EE_NAME  shows the manager name and her employee name(s) who work for her. It is a good habit to always alias your tables and prefix your column names with the table alias to eliminate any ambiguity as to where the column came from. This is critical where there is inconsistent table column naming convention. It also helps when debugging larger SQL queries. Cover inline tables in future section Side Note: Do not create an unintended Cartesian join. If one has more than one table in the FROM clause, make sure that every table in the FROM clause joins to at least one other table in the WHERE clause. If your result set has an unexpectantly high rowcount and long runtime, check for a missing join in the FROM clause. 19.3.4 WHERE Clause: Row Selection  Horizontal Partitioning of Data In the previous SELECT clause section, the SELECT statement either partitioned data vertically across the table columns or derived vertical column values. This section provides examples that partitions the table data across rows in the table. The WHERE clause defines all the conditions the data must meet to be included or excluded in the final result set. If all the conditions are met data is returned or it is rejected. This is commonly referred to as the data set filter condition. Side Note: For performance optimization reasons, the WHERE clause should reduce the dataset down to the smallest dataset as quickly as possible. This is typically done using indexed columns, range conditions, and any other condition that rejects a lot of rows from being retrieved. The WHERE condition(s) can be simple or complex, but in the end are the appliction of the logic rules shown in the table below. p q p and q p or q T T T T T F F T T N N T F F F F F N F T N N N N When the filter logic is complex, it is sometimes easier to represent the where clause symbollically and apply a version of DeMorgans law which is shown below. (A and B) = A or B (A or B) = A and B 19.3.4.1 Examples Continued We begin with 1, our simplest SQL query. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store; &quot;) kable(rs,caption = &#39;select all columns&#39;) Table 19.8: select all columns store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-04-07 14:12:50 19.3.4.2 8 WHERE condition logically never TRUE. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where 1 = 0; &quot;) kable(rs,caption = &#39;WHERE always FALSE&#39;) Table 19.9: WHERE always FALSE store_id manager_staff_id address_id last_update Since 1 = 0 is always false, no rows are ever returned. Initially this construct seems useless, but actually is quite handy when debugging large scripts where a portion of the script needs to be turned off or when creating an empty table with the exact same column names and types as the FROM table(s). 19.3.4.3 9 WHERE condition logically always TRUE. rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where 1 = 1; &quot;) kable(rs,caption = &#39;WHERE always TRUE&#39;) Table 19.10: WHERE always TRUE store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 10 10 10 2019-04-07 14:12:50 Since 1 = 1 is always true, all rows are always returned. Initially this construct seems useless, but actually is also quite handy when debugging large scripts and creating a backup of table. 19.3.4.4 10 WHERE equality condition rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where store_id = 2; &quot;) kable(rs,caption = &#39;WHERE EQUAL&#39;) Table 19.11: WHERE EQUAL store_id manager_staff_id address_id last_update 2 2 2 2006-02-15 09:57:12 The only row where the store_id = 2 is row 2 and it is the only row returned. 19.3.4.5 11 WHERE NOT equal conditions rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where store_id &lt;&gt; 2; &quot;) kable(rs,caption = &#39;WHERE NOT EQUAL&#39;) Table 19.12: WHERE NOT EQUAL store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 10 10 10 2019-04-07 14:12:50 &lt;&gt; is syntactically the same as != The only row where the store_id &lt;&gt; 2 is row 1 and only row 1 is returned. 19.3.4.6 12 WHERE OR condition rs &lt;- DBI::dbGetQuery( con, &quot; select * from store where manager_staff_id = 1 or store_id &lt; 3; &quot;) kable(rs,caption = &#39;WHERE OR condition&#39;) Table 19.13: WHERE OR condition store_id manager_staff_id address_id last_update 1 1 1 2006-02-15 09:57:12 2 2 2 2006-02-15 09:57:12 The first condition manager_staff_id = 1 returns a single row and the second condition store_id &lt; 3 returns two rows. Following table is modified from http://www.tutorialspoint.com/sql/sql-operators SQL Comparison Operators Operator Description example = Checks if the values of two operands are equal or not, if yes then condition becomes true. (a = b) is not true. != Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a != b) is true. &lt;&gt; Checks if the values of two operands are equal or not, if values are not equal then condition becomes true. (a &lt;&gt; b) is true. &gt; Checks if the value of left operand is greater than the value of right operand, if yes then condition becomes true. (a &gt; b) is not true. &lt; Checks if the value of left operand is less than the value of right operand, if yes then condition becomes true. (a &lt; b) is true. &gt;= Checks if the value of left operand is greater than or equal to the value of right operand, if yes then condition becomes true. (a &gt;= b) is not true. &lt;= Checks if the value of left operand is less than or equal to the value of right operand, if yes then condition becomes true. (a &lt;= b) is true. !&lt; Checks if the value of left operand is not less than the value of right operand, if yes then condition becomes true. (a !&lt; b) is false. !&gt; Checks if the value of left operand is not greater than the value of right operand, if yes then condition becomes true. (a !&gt; b) is true. Operator Description ALL The ALL operator is used to compare a value to all values in another value set. AND The AND operator allows the existence of multiple conditions in an SQL statements WHERE clause. ANY The ANY operator is used to compare a value to any applicable value in the list as per the condition. BETWEEN The BETWEEN operator is used to search for values that are within a set of values, given the minimum value and the maximum value. EXISTS The EXISTS operator is used to search for the presence of a row in a specified table that meets a certain criterion. IN The IN operator is used to compare a value to a list of literal values that have been specified. LIKE The LIKE operator is used to compare a value to similar values using wildcard operators. NOT The NOT operator reverses the meaning of the logical operator with which it is used. Eg: NOT EXISTS, NOT BETWEEN, NOT IN, etc. This is a negate operator. OR The OR operator is used to combine multiple conditions in an SQL statements WHERE clause. IS NULL The NULL operator is used to compare a value with a NULL value. UNIQUE The UNIQUE operator searches every row of a specified table for uniqueness (no duplicates). https://pgexercises.com/questions/basic ## TO-DOs inline tables correlated subqueries 19.4 Paradigm Shift from R-Dplyr to SQL Paraphrasing what some have said with an R dplyr background and no SQL experience, It is like working from the inside out. This sentiment occurs because The SQL SELECT statement begins at the end, the SELECT clause, and drills backwards, loosely speaking, to derive the desired result set. SQL SELECT statements are an all or nothing proposition. One gets nothing if there is any kind of syntax error. SQL SELECT result sets can be quite opaque. The WHERE clause can be very dense and difficult to trace through. It is rarely ever linear in nature. Validating all the permutations in the where clause can be tough and tedious. 19.4.1 Big bang versus piped incremental steps. Dplyr starts with one or more sources joined together in a conceptually similar way that SQL joins sources. The pipe and filter() function breaks down the filter conditions into small managable logical steps. This makes it much easier to understand what is happening in the derivation of the final tibble. Adding tees through out the pipe line gives one full trace back of all the data transformations at every pipe. Helpful tidyverse functions that output tibbles: tbl_module function in https://github.com/nhemerson/tibbleColumns package; Mental picture: SQL approach: Imagine a data lake named Niagera Falls and drinking from it without drowning. R-Dplyr approach: Imagine a resturant at the bottom of the Niagera Falls data lake and having a refreshing dring out of the water faucet. 19.4.2 SQL Execution Order The table below is derived from this site. https://www.periscopedata.com/blog/sql-query-order-of-operations It shows what goes on under the hood SQL SELECT hood. SEQ SQL Function Dplyr 1 WITH Common Table expression, CTE, one or more datasets/tables used FROM clause. .data parameter in dplyr functions 2 FROM Choose and join tables to get base data .data parameter in dplyr functions 3 ON Choose and join tables to get base data dplyr join family of functions 4 JOIN Choose and join tables to get base data dplyr join family of functions 5 WHERE filters the base data dplyr filter() 6 GROUP BY aggregates the base data dplyr group_by family of functions 7 WITH CUBE/ROLLUP aggregates the base data is this part of the dplyr grammar 8 HAVING filters aggregated data dplyr filter() 9 SELECT Returns final data set dplyr select() 10 DISTINCT Dedupe the final data set dplyr distinct() 11 ORDER BY Sorts the final data set arrange() 12 TOP/LIMIT Limits the number of rows in data set 13 OFFSET/FETCH Limits the number of rows in data set The SEQ column shows the standard order of SQL execution. One take away for this tutorial is that the SELECT clause actually executes late in the process, even though it is the first clause in the entire SELECT statement. A second take away is that SQL execution order, or tweaked order, plays a critical role in SQL query tuning. SQL for View table dependencies. Add cartesian join exercise. "],
["chapter-postgresql-metadata.html", "Chapter 20 Getting metadata about and from PostgreSQL 20.1 Database contents and structure 20.2 What columns do those tables contain? 20.3 Characterizing how things are named 20.4 Database keys 20.5 Creating your own data dictionary", " Chapter 20 Getting metadata about and from PostgreSQL This chapter demonstrates: What kind of data about the database is contained in a dbms Several methods for obtaining metadata from the dbms The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) library(glue) library(here) require(knitr) library(dbplyr) library(sqlpetr) Assume that the Docker container with PostgreSQL and the dvdrental database are ready to go. sp_docker_start(&quot;sql-pet&quot;) Connect to the database: con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 20.1 Database contents and structure After just looking at the data you seek, it might be worthwhile stepping back and looking at the big picture. 20.1.1 Database structure For large or complex databases you need to use both the available documentation for your database (e.g., the dvdrental database) and the other empirical tools that are available. For example its worth learning to interpret the symbols in an Entity Relationship Diagram: The information_schema is a trove of information about the database. Its format is more or less consistent across the different SQL implementations that are available. Here we explore some of whats available using several different methods. PostgreSQL stores a lot of metadata. 20.1.2 Contents of the information_schema For this chapter R needs the dbplyr package to access alternate schemas. A schema is an object that contains one or more tables. Most often there will be a default schema, but to access the metadata, you need to explicitly specify which schema contains the data you want. 20.1.3 What tables are in the database? The simplest way to get a list of tables is with table_list &lt;- DBI::dbListTables(con) kable(table_list) x actor_info customer_list film_list nicer_but_slower_film_list sales_by_film_category staff sales_by_store staff_list category film_category country actor language inventory payment rental city store film address film_actor customer smy_customer smy_compute_exercise 20.1.4 Digging into the information_schema We usually need more detail than just a list of tables. Most SQL databases have an information_schema that has a standard structure to describe and control the database. The information_schema is in a different schema from the default, so to connect to the tables table in the information_schema we connect to the database in a different way: table_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) The information_schema is large and complex and contains 212 tables. So its easy to get lost in it. This query retrieves a list of the tables in the database that includes additional detail, not just the name of the table. table_info &lt;- table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select(table_catalog, table_schema, table_name, table_type) %&gt;% arrange(table_type, table_name) %&gt;% collect() kable(table_info) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public smy_compute_exercise BASE TABLE dvdrental public smy_customer BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW In this context table_catalog is synonymous with `database `. Notice that VIEWS are composites made up of one or more BASE TABLES. The SQL world has its own terminology. For example rs is shorthand for result set. Thats equivalent to using df for a data frame. The following SQL query returns the same information as the previous one. rs &lt;- dbGetQuery( con, &quot;select table_catalog, table_schema, table_name, table_type from information_schema.tables where table_schema not in (&#39;pg_catalog&#39;,&#39;information_schema&#39;) order by table_type, table_name ;&quot; ) kable(rs) table_catalog table_schema table_name table_type dvdrental public actor BASE TABLE dvdrental public address BASE TABLE dvdrental public category BASE TABLE dvdrental public city BASE TABLE dvdrental public country BASE TABLE dvdrental public customer BASE TABLE dvdrental public film BASE TABLE dvdrental public film_actor BASE TABLE dvdrental public film_category BASE TABLE dvdrental public inventory BASE TABLE dvdrental public language BASE TABLE dvdrental public payment BASE TABLE dvdrental public rental BASE TABLE dvdrental public smy_compute_exercise BASE TABLE dvdrental public smy_customer BASE TABLE dvdrental public staff BASE TABLE dvdrental public store BASE TABLE dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public sales_by_store VIEW dvdrental public staff_list VIEW 20.2 What columns do those tables contain? Of course, the DBI package has a dbListFields function that provides the simplest way to get the minimum, a list of column names: DBI::dbListFields(con, &quot;rental&quot;) ## [1] &quot;rental_id&quot; &quot;rental_date&quot; &quot;inventory_id&quot; &quot;customer_id&quot; ## [5] &quot;return_date&quot; &quot;staff_id&quot; &quot;last_update&quot; But the information_schema has a lot more useful information that we can use. columns_info_schema_table &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;columns&quot;)) Since the information_schema contains 1892 columns, we are narrowing our focus to just one table. This query retrieves more information about the rental table: columns_info_schema_info &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% select( table_catalog, table_schema, table_name, column_name, data_type, ordinal_position, character_maximum_length, column_default, numeric_precision, numeric_precision_radix ) %&gt;% collect(n = Inf) %&gt;% mutate(data_type = case_when( data_type == &quot;character varying&quot; ~ paste0(data_type, &quot; (&quot;, character_maximum_length, &quot;)&quot;), data_type == &quot;real&quot; ~ paste0(data_type, &quot; (&quot;, numeric_precision, &quot;,&quot;, numeric_precision_radix, &quot;)&quot;), TRUE ~ data_type )) %&gt;% filter(table_name == &quot;rental&quot;) %&gt;% select(-table_schema, -numeric_precision, -numeric_precision_radix) glimpse(columns_info_schema_info) ## Observations: 7 ## Variables: 7 ## $ table_catalog &lt;chr&gt; &quot;dvdrental&quot;, &quot;dvdrental&quot;, &quot;dvdrental&quot;,  ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, ## $ column_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_ ## $ data_type &lt;chr&gt; &quot;integer&quot;, &quot;timestamp without time zone ## $ ordinal_position &lt;int&gt; 1, 2, 3, 4, 5, 6, 7 ## $ character_maximum_length &lt;int&gt; NA, NA, NA, NA, NA, NA, NA ## $ column_default &lt;chr&gt; &quot;nextval(&#39;rental_rental_id_seq&#39;::regcla kable(columns_info_schema_info) table_catalog table_name column_name data_type ordinal_position character_maximum_length column_default dvdrental rental rental_id integer 1 NA nextval(rental_rental_id_seq::regclass) dvdrental rental rental_date timestamp without time zone 2 NA NA dvdrental rental inventory_id integer 3 NA NA dvdrental rental customer_id smallint 4 NA NA dvdrental rental return_date timestamp without time zone 5 NA NA dvdrental rental staff_id smallint 6 NA NA dvdrental rental last_update timestamp without time zone 7 NA now() 20.2.1 What is the difference between a VIEW and a BASE TABLE? The BASE TABLE has the underlying data in the database table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;BASE TABLE&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default BASE TABLE customer store_id smallint 2 NA BASE TABLE customer first_name character varying 3 NA BASE TABLE customer last_name character varying 4 NA BASE TABLE customer email character varying 5 NA BASE TABLE customer address_id smallint 6 NA BASE TABLE customer active integer 10 NA BASE TABLE customer customer_id integer 1 nextval(customer_customer_id_seq::regclass) BASE TABLE customer activebool boolean 7 true BASE TABLE customer create_date date 8 (now::text)::date BASE TABLE customer last_update timestamp without time zone 9 now() BASE TABLE smy_customer customer_id integer 1 NA BASE TABLE smy_customer store_id smallint 2 NA BASE TABLE smy_customer first_name character varying 3 NA BASE TABLE smy_customer last_name character varying 4 NA BASE TABLE smy_customer email character varying 5 NA BASE TABLE smy_customer address_id smallint 6 NA BASE TABLE smy_customer activebool boolean 7 NA BASE TABLE smy_customer create_date date 8 NA BASE TABLE smy_customer last_update timestamp without time zone 9 NA BASE TABLE smy_customer active integer 10 NA Probably should explore how the VIEW is made up of data from BASE TABLEs. table_info_schema_table %&gt;% filter(table_schema == &quot;public&quot; &amp; table_type == &quot;VIEW&quot;) %&gt;% select(table_name, table_type) %&gt;% left_join(columns_info_schema_table, by = c(&quot;table_name&quot; = &quot;table_name&quot;)) %&gt;% select( table_type, table_name, column_name, data_type, ordinal_position, column_default ) %&gt;% collect(n = Inf) %&gt;% filter(str_detect(table_name, &quot;cust&quot;)) %&gt;% kable() table_type table_name column_name data_type ordinal_position column_default VIEW customer_list id integer 1 NA VIEW customer_list name text 2 NA VIEW customer_list address character varying 3 NA VIEW customer_list zip code character varying 4 NA VIEW customer_list phone character varying 5 NA VIEW customer_list city character varying 6 NA VIEW customer_list country character varying 7 NA VIEW customer_list notes text 8 NA VIEW customer_list sid smallint 9 NA 20.2.2 What data types are found in the database? columns_info_schema_info %&gt;% count(data_type) ## # A tibble: 3 x 2 ## data_type n ## &lt;chr&gt; &lt;int&gt; ## 1 integer 2 ## 2 smallint 2 ## 3 timestamp without time zone 3 20.3 Characterizing how things are named Names are the handle for accessing the data. Tables and columns may or may not be named consistently or in a way that makes sense to you. You should look at these names as data. 20.3.1 Counting columns and name reuse Pull out some rough-and-ready but useful statistics about your database. Since we are in SQL-land we talk about variables as columns. public_tables &lt;- columns_info_schema_table %&gt;% filter(table_schema == &quot;public&quot;) %&gt;% collect() public_tables %&gt;% count(table_name, sort = TRUE) %&gt;% head(n = 15) %&gt;% kable() table_name n smy_compute_exercise 27 film 13 staff 11 customer 10 smy_customer 10 customer_list 9 address 8 film_list 8 nicer_but_slower_film_list 8 staff_list 8 rental 7 payment 6 actor 4 actor_info 4 city 4 How many column names are shared across tables (or duplicated)? public_tables %&gt;% count(column_name, sort = TRUE) %&gt;% filter(n &gt; 1) ## # A tibble: 39 x 2 ## column_name n ## &lt;chr&gt; &lt;int&gt; ## 1 last_update 15 ## 2 address_id 5 ## 3 film_id 5 ## 4 first_name 5 ## 5 last_name 5 ## 6 store_id 5 ## 7 address 4 ## 8 city 4 ## 9 country 4 ## 10 customer_id 4 ## #  with 29 more rows How many column names are unique? public_tables %&gt;% count(column_name) %&gt;% filter(n == 1) %&gt;% count() ## # A tibble: 1 x 1 ## n ## &lt;int&gt; ## 1 33 20.4 Database keys 20.4.1 Direct SQL How do we use this output? Could it be generated by dplyr? rs &lt;- dbGetQuery( con, &quot; --SELECT conrelid::regclass as table_from select table_catalog||&#39;.&#39;||table_schema||&#39;.&#39;||table_name table_name , conname, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM information_schema.columns c,pg_catalog.pg_constraint r WHERE 1 = 1 --r.conrelid = &#39;16485&#39; AND r.contype in (&#39;f&#39;,&#39;p&#39;) ORDER BY 1 ;&quot; ) glimpse(rs) ## Observations: 62,436 ## Variables: 3 ## $ table_name &lt;chr&gt; &quot;dvdrental.information_schema.administrable_role_auth ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;actor_pkey&quot;, &quot;country_pk ## $ condef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (actor_id)&quot;, &quot; kable(head(rs)) table_name conname condef dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations actor_pkey PRIMARY KEY (actor_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) dvdrental.information_schema.administrable_role_authorizations country_pkey PRIMARY KEY (country_id) The following is more compact and looks more useful. What is the difference bet ween the two? rs &lt;- dbGetQuery( con, &quot;select conrelid::regclass as table_from ,c.conname ,pg_get_constraintdef(c.oid) from pg_constraint c join pg_namespace n on n.oid = c.connamespace where c.contype in (&#39;f&#39;,&#39;p&#39;) and n.nspname = &#39;public&#39; order by conrelid::regclass::text, contype DESC; &quot; ) glimpse(rs) ## Observations: 33 ## Variables: 3 ## $ table_from &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;,  ## $ conname &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address_c ## $ pg_get_constraintdef &lt;chr&gt; &quot;PRIMARY KEY (actor_id)&quot;, &quot;PRIMARY KEY (add kable(head(rs)) table_from conname pg_get_constraintdef actor actor_pkey PRIMARY KEY (actor_id) address address_pkey PRIMARY KEY (address_id) address fk_address_city FOREIGN KEY (city_id) REFERENCES city(city_id) category category_pkey PRIMARY KEY (category_id) city city_pkey PRIMARY KEY (city_id) city fk_city FOREIGN KEY (country_id) REFERENCES country(country_id) dim(rs)[1] ## [1] 33 20.4.2 Database keys with dplyr This query shows the primary and foreign keys in the database. tables &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;tables&quot;)) table_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;table_constraints&quot;)) key_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;key_column_usage&quot;)) referential_constraints &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;referential_constraints&quot;)) constraint_column_usage &lt;- tbl(con, dbplyr::in_schema(&quot;information_schema&quot;, &quot;constraint_column_usage&quot;)) keys &lt;- tables %&gt;% left_join(table_constraints, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot; )) %&gt;% # table_constraints %&gt;% filter(constraint_type %in% c(&quot;FOREIGN KEY&quot;, &quot;PRIMARY KEY&quot;)) %&gt;% left_join(key_column_usage, by = c( &quot;table_catalog&quot; = &quot;table_catalog&quot;, &quot;constraint_catalog&quot; = &quot;constraint_catalog&quot;, &quot;constraint_schema&quot; = &quot;constraint_schema&quot;, &quot;table_name&quot; = &quot;table_name&quot;, &quot;table_schema&quot; = &quot;table_schema&quot;, &quot;constraint_name&quot; = &quot;constraint_name&quot; ) ) %&gt;% # left_join(constraint_column_usage) %&gt;% # does this table add anything useful? select(table_name, table_type, constraint_name, constraint_type, column_name, ordinal_position) %&gt;% arrange(table_name) %&gt;% collect() glimpse(keys) ## Observations: 35 ## Variables: 6 ## $ table_name &lt;chr&gt; &quot;actor&quot;, &quot;address&quot;, &quot;address&quot;, &quot;category&quot;, &quot;cit ## $ table_type &lt;chr&gt; &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BASE TABLE&quot;, &quot;BASE ## $ constraint_name &lt;chr&gt; &quot;actor_pkey&quot;, &quot;address_pkey&quot;, &quot;fk_address_city&quot; ## $ constraint_type &lt;chr&gt; &quot;PRIMARY KEY&quot;, &quot;PRIMARY KEY&quot;, &quot;FOREIGN KEY&quot;, &quot;P ## $ column_name &lt;chr&gt; &quot;actor_id&quot;, &quot;address_id&quot;, &quot;city_id&quot;, &quot;category_ ## $ ordinal_position &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, kable(keys) table_name table_type constraint_name constraint_type column_name ordinal_position actor BASE TABLE actor_pkey PRIMARY KEY actor_id 1 address BASE TABLE address_pkey PRIMARY KEY address_id 1 address BASE TABLE fk_address_city FOREIGN KEY city_id 1 category BASE TABLE category_pkey PRIMARY KEY category_id 1 city BASE TABLE city_pkey PRIMARY KEY city_id 1 city BASE TABLE fk_city FOREIGN KEY country_id 1 country BASE TABLE country_pkey PRIMARY KEY country_id 1 customer BASE TABLE customer_address_id_fkey FOREIGN KEY address_id 1 customer BASE TABLE customer_pkey PRIMARY KEY customer_id 1 film BASE TABLE film_language_id_fkey FOREIGN KEY language_id 1 film BASE TABLE film_pkey PRIMARY KEY film_id 1 film_actor BASE TABLE film_actor_actor_id_fkey FOREIGN KEY actor_id 1 film_actor BASE TABLE film_actor_film_id_fkey FOREIGN KEY film_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY actor_id 1 film_actor BASE TABLE film_actor_pkey PRIMARY KEY film_id 2 film_category BASE TABLE film_category_category_id_fkey FOREIGN KEY category_id 1 film_category BASE TABLE film_category_film_id_fkey FOREIGN KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY film_id 1 film_category BASE TABLE film_category_pkey PRIMARY KEY category_id 2 inventory BASE TABLE inventory_film_id_fkey FOREIGN KEY film_id 1 inventory BASE TABLE inventory_pkey PRIMARY KEY inventory_id 1 language BASE TABLE language_pkey PRIMARY KEY language_id 1 payment BASE TABLE payment_customer_id_fkey FOREIGN KEY customer_id 1 payment BASE TABLE payment_pkey PRIMARY KEY payment_id 1 payment BASE TABLE payment_rental_id_fkey FOREIGN KEY rental_id 1 payment BASE TABLE payment_staff_id_fkey FOREIGN KEY staff_id 1 rental BASE TABLE rental_customer_id_fkey FOREIGN KEY customer_id 1 rental BASE TABLE rental_inventory_id_fkey FOREIGN KEY inventory_id 1 rental BASE TABLE rental_pkey PRIMARY KEY rental_id 1 rental BASE TABLE rental_staff_id_key FOREIGN KEY staff_id 1 staff BASE TABLE staff_address_id_fkey FOREIGN KEY address_id 1 staff BASE TABLE staff_pkey PRIMARY KEY staff_id 1 store BASE TABLE store_address_id_fkey FOREIGN KEY address_id 1 store BASE TABLE store_manager_staff_id_fkey FOREIGN KEY manager_staff_id 1 store BASE TABLE store_pkey PRIMARY KEY store_id 1 What do we learn from the following query? How is it useful? rs &lt;- dbGetQuery( con, &quot;SELECT r.*, pg_catalog.pg_get_constraintdef(r.oid, true) as condef FROM pg_catalog.pg_constraint r WHERE 1=1 --r.conrelid = &#39;16485&#39; AND r.contype = &#39;f&#39; ORDER BY 1; &quot; ) head(rs) ## conname connamespace contype condeferrable ## 1 cardinal_number_domain_check 12703 c FALSE ## 2 yes_or_no_check 12703 c FALSE ## 3 year_check 2200 c FALSE ## 4 actor_pkey 2200 p FALSE ## 5 address_pkey 2200 p FALSE ## 6 category_pkey 2200 p FALSE ## condeferred convalidated conrelid contypid conindid confrelid ## 1 FALSE TRUE 0 12716 0 0 ## 2 FALSE TRUE 0 12724 0 0 ## 3 FALSE TRUE 0 16397 0 0 ## 4 FALSE TRUE 16420 0 16555 0 ## 5 FALSE TRUE 16461 0 16557 0 ## 6 FALSE TRUE 16427 0 16559 0 ## confupdtype confdeltype confmatchtype conislocal coninhcount ## 1 TRUE 0 ## 2 TRUE 0 ## 3 TRUE 0 ## 4 TRUE 0 ## 5 TRUE 0 ## 6 TRUE 0 ## connoinherit conkey confkey conpfeqop conppeqop conffeqop conexclop ## 1 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 FALSE &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 TRUE {1} &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## conbin ## 1 {OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 195} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 204 :constvalue 4 [ 0 0 0 0 0 0 0 0 ]}) :location 201} ## 2 {SCALARARRAYOPEXPR :opno 98 :opfuncid 67 :useOr true :inputcollid 100 :args ({RELABELTYPE :arg {COERCETODOMAINVALUE :typeId 1043 :typeMod 7 :collation 100 :location 121} :resulttype 25 :resulttypmod -1 :resultcollid 100 :relabelformat 2 :location -1} {ARRAYCOERCEEXPR :arg {ARRAY :array_typeid 1015 :array_collid 100 :element_typeid 1043 :elements ({CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 131 :constvalue 7 [ 28 0 0 0 89 69 83 ]} {CONST :consttype 1043 :consttypmod -1 :constcollid 100 :constlen -1 :constbyval false :constisnull false :location 138 :constvalue 6 [ 24 0 0 0 78 79 ]}) :multidims false :location -1} :elemfuncid 0 :resulttype 1009 :resulttypmod -1 :resultcollid 100 :isExplicit false :coerceformat 2 :location -1}) :location 127} ## 3 {BOOLEXPR :boolop and :args ({OPEXPR :opno 525 :opfuncid 150 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 62} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 71 :constvalue 4 [ 109 7 0 0 0 0 0 0 ]}) :location 68} {OPEXPR :opno 523 :opfuncid 149 :opresulttype 16 :opretset false :opcollid 0 :inputcollid 0 :args ({COERCETODOMAINVALUE :typeId 23 :typeMod -1 :collation 0 :location 82} {CONST :consttype 23 :consttypmod -1 :constcollid 0 :constlen 4 :constbyval true :constisnull false :location 91 :constvalue 4 [ 107 8 0 0 0 0 0 0 ]}) :location 88}) :location 77} ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## consrc ## 1 (VALUE &gt;= 0) ## 2 ((VALUE)::text = ANY ((ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying])::text[])) ## 3 ((VALUE &gt;= 1901) AND (VALUE &lt;= 2155)) ## 4 &lt;NA&gt; ## 5 &lt;NA&gt; ## 6 &lt;NA&gt; ## condef ## 1 CHECK (VALUE &gt;= 0) ## 2 CHECK (VALUE::text = ANY (ARRAY[&#39;YES&#39;::character varying, &#39;NO&#39;::character varying]::text[])) ## 3 CHECK (VALUE &gt;= 1901 AND VALUE &lt;= 2155) ## 4 PRIMARY KEY (actor_id) ## 5 PRIMARY KEY (address_id) ## 6 PRIMARY KEY (category_id) 20.5 Creating your own data dictionary If you are going to work with a database for an extended period it can be useful to create your own data dictionary. This can take the form of keeping detaild notes as well as extracting metadata from the dbms. Here is an illustration of the idea. some_tables &lt;- c(&quot;rental&quot;, &quot;city&quot;, &quot;store&quot;) all_meta &lt;- map_df(some_tables, sp_get_dbms_data_dictionary, con = con) all_meta ## # A tibble: 15 x 11 ## table_name var_name var_type num_rows num_blank num_unique min q_25 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 rental rental_ integer 16045 0 16045 1 4013 ## 2 rental rental_ double 16045 0 15816 2005 2005 ## 3 rental invento integer 16045 0 4581 1 1154 ## 4 rental custome integer 16045 0 600 1 148 ## 5 rental return_ double 16045 183 15837 2005 2005 ## 6 rental staff_id integer 16045 0 2 1 1 ## 7 rental last_up double 16045 0 4 2006 2006 ## 8 city city_id integer 600 0 600 1 150 ## 9 city city charact 600 0 599 A Co Dzer ## 10 city country integer 600 0 109 1 28 ## 11 city last_up double 600 0 1 2006 2006 ## 12 store store_id integer 3 0 3 1 1 ## 13 store manager integer 3 0 3 1 1 ## 14 store address integer 3 0 3 1 1 ## 15 store last_up double 3 0 2 2006 2006 ## #  with 3 more variables: q_50 &lt;chr&gt;, q_75 &lt;chr&gt;, max &lt;chr&gt; glimpse(all_meta) ## Observations: 15 ## Variables: 11 ## $ table_name &lt;chr&gt; &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;rental&quot;, &quot;re ## $ var_name &lt;chr&gt; &quot;rental_id&quot;, &quot;rental_date&quot;, &quot;inventory_id&quot;, &quot;customer ## $ var_type &lt;chr&gt; &quot;integer&quot;, &quot;double&quot;, &quot;integer&quot;, &quot;integer&quot;, &quot;double&quot;,  ## $ num_rows &lt;int&gt; 16045, 16045, 16045, 16045, 16045, 16045, 16045, 600, ## $ num_blank &lt;int&gt; 0, 0, 0, 0, 183, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ## $ num_unique &lt;int&gt; 16045, 15816, 4581, 600, 15837, 2, 4, 600, 599, 109,  ## $ min &lt;chr&gt; &quot;1&quot;, &quot;2005-05-24 22:53:30&quot;, &quot;1&quot;, &quot;1&quot;, &quot;2005-05-25 23: ## $ q_25 &lt;chr&gt; &quot;4013&quot;, &quot;2005-07-07 00:58:00&quot;, &quot;1154&quot;, &quot;148&quot;, &quot;2005-0 ## $ q_50 &lt;chr&gt; &quot;8025&quot;, &quot;2005-07-28 16:03:27&quot;, &quot;2291&quot;, &quot;296&quot;, &quot;2005-0 ## $ q_75 &lt;chr&gt; &quot;12037&quot;, &quot;2005-08-17 21:13:35&quot;, &quot;3433&quot;, &quot;446&quot;, &quot;2005- ## $ max &lt;chr&gt; &quot;16050&quot;, &quot;2019-03-31&quot;, &quot;4582&quot;, &quot;600&quot;, &quot;2019-04-07&quot;, &quot; kable(head(all_meta)) table_name var_name var_type num_rows num_blank num_unique min q_25 q_50 q_75 max rental rental_id integer 16045 0 16045 1 4013 8025 12037 16050 rental rental_date double 16045 0 15816 2005-05-24 22:53:30 2005-07-07 00:58:00 2005-07-28 16:03:27 2005-08-17 21:13:35 2019-03-31 rental inventory_id integer 16045 0 4581 1 1154 2291 3433 4582 rental customer_id integer 16045 0 600 1 148 296 446 600 rental return_date double 16045 183 15837 2005-05-25 23:55:21 2005-07-10 15:48:58 2005-08-01 19:45:29 2005-08-20 23:49:25 2019-04-07 rental staff_id integer 16045 0 2 1 1 1 2 2 ## Save your work! The work you do to understand the structure and contents of a database can be useful for others (including future-you). So at the end of a session, you might look at all the data frames you want to save. Consider saving them in a form where you can add notes at the appropriate level (as in a Google Doc representing table or columns that you annotate over time). ls() ## [1] &quot;all_meta&quot; &quot;columns_info_schema_info&quot; ## [3] &quot;columns_info_schema_table&quot; &quot;con&quot; ## [5] &quot;constraint_column_usage&quot; &quot;key_column_usage&quot; ## [7] &quot;keys&quot; &quot;public_tables&quot; ## [9] &quot;referential_constraints&quot; &quot;rs&quot; ## [11] &quot;some_tables&quot; &quot;table_constraints&quot; ## [13] &quot;table_info&quot; &quot;table_info_schema_table&quot; ## [15] &quot;table_list&quot; &quot;tables&quot; "],
["chapter-dbms-environment.html", "Chapter 21 Drilling into your DBMS environment 21.1 Which database? 21.2 How many databases reside in the Docker Container? 21.3 Which Schema? 21.4 Exercises", " Chapter 21 Drilling into your DBMS environment This chapter investigates: Elements of the database environment Differences between a database, a schema, and other objects Exercises The following packages are used in this chapter: # These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(dbplyr) library(sqlpetr) display_rows &lt;- 15 # as a default, show 15 rows Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Now connect to the dvdrental database with R con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) con ## &lt;PqConnection&gt; dvdrental@localhost:5439 21.1 Which database? Your DBA will create your user accounts and priviledges for the database(s) that you can access. One of the challenges when working with a database(s) is finding where your data actually resides. Your best resources will be one or more subject matter experts, SME, and your DBA. Your data may actually reside in multiple databases, e.g., a detail and summary databases. In our tutorial, we focus on the one database, dvdrental. Database names usually reflect something about the data that they contain. Your laptop is a server for the Docker PostgreSQL databases. A database is a collection of files that PostgreSQL manages in the background. 21.2 How many databases reside in the Docker Container? rs &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Names in Docker&#39; showing ,datname DB FROM pg_database WHERE datistemplate = false; &quot; ) kable(rs) showing db DB Names in Docker postgres DB Names in Docker dvdrental Which databases are available? Modify the connection call to connect to the `postgres` database. # this code chunk is not evaluated because the `dbname` is not valid! con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;your code goes here&quot;, seconds_to_test = 30 ) con if (con != &quot;There is no connection&quot;) { dbDisconnect(con) } # Answer: con &lt;PqConnection&gt; postgres@localhost:5439 # Reconnect to dvdrental con &lt;- sp_get_postgres_connection( user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30 ) con ## &lt;PqConnection&gt; dvdrental@localhost:5439 Note that the two Sys.getenv function calls work in this tutorial because both the user and password are available in both databases. This is a common practice in organinzations that have implemented single sign on across their organization. Gotcha: If one has data in multiple databases or multiple environments, Development, Integration, and Prodution, it is very easy to connect to the wrong database in the wrong environment. Always double check your connection information when logging in and before performing any inserts, updates, or deletes against the database. The following code block should be used to reduce propagating the above gotcha. Current_database(), CURRENT_DATE or CURRENT_TIMESTAMP, and result set are the most useful and last three not so much. Instead of the host IP address having the actual hostname would be a nice addition. rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT current_database() DB ,CURRENT_DATE ,CURRENT_TIMESTAMP ,&#39;result set description&#39; showing ,session_user ,inet_server_addr() host ,inet_server_port() port &quot; ) kable(rs1) db current_date current_timestamp showing session_user host port dvdrental 2019-04-07 2019-04-07 14:12:59 result set description postgres 172.17.0.2 5439 Since we will only be working in the dvdrental database in this tutorial and reduce the number of output columns shown, only the result set description will be used. 21.3 Which Schema? In the code block below, we look at the information_schema.table which contains information about all the schemas and table/views within our dvdrental database. Databases can have one or more schemas, containers that hold tables or views. Schemas partition the database into big logical blocks of related data. Schema names usually reflect an application or logically related datasets. Occasionally a DBA will set up a new schema and use a users name. What schemas are in the dvdrental database? How many entries are in each schema? ## Database Schemas # rs1 &lt;- DBI::dbGetQuery( con, &quot;SELECT &#39;DB Schemas&#39; showing,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot; ) kable(rs1) showing db table_schema tbl_vws DB Schemas dvdrental pg_catalog 121 DB Schemas dvdrental public 24 DB Schemas dvdrental information_schema 67 We see that there are three schemas. The pg_catalog is the standard PostgreSQL meta data and core schema. PostgreSQL uses this schema to manage the internal workings of the database. DBAs are the primary users of pg_catalog. We used the pg_catalog schema to answer the question How many databases reside in the Docker Container?, but normally the data analyst is not interested in analyzing database data. The information_schema contains ANSI standardized views used across the different SQL vendors, (Oracle, Sysbase, MS SQL Server, IBM DB2, etc). The information_schema contains a plethora of metadata that will help you locate your data tables, understand the relationships between the tables, and write efficient SQL queries. 21.4 Exercises # # Add an order by clause to order the output by the table catalog. rs1 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;1. ORDER BY table_catalog&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot;) kable(rs1) showing db table_schema tbl_vws 1. ORDER BY table_catalog dvdrental pg_catalog 121 1. ORDER BY table_catalog dvdrental public 24 1. ORDER BY table_catalog dvdrental information_schema 67 # Add an order by clause to order the output by tbl_vws in descending order. rs2 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;2. ORDER BY tbl_vws desc&#39; showing ,t.table_catalog DB,t.table_schema,COUNT(*) tbl_vws FROM information_schema.tables t GROUP BY t.table_catalog,t.table_schema &quot;) kable(rs2) showing db table_schema tbl_vws 2. ORDER BY tbl_vws desc dvdrental pg_catalog 121 2. ORDER BY tbl_vws desc dvdrental public 24 2. ORDER BY tbl_vws desc dvdrental information_schema 67 # Complete the SQL statement to show everything about all the tables. rs3 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;3. all information_schema tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t &quot;) kable(head(rs3, display_rows)) showing ?column? 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here 3. all information_schema tables your code goes here # Use the results from above to pull interesting columns from just the information_schema rs4 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;4. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) head(rs4, display_rows) ## showing ?column? ## 1 4. information_schema.tables your code goes here ## 2 4. information_schema.tables your code goes here ## 3 4. information_schema.tables your code goes here ## 4 4. information_schema.tables your code goes here ## 5 4. information_schema.tables your code goes here ## 6 4. information_schema.tables your code goes here ## 7 4. information_schema.tables your code goes here ## 8 4. information_schema.tables your code goes here ## 9 4. information_schema.tables your code goes here ## 10 4. information_schema.tables your code goes here ## 11 4. information_schema.tables your code goes here ## 12 4. information_schema.tables your code goes here ## 13 4. information_schema.tables your code goes here ## 14 4. information_schema.tables your code goes here ## 15 4. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;tab&#39; rs5 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;5. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) kable(head(rs5, display_rows)) showing ?column? 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here 5. information_schema.tables your code goes here # Modify the SQL below with your interesting column names. # Update the where clause to return only rows from the information schema and begin with &#39;col&#39; rs6 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;6. information_schema.tables&#39; showing ,&#39;your code goes here&#39; FROM information_schema.tables t where &#39;your code goes here&#39; = &#39;your code goes here&#39; &quot;) kable(head(rs6, display_rows)) showing ?column? 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here 6. information_schema.tables your code goes here In the next exercise we combine both the table and column output from the previous exercises. Review the following code block. The last two lines of the WHERE clause are swithced. Will the result set be the same or different? Execute the code block and review the two datasets. rs7 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;7. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; and table_type = &#39;VIEW&#39; &quot;) kable(head(rs7, display_rows)) showing db_info table_name table_type 7. information_schema.tables dvdrental.information_schema collations VIEW 7. information_schema.tables dvdrental.information_schema collation_character_set_applicability VIEW 7. information_schema.tables dvdrental.information_schema column_domain_usage VIEW 7. information_schema.tables dvdrental.information_schema column_privileges VIEW 7. information_schema.tables dvdrental.information_schema column_udt_usage VIEW 7. information_schema.tables dvdrental.information_schema columns VIEW 7. information_schema.tables dvdrental.information_schema constraint_column_usage VIEW 7. information_schema.tables dvdrental.information_schema key_column_usage VIEW 7. information_schema.tables dvdrental.information_schema role_column_grants VIEW 7. information_schema.tables dvdrental.information_schema table_constraints VIEW 7. information_schema.tables dvdrental.information_schema table_privileges VIEW 7. information_schema.tables dvdrental.information_schema tables VIEW 7. information_schema.tables dvdrental.information_schema triggered_update_columns VIEW 7. information_schema.tables dvdrental.information_schema view_column_usage VIEW 7. information_schema.tables dvdrental.information_schema _pg_foreign_table_columns VIEW rs8 &lt;- DBI::dbGetQuery(con, &quot;SELECT &#39;8. information_schema.tables&#39; showing ,table_catalog||&#39;.&#39;||table_schema db_info, table_name, table_type FROM information_schema.tables t where table_schema = &#39;information_schema&#39; and table_type = &#39;VIEW&#39; and table_name like &#39;table%&#39; OR table_name like &#39;%col%&#39; &quot;) kable(head(rs8, display_rows)) showing db_info table_name table_type 8. information_schema.tables dvdrental.information_schema column_options VIEW 8. information_schema.tables dvdrental.information_schema _pg_foreign_table_columns VIEW 8. information_schema.tables dvdrental.information_schema view_column_usage VIEW 8. information_schema.tables dvdrental.information_schema triggered_update_columns VIEW 8. information_schema.tables dvdrental.information_schema tables VIEW 8. information_schema.tables dvdrental.information_schema table_privileges VIEW 8. information_schema.tables dvdrental.information_schema table_constraints VIEW 8. information_schema.tables dvdrental.information_schema role_column_grants VIEW 8. information_schema.tables dvdrental.information_schema key_column_usage VIEW 8. information_schema.tables dvdrental.information_schema constraint_column_usage VIEW 8. information_schema.tables dvdrental.information_schema columns VIEW 8. information_schema.tables dvdrental.information_schema column_udt_usage VIEW 8. information_schema.tables dvdrental.information_schema column_privileges VIEW 8. information_schema.tables dvdrental.information_schema column_domain_usage VIEW 8. information_schema.tables dvdrental.information_schema collation_character_set_applicability VIEW Operator/Element Associativity Description . left table/column name separator :: left PostgreSQL-style typecast [ ] left array element selection - right unary minus ^ left exponentiation * / % left multiplication, division, modulo + - left addition, subtraction IS IS TRUE, IS FALSE, IS UNKNOWN, IS NULL ISNULL test for null NOTNULL test for not null (any other) left all other native and user-defined operators IN set membership BETWEEN range containment OVERLAPS time interval overlap LIKE ILIKE SIMILAR string pattern matching &lt; &gt; less than, greater than = right equality, assignment NOT right logical negation AND left logical conjunction OR left logical disjunction rs1 &lt;- DBI::dbGetQuery(con, &quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_name,t.table_type FROM information_schema.tables t&quot;) rs2 &lt;- DBI::dbGetQuery(con, &quot;SELECT t.table_catalog DB ,t.table_schema ,t.table_type,COUNT(*) tbls FROM information_schema.tables t group by t.table_catalog ,t.table_schema ,t.table_type &quot;) rs3 &lt;- DBI::dbGetQuery(con, &quot;SELECT distinct t.table_catalog DB ,t.table_schema ,t.table_type tbls FROM information_schema.tables t &quot;) # kable(head(rs1 %&gt;% arrange (table_name))) # View(rs1) # View(rs2) # View(rs3) kable(head(rs1)) db table_schema table_name table_type dvdrental public actor_info VIEW dvdrental public customer_list VIEW dvdrental public film_list VIEW dvdrental public nicer_but_slower_film_list VIEW dvdrental public sales_by_film_category VIEW dvdrental public staff BASE TABLE kable(head(rs2)) db table_schema table_type tbls dvdrental information_schema BASE TABLE 7 dvdrental information_schema VIEW 60 dvdrental pg_catalog BASE TABLE 62 dvdrental public BASE TABLE 17 dvdrental public VIEW 7 dvdrental pg_catalog VIEW 59 kable(head(rs3)) db table_schema tbls dvdrental information_schema BASE TABLE dvdrental information_schema VIEW dvdrental pg_catalog BASE TABLE dvdrental public BASE TABLE dvdrental public VIEW dvdrental pg_catalog VIEW www.dataquest.io/blog/postgres-internals Comment on the practice of putting a comma at the beginning of a line in SQL code. ## Explain a `dplyr::join tbl_pk_fk_df &lt;- DBI::dbGetQuery( con, &quot; SELECT --t.table_catalog,t.table_schema, c.table_name ,kcu.column_name ,c.constraint_name ,c.constraint_type ,coalesce(c2.table_name, &#39;&#39;) ref_table ,coalesce(kcu2.column_name, &#39;&#39;) ref_table_col FROM information_schema.tables t LEFT JOIN information_schema.table_constraints c ON t.table_catalog = c.table_catalog AND t.table_schema = c.table_schema AND t.table_name = c.table_name LEFT JOIN information_schema.key_column_usage kcu ON c.constraint_schema = kcu.constraint_schema AND c.constraint_name = kcu.constraint_name LEFT JOIN information_schema.referential_constraints rc ON c.constraint_schema = rc.constraint_schema AND c.constraint_name = rc.constraint_name LEFT JOIN information_schema.table_constraints c2 ON rc.unique_constraint_schema = c2.constraint_schema AND rc.unique_constraint_name = c2.constraint_name LEFT JOIN information_schema.key_column_usage kcu2 ON c2.constraint_schema = kcu2.constraint_schema AND c2.constraint_name = kcu2.constraint_name AND kcu.ordinal_position = kcu2.ordinal_position WHERE c.constraint_type IN (&#39;PRIMARY KEY&#39;, &#39;FOREIGN KEY&#39;) AND c.table_catalog = &#39;dvdrental&#39; AND c.table_schema = &#39;public&#39; ORDER BY c.table_name; &quot; ) # View(tbl_pk_fk_df) tables_df &lt;- tbl_pk_fk_df %&gt;% distinct(table_name) # View(tables_df) library(DiagrammeR) table_nodes_ndf &lt;- create_node_df( n &lt;- nrow(tables_df) , type &lt;- &quot;table&quot; , label &lt;- tables_df$table_name , shape = &quot;rectangle&quot; , width = 1 , height = .5 , fontsize = 18 ) tbl_pk_fk_ids_df &lt;- inner_join(tbl_pk_fk_df, table_nodes_ndf , by = c(&quot;table_name&quot; = &quot;label&quot;) , suffix(c(&quot;st&quot;, &quot;s&quot;)) ) %&gt;% rename(&quot;src_tbl_id&quot; = id) %&gt;% left_join(table_nodes_ndf , by = c(&quot;ref_table&quot; = &quot;label&quot;) , suffix(c(&quot;st&quot;, &quot;t&quot;)) ) %&gt;% rename(&quot;fk_tbl_id&quot; = id) tbl_fk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &quot;FOREIGN KEY&quot;) tbl_pk_df &lt;- tbl_pk_fk_ids_df %&gt;% filter(constraint_type == &quot;PRIMARY KEY&quot;) # View(tbl_pk_fk_ids_df) # View(tbl_fk_df) # View(tbl_pk_df) kable(head(tbl_fk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y address city_id fk_address_city FOREIGN KEY city city_id 2 table rectangle 1 0.5 18 4 table rectangle 1 0.5 18 city country_id fk_city FOREIGN KEY country country_id 4 table rectangle 1 0.5 18 5 table rectangle 1 0.5 18 customer address_id customer_address_id_fkey FOREIGN KEY address address_id 6 table rectangle 1 0.5 18 2 table rectangle 1 0.5 18 film language_id film_language_id_fkey FOREIGN KEY language language_id 7 table rectangle 1 0.5 18 11 table rectangle 1 0.5 18 film_actor actor_id film_actor_actor_id_fkey FOREIGN KEY actor actor_id 8 table rectangle 1 0.5 18 1 table rectangle 1 0.5 18 film_actor film_id film_actor_film_id_fkey FOREIGN KEY film film_id 8 table rectangle 1 0.5 18 7 table rectangle 1 0.5 18 kable(head(tbl_pk_df)) table_name column_name constraint_name constraint_type ref_table ref_table_col src_tbl_id type.x shape.x width.x height.x fontsize.x fk_tbl_id type.y shape.y width.y height.y fontsize.y actor actor_id actor_pkey PRIMARY KEY 1 table rectangle 1 0.5 18 NA NA NA NA NA NA address address_id address_pkey PRIMARY KEY 2 table rectangle 1 0.5 18 NA NA NA NA NA NA category category_id category_pkey PRIMARY KEY 3 table rectangle 1 0.5 18 NA NA NA NA NA NA city city_id city_pkey PRIMARY KEY 4 table rectangle 1 0.5 18 NA NA NA NA NA NA country country_id country_pkey PRIMARY KEY 5 table rectangle 1 0.5 18 NA NA NA NA NA NA customer customer_id customer_pkey PRIMARY KEY 6 table rectangle 1 0.5 18 NA NA NA NA NA NA # Create an edge data frame, edf fk_edf &lt;- create_edge_df( from = tbl_fk_df$src_tbl_id, to = tbl_fk_df$fk_tbl_id, rel = &quot;fk&quot;, label = tbl_fk_df$constraint_name, fontsize = 15 ) # View(fk_edf) create_graph( nodes_df = table_nodes_ndf, edges_df = fk_edf, graph_name = &quot;Simple FK Graph&quot; ) %&gt;% render_graph() dbDisconnect(con) # system2(&#39;docker&#39;,&#39;stop sql-pet&#39;) "],
["chapter-explain-queries.html", "Chapter 22 Explain queries 22.1 Performance considerations 22.2 Clean up", " Chapter 22 Explain queries This chapter demonstrates: How to investigate SQL query performance # These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) library(glue) library(here) require(knitr) library(dbplyr) library(sqlpetr) examining dplyr queries (dplyr::show_query on the R side v EXPLAIN on the PostgreSQL side) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) now connect to the database with R con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 22.1 Performance considerations ## Explain a `dplyr::join` ## Explain the quivalent SQL join rs1 &lt;- DBI::dbGetQuery(con ,&quot;SELECT c.* FROM pg_catalog.pg_class c JOIN pg_catalog.pg_namespace n ON n.oid = c.relnamespace WHERE n.nspname = &#39;public&#39; AND c.relname = &#39;cust_movies&#39; AND c.relkind = &#39;r&#39; ; &quot; ) head(rs1) ## [1] relname relnamespace reltype ## [4] reloftype relowner relam ## [7] relfilenode reltablespace relpages ## [10] reltuples relallvisible reltoastrelid ## [13] relhasindex relisshared relpersistence ## [16] relkind relnatts relchecks ## [19] relhasoids relhaspkey relhasrules ## [22] relhastriggers relhassubclass relrowsecurity ## [25] relforcerowsecurity relispopulated relreplident ## [28] relispartition relfrozenxid relminmxid ## [31] relacl reloptions relpartbound ## &lt;0 rows&gt; (or 0-length row.names) This came from 14-sql_pet-examples-part-b.Rmd rs1 &lt;- DBI::dbGetQuery(con, &quot;explain select r.* from rental r ;&quot; ) head(rs1) ## QUERY PLAN ## 1 Seq Scan on rental r (cost=0.00..310.44 rows=16044 width=36) rs2 &lt;- DBI::dbGetQuery(con, &quot;explain select count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id where p.rental_id is null ;&quot;) head(rs2) ## QUERY PLAN ## 1 Aggregate (cost=2086.78..2086.80 rows=1 width=8) ## 2 -&gt; Merge Anti Join (cost=0.57..2066.73 rows=8022 width=0) ## 3 Merge Cond: (r.rental_id = p.rental_id) ## 4 -&gt; Index Only Scan using rental_pkey on rental r (cost=0.29..1024.95 rows=16044 width=4) ## 5 -&gt; Index Only Scan using idx_fk_rental_id on payment p (cost=0.29..819.23 rows=14596 width=4) rs3 &lt;- DBI::dbGetQuery(con, &quot;explain select sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id where p.rental_id is null ;&quot;) head(rs3) ## QUERY PLAN ## 1 Aggregate (cost=2353.64..2353.65 rows=1 width=40) ## 2 -&gt; Hash Join (cost=205.14..2313.53 rows=8022 width=12) ## 3 Hash Cond: (i.film_id = f.film_id) ## 4 -&gt; Hash Join (cost=128.64..2215.88 rows=8022 width=2) ## 5 Hash Cond: (r.inventory_id = i.inventory_id) ## 6 -&gt; Merge Anti Join (cost=0.57..2066.73 rows=8022 width=4) rs4 &lt;- DBI::dbGetQuery(con, &quot;explain select c.customer_id,c.first_name,c.last_name,sum(f.rental_rate) open_amt,count(*) count from rental r left outer join payment p on r.rental_id = p.rental_id join inventory i on r.inventory_id = i.inventory_id join film f on i.film_id = f.film_id join customer c on r.customer_id = c.customer_id where p.rental_id is null group by c.customer_id,c.first_name,c.last_name order by open_amt desc ;&quot; ) head(rs4) ## QUERY PLAN ## 1 Sort (cost=2452.49..2453.99 rows=599 width=260) ## 2 Sort Key: (sum(f.rental_rate)) DESC ## 3 -&gt; HashAggregate (cost=2417.37..2424.86 rows=599 width=260) ## 4 Group Key: c.customer_id ## 5 -&gt; Hash Join (cost=227.62..2357.21 rows=8022 width=232) ## 6 Hash Cond: (r.customer_id = c.customer_id) 22.2 Clean up # dbRemoveTable(con, &quot;cars&quot;) # dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-sql-queries-breakdown.html", "Chapter 23 SQL queries broken down 23.1 SQL Execution Steps 23.2 Passing values to SQL statements 23.3 Pass multiple sets of values with dbBind(): 23.4 Clean up", " Chapter 23 SQL queries broken down This chapter has two separate topics: SQL execution steps and passing values to SQL statements. Do they belong together? Does the chapter have the right title? This chapter explains: Some details about how SQL queries work behind the scenes SQL queries are executed behind the scenes You can pass values to SQL queries These packages are called in almost every chapter of the book: library(tidyverse) library(DBI) library(RPostgres) library(glue) require(knitr) library(dbplyr) library(sqlpetr) Start up the docker-pet container sp_docker_start(&quot;sql-pet&quot;) Connect to the database with R: con &lt;- sp_get_postgres_connection(user = Sys.getenv(&quot;DEFAULT_POSTGRES_USER_NAME&quot;), password = Sys.getenv(&quot;DEFAULT_POSTGRES_PASSWORD&quot;), dbname = &quot;dvdrental&quot;, seconds_to_test = 30, connection_tab = TRUE ) 23.1 SQL Execution Steps Parse the incoming SQL query Compile the SQL query Plan/optimize the data acquisition path Execute the optimized query / acquire and return data how do those steps map to the following code? dbWriteTable(con, &quot;mtcars&quot;, mtcars, overwrite = TRUE) rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 23.2 Passing values to SQL statements #Pass one set of values with the param argument: rs &lt;- dbSendQuery(con,&quot;SELECT * FROM mtcars WHERE cyl = 4&quot;) dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## 2 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## 3 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## 4 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## 5 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## 6 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## 7 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## 8 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## 9 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## 10 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## 11 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 dbClearResult(rs) 23.3 Pass multiple sets of values with dbBind(): rs &lt;- dbSendQuery(con, &quot;SELECT * FROM mtcars WHERE cyl = $1&quot;) dbBind(rs, list(6L)) # cyl = 6 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## 3 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## 4 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## 5 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## 6 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## 7 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 dbBind(rs, list(8L)) # cyl = 8 dbFetch(rs) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## 2 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## 3 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## 4 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## 5 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## 6 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## 7 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## 8 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## 9 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## 10 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## 11 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## 12 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## 13 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## 14 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 dbClearResult(rs) 23.4 Clean up # dbRemoveTable(con, &quot;cars&quot;) dbRemoveTable(con, &quot;mtcars&quot;) # dbRemoveTable(con, &quot;cust_movies&quot;) # diconnect from the db dbDisconnect(con) sp_docker_stop(&quot;sql-pet&quot;) "],
["chapter-writing-to-the-dbms.html", "Chapter 24 Writing to the DBMS 24.1 Set up a cattle container 24.2 Interact with PostgreSQL 24.3 Clean up", " Chapter 24 Writing to the DBMS This chapter demonstrates how to: Set up and connect to a cattle database Create, modify, and remove a database table In a corporate setting, you may be creating your own tables or modifying existing tables less frequently than retrieving data. Nevertheless, in our sandbox you can easily do so. The following packages are used in this chapter: library(tidyverse) library(DBI) library(RPostgres) require(knitr) library(sqlpetr) 24.1 Set up a cattle container Check that Docker is up and running: sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; 24.1.1 Remove previous containers if they exist Remove the cattle and sql-pet containers if they exist (e.g., from prior experiments). sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 Create a new cattle container: sp_make_simple_pg(&quot;cattle&quot;) Show that were ready to connect: sp_check_that_docker_is_up() ## [1] &quot;Docker is up, running these containers:&quot; ## [2] &quot;CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&quot; ## [3] &quot;83ffac619f81 postgres:10 \\&quot;docker-entrypoint.s\\&quot; 1 second ago Up Less than a second 5432/tcp, 0.0.0.0:5439-&gt;5439/tcp cattle&quot; 24.1.2 Connect to PostgreSQL Connect to PostgreSQL using the sp_get_postgres_connection function: con &lt;- sp_get_postgres_connection(user = &quot;postgres&quot;, password = &quot;postgres&quot;, dbname = &quot;postgres&quot;, seconds_to_test = 30, connection_tab = TRUE ) 24.2 Interact with PostgreSQL Check on the contents of the database. DBI::dbListTables(con) ## character(0) It does not contain any tables yet. 24.2.1 Create a new table in the database This is an example from the DBI help file using the cars built-in dataset, not to be confused with mtcars: dbWriteTable(con, &quot;cars&quot;, head(cars, 3)) # The cars table has 3 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 24.2.2 Modify an existing table To add additional rows or instances to the cars table, we will use INSERT command with their values. There are two different ways of adding values: list them or pass values using the param argument. dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES (1, 1), (2, 2), (3, 3)&quot; ) ## [1] 3 Now it has 6 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 Pass values using the param argument: dbExecute( con, &quot;INSERT INTO cars (speed, dist) VALUES ($1, $2)&quot;, param = list(4:7, 5:8) ) ## [1] 4 Now there are 10 rows: dbReadTable(con, &quot;cars&quot;) ## speed dist ## 1 4 2 ## 2 4 10 ## 3 7 4 ## 4 1 1 ## 5 2 2 ## 6 3 3 ## 7 4 5 ## 8 5 6 ## 9 6 7 ## 10 7 8 24.2.3 Remove the table Remove the cars table. dbRemoveTable(con, &quot;cars&quot;) 24.3 Clean up Disconnect from the database: dbDisconnect(con) Stop the cattle container, but leave it around for future use. sp_docker_stop(&quot;cattle&quot;) "],
["chapter-appendix-setup-instructions.html", "A Appendix A - Setup instructions A.1 Sandbox prerequisites A.2 R, RStudio and Git A.3 Install Docker", " A Appendix A - Setup instructions This appendix explains: Hardware and software prerequisites for setting up the sandbox used in this book Documentation for all of the elements used in this sandbox A.1 Sandbox prerequisites The sandbox environment requires: A computer running Windows (Windows 7 64-bit or later - Windows 10-Pro is recommended), MacOS, or Linux (any Linux distro that will run Docker Community Edition, R and RStudio will work) Current versions of R and RStudio [Vargas (2018)) required. Docker (instructions below) Our companion package sqlpetr (Borasky et al. 2018) The database we use is PostgreSQL 10, but you do not need to install it - its installed via a Docker image. In addition to the current version of R and RStudio, you will need current versions of the following packages: DBI (R Special Interest Group on Databases (R-SIG-DB), Wickham, and Mller 2018) DiagrammeR (Iannone 2018) RPostgres (Wickham, Ooms, and Mller 2018) dbplyr (Wickham and Ruiz 2019) devtools (Wickham, Hester, and Chang 2018) downloader (Chang 2015) glue (Hester 2019) here (Mller 2017) knitr (Xie 2019) skimr (McNamara et al. 2019) tidyverse (Wickham 2017) bookdown (Xie 2018) (for compiling the book, if you want to) A.2 R, RStudio and Git Most readers will probably have these already, but if not: If you do not have R: Go to https://cran.rstudio.com/ (R Core Team 2018). Select the download link for your system. For Linux, choose your distro. We recommend Ubuntu 18.04 LTS Bionic Beaver. Its much easier to find support answers on the web for Ubuntu than other distros. Follow the instructions. Note: if you already have R, make sure its upgraded to R 3.5.1. We dont test on older versions! If you do not have RStudio: go to https://www.rstudio.com/products/rstudio/download/#download. Make sure you have version 1.1.463 or later. If you do not have Git: On Windows, go to https://git-scm.com/download/win and follow instructions. There are a lot of options. Just pick the defaults!!! On MacOS, go to https://sourceforge.net/projects/git-osx-installer/files/ and follow instructions. On Linux, install Git from your distribution. A.3 Install Docker Installation depends on your operating system and we have found that it can be somewhat intricate. You will need Docker Community Edition (Docker CE): For Windows, consider these issues and follow these instructions: Go to https://store.docker.com/editions/community/docker-ce-desktop-windows. If you dont have a Docker Store log in, youll need to create one. Then: If you have Windows 10 Pro, download and install Docker for Windows. If you have an older version of Windows, download and install Docker Toolbox (https://docs.docker.com/toolbox/overview/). Note that both versions require 64-bit hardware and the virtualization needs to be enabled in the firmware. On a Mac (Docker 2018c): Go to https://store.docker.com/editions/community/docker-ce-desktop-mac. If you dont have a Docker Store login, youll need to create one. Then download and install Docker for Mac. Your MacOS must be at least release Yosemite (10.10.3). On UNIX flavors (Docker 2018a): note that, as with Windows and MacOS, youll need a Docker Store loin. Although most Linux distros ship with some version of Docker, chances are its not the same as the official Docker CE version. Ubuntu: https://store.docker.com/editions/community/docker-ce-server-ubuntu, Fedora: https://store.docker.com/editions/community/docker-ce-server-fedora, Cent OS: https://store.docker.com/editions/community/docker-ce-server-centos, Debian: https://store.docker.com/editions/community/docker-ce-server-debian. Note that on Linux, you will need to be a member of the docker group to use Docker. To do that, execute sudo usermod -aG docker ${USER}. Then, log out and back in again. References "],
["chapter-windows-tech-details.html", "B Appendix B - Additional technical details for Windows users B.1 Hardware requirements B.2 Software requirements B.3 Docker for Windows settings B.4 Git, GitHub and line endings", " B Appendix B - Additional technical details for Windows users This chapter explains: How to setup your environment for Windows How to use Git and GitHub effectively on Windows Skip these instructions if your computer has either OSX or a Unix variant. B.1 Hardware requirements You will need an Intel or AMD processor with 64-bit hardware and the hardware virtualization feature. Most machines you buy today will have that, but older ones may not. You will need to go into the BIOS / firmware and enable the virtualization feature. You will need at least 4 gigabytes of RAM! B.2 Software requirements You will need Windows 7 64-bit or later. If you can afford it, I highly recommend upgrading to Windows 10 Pro. B.2.1 Windows 7, 8, 8.1 and Windows 10 Home (64 bit) Install Docker Toolbox. The instructions are here: https://docs.docker.com/toolbox/toolbox_install_windows/. Make sure you try the test cases and they work! B.2.2 Windows 10 Pro Install Docker for Windows stable. The instructions are here: https://docs.docker.com/docker-for-windows/install/#start-docker-for-windows. Again, make sure you try the test cases and they work. B.3 Docker for Windows settings B.3.1 Shared drives If youre going to mount host files into container file systems (as we do in the following chapters), you need to set up shared drives. Open the Docker settings dialog and select Shared Drives. Check the drives you want to share. In this screenshot, the D: drive is my 1 terabyte hard drive. B.3.2 Kubernetes Kubernetes is a container orchestration / cloud management package thats a major DevOps tool. Its heavily supported by Red Hat and Google, and as a result is becoming a required skill for DevOps. However, its overkill for this project at the moment. So you should make sure its not enabled. Go to the Kubernetes dialog and make sure the Enable Kubernetes checkbox is cleared. B.4 Git, GitHub and line endings Git was originally developed for Linux - in fact, it was created by Linus Torvalds to manage hundreds of different versions of the Linux kernel on different machines all around the world. As usage has grown, Git has achieved a huge following and is the version control system used by most large open source projects, including this one. If youre on Windows, there are some things about Git and GitHub you need to watch. First of all, there are quite a few tools for running Git on Windows, but the RStudio default and recommended one is Git for Windows (https://git-scm.com/download/win). By default, text files on Linux end with a single linefeed (\\n) character. But on Windows, text files end with a carriage return and a line feed (\\r\\n). See https://en.wikipedia.org/wiki/Newline for the gory details. Git defaults to checking files out in the native mode. So if youre on Linux, a text file will show up with the Linux convention, and if youre on Windows, it will show up with the Windows convention. Most of the time this doesnt cause any problems. But Docker containers usually run Linux, and if you have files from a repository on Windows that youve sent to the container, the container may malfunction or give weird results. This kind of situation has caused a lot of grief for contributors to this project, so beware. In particular, executable sh or bash scripts will fail in a Docker container if they have Windows line endings. You may see an error message with \\r in it, which means the shell saw the carriage return (\\r) and gave up. But often youll see no hint at all what the problem was. So you need a way to tell Git that some files need to be checked out with Linux line endings. See https://help.github.com/articles/dealing-with-line-endings/ for the details. Summary: Youll need a .gitattributes file in the root of the repository. In that file, all text files (scripts, program source, data, etc.) that are destined for a Docker container will need to have the designator &lt;spec&gt; text eol=lf, where &lt;spec&gt; is the file name specifier, for example, *.sh. This repo includes a sample: .gitattributes "],
["chapter-appendix-postresql-authentication.html", "C Appendix C - PostgreSQL Authentication C.1 Introduction C.2 Password authentication on the PostgreSQL Docker image C.3 Adding roles", " C Appendix C - PostgreSQL Authentication C.1 Introduction PostgreSQL has a very robust and flexible set of authentication methods (PostgreSQL Global Development Group 2018a). In most production environments, these will be managed by the database administrator (DBA) on a need-to-access basis. People and programs will be granted access only to a minimum set of capabilities required to function, and nothing more. In this book, we are using a PostgreSQL Docker image (Docker 2018d). When we create a container from that image, we use its native mechanism to create the postgres database superuser with a password specified in an R environment file ~/.Renviron. See Securing and using your dbms log-in credentials for how we do this. What that means is that you are the DBA - the database superuser - for the PostgreSQL database cluster running in the container! You can create and destroy databases, schemas, tables, views, etc. You can also create and destroy users - called roles in PostgreSQL, and GRANT or REVOKE their privileges with great precision. You dont have to do that to use this book. But if you want to experiment with it, feel free! C.2 Password authentication on the PostgreSQL Docker image Of the many PostgreSQL authentication mechanisms, the simplest thats universallly available is password authentication (PostgreSQL Global Development Group 2018c). Thats what we use for the postgres database superuser, and what we recommend for any roles you may create. Once a role has been created, you need five items to open a connection to the PostgreSQL database cluster: The host. This is a name or IP address that your network can access. In this book, with the database running in a Docker container, thats usually localhost. The port. This is the port the server is listening on. Its usually the default, 5439, and thats what we use. But in a secure environment, it will often be some random number to lower the chances that an attacker can find the database server. And if you have more than one server on the network, youll need to use different ports for each of them. The dbname to connect to. This database must exist or the connection attempt will fail. The user. This user must exist in the database cluster and be allowed to access the database. We are using the database superuser postgres in this book. The password. This is set by the DBA for the user. In this book we use the password defined in Securing and using your dbms log-in credentials. C.3 Adding roles As noted above, PostgreSQL has a very flexible fine-grained access permissions system. We cant cover all of it; see PostgreSQL Global Development Group (2018b) for the full details. But we can give an example. C.3.1 Setting up Docker First, we need to make sure we dont have any other databases listening on the default port 5439. sqlpetr::sp_check_that_docker_is_up() ## [1] &quot;Docker is up but running no containers&quot; sqlpetr::sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 sqlpetr::sp_docker_remove_container(&quot;sql-pet&quot;) ## [1] 0 # sqlpetr::sp_docker_stop(&quot;sql-pet&quot;) C.3.2 Creating a new container Well create a cattle container with a default PostgreSQL 10 database cluster. sqlpetr::sp_make_simple_pg(&quot;cattle&quot;) cattle_conn &lt;- sqlpetr::sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, dbname = &quot;postgres&quot;, user = &quot;postgres&quot;, password = &quot;postgres&quot;, seconds_to_test = 30, connection_tab = TRUE ) C.3.3 Adding a role Now, lets add a role. Well add a role that can log in and create databases, but isnt a superuser. Since this is a demo and not a real production database cluster, well specify a password in plaintext. And well create a database for our new user. Create the role: CREATE ROLE charlie LOGIN CREATEDB PASSWORD &#39;chaplin&#39;; Create the database: CREATE DATABASE charlie OWNER = charlie; C.3.4 Did it work? DBI::dbDisconnect(cattle_conn) cattle_conn &lt;- sqlpetr::sp_get_postgres_connection( host = &quot;localhost&quot;, port = 5439, dbname = &quot;charlie&quot;, user = &quot;charlie&quot;, password = &quot;chaplin&quot;, seconds_to_test = 30, connection_tab = TRUE ) print(cattle_conn) ## &lt;PqConnection&gt; charlie@localhost:5439 OK, we can connect. Lets do some stuff! data(&quot;iris&quot;) dbCreateTable creates the table with columns matching the data frame. But it does not send data to the table. DBI::dbCreateTable(cattle_conn, &quot;iris&quot;, iris) To send data, we use dbAppendTable. DBI::dbAppendTable(cattle_conn, &quot;iris&quot;, iris) ## Warning: Factors converted to character ## [1] 150 DBI::dbListTables(cattle_conn) ## [1] &quot;iris&quot; head(DBI::dbReadTable(cattle_conn, &quot;iris&quot;)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa DBI::dbDisconnect(cattle_conn) C.3.5 Remove the container sqlpetr::sp_docker_remove_container(&quot;cattle&quot;) ## [1] 0 References "],
["chapter-appendix-sql-quick-guide.html", "D APPENDIX D - Quick Guide to SQL D.1 Data Manipulation Langauge (DML) D.2 Data Definition Langauge (DDL) D.3 Data Control Language (DCL) D.4 Transaction Control Language (TCL)", " D APPENDIX D - Quick Guide to SQL SQL stands for Structured Query Language. It is a database language where we can perform certain operations on the existing database and we can use it create a new database. There are four main categories where the SQL commands fall into: DML, DDL, DCL, and TCL. D.1 Data Manipulation Langauge (DML) These four SQL commands deal with the manipulation of data in the database. For everyday analytical work, these are the commands that you will use the most. 1. SELECT 2. INSERT 3. UPDATE 4. DELETE D.2 Data Definition Langauge (DDL) It consists of the SQL commands that can be used to define a database schema. The DDL commands include: 1. CREATE 2. ALTER 3. TRUNCATE 4. COMMENT 5. RENAME 6. DROP D.3 Data Control Language (DCL) The DCL commands deals with user rights, permissions and other controls in database management system. 1. GRANT 2. REVOKE D.4 Transaction Control Language (TCL) These commands deal with the control over transaction within the database. Transaction combines a set of tasks into single execution. 1. SET TRANSACTION 2. SAVEPOINT 3. ROLLBACK 4. COMMIT "],
["chapter-appendix-dplyr-functions.html", "E Dplyr functions and SQL cross-walk", " E Dplyr functions and SQL cross-walk Where are these covered and should they be included? Dplyr Function description SQL Clause Where Category all_equal() all.equal() Flexible equality comparison for data frames Two-table verbs all_vars() any_vars() Apply predicate to all variables scoped-Operate on a selection of variables arrange() Arrange rows by variables ORDER BY 13.1.4 (21) Basic single-table verbs arrange_all() arrange_at() arrange_if() Arrange rows by a selection of variables ORDER BY scoped-Operate on a selection of variables auto_copy() Copy tables to same source, if necessary Remote tables between() Do values in a numeric vector fall in specified range? Vector functions bind_rows() bind_cols() combine() Efficiently bind multiple data frames by row and column Two-table verbs case_when() A general vectorised if Vector functions coalesce() Find first non-missing element Vector functions compute() collect() collapse() Force computation of a database query Remote tables copy_to() Copy a local data frame to a remote src Remote tables cumall() cumany() cummean() Cumulativate versions of any, all, and mean Vector functions desc() Descending order Vector functions distinct() Return rows with matching conditions SELECT distinct * Basic single-table verbs distinct() Select distinct/unique rows SELECT distinct {colname1,colnamen} Basic single-table verbs do() Do anything NA Basic single-table verbs explain() show_query() Explain details of a tbl Remote tables filter_all() filter_if() filter_at() Filter within a selection of variables scoped-Operate on a selection of variables funs() Create a list of functions calls. scoped-Operate on a selection of variables group_by() ungroup() Objects exported from other packages GROUP BY no ungroup Basic single-table verbs group_by_all() group_by_at() group_by_if() Group by a selection of variables scoped-Operate on a selection of variables groups() group_vars() Return grouping variables Metadata ident() Flag a character vector as SQL identifiers Remote tables if_else() Vectorised if Vector functions inner_join() left_join() right_join() full_join() semi_join() anti_join() Join two tbls together Two-table verbs inner_join()left_join() right_join() full_join() semi_join() anti_join() Join data frame tbls Two-table verbs intersect() union() union_all() setdiff() setequal() Set operations Two-table verbs lead() lag() Lead and lag. Vector functions mutate() transmute() Add new variables SELECT computed_value computed_name 11.5.2 (13) Basic single-table verbs n() The number of observations in the current group. Vector functions n_distinct() Efficiently count the number of unique values in a set of vector Vector functions na_if() Convert values to NA Vector functions near() Compare two numeric vectors Vector functions nth() first() last() Extract the first, last or nth value from a vector Vector functions order_by() A helper function for ordering window function output Vector functions pull() Pull out a single variable SELECT column_name; Basic single-table verbs recode() recode_factor() Recode values Vector functions row_number() ntile() min_rank() dense_rank() percent_rank() cume_dist() Windowed rank functions. Vector functions rowwise() Group input by rows Other backends sample_n() sample_frac() Sample n rows from a table ORDER BY RANDOM() LIMIT 10 Basic single-table verbs select() rename() Select/rename variables by name SELECT column_name alias_name 9.1.8 (11) Basic single-table verbs select_all() rename_all() select_if() rename_if() select_at() rename_at() Select and rename a selection of variables scoped-Operate on a selection of variables slice() Select rows by position SELECT row_number() over (partition by expression(s) order_by exp) Basic single-table verbs sql() SQL escaping. Remote tables src_mysql() src_postgres() src_sqlite() Source for database backends Remote tables summarise_all() summarise_if() summarise_at() summarize_all() summarize_if() summarize_at() mutate_all() mutate_if() mutate_at() transmute_all() transmute_if() transmute_at() Summarise and mutate multiple columns. scoped-Operate on a selection of variables summarize() Reduces multiple values down to a single value SELECT aggregate_functions GROUP BY 11.5.1 (13) Basic single-table verbs tally() count()add_tally() add_count() Count/tally observations by group GROUP BY 9.1.6 (11) Single-table helpers tbl() is.tbl() as.tbl() Create a table from a data source Remote tables top_n() Select top (or bottom) n rows (by value) ORDER BY VALUE {DESC} LIMIT 10 Single-table helpers vars() Select variables scoped-Operate on a selection of variables "],
["chapter-appendix-dbi-functions.html", "F DBI package functions - coverage", " F DBI package functions - coverage Where are these covered and should the by included? DBI 1st time Call Example/Notes DBIConnct 6.3.2 (04) in sp_get_postgres_connection dbAppendTable dbCreateTable dbDisconnect 6.4n (04) dbDisconnect(con) dbExecute 10.4.2 (13) Executes a statement and returns the number of rows affected. dbExecute() comes with a default implementation (which should work with most backends) that calls dbSendStatement(), then dbGetRowsAffected(), ensuring that the result is always free-d by dbClearResult(). dbExistsTable dbExistsTable(con,actor) dbFetch 17.1 (72) dbFetch(rs) dbGetException dbGetInfo dbGetInfo(con) dbGetQuery 10.4.1 (13) dbGetQuery(con,select * from store;) dbIsReadOnly dbIsReadOnly(con) dbIsValid dbIsValid(con) dbListFields 6.3.3 (04) DBI::dbListFields(con, mtcars) dbListObjects dbListObjects(con) dbListTables 6.3.2 (04) DBI::dbListTables(con, con) dbReadTable 8.1.2 DBI::dbReadTable(con, rental) dbRemoveTable dbSendQuery 17.1 (72) rs &lt;- dbSendQuery(con, SELECT * FROM mtcars WHERE cyl = 4) dbSendStatement The dbSendStatement() method only submits and synchronously executes the SQL data manipulation statement (e.g., UPDATE, DELETE, INSERT INTO, DROP TABLE, ) to the database engine. dbWriteTable 6.3.3 (04) dbWriteTable(con, mtcars, mtcars, overwrite = TRUE) "],
["chapter-appendix-additional-resources.html", "G Appendix Additional resources G.1 Editing this book G.2 Docker alternatives G.3 Docker and R G.4 Documentation for Docker and PostgreSQL G.5 SQL and dplyr G.6 More Resources", " G Appendix Additional resources G.1 Editing this book Here are instructions for editing this book G.2 Docker alternatives Choosing between Docker and Vagrant (Zait 2017) G.3 Docker and R Noam Ross talk on Docker for the UseR (Ross 2018b) and his Slides (Ross 2018a) give a lot of context and tips. Good Docker tutorials An introductory Docker tutorial (Srivastav 2018) A Docker curriculum (Hall 2018) Scott Cames materials about Docker and R on his website (Came 2018) and at the 2018 UseR Conference focus on R inside Docker. Its worth studying the ROpensci Docker tutorial (ROpenSciLabs 2018) G.4 Documentation for Docker and PostgreSQL The Postgres image documentation (Docker 2018d) PostgreSQL &amp; Docker documentation (Docker 2018d) Dockerize PostgreSQL (Docker 2018b) Usage examples of PostgreSQL with Docker WARNING-EXPIRED CERTIFICATE 2018-12-20 G.5 SQL and dplyr Why SQL is not for analysis but dplyr is (Nishida 2016) Data Manipulation with dplyr (With 50 Examples) (ListenData.com 2016) G.6 More Resources David Severski describes some key elements of connecting to databases with R for MacOS users (Severski 2018) This tutorial picks up ideas and tips from Ed Boraskys Data Science pet containers (Borasky 2018), which creates a framework based on that Hack Oregon example and explains why this repo is named pet-sql. References "],
["references.html", "References", " References "]
>>>>>>> master
]
