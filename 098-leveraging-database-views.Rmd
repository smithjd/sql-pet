# Leveraging Database Views {#chapter_leveraging-database-views}

> This chapter demonstrates how to:
>
>   * Assess database views, understand their importance
>   * Unpack a database view and check its assumptions
>   * Create a database view either for personal use or for submittal to your enterprise DBA


## Setup our standard working environment

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits = 10)
sleep_default <- 1
```

Use these libraries:
```{r libraries, message=FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(glue)
require(knitr)
library(dbplyr)
library(sqlpetr)
library(bookdown)
library(here)
library(lubridate)
library(skimr)
library(DiagrammeR)

library(scales) # ggplot xy scales
theme_set(theme_light())
```

Connect to `adventureworks`:
```{r, start adventureworks and connect}
sp_docker_start("adventureworks")
Sys.sleep(sleep_default)
con <- sp_get_postgres_connection(
  host = "localhost",
  port = 5432,
  user = "postgres",
  password = "postgres",
  dbname = "adventureworks",
  seconds_to_test = sleep_default, connection_tab = TRUE
)
```


## The role of database `views`

A database `view` is an SQL query that is stored in the database.  Most `views` are used for data retrieval, since they usually denormalize the tables involved.  Because they are standardized and well-understood, they can save you a lot of work.

### Why database `views` are useful

Database `views` are useful for many reasons.

  * **Authoritative**: database `views` are typically written by the business application vendor or DBA, so they contain authoritative knowledge about the structure and intended use of the database.
  * **Performance**: `views` are designed to gather data in an efficient way, using all the indexes in an efficient sequence and doing as much work on the database server as possible.
  * **Abstraction**: `views` are abstractions or simplifications of complex queries that provide customary (useful) aggregations.  Common examples would be monthly totals or aggregation of activity tied to one individual.
  * **Reuse**: a `view` puts commonly used code in one place where it can be used for many purposes by many people. If there is a change or a problem found in a `view`, it only needs to be fixed in one place, rather than having to change many places downstream.
  * **Security**: a view can give selective access to someone who does not have access to underlying tables or columns.
  * **Provenance**: `views` standardize data provenance.  For example, the `AdventureWorks` database all of them are named in a consistent way that suggests the underlying tables that they query.  And they all start with a **v**.

### Rely on **and** be critical of `views`

Because they represent a conventional view of the database, a `view` may seem quite boring; remember why they are very important. Just because they are conventional and authorized, they may still need verification or auditing when used for a purpose other than the original intent. They can guide you toward what you need from the database but they could also mislead because they are easy to use and available.  People may forget why a specific view exists and who is using it. Therefore any given view might be a forgotten vestige or part of a production data pipeline or a priceless nugget of insight. How can you tell? Consider the owner and schema, whether it's a materialized index view or not, if it has a trigger and try to deduce the intentionality behind the view.

### How to unpack and inspect a `view`

From a retrieval perspective a database `view` is just like any other table.  Using a view to retrieve data from the database will be completely standard across all flavors of SQL.  (To find out what a view does behind the scenes requires that you use functions that are **not** standard.)

```{r}
v_salesperson_sales_by_fiscal_years_data <- 
  tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>% 
  collect()

str(v_salesperson_sales_by_fiscal_years_data)

tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>% filter(salespersonid == 275)
```
Local idioms for looking at a view itself will vary.  Here is the code to retrieve a PostgreSQL view (using the `pg_get_viewdef` function):

```{r}
view_definition <- dbGetQuery(con, "select 
                   pg_get_viewdef('sales.vsalespersonsalesbyfiscalyearsdata', 
                   true)")

str(view_definition)

cat(str_replace_all(view_definition$pg_get_viewdef, "\\\\\\\\n", "\\\\n")) 
```

Even if you don't intend to become fluent in SQL, it's useful to read as much of it as possible.  

To understand this query, you really need to have the Entity Relationship Diagram (ERD) handy.  The ERD for `AdventureWorks` is [here](https://i.stack.imgur.com/LMu4W.gif)



## Reproduce the `view` with dplyr

Save and study the SQL.

It can be helpful to actually mark up the ERD to identify the specific tables that are involved in the view you are going to reproduce.
![](screenshots/AW-2008-OLTP-ERD.gif)

Define each table that is involved and identify the columns that will be needed from that table.  The tables that are involved are:

  1. employee
  2. person
  3. sales_person
  3. sales_order_header
  3. sales_territory

Select the columns and do any necessary changes or renaming.  In this case we follow the convention that any column that we change or create on the fly uses a snake case naming con vention.
```{r}

sales_order_header <- tbl(con, in_schema("sales", "salesorderheader")) %>% 
  # Because we're lazy, we will keep both a crude `year` column and `orderdate` for later use
  mutate(sales_order_year = year(orderdate)) %>% 
  select(sales_order_year, salespersonid, subtotal, orderdate) 

sales_territory <- tbl(con, in_schema("sales", "salesterritory")) %>% 
    select(territoryid, territory_name = name) 
  
sales_person <- tbl(con, in_schema("sales", "salesperson")) %>% 
  select(businessentityid, territoryid) 

employee <- tbl(con, in_schema("humanresources", "employee")) %>% 
  select(businessentityid, jobtitle)

person <- tbl(con, in_schema("person", "person")) %>% 
  mutate(full_name = paste(firstname, middlename, lastname)) %>% 
  select(businessentityid, full_name)

```

Double check on the names that are defined in each `tbl` object.  First define a function to show the names of columns you will retrieve.

```{r}
getnames <- function(table) {
  {table} %>% collect(n = 5) %>% names()
}
```

Verify the names selected:
```{r}
getnames(employee)
getnames(person)
getnames(sales_person)
getnames(sales_order_header)
getnames(sales_territory)

```

Join all of the data pertaining to a person.

```{r}
salesperson_info <- sales_person %>% 
  left_join(employee) %>% 
  left_join(person) %>% 
  left_join(sales_territory) %>%
  collect()

str(salesperson_info)
```

Do a crude version with `sales_order_year`.  All of the work can be done on the database server.

```{r}
sales_data_year <- sales_person %>% 
  left_join(sales_order_header, by = c("businessentityid" = "salespersonid")) %>% 
  group_by(businessentityid, sales_order_year) %>% 
  summarize(sales_total = sum(subtotal, na.rm = TRUE))  %>%
  collect()
  
```

Lubridate makes it very easy to convert `orderdate` to `fiscal_year`.  Doing that conversion interleaving dplyr and **ANSI-STANDARD** SQL is harder.  Too lazy!  Therefore we just pull the data from the server after the `left_join` and do the rest of the job on the R side.

```{r}
sales_data_fiscal_year <- sales_person %>% 
  left_join(sales_order_header, by = c("businessentityid" = "salespersonid")) %>% 
  collect() %>% 
  mutate(fiscal_year = year(orderdate %m+% months(6))) %>% 
  group_by(businessentityid, fiscal_year) %>%
  summarize(sales_total = sum(subtotal, na.rm = TRUE)) %>% 
  ungroup()
  
```

Put the two parts together: `sales_data_fiscal_year` and `person_info` to yeild the final query.

```{r}
salesperson_sales_by_fiscal_years_dplyr <- sales_data_fiscal_year %>% 
  left_join(salesperson_info) %>% 
  filter(!is.na(territoryid))
```
 Notice that we're droping the Sales Managers -- who don't have a `territoryid`.

### Compare the two versions

Use `pivot_wider` to make it easier to compare the native view to our dplyr version.

```{r}
salesperson_sales_by_fiscal_years_dplyr %>% 
  select(-jobtitle, - territoryid) %>% 
  pivot_wider(names_from = fiscal_year, values_from = sales_total)

v_salesperson_sales_by_fiscal_years_data %>% 
  select(-jobtitle) %>%
  pivot_wider(names_from = fiscalyear, values_from = salestotal)
```

The column names don't match up, partly because we are using snake case convention for derived elements.

```{r}
names(salesperson_sales_by_fiscal_years_dplyr) %>% sort()
names(v_salesperson_sales_by_fiscal_years_data) %>% sort()
```

Why 3 sales folks in vsalesperson donâ€™t show up in 2014 vsalespersonsalesbyfiscalyearsdata

Different environments / SQL dialects

### Revise the view

  * What about by month? This could be motivation for creating a new view that does aggregation in the database, rather than in R.
  * See SQL code for 'vsalespersonsalesbyfiscalyearsdata'. Consider:
  * Modifying that to include quantity of sales.
  * Modifying that to include monthly totals, in addition to the yearly totals that it already has.
  * Why are 3 of the sales people from 'vsalesperson' missing in 'vsalespersonsalesbyfiscalyearsdata'?
     * Amy Alberts
     * Stephen Jiang
     * Syed Abbas
  * Making the change may not be your prerogative, but it's your responsibility to propose any reasonable changes to those who have the authority to make the make the change.



## Save a `view` in the database

