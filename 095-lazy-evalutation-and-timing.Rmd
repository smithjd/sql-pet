# Lazy Evaluation and Execution Environment {#chapter_lazy-evaluation-and-timing}

> This chapter:
> 
> * Builds on the lazy loading discussion in the previous chapter
> * Demonstrates how the use of the `dplyr::collect()` creates a boundary between code that is sent to a dbms and code that is executed locally

## Setup

The following packages are used in this chapter:
```{r chapter package list, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(DBI)
library(RPostgres)
library(dbplyr)
require(knitr)
library(bookdown)
library(sqlpetr)
```
If you have not yet set up the Docker container with PostgreSQL and the dvdrental database, go back to [those instructions][Build the pet-sql Docker Image] to configure your environment. Otherwise, start your `sql-pet` container:
```{r check on sql-pet}
sqlpetr::sp_docker_start("sql-pet")
```
Connect to the database:
```{r connect to postgresql}
con <- sqlpetr::sp_get_postgres_connection(
  user = Sys.getenv("DEFAULT_POSTGRES_USER_NAME"),
  password = Sys.getenv("DEFAULT_POSTGRES_PASSWORD"),
  dbname = "dvdrental",
  seconds_to_test = 30, connection_tab = TRUE
)
```
Define two tables to use in a simple query to use in the following discussion.
```{r connect to two tables}
rental_table <- dplyr::tbl(con, "rental")
customer_table <- dplyr::tbl(con, "customer")
```

Here is a simple string of `dplyr` verbs similar to the query used to illustrate issues in the last chapter:

```{r create simple join}
Q <- rental_table %>%
  dplyr::left_join(customer_table, by = c("customer_id" = "customer_id")) %>%
  dplyr::select(rental_date, email)

Q
```
Note that in the previous example we follow this book's convention of creating a connection object to each table and fully qualifying function names (e.g., specifying the package).  In practice, it's possible and convenient to use more abbreviated notation.
```{r simplify the simpe join}
Q <- tbl(con, "rental") %>%
  left_join(tbl(con, "customer"), by = c("customer_id" = "customer_id")) %>%
  select(rental_date, email)

Q
```

### Experiment overview
Think of `Q` as a black box for the moment.  The following examples will show how `Q` is interpreted differently by different functions. It's important to remember in the following discussion that the "**and then**" operator (`%>%`) actually wraps the subsequent code inside the preceding code so that `Q %>% print()` is equivalent to `print(Q)`.

**Notation**

> |Symbol|Explanation
> |----|-------------
> | ![](screenshots/green-check.png)| A single green check indicates that some rows are returned. <br>
> | ![](screenshots/green-check.png) ![](screenshots/green-check.png)| Two green checks indicate that all the rows are returned.
> | ![](screenshots/red-x.png) |The red X indicates that no rows are returned.
>


> R code | Result 
> -------| --------------
> **Time-based, execution environment issues** | 
> [`Qc <- Q %>% count(email, sort = TRUE)`](#lazy_q_build) | ![](screenshots/red-x.png) **Extends** the lazy query object
> 
> 

The next chapter will discuss how to build queries and how to explore intermediate steps. But first, the following subsections provide a more detailed discussion of each row in the preceding table.

### Time-based, execution environment issues

Remember that if the expression is assigned to an object, it is not executed.  If an expression is entered on the command line or appears in your script by itself, a `print()` function is implied. 

> *These two are different:*
> Q %>% count(email) 
> Q_query <- Q %>% count(email) 
>

This behavior is the basis of a useful debugging and development process where queries are built up incrementally.

### Q %>% `more dplyr` {#lazy_q_build}

![](screenshots/green-check.png) Because the following statement implies a `print()` function at the end, we can run it repeatedly, adding dplyr expressions, and only get 10 rows back.  Every time we add a dplyr expression to a chain, R will rewrite the SQL code.  For example:
```{r one more dplyr}
Q %>% count(email) 
```
As we understand more about the data, we simply add dplyr expressions to pinpoint what we are looking for:
```{r three more dplyr}
Q %>% count(email) %>% 
  filter(n > 40) %>% 
  arrange(email)
```

![](screenshots/green-check.png) When all the accumulated `dplyr` verbs are executed, they are submitted to the dbms and the number of rows that are returned follow the same rules as discussed above.
### Interspersing SQL and dplyr

```{r date in both}
rental_table %>% 
  mutate(rental_date = date(rental_date)) %>% 
  show_query()

rental_table %>% 
  mutate(rental_date = date(rental_date))

try(rental_table %>% 
  mutate(rental_date = lubridate::date(rental_date))
)

rental_table %>% collect() %>% 
  mutate(rental_date = lubridate::date(rental_date)) 

```


```{r}
to_char <- function(date, fmt) {return(fmt)}

rental_table %>% 
  mutate(rental_date = to_char(rental_date, "YYYY-MM")) %>% 
  show_query()

rental_table %>% 
  mutate(rental_date = to_char(rental_date, "YYYY-MM")) 
```


### Many handy R functions can't be translated to SQL

![](screenshots/green-check.png) It just so happens that PostgreSQL has a `date` function that does the same thing as the `date` function in the `lubridate` package.  In the following code the `date` function is executed by PostreSQL.
```{r postgresql homonym}
rental_table %>% mutate(rental_date = date(rental_date))
```
![](screenshots/green-check.png) ![](screenshots/green-check.png) If we specify that we want to use the `lubridate` version (or any number of other R functions) they are passed to the dbms unless we explicitly tell `dplyr` to stop translating and bring the results back to the R environment for local processing.
```{r collect as delimiter}
try(rental_table %>% collect() %>% 
  mutate(rental_date = lubridate::date(rental_date)))
```

### Further lazy execution examples

See more examples of lazy execution [here](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html).

```{r}
DBI::dbDisconnect(con)
sqlpetr::sp_docker_stop("sql-pet")
```


## Other resources

* Benjamin S. Baumer. 2017. A Grammar for Reproducible and Painless Extract-Transform-Load Operations on Medium Data. [https://arxiv.org/abs/1708.07073](https://arxiv.org/abs/1708.07073) 
* dplyr Reference documentation: Remote tables. [https://dplyr.tidyverse.org/reference/index.html#section-remote-tables](https://dplyr.tidyverse.org/reference/index.html#section-remote-tables)
* Data Carpentry. SQL Databases and R. [https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html](https://datacarpentry.org/R-ecology-lesson/05-r-and-databases.html)
